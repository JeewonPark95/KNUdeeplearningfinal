{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vggdropout_epoch250.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM886HnVB4s5lprjIcd5hTi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeewonPark95/KNUdeeplearningfinal/blob/main/vggdropout_epoch250.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLAxLnRsEvAb",
        "outputId": "2d377bb4-e586-4355-ff39-60f3cb5a2a9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "USE 1 GPUs!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "# TEST : Loss: (0.3781) | Acc: (91.66%) (9166/10000)\n",
            "Epoch: 131 | Batch_idx: 0 |  Loss: (0.0156) | Acc: (98.44%) (126/128)\n",
            "Epoch: 131 | Batch_idx: 10 |  Loss: (0.0158) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 131 | Batch_idx: 20 |  Loss: (0.0178) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 131 | Batch_idx: 30 |  Loss: (0.0193) | Acc: (99.34%) (3942/3968)\n",
            "Epoch: 131 | Batch_idx: 40 |  Loss: (0.0193) | Acc: (99.33%) (5213/5248)\n",
            "Epoch: 131 | Batch_idx: 50 |  Loss: (0.0186) | Acc: (99.31%) (6483/6528)\n",
            "Epoch: 131 | Batch_idx: 60 |  Loss: (0.0198) | Acc: (99.30%) (7753/7808)\n",
            "Epoch: 131 | Batch_idx: 70 |  Loss: (0.0195) | Acc: (99.34%) (9028/9088)\n",
            "Epoch: 131 | Batch_idx: 80 |  Loss: (0.0202) | Acc: (99.35%) (10301/10368)\n",
            "Epoch: 131 | Batch_idx: 90 |  Loss: (0.0202) | Acc: (99.37%) (11575/11648)\n",
            "Epoch: 131 | Batch_idx: 100 |  Loss: (0.0208) | Acc: (99.33%) (12842/12928)\n",
            "Epoch: 131 | Batch_idx: 110 |  Loss: (0.0216) | Acc: (99.35%) (14115/14208)\n",
            "Epoch: 131 | Batch_idx: 120 |  Loss: (0.0208) | Acc: (99.37%) (15391/15488)\n",
            "Epoch: 131 | Batch_idx: 130 |  Loss: (0.0202) | Acc: (99.38%) (16664/16768)\n",
            "Epoch: 131 | Batch_idx: 140 |  Loss: (0.0207) | Acc: (99.34%) (17929/18048)\n",
            "Epoch: 131 | Batch_idx: 150 |  Loss: (0.0218) | Acc: (99.31%) (19194/19328)\n",
            "Epoch: 131 | Batch_idx: 160 |  Loss: (0.0219) | Acc: (99.32%) (20468/20608)\n",
            "Epoch: 131 | Batch_idx: 170 |  Loss: (0.0218) | Acc: (99.31%) (21737/21888)\n",
            "Epoch: 131 | Batch_idx: 180 |  Loss: (0.0218) | Acc: (99.30%) (23006/23168)\n",
            "Epoch: 131 | Batch_idx: 190 |  Loss: (0.0220) | Acc: (99.29%) (24274/24448)\n",
            "Epoch: 131 | Batch_idx: 200 |  Loss: (0.0219) | Acc: (99.28%) (25544/25728)\n",
            "Epoch: 131 | Batch_idx: 210 |  Loss: (0.0219) | Acc: (99.29%) (26815/27008)\n",
            "Epoch: 131 | Batch_idx: 220 |  Loss: (0.0217) | Acc: (99.29%) (28086/28288)\n",
            "Epoch: 131 | Batch_idx: 230 |  Loss: (0.0217) | Acc: (99.29%) (29357/29568)\n",
            "Epoch: 131 | Batch_idx: 240 |  Loss: (0.0220) | Acc: (99.28%) (30625/30848)\n",
            "Epoch: 131 | Batch_idx: 250 |  Loss: (0.0219) | Acc: (99.27%) (31895/32128)\n",
            "Epoch: 131 | Batch_idx: 260 |  Loss: (0.0219) | Acc: (99.28%) (33167/33408)\n",
            "Epoch: 131 | Batch_idx: 270 |  Loss: (0.0218) | Acc: (99.27%) (34436/34688)\n",
            "Epoch: 131 | Batch_idx: 280 |  Loss: (0.0218) | Acc: (99.27%) (35704/35968)\n",
            "Epoch: 131 | Batch_idx: 290 |  Loss: (0.0216) | Acc: (99.27%) (36977/37248)\n",
            "Epoch: 131 | Batch_idx: 300 |  Loss: (0.0215) | Acc: (99.28%) (38251/38528)\n",
            "Epoch: 131 | Batch_idx: 310 |  Loss: (0.0213) | Acc: (99.29%) (39524/39808)\n",
            "Epoch: 131 | Batch_idx: 320 |  Loss: (0.0211) | Acc: (99.29%) (40797/41088)\n",
            "Epoch: 131 | Batch_idx: 330 |  Loss: (0.0210) | Acc: (99.29%) (42067/42368)\n",
            "Epoch: 131 | Batch_idx: 340 |  Loss: (0.0213) | Acc: (99.28%) (43334/43648)\n",
            "Epoch: 131 | Batch_idx: 350 |  Loss: (0.0215) | Acc: (99.27%) (44602/44928)\n",
            "Epoch: 131 | Batch_idx: 360 |  Loss: (0.0214) | Acc: (99.27%) (45870/46208)\n",
            "Epoch: 131 | Batch_idx: 370 |  Loss: (0.0215) | Acc: (99.27%) (47139/47488)\n",
            "Epoch: 131 | Batch_idx: 380 |  Loss: (0.0218) | Acc: (99.26%) (48407/48768)\n",
            "Epoch: 131 | Batch_idx: 390 |  Loss: (0.0218) | Acc: (99.26%) (49628/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3755) | Acc: (91.61%) (9161/10000)\n",
            "Epoch: 132 | Batch_idx: 0 |  Loss: (0.0092) | Acc: (100.00%) (128/128)\n",
            "Epoch: 132 | Batch_idx: 10 |  Loss: (0.0138) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 132 | Batch_idx: 20 |  Loss: (0.0197) | Acc: (99.37%) (2671/2688)\n",
            "Epoch: 132 | Batch_idx: 30 |  Loss: (0.0247) | Acc: (99.19%) (3936/3968)\n",
            "Epoch: 132 | Batch_idx: 40 |  Loss: (0.0224) | Acc: (99.28%) (5210/5248)\n",
            "Epoch: 132 | Batch_idx: 50 |  Loss: (0.0228) | Acc: (99.25%) (6479/6528)\n",
            "Epoch: 132 | Batch_idx: 60 |  Loss: (0.0235) | Acc: (99.23%) (7748/7808)\n",
            "Epoch: 132 | Batch_idx: 70 |  Loss: (0.0232) | Acc: (99.26%) (9021/9088)\n",
            "Epoch: 132 | Batch_idx: 80 |  Loss: (0.0240) | Acc: (99.26%) (10291/10368)\n",
            "Epoch: 132 | Batch_idx: 90 |  Loss: (0.0242) | Acc: (99.27%) (11563/11648)\n",
            "Epoch: 132 | Batch_idx: 100 |  Loss: (0.0238) | Acc: (99.30%) (12837/12928)\n",
            "Epoch: 132 | Batch_idx: 110 |  Loss: (0.0236) | Acc: (99.30%) (14108/14208)\n",
            "Epoch: 132 | Batch_idx: 120 |  Loss: (0.0233) | Acc: (99.30%) (15379/15488)\n",
            "Epoch: 132 | Batch_idx: 130 |  Loss: (0.0229) | Acc: (99.30%) (16651/16768)\n",
            "Epoch: 132 | Batch_idx: 140 |  Loss: (0.0226) | Acc: (99.31%) (17923/18048)\n",
            "Epoch: 132 | Batch_idx: 150 |  Loss: (0.0227) | Acc: (99.30%) (19192/19328)\n",
            "Epoch: 132 | Batch_idx: 160 |  Loss: (0.0227) | Acc: (99.28%) (20460/20608)\n",
            "Epoch: 132 | Batch_idx: 170 |  Loss: (0.0221) | Acc: (99.29%) (21733/21888)\n",
            "Epoch: 132 | Batch_idx: 180 |  Loss: (0.0223) | Acc: (99.29%) (23003/23168)\n",
            "Epoch: 132 | Batch_idx: 190 |  Loss: (0.0224) | Acc: (99.29%) (24275/24448)\n",
            "Epoch: 132 | Batch_idx: 200 |  Loss: (0.0223) | Acc: (99.30%) (25547/25728)\n",
            "Epoch: 132 | Batch_idx: 210 |  Loss: (0.0227) | Acc: (99.28%) (26813/27008)\n",
            "Epoch: 132 | Batch_idx: 220 |  Loss: (0.0228) | Acc: (99.28%) (28083/28288)\n",
            "Epoch: 132 | Batch_idx: 230 |  Loss: (0.0229) | Acc: (99.26%) (29350/29568)\n",
            "Epoch: 132 | Batch_idx: 240 |  Loss: (0.0230) | Acc: (99.25%) (30617/30848)\n",
            "Epoch: 132 | Batch_idx: 250 |  Loss: (0.0227) | Acc: (99.26%) (31890/32128)\n",
            "Epoch: 132 | Batch_idx: 260 |  Loss: (0.0225) | Acc: (99.26%) (33161/33408)\n",
            "Epoch: 132 | Batch_idx: 270 |  Loss: (0.0223) | Acc: (99.27%) (34434/34688)\n",
            "Epoch: 132 | Batch_idx: 280 |  Loss: (0.0220) | Acc: (99.27%) (35707/35968)\n",
            "Epoch: 132 | Batch_idx: 290 |  Loss: (0.0219) | Acc: (99.28%) (36978/37248)\n",
            "Epoch: 132 | Batch_idx: 300 |  Loss: (0.0219) | Acc: (99.27%) (38248/38528)\n",
            "Epoch: 132 | Batch_idx: 310 |  Loss: (0.0218) | Acc: (99.28%) (39521/39808)\n",
            "Epoch: 132 | Batch_idx: 320 |  Loss: (0.0216) | Acc: (99.29%) (40796/41088)\n",
            "Epoch: 132 | Batch_idx: 330 |  Loss: (0.0216) | Acc: (99.29%) (42068/42368)\n",
            "Epoch: 132 | Batch_idx: 340 |  Loss: (0.0216) | Acc: (99.29%) (43338/43648)\n",
            "Epoch: 132 | Batch_idx: 350 |  Loss: (0.0215) | Acc: (99.29%) (44608/44928)\n",
            "Epoch: 132 | Batch_idx: 360 |  Loss: (0.0215) | Acc: (99.29%) (45879/46208)\n",
            "Epoch: 132 | Batch_idx: 370 |  Loss: (0.0213) | Acc: (99.30%) (47154/47488)\n",
            "Epoch: 132 | Batch_idx: 380 |  Loss: (0.0214) | Acc: (99.29%) (48423/48768)\n",
            "Epoch: 132 | Batch_idx: 390 |  Loss: (0.0215) | Acc: (99.29%) (49643/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3772) | Acc: (91.65%) (9165/10000)\n",
            "Epoch: 133 | Batch_idx: 0 |  Loss: (0.0228) | Acc: (98.44%) (126/128)\n",
            "Epoch: 133 | Batch_idx: 10 |  Loss: (0.0205) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 133 | Batch_idx: 20 |  Loss: (0.0214) | Acc: (99.33%) (2670/2688)\n",
            "Epoch: 133 | Batch_idx: 30 |  Loss: (0.0244) | Acc: (99.22%) (3937/3968)\n",
            "Epoch: 133 | Batch_idx: 40 |  Loss: (0.0247) | Acc: (99.22%) (5207/5248)\n",
            "Epoch: 133 | Batch_idx: 50 |  Loss: (0.0221) | Acc: (99.30%) (6482/6528)\n",
            "Epoch: 133 | Batch_idx: 60 |  Loss: (0.0233) | Acc: (99.23%) (7748/7808)\n",
            "Epoch: 133 | Batch_idx: 70 |  Loss: (0.0223) | Acc: (99.27%) (9022/9088)\n",
            "Epoch: 133 | Batch_idx: 80 |  Loss: (0.0218) | Acc: (99.32%) (10298/10368)\n",
            "Epoch: 133 | Batch_idx: 90 |  Loss: (0.0210) | Acc: (99.35%) (11572/11648)\n",
            "Epoch: 133 | Batch_idx: 100 |  Loss: (0.0208) | Acc: (99.34%) (12843/12928)\n",
            "Epoch: 133 | Batch_idx: 110 |  Loss: (0.0202) | Acc: (99.37%) (14118/14208)\n",
            "Epoch: 133 | Batch_idx: 120 |  Loss: (0.0205) | Acc: (99.35%) (15388/15488)\n",
            "Epoch: 133 | Batch_idx: 130 |  Loss: (0.0204) | Acc: (99.35%) (16659/16768)\n",
            "Epoch: 133 | Batch_idx: 140 |  Loss: (0.0205) | Acc: (99.36%) (17933/18048)\n",
            "Epoch: 133 | Batch_idx: 150 |  Loss: (0.0207) | Acc: (99.36%) (19205/19328)\n",
            "Epoch: 133 | Batch_idx: 160 |  Loss: (0.0206) | Acc: (99.37%) (20479/20608)\n",
            "Epoch: 133 | Batch_idx: 170 |  Loss: (0.0205) | Acc: (99.37%) (21750/21888)\n",
            "Epoch: 133 | Batch_idx: 180 |  Loss: (0.0204) | Acc: (99.37%) (23022/23168)\n",
            "Epoch: 133 | Batch_idx: 190 |  Loss: (0.0209) | Acc: (99.37%) (24293/24448)\n",
            "Epoch: 133 | Batch_idx: 200 |  Loss: (0.0212) | Acc: (99.36%) (25563/25728)\n",
            "Epoch: 133 | Batch_idx: 210 |  Loss: (0.0208) | Acc: (99.37%) (26839/27008)\n",
            "Epoch: 133 | Batch_idx: 220 |  Loss: (0.0206) | Acc: (99.37%) (28111/28288)\n",
            "Epoch: 133 | Batch_idx: 230 |  Loss: (0.0208) | Acc: (99.37%) (29381/29568)\n",
            "Epoch: 133 | Batch_idx: 240 |  Loss: (0.0207) | Acc: (99.36%) (30651/30848)\n",
            "Epoch: 133 | Batch_idx: 250 |  Loss: (0.0207) | Acc: (99.35%) (31920/32128)\n",
            "Epoch: 133 | Batch_idx: 260 |  Loss: (0.0206) | Acc: (99.36%) (33193/33408)\n",
            "Epoch: 133 | Batch_idx: 270 |  Loss: (0.0206) | Acc: (99.35%) (34463/34688)\n",
            "Epoch: 133 | Batch_idx: 280 |  Loss: (0.0207) | Acc: (99.35%) (35733/35968)\n",
            "Epoch: 133 | Batch_idx: 290 |  Loss: (0.0210) | Acc: (99.34%) (37002/37248)\n",
            "Epoch: 133 | Batch_idx: 300 |  Loss: (0.0205) | Acc: (99.36%) (38280/38528)\n",
            "Epoch: 133 | Batch_idx: 310 |  Loss: (0.0203) | Acc: (99.36%) (39554/39808)\n",
            "Epoch: 133 | Batch_idx: 320 |  Loss: (0.0203) | Acc: (99.36%) (40824/41088)\n",
            "Epoch: 133 | Batch_idx: 330 |  Loss: (0.0203) | Acc: (99.35%) (42094/42368)\n",
            "Epoch: 133 | Batch_idx: 340 |  Loss: (0.0202) | Acc: (99.35%) (43366/43648)\n",
            "Epoch: 133 | Batch_idx: 350 |  Loss: (0.0201) | Acc: (99.35%) (44637/44928)\n",
            "Epoch: 133 | Batch_idx: 360 |  Loss: (0.0202) | Acc: (99.35%) (45906/46208)\n",
            "Epoch: 133 | Batch_idx: 370 |  Loss: (0.0202) | Acc: (99.35%) (47177/47488)\n",
            "Epoch: 133 | Batch_idx: 380 |  Loss: (0.0203) | Acc: (99.34%) (48447/48768)\n",
            "Epoch: 133 | Batch_idx: 390 |  Loss: (0.0205) | Acc: (99.34%) (49672/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3775) | Acc: (91.86%) (9186/10000)\n",
            "Epoch: 134 | Batch_idx: 0 |  Loss: (0.0258) | Acc: (99.22%) (127/128)\n",
            "Epoch: 134 | Batch_idx: 10 |  Loss: (0.0217) | Acc: (99.15%) (1396/1408)\n",
            "Epoch: 134 | Batch_idx: 20 |  Loss: (0.0197) | Acc: (99.26%) (2668/2688)\n",
            "Epoch: 134 | Batch_idx: 30 |  Loss: (0.0201) | Acc: (99.27%) (3939/3968)\n",
            "Epoch: 134 | Batch_idx: 40 |  Loss: (0.0196) | Acc: (99.35%) (5214/5248)\n",
            "Epoch: 134 | Batch_idx: 50 |  Loss: (0.0196) | Acc: (99.36%) (6486/6528)\n",
            "Epoch: 134 | Batch_idx: 60 |  Loss: (0.0197) | Acc: (99.36%) (7758/7808)\n",
            "Epoch: 134 | Batch_idx: 70 |  Loss: (0.0207) | Acc: (99.33%) (9027/9088)\n",
            "Epoch: 134 | Batch_idx: 80 |  Loss: (0.0203) | Acc: (99.32%) (10298/10368)\n",
            "Epoch: 134 | Batch_idx: 90 |  Loss: (0.0204) | Acc: (99.32%) (11569/11648)\n",
            "Epoch: 134 | Batch_idx: 100 |  Loss: (0.0202) | Acc: (99.32%) (12840/12928)\n",
            "Epoch: 134 | Batch_idx: 110 |  Loss: (0.0195) | Acc: (99.34%) (14114/14208)\n",
            "Epoch: 134 | Batch_idx: 120 |  Loss: (0.0196) | Acc: (99.32%) (15382/15488)\n",
            "Epoch: 134 | Batch_idx: 130 |  Loss: (0.0195) | Acc: (99.31%) (16653/16768)\n",
            "Epoch: 134 | Batch_idx: 140 |  Loss: (0.0196) | Acc: (99.32%) (17925/18048)\n",
            "Epoch: 134 | Batch_idx: 150 |  Loss: (0.0196) | Acc: (99.32%) (19196/19328)\n",
            "Epoch: 134 | Batch_idx: 160 |  Loss: (0.0193) | Acc: (99.33%) (20469/20608)\n",
            "Epoch: 134 | Batch_idx: 170 |  Loss: (0.0191) | Acc: (99.34%) (21743/21888)\n",
            "Epoch: 134 | Batch_idx: 180 |  Loss: (0.0193) | Acc: (99.33%) (23013/23168)\n",
            "Epoch: 134 | Batch_idx: 190 |  Loss: (0.0189) | Acc: (99.34%) (24287/24448)\n",
            "Epoch: 134 | Batch_idx: 200 |  Loss: (0.0190) | Acc: (99.34%) (25559/25728)\n",
            "Epoch: 134 | Batch_idx: 210 |  Loss: (0.0189) | Acc: (99.35%) (26832/27008)\n",
            "Epoch: 134 | Batch_idx: 220 |  Loss: (0.0187) | Acc: (99.35%) (28103/28288)\n",
            "Epoch: 134 | Batch_idx: 230 |  Loss: (0.0185) | Acc: (99.36%) (29378/29568)\n",
            "Epoch: 134 | Batch_idx: 240 |  Loss: (0.0185) | Acc: (99.36%) (30652/30848)\n",
            "Epoch: 134 | Batch_idx: 250 |  Loss: (0.0186) | Acc: (99.35%) (31919/32128)\n",
            "Epoch: 134 | Batch_idx: 260 |  Loss: (0.0189) | Acc: (99.34%) (33186/33408)\n",
            "Epoch: 134 | Batch_idx: 270 |  Loss: (0.0191) | Acc: (99.33%) (34456/34688)\n",
            "Epoch: 134 | Batch_idx: 280 |  Loss: (0.0196) | Acc: (99.32%) (35725/35968)\n",
            "Epoch: 134 | Batch_idx: 290 |  Loss: (0.0200) | Acc: (99.31%) (36992/37248)\n",
            "Epoch: 134 | Batch_idx: 300 |  Loss: (0.0201) | Acc: (99.31%) (38263/38528)\n",
            "Epoch: 134 | Batch_idx: 310 |  Loss: (0.0198) | Acc: (99.33%) (39540/39808)\n",
            "Epoch: 134 | Batch_idx: 320 |  Loss: (0.0196) | Acc: (99.33%) (40813/41088)\n",
            "Epoch: 134 | Batch_idx: 330 |  Loss: (0.0199) | Acc: (99.32%) (42079/42368)\n",
            "Epoch: 134 | Batch_idx: 340 |  Loss: (0.0197) | Acc: (99.32%) (43353/43648)\n",
            "Epoch: 134 | Batch_idx: 350 |  Loss: (0.0196) | Acc: (99.33%) (44627/44928)\n",
            "Epoch: 134 | Batch_idx: 360 |  Loss: (0.0194) | Acc: (99.33%) (45900/46208)\n",
            "Epoch: 134 | Batch_idx: 370 |  Loss: (0.0195) | Acc: (99.34%) (47173/47488)\n",
            "Epoch: 134 | Batch_idx: 380 |  Loss: (0.0193) | Acc: (99.35%) (48449/48768)\n",
            "Epoch: 134 | Batch_idx: 390 |  Loss: (0.0195) | Acc: (99.34%) (49670/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3759) | Acc: (91.56%) (9156/10000)\n",
            "Epoch: 135 | Batch_idx: 0 |  Loss: (0.0174) | Acc: (99.22%) (127/128)\n",
            "Epoch: 135 | Batch_idx: 10 |  Loss: (0.0245) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 135 | Batch_idx: 20 |  Loss: (0.0204) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 135 | Batch_idx: 30 |  Loss: (0.0187) | Acc: (99.47%) (3947/3968)\n",
            "Epoch: 135 | Batch_idx: 40 |  Loss: (0.0174) | Acc: (99.49%) (5221/5248)\n",
            "Epoch: 135 | Batch_idx: 50 |  Loss: (0.0173) | Acc: (99.45%) (6492/6528)\n",
            "Epoch: 135 | Batch_idx: 60 |  Loss: (0.0190) | Acc: (99.40%) (7761/7808)\n",
            "Epoch: 135 | Batch_idx: 70 |  Loss: (0.0191) | Acc: (99.41%) (9034/9088)\n",
            "Epoch: 135 | Batch_idx: 80 |  Loss: (0.0185) | Acc: (99.39%) (10305/10368)\n",
            "Epoch: 135 | Batch_idx: 90 |  Loss: (0.0184) | Acc: (99.37%) (11575/11648)\n",
            "Epoch: 135 | Batch_idx: 100 |  Loss: (0.0181) | Acc: (99.39%) (12849/12928)\n",
            "Epoch: 135 | Batch_idx: 110 |  Loss: (0.0176) | Acc: (99.41%) (14124/14208)\n",
            "Epoch: 135 | Batch_idx: 120 |  Loss: (0.0175) | Acc: (99.39%) (15394/15488)\n",
            "Epoch: 135 | Batch_idx: 130 |  Loss: (0.0175) | Acc: (99.40%) (16667/16768)\n",
            "Epoch: 135 | Batch_idx: 140 |  Loss: (0.0173) | Acc: (99.41%) (17941/18048)\n",
            "Epoch: 135 | Batch_idx: 150 |  Loss: (0.0175) | Acc: (99.41%) (19213/19328)\n",
            "Epoch: 135 | Batch_idx: 160 |  Loss: (0.0175) | Acc: (99.41%) (20486/20608)\n",
            "Epoch: 135 | Batch_idx: 170 |  Loss: (0.0172) | Acc: (99.41%) (21759/21888)\n",
            "Epoch: 135 | Batch_idx: 180 |  Loss: (0.0180) | Acc: (99.39%) (23026/23168)\n",
            "Epoch: 135 | Batch_idx: 190 |  Loss: (0.0185) | Acc: (99.37%) (24295/24448)\n",
            "Epoch: 135 | Batch_idx: 200 |  Loss: (0.0192) | Acc: (99.35%) (25562/25728)\n",
            "Epoch: 135 | Batch_idx: 210 |  Loss: (0.0195) | Acc: (99.34%) (26831/27008)\n",
            "Epoch: 135 | Batch_idx: 220 |  Loss: (0.0193) | Acc: (99.35%) (28105/28288)\n",
            "Epoch: 135 | Batch_idx: 230 |  Loss: (0.0189) | Acc: (99.37%) (29381/29568)\n",
            "Epoch: 135 | Batch_idx: 240 |  Loss: (0.0190) | Acc: (99.36%) (30651/30848)\n",
            "Epoch: 135 | Batch_idx: 250 |  Loss: (0.0189) | Acc: (99.36%) (31923/32128)\n",
            "Epoch: 135 | Batch_idx: 260 |  Loss: (0.0186) | Acc: (99.37%) (33196/33408)\n",
            "Epoch: 135 | Batch_idx: 270 |  Loss: (0.0188) | Acc: (99.36%) (34466/34688)\n",
            "Epoch: 135 | Batch_idx: 280 |  Loss: (0.0189) | Acc: (99.36%) (35738/35968)\n",
            "Epoch: 135 | Batch_idx: 290 |  Loss: (0.0187) | Acc: (99.36%) (37010/37248)\n",
            "Epoch: 135 | Batch_idx: 300 |  Loss: (0.0186) | Acc: (99.37%) (38284/38528)\n",
            "Epoch: 135 | Batch_idx: 310 |  Loss: (0.0186) | Acc: (99.37%) (39559/39808)\n",
            "Epoch: 135 | Batch_idx: 320 |  Loss: (0.0186) | Acc: (99.37%) (40831/41088)\n",
            "Epoch: 135 | Batch_idx: 330 |  Loss: (0.0187) | Acc: (99.37%) (42101/42368)\n",
            "Epoch: 135 | Batch_idx: 340 |  Loss: (0.0187) | Acc: (99.37%) (43374/43648)\n",
            "Epoch: 135 | Batch_idx: 350 |  Loss: (0.0187) | Acc: (99.37%) (44646/44928)\n",
            "Epoch: 135 | Batch_idx: 360 |  Loss: (0.0186) | Acc: (99.38%) (45921/46208)\n",
            "Epoch: 135 | Batch_idx: 370 |  Loss: (0.0186) | Acc: (99.37%) (47191/47488)\n",
            "Epoch: 135 | Batch_idx: 380 |  Loss: (0.0187) | Acc: (99.37%) (48462/48768)\n",
            "Epoch: 135 | Batch_idx: 390 |  Loss: (0.0185) | Acc: (99.38%) (49690/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3792) | Acc: (91.64%) (9164/10000)\n",
            "Epoch: 136 | Batch_idx: 0 |  Loss: (0.0029) | Acc: (100.00%) (128/128)\n",
            "Epoch: 136 | Batch_idx: 10 |  Loss: (0.0165) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 136 | Batch_idx: 20 |  Loss: (0.0149) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 136 | Batch_idx: 30 |  Loss: (0.0180) | Acc: (99.42%) (3945/3968)\n",
            "Epoch: 136 | Batch_idx: 40 |  Loss: (0.0174) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 136 | Batch_idx: 50 |  Loss: (0.0163) | Acc: (99.46%) (6493/6528)\n",
            "Epoch: 136 | Batch_idx: 60 |  Loss: (0.0164) | Acc: (99.45%) (7765/7808)\n",
            "Epoch: 136 | Batch_idx: 70 |  Loss: (0.0160) | Acc: (99.48%) (9041/9088)\n",
            "Epoch: 136 | Batch_idx: 80 |  Loss: (0.0157) | Acc: (99.50%) (10316/10368)\n",
            "Epoch: 136 | Batch_idx: 90 |  Loss: (0.0154) | Acc: (99.51%) (11591/11648)\n",
            "Epoch: 136 | Batch_idx: 100 |  Loss: (0.0156) | Acc: (99.48%) (12861/12928)\n",
            "Epoch: 136 | Batch_idx: 110 |  Loss: (0.0174) | Acc: (99.44%) (14128/14208)\n",
            "Epoch: 136 | Batch_idx: 120 |  Loss: (0.0173) | Acc: (99.43%) (15400/15488)\n",
            "Epoch: 136 | Batch_idx: 130 |  Loss: (0.0174) | Acc: (99.42%) (16671/16768)\n",
            "Epoch: 136 | Batch_idx: 140 |  Loss: (0.0177) | Acc: (99.40%) (17940/18048)\n",
            "Epoch: 136 | Batch_idx: 150 |  Loss: (0.0175) | Acc: (99.40%) (19212/19328)\n",
            "Epoch: 136 | Batch_idx: 160 |  Loss: (0.0174) | Acc: (99.41%) (20486/20608)\n",
            "Epoch: 136 | Batch_idx: 170 |  Loss: (0.0176) | Acc: (99.40%) (21756/21888)\n",
            "Epoch: 136 | Batch_idx: 180 |  Loss: (0.0178) | Acc: (99.40%) (23029/23168)\n",
            "Epoch: 136 | Batch_idx: 190 |  Loss: (0.0174) | Acc: (99.42%) (24305/24448)\n",
            "Epoch: 136 | Batch_idx: 200 |  Loss: (0.0172) | Acc: (99.42%) (25579/25728)\n",
            "Epoch: 136 | Batch_idx: 210 |  Loss: (0.0173) | Acc: (99.42%) (26852/27008)\n",
            "Epoch: 136 | Batch_idx: 220 |  Loss: (0.0172) | Acc: (99.43%) (28127/28288)\n",
            "Epoch: 136 | Batch_idx: 230 |  Loss: (0.0176) | Acc: (99.42%) (29397/29568)\n",
            "Epoch: 136 | Batch_idx: 240 |  Loss: (0.0176) | Acc: (99.42%) (30669/30848)\n",
            "Epoch: 136 | Batch_idx: 250 |  Loss: (0.0173) | Acc: (99.43%) (31946/32128)\n",
            "Epoch: 136 | Batch_idx: 260 |  Loss: (0.0176) | Acc: (99.42%) (33213/33408)\n",
            "Epoch: 136 | Batch_idx: 270 |  Loss: (0.0181) | Acc: (99.40%) (34481/34688)\n",
            "Epoch: 136 | Batch_idx: 280 |  Loss: (0.0184) | Acc: (99.39%) (35749/35968)\n",
            "Epoch: 136 | Batch_idx: 290 |  Loss: (0.0185) | Acc: (99.39%) (37019/37248)\n",
            "Epoch: 136 | Batch_idx: 300 |  Loss: (0.0184) | Acc: (99.38%) (38291/38528)\n",
            "Epoch: 136 | Batch_idx: 310 |  Loss: (0.0187) | Acc: (99.38%) (39561/39808)\n",
            "Epoch: 136 | Batch_idx: 320 |  Loss: (0.0191) | Acc: (99.37%) (40831/41088)\n",
            "Epoch: 136 | Batch_idx: 330 |  Loss: (0.0190) | Acc: (99.38%) (42107/42368)\n",
            "Epoch: 136 | Batch_idx: 340 |  Loss: (0.0190) | Acc: (99.39%) (43380/43648)\n",
            "Epoch: 136 | Batch_idx: 350 |  Loss: (0.0189) | Acc: (99.39%) (44652/44928)\n",
            "Epoch: 136 | Batch_idx: 360 |  Loss: (0.0191) | Acc: (99.38%) (45921/46208)\n",
            "Epoch: 136 | Batch_idx: 370 |  Loss: (0.0192) | Acc: (99.37%) (47191/47488)\n",
            "Epoch: 136 | Batch_idx: 380 |  Loss: (0.0190) | Acc: (99.38%) (48467/48768)\n",
            "Epoch: 136 | Batch_idx: 390 |  Loss: (0.0191) | Acc: (99.38%) (49691/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3739) | Acc: (91.64%) (9164/10000)\n",
            "Epoch: 137 | Batch_idx: 0 |  Loss: (0.0559) | Acc: (99.22%) (127/128)\n",
            "Epoch: 137 | Batch_idx: 10 |  Loss: (0.0251) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 137 | Batch_idx: 20 |  Loss: (0.0240) | Acc: (99.33%) (2670/2688)\n",
            "Epoch: 137 | Batch_idx: 30 |  Loss: (0.0206) | Acc: (99.34%) (3942/3968)\n",
            "Epoch: 137 | Batch_idx: 40 |  Loss: (0.0208) | Acc: (99.33%) (5213/5248)\n",
            "Epoch: 137 | Batch_idx: 50 |  Loss: (0.0215) | Acc: (99.28%) (6481/6528)\n",
            "Epoch: 137 | Batch_idx: 60 |  Loss: (0.0205) | Acc: (99.32%) (7755/7808)\n",
            "Epoch: 137 | Batch_idx: 70 |  Loss: (0.0211) | Acc: (99.31%) (9025/9088)\n",
            "Epoch: 137 | Batch_idx: 80 |  Loss: (0.0216) | Acc: (99.28%) (10293/10368)\n",
            "Epoch: 137 | Batch_idx: 90 |  Loss: (0.0222) | Acc: (99.24%) (11560/11648)\n",
            "Epoch: 137 | Batch_idx: 100 |  Loss: (0.0215) | Acc: (99.27%) (12834/12928)\n",
            "Epoch: 137 | Batch_idx: 110 |  Loss: (0.0212) | Acc: (99.29%) (14107/14208)\n",
            "Epoch: 137 | Batch_idx: 120 |  Loss: (0.0216) | Acc: (99.28%) (15376/15488)\n",
            "Epoch: 137 | Batch_idx: 130 |  Loss: (0.0224) | Acc: (99.26%) (16644/16768)\n",
            "Epoch: 137 | Batch_idx: 140 |  Loss: (0.0218) | Acc: (99.29%) (17919/18048)\n",
            "Epoch: 137 | Batch_idx: 150 |  Loss: (0.0219) | Acc: (99.28%) (19188/19328)\n",
            "Epoch: 137 | Batch_idx: 160 |  Loss: (0.0221) | Acc: (99.28%) (20459/20608)\n",
            "Epoch: 137 | Batch_idx: 170 |  Loss: (0.0220) | Acc: (99.27%) (21729/21888)\n",
            "Epoch: 137 | Batch_idx: 180 |  Loss: (0.0216) | Acc: (99.29%) (23004/23168)\n",
            "Epoch: 137 | Batch_idx: 190 |  Loss: (0.0210) | Acc: (99.31%) (24279/24448)\n",
            "Epoch: 137 | Batch_idx: 200 |  Loss: (0.0207) | Acc: (99.32%) (25553/25728)\n",
            "Epoch: 137 | Batch_idx: 210 |  Loss: (0.0208) | Acc: (99.32%) (26824/27008)\n",
            "Epoch: 137 | Batch_idx: 220 |  Loss: (0.0212) | Acc: (99.31%) (28092/28288)\n",
            "Epoch: 137 | Batch_idx: 230 |  Loss: (0.0211) | Acc: (99.31%) (29364/29568)\n",
            "Epoch: 137 | Batch_idx: 240 |  Loss: (0.0211) | Acc: (99.31%) (30634/30848)\n",
            "Epoch: 137 | Batch_idx: 250 |  Loss: (0.0211) | Acc: (99.30%) (31904/32128)\n",
            "Epoch: 137 | Batch_idx: 260 |  Loss: (0.0214) | Acc: (99.28%) (33167/33408)\n",
            "Epoch: 137 | Batch_idx: 270 |  Loss: (0.0213) | Acc: (99.28%) (34438/34688)\n",
            "Epoch: 137 | Batch_idx: 280 |  Loss: (0.0215) | Acc: (99.28%) (35708/35968)\n",
            "Epoch: 137 | Batch_idx: 290 |  Loss: (0.0217) | Acc: (99.25%) (36970/37248)\n",
            "Epoch: 137 | Batch_idx: 300 |  Loss: (0.0218) | Acc: (99.25%) (38240/38528)\n",
            "Epoch: 137 | Batch_idx: 310 |  Loss: (0.0217) | Acc: (99.25%) (39510/39808)\n",
            "Epoch: 137 | Batch_idx: 320 |  Loss: (0.0213) | Acc: (99.26%) (40785/41088)\n",
            "Epoch: 137 | Batch_idx: 330 |  Loss: (0.0213) | Acc: (99.26%) (42056/42368)\n",
            "Epoch: 137 | Batch_idx: 340 |  Loss: (0.0210) | Acc: (99.27%) (43329/43648)\n",
            "Epoch: 137 | Batch_idx: 350 |  Loss: (0.0209) | Acc: (99.28%) (44603/44928)\n",
            "Epoch: 137 | Batch_idx: 360 |  Loss: (0.0210) | Acc: (99.28%) (45874/46208)\n",
            "Epoch: 137 | Batch_idx: 370 |  Loss: (0.0209) | Acc: (99.28%) (47148/47488)\n",
            "Epoch: 137 | Batch_idx: 380 |  Loss: (0.0210) | Acc: (99.29%) (48420/48768)\n",
            "Epoch: 137 | Batch_idx: 390 |  Loss: (0.0212) | Acc: (99.27%) (49637/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3791) | Acc: (91.71%) (9171/10000)\n",
            "Epoch: 138 | Batch_idx: 0 |  Loss: (0.0067) | Acc: (100.00%) (128/128)\n",
            "Epoch: 138 | Batch_idx: 10 |  Loss: (0.0105) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 138 | Batch_idx: 20 |  Loss: (0.0132) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 138 | Batch_idx: 30 |  Loss: (0.0123) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 138 | Batch_idx: 40 |  Loss: (0.0148) | Acc: (99.56%) (5225/5248)\n",
            "Epoch: 138 | Batch_idx: 50 |  Loss: (0.0154) | Acc: (99.53%) (6497/6528)\n",
            "Epoch: 138 | Batch_idx: 60 |  Loss: (0.0151) | Acc: (99.49%) (7768/7808)\n",
            "Epoch: 138 | Batch_idx: 70 |  Loss: (0.0147) | Acc: (99.49%) (9042/9088)\n",
            "Epoch: 138 | Batch_idx: 80 |  Loss: (0.0159) | Acc: (99.45%) (10311/10368)\n",
            "Epoch: 138 | Batch_idx: 90 |  Loss: (0.0154) | Acc: (99.46%) (11585/11648)\n",
            "Epoch: 138 | Batch_idx: 100 |  Loss: (0.0151) | Acc: (99.46%) (12858/12928)\n",
            "Epoch: 138 | Batch_idx: 110 |  Loss: (0.0159) | Acc: (99.43%) (14127/14208)\n",
            "Epoch: 138 | Batch_idx: 120 |  Loss: (0.0164) | Acc: (99.43%) (15400/15488)\n",
            "Epoch: 138 | Batch_idx: 130 |  Loss: (0.0169) | Acc: (99.41%) (16669/16768)\n",
            "Epoch: 138 | Batch_idx: 140 |  Loss: (0.0172) | Acc: (99.40%) (17940/18048)\n",
            "Epoch: 138 | Batch_idx: 150 |  Loss: (0.0170) | Acc: (99.41%) (19213/19328)\n",
            "Epoch: 138 | Batch_idx: 160 |  Loss: (0.0171) | Acc: (99.40%) (20484/20608)\n",
            "Epoch: 138 | Batch_idx: 170 |  Loss: (0.0171) | Acc: (99.40%) (21757/21888)\n",
            "Epoch: 138 | Batch_idx: 180 |  Loss: (0.0169) | Acc: (99.40%) (23030/23168)\n",
            "Epoch: 138 | Batch_idx: 190 |  Loss: (0.0168) | Acc: (99.41%) (24304/24448)\n",
            "Epoch: 138 | Batch_idx: 200 |  Loss: (0.0176) | Acc: (99.39%) (25570/25728)\n",
            "Epoch: 138 | Batch_idx: 210 |  Loss: (0.0176) | Acc: (99.39%) (26843/27008)\n",
            "Epoch: 138 | Batch_idx: 220 |  Loss: (0.0180) | Acc: (99.37%) (28111/28288)\n",
            "Epoch: 138 | Batch_idx: 230 |  Loss: (0.0181) | Acc: (99.37%) (29382/29568)\n",
            "Epoch: 138 | Batch_idx: 240 |  Loss: (0.0180) | Acc: (99.37%) (30655/30848)\n",
            "Epoch: 138 | Batch_idx: 250 |  Loss: (0.0181) | Acc: (99.37%) (31924/32128)\n",
            "Epoch: 138 | Batch_idx: 260 |  Loss: (0.0178) | Acc: (99.37%) (33199/33408)\n",
            "Epoch: 138 | Batch_idx: 270 |  Loss: (0.0179) | Acc: (99.37%) (34469/34688)\n",
            "Epoch: 138 | Batch_idx: 280 |  Loss: (0.0182) | Acc: (99.37%) (35740/35968)\n",
            "Epoch: 138 | Batch_idx: 290 |  Loss: (0.0184) | Acc: (99.36%) (37008/37248)\n",
            "Epoch: 138 | Batch_idx: 300 |  Loss: (0.0182) | Acc: (99.36%) (38282/38528)\n",
            "Epoch: 138 | Batch_idx: 310 |  Loss: (0.0184) | Acc: (99.36%) (39554/39808)\n",
            "Epoch: 138 | Batch_idx: 320 |  Loss: (0.0184) | Acc: (99.36%) (40826/41088)\n",
            "Epoch: 138 | Batch_idx: 330 |  Loss: (0.0183) | Acc: (99.36%) (42097/42368)\n",
            "Epoch: 138 | Batch_idx: 340 |  Loss: (0.0185) | Acc: (99.36%) (43368/43648)\n",
            "Epoch: 138 | Batch_idx: 350 |  Loss: (0.0182) | Acc: (99.36%) (44642/44928)\n",
            "Epoch: 138 | Batch_idx: 360 |  Loss: (0.0183) | Acc: (99.36%) (45914/46208)\n",
            "Epoch: 138 | Batch_idx: 370 |  Loss: (0.0183) | Acc: (99.36%) (47186/47488)\n",
            "Epoch: 138 | Batch_idx: 380 |  Loss: (0.0183) | Acc: (99.36%) (48455/48768)\n",
            "Epoch: 138 | Batch_idx: 390 |  Loss: (0.0183) | Acc: (99.36%) (49680/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3793) | Acc: (91.75%) (9175/10000)\n",
            "Epoch: 139 | Batch_idx: 0 |  Loss: (0.0103) | Acc: (100.00%) (128/128)\n",
            "Epoch: 139 | Batch_idx: 10 |  Loss: (0.0194) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 139 | Batch_idx: 20 |  Loss: (0.0181) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 139 | Batch_idx: 30 |  Loss: (0.0189) | Acc: (99.40%) (3944/3968)\n",
            "Epoch: 139 | Batch_idx: 40 |  Loss: (0.0194) | Acc: (99.37%) (5215/5248)\n",
            "Epoch: 139 | Batch_idx: 50 |  Loss: (0.0184) | Acc: (99.45%) (6492/6528)\n",
            "Epoch: 139 | Batch_idx: 60 |  Loss: (0.0197) | Acc: (99.40%) (7761/7808)\n",
            "Epoch: 139 | Batch_idx: 70 |  Loss: (0.0190) | Acc: (99.41%) (9034/9088)\n",
            "Epoch: 139 | Batch_idx: 80 |  Loss: (0.0191) | Acc: (99.39%) (10305/10368)\n",
            "Epoch: 139 | Batch_idx: 90 |  Loss: (0.0197) | Acc: (99.36%) (11574/11648)\n",
            "Epoch: 139 | Batch_idx: 100 |  Loss: (0.0186) | Acc: (99.40%) (12851/12928)\n",
            "Epoch: 139 | Batch_idx: 110 |  Loss: (0.0181) | Acc: (99.42%) (14126/14208)\n",
            "Epoch: 139 | Batch_idx: 120 |  Loss: (0.0182) | Acc: (99.43%) (15400/15488)\n",
            "Epoch: 139 | Batch_idx: 130 |  Loss: (0.0181) | Acc: (99.44%) (16674/16768)\n",
            "Epoch: 139 | Batch_idx: 140 |  Loss: (0.0186) | Acc: (99.42%) (17944/18048)\n",
            "Epoch: 139 | Batch_idx: 150 |  Loss: (0.0182) | Acc: (99.44%) (19220/19328)\n",
            "Epoch: 139 | Batch_idx: 160 |  Loss: (0.0185) | Acc: (99.43%) (20490/20608)\n",
            "Epoch: 139 | Batch_idx: 170 |  Loss: (0.0187) | Acc: (99.41%) (21758/21888)\n",
            "Epoch: 139 | Batch_idx: 180 |  Loss: (0.0185) | Acc: (99.41%) (23032/23168)\n",
            "Epoch: 139 | Batch_idx: 190 |  Loss: (0.0189) | Acc: (99.40%) (24302/24448)\n",
            "Epoch: 139 | Batch_idx: 200 |  Loss: (0.0190) | Acc: (99.39%) (25571/25728)\n",
            "Epoch: 139 | Batch_idx: 210 |  Loss: (0.0188) | Acc: (99.40%) (26845/27008)\n",
            "Epoch: 139 | Batch_idx: 220 |  Loss: (0.0191) | Acc: (99.37%) (28111/28288)\n",
            "Epoch: 139 | Batch_idx: 230 |  Loss: (0.0194) | Acc: (99.35%) (29377/29568)\n",
            "Epoch: 139 | Batch_idx: 240 |  Loss: (0.0194) | Acc: (99.35%) (30647/30848)\n",
            "Epoch: 139 | Batch_idx: 250 |  Loss: (0.0189) | Acc: (99.36%) (31923/32128)\n",
            "Epoch: 139 | Batch_idx: 260 |  Loss: (0.0188) | Acc: (99.37%) (33196/33408)\n",
            "Epoch: 139 | Batch_idx: 270 |  Loss: (0.0185) | Acc: (99.38%) (34474/34688)\n",
            "Epoch: 139 | Batch_idx: 280 |  Loss: (0.0184) | Acc: (99.39%) (35747/35968)\n",
            "Epoch: 139 | Batch_idx: 290 |  Loss: (0.0184) | Acc: (99.39%) (37021/37248)\n",
            "Epoch: 139 | Batch_idx: 300 |  Loss: (0.0184) | Acc: (99.39%) (38293/38528)\n",
            "Epoch: 139 | Batch_idx: 310 |  Loss: (0.0186) | Acc: (99.38%) (39562/39808)\n",
            "Epoch: 139 | Batch_idx: 320 |  Loss: (0.0188) | Acc: (99.38%) (40833/41088)\n",
            "Epoch: 139 | Batch_idx: 330 |  Loss: (0.0187) | Acc: (99.38%) (42105/42368)\n",
            "Epoch: 139 | Batch_idx: 340 |  Loss: (0.0184) | Acc: (99.39%) (43381/43648)\n",
            "Epoch: 139 | Batch_idx: 350 |  Loss: (0.0183) | Acc: (99.39%) (44654/44928)\n",
            "Epoch: 139 | Batch_idx: 360 |  Loss: (0.0183) | Acc: (99.39%) (45925/46208)\n",
            "Epoch: 139 | Batch_idx: 370 |  Loss: (0.0183) | Acc: (99.39%) (47197/47488)\n",
            "Epoch: 139 | Batch_idx: 380 |  Loss: (0.0182) | Acc: (99.39%) (48470/48768)\n",
            "Epoch: 139 | Batch_idx: 390 |  Loss: (0.0182) | Acc: (99.39%) (49696/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3835) | Acc: (91.81%) (9181/10000)\n",
            "Epoch: 140 | Batch_idx: 0 |  Loss: (0.0299) | Acc: (98.44%) (126/128)\n",
            "Epoch: 140 | Batch_idx: 10 |  Loss: (0.0176) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 140 | Batch_idx: 20 |  Loss: (0.0196) | Acc: (99.29%) (2669/2688)\n",
            "Epoch: 140 | Batch_idx: 30 |  Loss: (0.0230) | Acc: (99.02%) (3929/3968)\n",
            "Epoch: 140 | Batch_idx: 40 |  Loss: (0.0216) | Acc: (99.09%) (5200/5248)\n",
            "Epoch: 140 | Batch_idx: 50 |  Loss: (0.0195) | Acc: (99.16%) (6473/6528)\n",
            "Epoch: 140 | Batch_idx: 60 |  Loss: (0.0202) | Acc: (99.18%) (7744/7808)\n",
            "Epoch: 140 | Batch_idx: 70 |  Loss: (0.0204) | Acc: (99.21%) (9016/9088)\n",
            "Epoch: 140 | Batch_idx: 80 |  Loss: (0.0204) | Acc: (99.25%) (10290/10368)\n",
            "Epoch: 140 | Batch_idx: 90 |  Loss: (0.0204) | Acc: (99.24%) (11560/11648)\n",
            "Epoch: 140 | Batch_idx: 100 |  Loss: (0.0204) | Acc: (99.23%) (12828/12928)\n",
            "Epoch: 140 | Batch_idx: 110 |  Loss: (0.0198) | Acc: (99.26%) (14103/14208)\n",
            "Epoch: 140 | Batch_idx: 120 |  Loss: (0.0194) | Acc: (99.29%) (15378/15488)\n",
            "Epoch: 140 | Batch_idx: 130 |  Loss: (0.0191) | Acc: (99.31%) (16652/16768)\n",
            "Epoch: 140 | Batch_idx: 140 |  Loss: (0.0188) | Acc: (99.32%) (17925/18048)\n",
            "Epoch: 140 | Batch_idx: 150 |  Loss: (0.0188) | Acc: (99.32%) (19197/19328)\n",
            "Epoch: 140 | Batch_idx: 160 |  Loss: (0.0190) | Acc: (99.32%) (20468/20608)\n",
            "Epoch: 140 | Batch_idx: 170 |  Loss: (0.0191) | Acc: (99.32%) (21740/21888)\n",
            "Epoch: 140 | Batch_idx: 180 |  Loss: (0.0193) | Acc: (99.32%) (23010/23168)\n",
            "Epoch: 140 | Batch_idx: 190 |  Loss: (0.0193) | Acc: (99.31%) (24280/24448)\n",
            "Epoch: 140 | Batch_idx: 200 |  Loss: (0.0193) | Acc: (99.32%) (25554/25728)\n",
            "Epoch: 140 | Batch_idx: 210 |  Loss: (0.0190) | Acc: (99.33%) (26827/27008)\n",
            "Epoch: 140 | Batch_idx: 220 |  Loss: (0.0191) | Acc: (99.32%) (28096/28288)\n",
            "Epoch: 140 | Batch_idx: 230 |  Loss: (0.0192) | Acc: (99.31%) (29365/29568)\n",
            "Epoch: 140 | Batch_idx: 240 |  Loss: (0.0190) | Acc: (99.33%) (30640/30848)\n",
            "Epoch: 140 | Batch_idx: 250 |  Loss: (0.0189) | Acc: (99.32%) (31911/32128)\n",
            "Epoch: 140 | Batch_idx: 260 |  Loss: (0.0185) | Acc: (99.34%) (33188/33408)\n",
            "Epoch: 140 | Batch_idx: 270 |  Loss: (0.0186) | Acc: (99.34%) (34458/34688)\n",
            "Epoch: 140 | Batch_idx: 280 |  Loss: (0.0185) | Acc: (99.34%) (35731/35968)\n",
            "Epoch: 140 | Batch_idx: 290 |  Loss: (0.0184) | Acc: (99.34%) (37003/37248)\n",
            "Epoch: 140 | Batch_idx: 300 |  Loss: (0.0182) | Acc: (99.35%) (38278/38528)\n",
            "Epoch: 140 | Batch_idx: 310 |  Loss: (0.0185) | Acc: (99.34%) (39547/39808)\n",
            "Epoch: 140 | Batch_idx: 320 |  Loss: (0.0185) | Acc: (99.34%) (40818/41088)\n",
            "Epoch: 140 | Batch_idx: 330 |  Loss: (0.0185) | Acc: (99.34%) (42089/42368)\n",
            "Epoch: 140 | Batch_idx: 340 |  Loss: (0.0185) | Acc: (99.34%) (43361/43648)\n",
            "Epoch: 140 | Batch_idx: 350 |  Loss: (0.0185) | Acc: (99.34%) (44632/44928)\n",
            "Epoch: 140 | Batch_idx: 360 |  Loss: (0.0185) | Acc: (99.34%) (45902/46208)\n",
            "Epoch: 140 | Batch_idx: 370 |  Loss: (0.0185) | Acc: (99.33%) (47170/47488)\n",
            "Epoch: 140 | Batch_idx: 380 |  Loss: (0.0186) | Acc: (99.33%) (48440/48768)\n",
            "Epoch: 140 | Batch_idx: 390 |  Loss: (0.0187) | Acc: (99.33%) (49664/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3799) | Acc: (91.76%) (9176/10000)\n",
            "Epoch: 141 | Batch_idx: 0 |  Loss: (0.0079) | Acc: (100.00%) (128/128)\n",
            "Epoch: 141 | Batch_idx: 10 |  Loss: (0.0149) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 141 | Batch_idx: 20 |  Loss: (0.0199) | Acc: (99.18%) (2666/2688)\n",
            "Epoch: 141 | Batch_idx: 30 |  Loss: (0.0171) | Acc: (99.37%) (3943/3968)\n",
            "Epoch: 141 | Batch_idx: 40 |  Loss: (0.0193) | Acc: (99.33%) (5213/5248)\n",
            "Epoch: 141 | Batch_idx: 50 |  Loss: (0.0177) | Acc: (99.36%) (6486/6528)\n",
            "Epoch: 141 | Batch_idx: 60 |  Loss: (0.0181) | Acc: (99.32%) (7755/7808)\n",
            "Epoch: 141 | Batch_idx: 70 |  Loss: (0.0180) | Acc: (99.33%) (9027/9088)\n",
            "Epoch: 141 | Batch_idx: 80 |  Loss: (0.0183) | Acc: (99.32%) (10298/10368)\n",
            "Epoch: 141 | Batch_idx: 90 |  Loss: (0.0184) | Acc: (99.33%) (11570/11648)\n",
            "Epoch: 141 | Batch_idx: 100 |  Loss: (0.0180) | Acc: (99.37%) (12847/12928)\n",
            "Epoch: 141 | Batch_idx: 110 |  Loss: (0.0189) | Acc: (99.34%) (14114/14208)\n",
            "Epoch: 141 | Batch_idx: 120 |  Loss: (0.0187) | Acc: (99.36%) (15389/15488)\n",
            "Epoch: 141 | Batch_idx: 130 |  Loss: (0.0188) | Acc: (99.34%) (16657/16768)\n",
            "Epoch: 141 | Batch_idx: 140 |  Loss: (0.0185) | Acc: (99.36%) (17932/18048)\n",
            "Epoch: 141 | Batch_idx: 150 |  Loss: (0.0189) | Acc: (99.35%) (19202/19328)\n",
            "Epoch: 141 | Batch_idx: 160 |  Loss: (0.0189) | Acc: (99.34%) (20472/20608)\n",
            "Epoch: 141 | Batch_idx: 170 |  Loss: (0.0196) | Acc: (99.32%) (21739/21888)\n",
            "Epoch: 141 | Batch_idx: 180 |  Loss: (0.0192) | Acc: (99.33%) (23013/23168)\n",
            "Epoch: 141 | Batch_idx: 190 |  Loss: (0.0187) | Acc: (99.35%) (24290/24448)\n",
            "Epoch: 141 | Batch_idx: 200 |  Loss: (0.0190) | Acc: (99.36%) (25563/25728)\n",
            "Epoch: 141 | Batch_idx: 210 |  Loss: (0.0191) | Acc: (99.36%) (26835/27008)\n",
            "Epoch: 141 | Batch_idx: 220 |  Loss: (0.0186) | Acc: (99.38%) (28112/28288)\n",
            "Epoch: 141 | Batch_idx: 230 |  Loss: (0.0187) | Acc: (99.37%) (29383/29568)\n",
            "Epoch: 141 | Batch_idx: 240 |  Loss: (0.0183) | Acc: (99.39%) (30660/30848)\n",
            "Epoch: 141 | Batch_idx: 250 |  Loss: (0.0183) | Acc: (99.39%) (31932/32128)\n",
            "Epoch: 141 | Batch_idx: 260 |  Loss: (0.0189) | Acc: (99.37%) (33199/33408)\n",
            "Epoch: 141 | Batch_idx: 270 |  Loss: (0.0186) | Acc: (99.37%) (34471/34688)\n",
            "Epoch: 141 | Batch_idx: 280 |  Loss: (0.0187) | Acc: (99.37%) (35743/35968)\n",
            "Epoch: 141 | Batch_idx: 290 |  Loss: (0.0184) | Acc: (99.38%) (37018/37248)\n",
            "Epoch: 141 | Batch_idx: 300 |  Loss: (0.0185) | Acc: (99.38%) (38288/38528)\n",
            "Epoch: 141 | Batch_idx: 310 |  Loss: (0.0185) | Acc: (99.38%) (39560/39808)\n",
            "Epoch: 141 | Batch_idx: 320 |  Loss: (0.0185) | Acc: (99.38%) (40833/41088)\n",
            "Epoch: 141 | Batch_idx: 330 |  Loss: (0.0187) | Acc: (99.37%) (42101/42368)\n",
            "Epoch: 141 | Batch_idx: 340 |  Loss: (0.0186) | Acc: (99.37%) (43375/43648)\n",
            "Epoch: 141 | Batch_idx: 350 |  Loss: (0.0184) | Acc: (99.38%) (44649/44928)\n",
            "Epoch: 141 | Batch_idx: 360 |  Loss: (0.0187) | Acc: (99.37%) (45918/46208)\n",
            "Epoch: 141 | Batch_idx: 370 |  Loss: (0.0185) | Acc: (99.39%) (47196/47488)\n",
            "Epoch: 141 | Batch_idx: 380 |  Loss: (0.0185) | Acc: (99.38%) (48466/48768)\n",
            "Epoch: 141 | Batch_idx: 390 |  Loss: (0.0187) | Acc: (99.37%) (49687/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3807) | Acc: (91.63%) (9163/10000)\n",
            "Epoch: 142 | Batch_idx: 0 |  Loss: (0.0067) | Acc: (100.00%) (128/128)\n",
            "Epoch: 142 | Batch_idx: 10 |  Loss: (0.0150) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 142 | Batch_idx: 20 |  Loss: (0.0171) | Acc: (99.52%) (2675/2688)\n",
            "Epoch: 142 | Batch_idx: 30 |  Loss: (0.0200) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 142 | Batch_idx: 40 |  Loss: (0.0208) | Acc: (99.41%) (5217/5248)\n",
            "Epoch: 142 | Batch_idx: 50 |  Loss: (0.0194) | Acc: (99.45%) (6492/6528)\n",
            "Epoch: 142 | Batch_idx: 60 |  Loss: (0.0201) | Acc: (99.45%) (7765/7808)\n",
            "Epoch: 142 | Batch_idx: 70 |  Loss: (0.0190) | Acc: (99.49%) (9042/9088)\n",
            "Epoch: 142 | Batch_idx: 80 |  Loss: (0.0186) | Acc: (99.46%) (10312/10368)\n",
            "Epoch: 142 | Batch_idx: 90 |  Loss: (0.0183) | Acc: (99.44%) (11583/11648)\n",
            "Epoch: 142 | Batch_idx: 100 |  Loss: (0.0188) | Acc: (99.42%) (12853/12928)\n",
            "Epoch: 142 | Batch_idx: 110 |  Loss: (0.0181) | Acc: (99.45%) (14130/14208)\n",
            "Epoch: 142 | Batch_idx: 120 |  Loss: (0.0185) | Acc: (99.43%) (15399/15488)\n",
            "Epoch: 142 | Batch_idx: 130 |  Loss: (0.0182) | Acc: (99.43%) (16672/16768)\n",
            "Epoch: 142 | Batch_idx: 140 |  Loss: (0.0192) | Acc: (99.41%) (17942/18048)\n",
            "Epoch: 142 | Batch_idx: 150 |  Loss: (0.0187) | Acc: (99.43%) (19218/19328)\n",
            "Epoch: 142 | Batch_idx: 160 |  Loss: (0.0187) | Acc: (99.44%) (20492/20608)\n",
            "Epoch: 142 | Batch_idx: 170 |  Loss: (0.0192) | Acc: (99.42%) (21760/21888)\n",
            "Epoch: 142 | Batch_idx: 180 |  Loss: (0.0197) | Acc: (99.40%) (23029/23168)\n",
            "Epoch: 142 | Batch_idx: 190 |  Loss: (0.0193) | Acc: (99.42%) (24305/24448)\n",
            "Epoch: 142 | Batch_idx: 200 |  Loss: (0.0193) | Acc: (99.42%) (25578/25728)\n",
            "Epoch: 142 | Batch_idx: 210 |  Loss: (0.0193) | Acc: (99.42%) (26851/27008)\n",
            "Epoch: 142 | Batch_idx: 220 |  Loss: (0.0194) | Acc: (99.42%) (28124/28288)\n",
            "Epoch: 142 | Batch_idx: 230 |  Loss: (0.0192) | Acc: (99.43%) (29398/29568)\n",
            "Epoch: 142 | Batch_idx: 240 |  Loss: (0.0189) | Acc: (99.44%) (30674/30848)\n",
            "Epoch: 142 | Batch_idx: 250 |  Loss: (0.0187) | Acc: (99.43%) (31945/32128)\n",
            "Epoch: 142 | Batch_idx: 260 |  Loss: (0.0186) | Acc: (99.43%) (33218/33408)\n",
            "Epoch: 142 | Batch_idx: 270 |  Loss: (0.0185) | Acc: (99.44%) (34493/34688)\n",
            "Epoch: 142 | Batch_idx: 280 |  Loss: (0.0184) | Acc: (99.44%) (35765/35968)\n",
            "Epoch: 142 | Batch_idx: 290 |  Loss: (0.0182) | Acc: (99.44%) (37039/37248)\n",
            "Epoch: 142 | Batch_idx: 300 |  Loss: (0.0184) | Acc: (99.44%) (38311/38528)\n",
            "Epoch: 142 | Batch_idx: 310 |  Loss: (0.0181) | Acc: (99.44%) (39587/39808)\n",
            "Epoch: 142 | Batch_idx: 320 |  Loss: (0.0179) | Acc: (99.45%) (40862/41088)\n",
            "Epoch: 142 | Batch_idx: 330 |  Loss: (0.0178) | Acc: (99.45%) (42136/42368)\n",
            "Epoch: 142 | Batch_idx: 340 |  Loss: (0.0177) | Acc: (99.45%) (43408/43648)\n",
            "Epoch: 142 | Batch_idx: 350 |  Loss: (0.0176) | Acc: (99.45%) (44682/44928)\n",
            "Epoch: 142 | Batch_idx: 360 |  Loss: (0.0176) | Acc: (99.45%) (45956/46208)\n",
            "Epoch: 142 | Batch_idx: 370 |  Loss: (0.0176) | Acc: (99.45%) (47226/47488)\n",
            "Epoch: 142 | Batch_idx: 380 |  Loss: (0.0173) | Acc: (99.46%) (48503/48768)\n",
            "Epoch: 142 | Batch_idx: 390 |  Loss: (0.0177) | Acc: (99.44%) (49722/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3827) | Acc: (91.72%) (9172/10000)\n",
            "Epoch: 143 | Batch_idx: 0 |  Loss: (0.0218) | Acc: (99.22%) (127/128)\n",
            "Epoch: 143 | Batch_idx: 10 |  Loss: (0.0265) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 143 | Batch_idx: 20 |  Loss: (0.0234) | Acc: (99.07%) (2663/2688)\n",
            "Epoch: 143 | Batch_idx: 30 |  Loss: (0.0197) | Acc: (99.24%) (3938/3968)\n",
            "Epoch: 143 | Batch_idx: 40 |  Loss: (0.0195) | Acc: (99.29%) (5211/5248)\n",
            "Epoch: 143 | Batch_idx: 50 |  Loss: (0.0185) | Acc: (99.33%) (6484/6528)\n",
            "Epoch: 143 | Batch_idx: 60 |  Loss: (0.0187) | Acc: (99.36%) (7758/7808)\n",
            "Epoch: 143 | Batch_idx: 70 |  Loss: (0.0195) | Acc: (99.34%) (9028/9088)\n",
            "Epoch: 143 | Batch_idx: 80 |  Loss: (0.0183) | Acc: (99.40%) (10306/10368)\n",
            "Epoch: 143 | Batch_idx: 90 |  Loss: (0.0178) | Acc: (99.41%) (11579/11648)\n",
            "Epoch: 143 | Batch_idx: 100 |  Loss: (0.0187) | Acc: (99.37%) (12847/12928)\n",
            "Epoch: 143 | Batch_idx: 110 |  Loss: (0.0184) | Acc: (99.38%) (14120/14208)\n",
            "Epoch: 143 | Batch_idx: 120 |  Loss: (0.0189) | Acc: (99.37%) (15390/15488)\n",
            "Epoch: 143 | Batch_idx: 130 |  Loss: (0.0188) | Acc: (99.37%) (16662/16768)\n",
            "Epoch: 143 | Batch_idx: 140 |  Loss: (0.0182) | Acc: (99.39%) (17938/18048)\n",
            "Epoch: 143 | Batch_idx: 150 |  Loss: (0.0182) | Acc: (99.37%) (19207/19328)\n",
            "Epoch: 143 | Batch_idx: 160 |  Loss: (0.0184) | Acc: (99.36%) (20477/20608)\n",
            "Epoch: 143 | Batch_idx: 170 |  Loss: (0.0185) | Acc: (99.37%) (21750/21888)\n",
            "Epoch: 143 | Batch_idx: 180 |  Loss: (0.0180) | Acc: (99.39%) (23026/23168)\n",
            "Epoch: 143 | Batch_idx: 190 |  Loss: (0.0181) | Acc: (99.39%) (24298/24448)\n",
            "Epoch: 143 | Batch_idx: 200 |  Loss: (0.0181) | Acc: (99.39%) (25570/25728)\n",
            "Epoch: 143 | Batch_idx: 210 |  Loss: (0.0182) | Acc: (99.39%) (26842/27008)\n",
            "Epoch: 143 | Batch_idx: 220 |  Loss: (0.0180) | Acc: (99.39%) (28116/28288)\n",
            "Epoch: 143 | Batch_idx: 230 |  Loss: (0.0180) | Acc: (99.39%) (29389/29568)\n",
            "Epoch: 143 | Batch_idx: 240 |  Loss: (0.0178) | Acc: (99.39%) (30661/30848)\n",
            "Epoch: 143 | Batch_idx: 250 |  Loss: (0.0177) | Acc: (99.39%) (31932/32128)\n",
            "Epoch: 143 | Batch_idx: 260 |  Loss: (0.0176) | Acc: (99.39%) (33205/33408)\n",
            "Epoch: 143 | Batch_idx: 270 |  Loss: (0.0179) | Acc: (99.39%) (34477/34688)\n",
            "Epoch: 143 | Batch_idx: 280 |  Loss: (0.0177) | Acc: (99.39%) (35749/35968)\n",
            "Epoch: 143 | Batch_idx: 290 |  Loss: (0.0180) | Acc: (99.39%) (37019/37248)\n",
            "Epoch: 143 | Batch_idx: 300 |  Loss: (0.0179) | Acc: (99.39%) (38293/38528)\n",
            "Epoch: 143 | Batch_idx: 310 |  Loss: (0.0178) | Acc: (99.39%) (39566/39808)\n",
            "Epoch: 143 | Batch_idx: 320 |  Loss: (0.0177) | Acc: (99.39%) (40838/41088)\n",
            "Epoch: 143 | Batch_idx: 330 |  Loss: (0.0175) | Acc: (99.41%) (42116/42368)\n",
            "Epoch: 143 | Batch_idx: 340 |  Loss: (0.0178) | Acc: (99.40%) (43388/43648)\n",
            "Epoch: 143 | Batch_idx: 350 |  Loss: (0.0182) | Acc: (99.39%) (44655/44928)\n",
            "Epoch: 143 | Batch_idx: 360 |  Loss: (0.0181) | Acc: (99.39%) (45928/46208)\n",
            "Epoch: 143 | Batch_idx: 370 |  Loss: (0.0183) | Acc: (99.38%) (47195/47488)\n",
            "Epoch: 143 | Batch_idx: 380 |  Loss: (0.0182) | Acc: (99.38%) (48466/48768)\n",
            "Epoch: 143 | Batch_idx: 390 |  Loss: (0.0181) | Acc: (99.38%) (49692/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3811) | Acc: (91.69%) (9169/10000)\n",
            "Epoch: 144 | Batch_idx: 0 |  Loss: (0.0161) | Acc: (99.22%) (127/128)\n",
            "Epoch: 144 | Batch_idx: 10 |  Loss: (0.0214) | Acc: (99.22%) (1397/1408)\n",
            "Epoch: 144 | Batch_idx: 20 |  Loss: (0.0148) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 144 | Batch_idx: 30 |  Loss: (0.0173) | Acc: (99.37%) (3943/3968)\n",
            "Epoch: 144 | Batch_idx: 40 |  Loss: (0.0183) | Acc: (99.31%) (5212/5248)\n",
            "Epoch: 144 | Batch_idx: 50 |  Loss: (0.0172) | Acc: (99.33%) (6484/6528)\n",
            "Epoch: 144 | Batch_idx: 60 |  Loss: (0.0177) | Acc: (99.32%) (7755/7808)\n",
            "Epoch: 144 | Batch_idx: 70 |  Loss: (0.0181) | Acc: (99.33%) (9027/9088)\n",
            "Epoch: 144 | Batch_idx: 80 |  Loss: (0.0181) | Acc: (99.32%) (10298/10368)\n",
            "Epoch: 144 | Batch_idx: 90 |  Loss: (0.0181) | Acc: (99.33%) (11570/11648)\n",
            "Epoch: 144 | Batch_idx: 100 |  Loss: (0.0177) | Acc: (99.34%) (12843/12928)\n",
            "Epoch: 144 | Batch_idx: 110 |  Loss: (0.0171) | Acc: (99.37%) (14119/14208)\n",
            "Epoch: 144 | Batch_idx: 120 |  Loss: (0.0173) | Acc: (99.39%) (15394/15488)\n",
            "Epoch: 144 | Batch_idx: 130 |  Loss: (0.0169) | Acc: (99.42%) (16670/16768)\n",
            "Epoch: 144 | Batch_idx: 140 |  Loss: (0.0169) | Acc: (99.42%) (17943/18048)\n",
            "Epoch: 144 | Batch_idx: 150 |  Loss: (0.0169) | Acc: (99.42%) (19216/19328)\n",
            "Epoch: 144 | Batch_idx: 160 |  Loss: (0.0172) | Acc: (99.42%) (20488/20608)\n",
            "Epoch: 144 | Batch_idx: 170 |  Loss: (0.0175) | Acc: (99.39%) (21755/21888)\n",
            "Epoch: 144 | Batch_idx: 180 |  Loss: (0.0177) | Acc: (99.38%) (23025/23168)\n",
            "Epoch: 144 | Batch_idx: 190 |  Loss: (0.0178) | Acc: (99.38%) (24297/24448)\n",
            "Epoch: 144 | Batch_idx: 200 |  Loss: (0.0175) | Acc: (99.39%) (25571/25728)\n",
            "Epoch: 144 | Batch_idx: 210 |  Loss: (0.0174) | Acc: (99.40%) (26845/27008)\n",
            "Epoch: 144 | Batch_idx: 220 |  Loss: (0.0173) | Acc: (99.40%) (28119/28288)\n",
            "Epoch: 144 | Batch_idx: 230 |  Loss: (0.0172) | Acc: (99.40%) (29392/29568)\n",
            "Epoch: 144 | Batch_idx: 240 |  Loss: (0.0172) | Acc: (99.41%) (30665/30848)\n",
            "Epoch: 144 | Batch_idx: 250 |  Loss: (0.0176) | Acc: (99.40%) (31936/32128)\n",
            "Epoch: 144 | Batch_idx: 260 |  Loss: (0.0176) | Acc: (99.40%) (33206/33408)\n",
            "Epoch: 144 | Batch_idx: 270 |  Loss: (0.0178) | Acc: (99.38%) (34473/34688)\n",
            "Epoch: 144 | Batch_idx: 280 |  Loss: (0.0174) | Acc: (99.40%) (35751/35968)\n",
            "Epoch: 144 | Batch_idx: 290 |  Loss: (0.0177) | Acc: (99.40%) (37023/37248)\n",
            "Epoch: 144 | Batch_idx: 300 |  Loss: (0.0179) | Acc: (99.39%) (38294/38528)\n",
            "Epoch: 144 | Batch_idx: 310 |  Loss: (0.0178) | Acc: (99.39%) (39567/39808)\n",
            "Epoch: 144 | Batch_idx: 320 |  Loss: (0.0179) | Acc: (99.40%) (40840/41088)\n",
            "Epoch: 144 | Batch_idx: 330 |  Loss: (0.0179) | Acc: (99.39%) (42110/42368)\n",
            "Epoch: 144 | Batch_idx: 340 |  Loss: (0.0178) | Acc: (99.40%) (43385/43648)\n",
            "Epoch: 144 | Batch_idx: 350 |  Loss: (0.0179) | Acc: (99.39%) (44653/44928)\n",
            "Epoch: 144 | Batch_idx: 360 |  Loss: (0.0180) | Acc: (99.39%) (45924/46208)\n",
            "Epoch: 144 | Batch_idx: 370 |  Loss: (0.0178) | Acc: (99.40%) (47201/47488)\n",
            "Epoch: 144 | Batch_idx: 380 |  Loss: (0.0178) | Acc: (99.40%) (48473/48768)\n",
            "Epoch: 144 | Batch_idx: 390 |  Loss: (0.0180) | Acc: (99.39%) (49695/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3848) | Acc: (91.80%) (9180/10000)\n",
            "Epoch: 145 | Batch_idx: 0 |  Loss: (0.0084) | Acc: (100.00%) (128/128)\n",
            "Epoch: 145 | Batch_idx: 10 |  Loss: (0.0217) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 145 | Batch_idx: 20 |  Loss: (0.0189) | Acc: (99.33%) (2670/2688)\n",
            "Epoch: 145 | Batch_idx: 30 |  Loss: (0.0171) | Acc: (99.47%) (3947/3968)\n",
            "Epoch: 145 | Batch_idx: 40 |  Loss: (0.0166) | Acc: (99.50%) (5222/5248)\n",
            "Epoch: 145 | Batch_idx: 50 |  Loss: (0.0159) | Acc: (99.51%) (6496/6528)\n",
            "Epoch: 145 | Batch_idx: 60 |  Loss: (0.0153) | Acc: (99.54%) (7772/7808)\n",
            "Epoch: 145 | Batch_idx: 70 |  Loss: (0.0151) | Acc: (99.53%) (9045/9088)\n",
            "Epoch: 145 | Batch_idx: 80 |  Loss: (0.0164) | Acc: (99.49%) (10315/10368)\n",
            "Epoch: 145 | Batch_idx: 90 |  Loss: (0.0159) | Acc: (99.49%) (11589/11648)\n",
            "Epoch: 145 | Batch_idx: 100 |  Loss: (0.0153) | Acc: (99.50%) (12864/12928)\n",
            "Epoch: 145 | Batch_idx: 110 |  Loss: (0.0155) | Acc: (99.49%) (14136/14208)\n",
            "Epoch: 145 | Batch_idx: 120 |  Loss: (0.0165) | Acc: (99.44%) (15402/15488)\n",
            "Epoch: 145 | Batch_idx: 130 |  Loss: (0.0163) | Acc: (99.45%) (16676/16768)\n",
            "Epoch: 145 | Batch_idx: 140 |  Loss: (0.0163) | Acc: (99.44%) (17947/18048)\n",
            "Epoch: 145 | Batch_idx: 150 |  Loss: (0.0161) | Acc: (99.44%) (19220/19328)\n",
            "Epoch: 145 | Batch_idx: 160 |  Loss: (0.0160) | Acc: (99.45%) (20494/20608)\n",
            "Epoch: 145 | Batch_idx: 170 |  Loss: (0.0161) | Acc: (99.46%) (21769/21888)\n",
            "Epoch: 145 | Batch_idx: 180 |  Loss: (0.0162) | Acc: (99.46%) (23042/23168)\n",
            "Epoch: 145 | Batch_idx: 190 |  Loss: (0.0163) | Acc: (99.44%) (24311/24448)\n",
            "Epoch: 145 | Batch_idx: 200 |  Loss: (0.0164) | Acc: (99.45%) (25586/25728)\n",
            "Epoch: 145 | Batch_idx: 210 |  Loss: (0.0164) | Acc: (99.44%) (26858/27008)\n",
            "Epoch: 145 | Batch_idx: 220 |  Loss: (0.0165) | Acc: (99.44%) (28131/28288)\n",
            "Epoch: 145 | Batch_idx: 230 |  Loss: (0.0164) | Acc: (99.45%) (29404/29568)\n",
            "Epoch: 145 | Batch_idx: 240 |  Loss: (0.0163) | Acc: (99.45%) (30678/30848)\n",
            "Epoch: 145 | Batch_idx: 250 |  Loss: (0.0163) | Acc: (99.45%) (31952/32128)\n",
            "Epoch: 145 | Batch_idx: 260 |  Loss: (0.0167) | Acc: (99.44%) (33222/33408)\n",
            "Epoch: 145 | Batch_idx: 270 |  Loss: (0.0167) | Acc: (99.44%) (34493/34688)\n",
            "Epoch: 145 | Batch_idx: 280 |  Loss: (0.0168) | Acc: (99.43%) (35764/35968)\n",
            "Epoch: 145 | Batch_idx: 290 |  Loss: (0.0168) | Acc: (99.43%) (37037/37248)\n",
            "Epoch: 145 | Batch_idx: 300 |  Loss: (0.0167) | Acc: (99.44%) (38312/38528)\n",
            "Epoch: 145 | Batch_idx: 310 |  Loss: (0.0171) | Acc: (99.43%) (39581/39808)\n",
            "Epoch: 145 | Batch_idx: 320 |  Loss: (0.0170) | Acc: (99.43%) (40854/41088)\n",
            "Epoch: 145 | Batch_idx: 330 |  Loss: (0.0169) | Acc: (99.42%) (42124/42368)\n",
            "Epoch: 145 | Batch_idx: 340 |  Loss: (0.0170) | Acc: (99.42%) (43397/43648)\n",
            "Epoch: 145 | Batch_idx: 350 |  Loss: (0.0171) | Acc: (99.42%) (44668/44928)\n",
            "Epoch: 145 | Batch_idx: 360 |  Loss: (0.0174) | Acc: (99.41%) (45936/46208)\n",
            "Epoch: 145 | Batch_idx: 370 |  Loss: (0.0177) | Acc: (99.40%) (47204/47488)\n",
            "Epoch: 145 | Batch_idx: 380 |  Loss: (0.0176) | Acc: (99.41%) (48478/48768)\n",
            "Epoch: 145 | Batch_idx: 390 |  Loss: (0.0175) | Acc: (99.41%) (49704/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3881) | Acc: (91.80%) (9180/10000)\n",
            "Epoch: 146 | Batch_idx: 0 |  Loss: (0.0168) | Acc: (99.22%) (127/128)\n",
            "Epoch: 146 | Batch_idx: 10 |  Loss: (0.0148) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 146 | Batch_idx: 20 |  Loss: (0.0139) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 146 | Batch_idx: 30 |  Loss: (0.0162) | Acc: (99.34%) (3942/3968)\n",
            "Epoch: 146 | Batch_idx: 40 |  Loss: (0.0170) | Acc: (99.33%) (5213/5248)\n",
            "Epoch: 146 | Batch_idx: 50 |  Loss: (0.0195) | Acc: (99.28%) (6481/6528)\n",
            "Epoch: 146 | Batch_idx: 60 |  Loss: (0.0190) | Acc: (99.32%) (7755/7808)\n",
            "Epoch: 146 | Batch_idx: 70 |  Loss: (0.0187) | Acc: (99.31%) (9025/9088)\n",
            "Epoch: 146 | Batch_idx: 80 |  Loss: (0.0196) | Acc: (99.29%) (10294/10368)\n",
            "Epoch: 146 | Batch_idx: 90 |  Loss: (0.0208) | Acc: (99.25%) (11561/11648)\n",
            "Epoch: 146 | Batch_idx: 100 |  Loss: (0.0202) | Acc: (99.28%) (12835/12928)\n",
            "Epoch: 146 | Batch_idx: 110 |  Loss: (0.0205) | Acc: (99.28%) (14105/14208)\n",
            "Epoch: 146 | Batch_idx: 120 |  Loss: (0.0200) | Acc: (99.29%) (15378/15488)\n",
            "Epoch: 146 | Batch_idx: 130 |  Loss: (0.0198) | Acc: (99.29%) (16649/16768)\n",
            "Epoch: 146 | Batch_idx: 140 |  Loss: (0.0196) | Acc: (99.29%) (17920/18048)\n",
            "Epoch: 146 | Batch_idx: 150 |  Loss: (0.0191) | Acc: (99.31%) (19194/19328)\n",
            "Epoch: 146 | Batch_idx: 160 |  Loss: (0.0192) | Acc: (99.33%) (20469/20608)\n",
            "Epoch: 146 | Batch_idx: 170 |  Loss: (0.0191) | Acc: (99.32%) (21739/21888)\n",
            "Epoch: 146 | Batch_idx: 180 |  Loss: (0.0186) | Acc: (99.34%) (23014/23168)\n",
            "Epoch: 146 | Batch_idx: 190 |  Loss: (0.0184) | Acc: (99.35%) (24288/24448)\n",
            "Epoch: 146 | Batch_idx: 200 |  Loss: (0.0183) | Acc: (99.35%) (25562/25728)\n",
            "Epoch: 146 | Batch_idx: 210 |  Loss: (0.0179) | Acc: (99.37%) (26838/27008)\n",
            "Epoch: 146 | Batch_idx: 220 |  Loss: (0.0187) | Acc: (99.34%) (28101/28288)\n",
            "Epoch: 146 | Batch_idx: 230 |  Loss: (0.0190) | Acc: (99.33%) (29370/29568)\n",
            "Epoch: 146 | Batch_idx: 240 |  Loss: (0.0188) | Acc: (99.34%) (30644/30848)\n",
            "Epoch: 146 | Batch_idx: 250 |  Loss: (0.0188) | Acc: (99.34%) (31917/32128)\n",
            "Epoch: 146 | Batch_idx: 260 |  Loss: (0.0188) | Acc: (99.34%) (33189/33408)\n",
            "Epoch: 146 | Batch_idx: 270 |  Loss: (0.0184) | Acc: (99.36%) (34465/34688)\n",
            "Epoch: 146 | Batch_idx: 280 |  Loss: (0.0182) | Acc: (99.37%) (35740/35968)\n",
            "Epoch: 146 | Batch_idx: 290 |  Loss: (0.0180) | Acc: (99.38%) (37016/37248)\n",
            "Epoch: 146 | Batch_idx: 300 |  Loss: (0.0181) | Acc: (99.37%) (38287/38528)\n",
            "Epoch: 146 | Batch_idx: 310 |  Loss: (0.0182) | Acc: (99.38%) (39560/39808)\n",
            "Epoch: 146 | Batch_idx: 320 |  Loss: (0.0181) | Acc: (99.38%) (40832/41088)\n",
            "Epoch: 146 | Batch_idx: 330 |  Loss: (0.0182) | Acc: (99.38%) (42104/42368)\n",
            "Epoch: 146 | Batch_idx: 340 |  Loss: (0.0182) | Acc: (99.38%) (43377/43648)\n",
            "Epoch: 146 | Batch_idx: 350 |  Loss: (0.0181) | Acc: (99.38%) (44651/44928)\n",
            "Epoch: 146 | Batch_idx: 360 |  Loss: (0.0183) | Acc: (99.38%) (45923/46208)\n",
            "Epoch: 146 | Batch_idx: 370 |  Loss: (0.0185) | Acc: (99.38%) (47194/47488)\n",
            "Epoch: 146 | Batch_idx: 380 |  Loss: (0.0189) | Acc: (99.37%) (48461/48768)\n",
            "Epoch: 146 | Batch_idx: 390 |  Loss: (0.0191) | Acc: (99.37%) (49686/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3883) | Acc: (91.73%) (9173/10000)\n",
            "Epoch: 147 | Batch_idx: 0 |  Loss: (0.0031) | Acc: (100.00%) (128/128)\n",
            "Epoch: 147 | Batch_idx: 10 |  Loss: (0.0161) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 147 | Batch_idx: 20 |  Loss: (0.0191) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 147 | Batch_idx: 30 |  Loss: (0.0192) | Acc: (99.40%) (3944/3968)\n",
            "Epoch: 147 | Batch_idx: 40 |  Loss: (0.0196) | Acc: (99.37%) (5215/5248)\n",
            "Epoch: 147 | Batch_idx: 50 |  Loss: (0.0184) | Acc: (99.40%) (6489/6528)\n",
            "Epoch: 147 | Batch_idx: 60 |  Loss: (0.0175) | Acc: (99.41%) (7762/7808)\n",
            "Epoch: 147 | Batch_idx: 70 |  Loss: (0.0181) | Acc: (99.42%) (9035/9088)\n",
            "Epoch: 147 | Batch_idx: 80 |  Loss: (0.0191) | Acc: (99.39%) (10305/10368)\n",
            "Epoch: 147 | Batch_idx: 90 |  Loss: (0.0183) | Acc: (99.43%) (11582/11648)\n",
            "Epoch: 147 | Batch_idx: 100 |  Loss: (0.0192) | Acc: (99.39%) (12849/12928)\n",
            "Epoch: 147 | Batch_idx: 110 |  Loss: (0.0187) | Acc: (99.41%) (14124/14208)\n",
            "Epoch: 147 | Batch_idx: 120 |  Loss: (0.0187) | Acc: (99.41%) (15396/15488)\n",
            "Epoch: 147 | Batch_idx: 130 |  Loss: (0.0195) | Acc: (99.39%) (16665/16768)\n",
            "Epoch: 147 | Batch_idx: 140 |  Loss: (0.0193) | Acc: (99.40%) (17940/18048)\n",
            "Epoch: 147 | Batch_idx: 150 |  Loss: (0.0193) | Acc: (99.39%) (19211/19328)\n",
            "Epoch: 147 | Batch_idx: 160 |  Loss: (0.0187) | Acc: (99.41%) (20487/20608)\n",
            "Epoch: 147 | Batch_idx: 170 |  Loss: (0.0195) | Acc: (99.39%) (21754/21888)\n",
            "Epoch: 147 | Batch_idx: 180 |  Loss: (0.0189) | Acc: (99.41%) (23031/23168)\n",
            "Epoch: 147 | Batch_idx: 190 |  Loss: (0.0197) | Acc: (99.38%) (24296/24448)\n",
            "Epoch: 147 | Batch_idx: 200 |  Loss: (0.0196) | Acc: (99.38%) (25569/25728)\n",
            "Epoch: 147 | Batch_idx: 210 |  Loss: (0.0193) | Acc: (99.39%) (26842/27008)\n",
            "Epoch: 147 | Batch_idx: 220 |  Loss: (0.0193) | Acc: (99.37%) (28110/28288)\n",
            "Epoch: 147 | Batch_idx: 230 |  Loss: (0.0193) | Acc: (99.37%) (29383/29568)\n",
            "Epoch: 147 | Batch_idx: 240 |  Loss: (0.0197) | Acc: (99.37%) (30653/30848)\n",
            "Epoch: 147 | Batch_idx: 250 |  Loss: (0.0193) | Acc: (99.38%) (31929/32128)\n",
            "Epoch: 147 | Batch_idx: 260 |  Loss: (0.0190) | Acc: (99.39%) (33205/33408)\n",
            "Epoch: 147 | Batch_idx: 270 |  Loss: (0.0189) | Acc: (99.40%) (34480/34688)\n",
            "Epoch: 147 | Batch_idx: 280 |  Loss: (0.0191) | Acc: (99.39%) (35750/35968)\n",
            "Epoch: 147 | Batch_idx: 290 |  Loss: (0.0186) | Acc: (99.41%) (37028/37248)\n",
            "Epoch: 147 | Batch_idx: 300 |  Loss: (0.0186) | Acc: (99.41%) (38301/38528)\n",
            "Epoch: 147 | Batch_idx: 310 |  Loss: (0.0187) | Acc: (99.39%) (39566/39808)\n",
            "Epoch: 147 | Batch_idx: 320 |  Loss: (0.0188) | Acc: (99.38%) (40834/41088)\n",
            "Epoch: 147 | Batch_idx: 330 |  Loss: (0.0186) | Acc: (99.38%) (42107/42368)\n",
            "Epoch: 147 | Batch_idx: 340 |  Loss: (0.0186) | Acc: (99.38%) (43377/43648)\n",
            "Epoch: 147 | Batch_idx: 350 |  Loss: (0.0182) | Acc: (99.39%) (44654/44928)\n",
            "Epoch: 147 | Batch_idx: 360 |  Loss: (0.0183) | Acc: (99.39%) (45926/46208)\n",
            "Epoch: 147 | Batch_idx: 370 |  Loss: (0.0181) | Acc: (99.40%) (47201/47488)\n",
            "Epoch: 147 | Batch_idx: 380 |  Loss: (0.0181) | Acc: (99.40%) (48473/48768)\n",
            "Epoch: 147 | Batch_idx: 390 |  Loss: (0.0181) | Acc: (99.39%) (49697/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3889) | Acc: (91.84%) (9184/10000)\n",
            "Epoch: 148 | Batch_idx: 0 |  Loss: (0.0434) | Acc: (99.22%) (127/128)\n",
            "Epoch: 148 | Batch_idx: 10 |  Loss: (0.0141) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 148 | Batch_idx: 20 |  Loss: (0.0182) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 148 | Batch_idx: 30 |  Loss: (0.0169) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 148 | Batch_idx: 40 |  Loss: (0.0193) | Acc: (99.41%) (5217/5248)\n",
            "Epoch: 148 | Batch_idx: 50 |  Loss: (0.0203) | Acc: (99.34%) (6485/6528)\n",
            "Epoch: 148 | Batch_idx: 60 |  Loss: (0.0197) | Acc: (99.36%) (7758/7808)\n",
            "Epoch: 148 | Batch_idx: 70 |  Loss: (0.0189) | Acc: (99.38%) (9032/9088)\n",
            "Epoch: 148 | Batch_idx: 80 |  Loss: (0.0188) | Acc: (99.37%) (10303/10368)\n",
            "Epoch: 148 | Batch_idx: 90 |  Loss: (0.0187) | Acc: (99.39%) (11577/11648)\n",
            "Epoch: 148 | Batch_idx: 100 |  Loss: (0.0188) | Acc: (99.37%) (12847/12928)\n",
            "Epoch: 148 | Batch_idx: 110 |  Loss: (0.0183) | Acc: (99.39%) (14121/14208)\n",
            "Epoch: 148 | Batch_idx: 120 |  Loss: (0.0173) | Acc: (99.43%) (15400/15488)\n",
            "Epoch: 148 | Batch_idx: 130 |  Loss: (0.0180) | Acc: (99.42%) (16670/16768)\n",
            "Epoch: 148 | Batch_idx: 140 |  Loss: (0.0177) | Acc: (99.41%) (17942/18048)\n",
            "Epoch: 148 | Batch_idx: 150 |  Loss: (0.0182) | Acc: (99.42%) (19215/19328)\n",
            "Epoch: 148 | Batch_idx: 160 |  Loss: (0.0182) | Acc: (99.41%) (20487/20608)\n",
            "Epoch: 148 | Batch_idx: 170 |  Loss: (0.0183) | Acc: (99.39%) (21755/21888)\n",
            "Epoch: 148 | Batch_idx: 180 |  Loss: (0.0182) | Acc: (99.40%) (23028/23168)\n",
            "Epoch: 148 | Batch_idx: 190 |  Loss: (0.0177) | Acc: (99.42%) (24305/24448)\n",
            "Epoch: 148 | Batch_idx: 200 |  Loss: (0.0180) | Acc: (99.40%) (25573/25728)\n",
            "Epoch: 148 | Batch_idx: 210 |  Loss: (0.0177) | Acc: (99.41%) (26850/27008)\n",
            "Epoch: 148 | Batch_idx: 220 |  Loss: (0.0175) | Acc: (99.42%) (28123/28288)\n",
            "Epoch: 148 | Batch_idx: 230 |  Loss: (0.0177) | Acc: (99.41%) (29394/29568)\n",
            "Epoch: 148 | Batch_idx: 240 |  Loss: (0.0176) | Acc: (99.42%) (30669/30848)\n",
            "Epoch: 148 | Batch_idx: 250 |  Loss: (0.0174) | Acc: (99.42%) (31942/32128)\n",
            "Epoch: 148 | Batch_idx: 260 |  Loss: (0.0172) | Acc: (99.43%) (33216/33408)\n",
            "Epoch: 148 | Batch_idx: 270 |  Loss: (0.0172) | Acc: (99.42%) (34487/34688)\n",
            "Epoch: 148 | Batch_idx: 280 |  Loss: (0.0174) | Acc: (99.41%) (35756/35968)\n",
            "Epoch: 148 | Batch_idx: 290 |  Loss: (0.0175) | Acc: (99.41%) (37027/37248)\n",
            "Epoch: 148 | Batch_idx: 300 |  Loss: (0.0174) | Acc: (99.42%) (38303/38528)\n",
            "Epoch: 148 | Batch_idx: 310 |  Loss: (0.0173) | Acc: (99.42%) (39578/39808)\n",
            "Epoch: 148 | Batch_idx: 320 |  Loss: (0.0174) | Acc: (99.42%) (40850/41088)\n",
            "Epoch: 148 | Batch_idx: 330 |  Loss: (0.0175) | Acc: (99.42%) (42121/42368)\n",
            "Epoch: 148 | Batch_idx: 340 |  Loss: (0.0174) | Acc: (99.42%) (43393/43648)\n",
            "Epoch: 148 | Batch_idx: 350 |  Loss: (0.0173) | Acc: (99.41%) (44665/44928)\n",
            "Epoch: 148 | Batch_idx: 360 |  Loss: (0.0172) | Acc: (99.42%) (45939/46208)\n",
            "Epoch: 148 | Batch_idx: 370 |  Loss: (0.0173) | Acc: (99.41%) (47208/47488)\n",
            "Epoch: 148 | Batch_idx: 380 |  Loss: (0.0173) | Acc: (99.41%) (48481/48768)\n",
            "Epoch: 148 | Batch_idx: 390 |  Loss: (0.0174) | Acc: (99.41%) (49703/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3881) | Acc: (91.78%) (9178/10000)\n",
            "Epoch: 149 | Batch_idx: 0 |  Loss: (0.0053) | Acc: (100.00%) (128/128)\n",
            "Epoch: 149 | Batch_idx: 10 |  Loss: (0.0125) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 149 | Batch_idx: 20 |  Loss: (0.0118) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 149 | Batch_idx: 30 |  Loss: (0.0129) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 149 | Batch_idx: 40 |  Loss: (0.0147) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 149 | Batch_idx: 50 |  Loss: (0.0140) | Acc: (99.46%) (6493/6528)\n",
            "Epoch: 149 | Batch_idx: 60 |  Loss: (0.0131) | Acc: (99.51%) (7770/7808)\n",
            "Epoch: 149 | Batch_idx: 70 |  Loss: (0.0138) | Acc: (99.52%) (9044/9088)\n",
            "Epoch: 149 | Batch_idx: 80 |  Loss: (0.0156) | Acc: (99.49%) (10315/10368)\n",
            "Epoch: 149 | Batch_idx: 90 |  Loss: (0.0175) | Acc: (99.46%) (11585/11648)\n",
            "Epoch: 149 | Batch_idx: 100 |  Loss: (0.0179) | Acc: (99.45%) (12857/12928)\n",
            "Epoch: 149 | Batch_idx: 110 |  Loss: (0.0181) | Acc: (99.42%) (14126/14208)\n",
            "Epoch: 149 | Batch_idx: 120 |  Loss: (0.0175) | Acc: (99.44%) (15401/15488)\n",
            "Epoch: 149 | Batch_idx: 130 |  Loss: (0.0176) | Acc: (99.45%) (16675/16768)\n",
            "Epoch: 149 | Batch_idx: 140 |  Loss: (0.0172) | Acc: (99.46%) (17950/18048)\n",
            "Epoch: 149 | Batch_idx: 150 |  Loss: (0.0167) | Acc: (99.47%) (19226/19328)\n",
            "Epoch: 149 | Batch_idx: 160 |  Loss: (0.0167) | Acc: (99.48%) (20501/20608)\n",
            "Epoch: 149 | Batch_idx: 170 |  Loss: (0.0168) | Acc: (99.46%) (21770/21888)\n",
            "Epoch: 149 | Batch_idx: 180 |  Loss: (0.0165) | Acc: (99.46%) (23044/23168)\n",
            "Epoch: 149 | Batch_idx: 190 |  Loss: (0.0167) | Acc: (99.47%) (24318/24448)\n",
            "Epoch: 149 | Batch_idx: 200 |  Loss: (0.0165) | Acc: (99.48%) (25593/25728)\n",
            "Epoch: 149 | Batch_idx: 210 |  Loss: (0.0161) | Acc: (99.49%) (26870/27008)\n",
            "Epoch: 149 | Batch_idx: 220 |  Loss: (0.0164) | Acc: (99.48%) (28142/28288)\n",
            "Epoch: 149 | Batch_idx: 230 |  Loss: (0.0163) | Acc: (99.49%) (29416/29568)\n",
            "Epoch: 149 | Batch_idx: 240 |  Loss: (0.0163) | Acc: (99.48%) (30688/30848)\n",
            "Epoch: 149 | Batch_idx: 250 |  Loss: (0.0161) | Acc: (99.48%) (31962/32128)\n",
            "Epoch: 149 | Batch_idx: 260 |  Loss: (0.0162) | Acc: (99.48%) (33233/33408)\n",
            "Epoch: 149 | Batch_idx: 270 |  Loss: (0.0163) | Acc: (99.48%) (34506/34688)\n",
            "Epoch: 149 | Batch_idx: 280 |  Loss: (0.0166) | Acc: (99.46%) (35774/35968)\n",
            "Epoch: 149 | Batch_idx: 290 |  Loss: (0.0167) | Acc: (99.46%) (37045/37248)\n",
            "Epoch: 149 | Batch_idx: 300 |  Loss: (0.0168) | Acc: (99.45%) (38316/38528)\n",
            "Epoch: 149 | Batch_idx: 310 |  Loss: (0.0169) | Acc: (99.45%) (39589/39808)\n",
            "Epoch: 149 | Batch_idx: 320 |  Loss: (0.0168) | Acc: (99.45%) (40864/41088)\n",
            "Epoch: 149 | Batch_idx: 330 |  Loss: (0.0170) | Acc: (99.46%) (42138/42368)\n",
            "Epoch: 149 | Batch_idx: 340 |  Loss: (0.0172) | Acc: (99.45%) (43410/43648)\n",
            "Epoch: 149 | Batch_idx: 350 |  Loss: (0.0174) | Acc: (99.45%) (44682/44928)\n",
            "Epoch: 149 | Batch_idx: 360 |  Loss: (0.0175) | Acc: (99.45%) (45955/46208)\n",
            "Epoch: 149 | Batch_idx: 370 |  Loss: (0.0175) | Acc: (99.45%) (47226/47488)\n",
            "Epoch: 149 | Batch_idx: 380 |  Loss: (0.0177) | Acc: (99.43%) (48492/48768)\n",
            "Epoch: 149 | Batch_idx: 390 |  Loss: (0.0178) | Acc: (99.43%) (49716/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3826) | Acc: (91.80%) (9180/10000)\n",
            "Epoch: 150 | Batch_idx: 0 |  Loss: (0.0029) | Acc: (100.00%) (128/128)\n",
            "Epoch: 150 | Batch_idx: 10 |  Loss: (0.0153) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 150 | Batch_idx: 20 |  Loss: (0.0165) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 150 | Batch_idx: 30 |  Loss: (0.0163) | Acc: (99.47%) (3947/3968)\n",
            "Epoch: 150 | Batch_idx: 40 |  Loss: (0.0162) | Acc: (99.43%) (5218/5248)\n",
            "Epoch: 150 | Batch_idx: 50 |  Loss: (0.0160) | Acc: (99.43%) (6491/6528)\n",
            "Epoch: 150 | Batch_idx: 60 |  Loss: (0.0160) | Acc: (99.45%) (7765/7808)\n",
            "Epoch: 150 | Batch_idx: 70 |  Loss: (0.0159) | Acc: (99.47%) (9040/9088)\n",
            "Epoch: 150 | Batch_idx: 80 |  Loss: (0.0162) | Acc: (99.48%) (10314/10368)\n",
            "Epoch: 150 | Batch_idx: 90 |  Loss: (0.0167) | Acc: (99.47%) (11586/11648)\n",
            "Epoch: 150 | Batch_idx: 100 |  Loss: (0.0167) | Acc: (99.47%) (12859/12928)\n",
            "Epoch: 150 | Batch_idx: 110 |  Loss: (0.0169) | Acc: (99.47%) (14132/14208)\n",
            "Epoch: 150 | Batch_idx: 120 |  Loss: (0.0166) | Acc: (99.46%) (15405/15488)\n",
            "Epoch: 150 | Batch_idx: 130 |  Loss: (0.0169) | Acc: (99.45%) (16676/16768)\n",
            "Epoch: 150 | Batch_idx: 140 |  Loss: (0.0167) | Acc: (99.46%) (17950/18048)\n",
            "Epoch: 150 | Batch_idx: 150 |  Loss: (0.0167) | Acc: (99.46%) (19224/19328)\n",
            "Epoch: 150 | Batch_idx: 160 |  Loss: (0.0168) | Acc: (99.47%) (20499/20608)\n",
            "Epoch: 150 | Batch_idx: 170 |  Loss: (0.0167) | Acc: (99.46%) (21770/21888)\n",
            "Epoch: 150 | Batch_idx: 180 |  Loss: (0.0163) | Acc: (99.47%) (23045/23168)\n",
            "Epoch: 150 | Batch_idx: 190 |  Loss: (0.0171) | Acc: (99.45%) (24314/24448)\n",
            "Epoch: 150 | Batch_idx: 200 |  Loss: (0.0168) | Acc: (99.46%) (25590/25728)\n",
            "Epoch: 150 | Batch_idx: 210 |  Loss: (0.0173) | Acc: (99.46%) (26861/27008)\n",
            "Epoch: 150 | Batch_idx: 220 |  Loss: (0.0169) | Acc: (99.47%) (28139/28288)\n",
            "Epoch: 150 | Batch_idx: 230 |  Loss: (0.0167) | Acc: (99.48%) (29415/29568)\n",
            "Epoch: 150 | Batch_idx: 240 |  Loss: (0.0171) | Acc: (99.47%) (30684/30848)\n",
            "Epoch: 150 | Batch_idx: 250 |  Loss: (0.0170) | Acc: (99.47%) (31957/32128)\n",
            "Epoch: 150 | Batch_idx: 260 |  Loss: (0.0174) | Acc: (99.45%) (33225/33408)\n",
            "Epoch: 150 | Batch_idx: 270 |  Loss: (0.0174) | Acc: (99.46%) (34500/34688)\n",
            "Epoch: 150 | Batch_idx: 280 |  Loss: (0.0171) | Acc: (99.47%) (35776/35968)\n",
            "Epoch: 150 | Batch_idx: 290 |  Loss: (0.0171) | Acc: (99.46%) (37046/37248)\n",
            "Epoch: 150 | Batch_idx: 300 |  Loss: (0.0172) | Acc: (99.45%) (38317/38528)\n",
            "Epoch: 150 | Batch_idx: 310 |  Loss: (0.0171) | Acc: (99.45%) (39588/39808)\n",
            "Epoch: 150 | Batch_idx: 320 |  Loss: (0.0171) | Acc: (99.45%) (40860/41088)\n",
            "Epoch: 150 | Batch_idx: 330 |  Loss: (0.0170) | Acc: (99.45%) (42135/42368)\n",
            "Epoch: 150 | Batch_idx: 340 |  Loss: (0.0168) | Acc: (99.45%) (43410/43648)\n",
            "Epoch: 150 | Batch_idx: 350 |  Loss: (0.0166) | Acc: (99.46%) (44684/44928)\n",
            "Epoch: 150 | Batch_idx: 360 |  Loss: (0.0168) | Acc: (99.45%) (45956/46208)\n",
            "Epoch: 150 | Batch_idx: 370 |  Loss: (0.0169) | Acc: (99.46%) (47230/47488)\n",
            "Epoch: 150 | Batch_idx: 380 |  Loss: (0.0170) | Acc: (99.45%) (48501/48768)\n",
            "Epoch: 150 | Batch_idx: 390 |  Loss: (0.0170) | Acc: (99.45%) (49723/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3878) | Acc: (91.82%) (9182/10000)\n",
            "Epoch: 151 | Batch_idx: 0 |  Loss: (0.0016) | Acc: (100.00%) (128/128)\n",
            "Epoch: 151 | Batch_idx: 10 |  Loss: (0.0172) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 151 | Batch_idx: 20 |  Loss: (0.0180) | Acc: (99.37%) (2671/2688)\n",
            "Epoch: 151 | Batch_idx: 30 |  Loss: (0.0208) | Acc: (99.27%) (3939/3968)\n",
            "Epoch: 151 | Batch_idx: 40 |  Loss: (0.0182) | Acc: (99.35%) (5214/5248)\n",
            "Epoch: 151 | Batch_idx: 50 |  Loss: (0.0177) | Acc: (99.36%) (6486/6528)\n",
            "Epoch: 151 | Batch_idx: 60 |  Loss: (0.0160) | Acc: (99.42%) (7763/7808)\n",
            "Epoch: 151 | Batch_idx: 70 |  Loss: (0.0163) | Acc: (99.39%) (9033/9088)\n",
            "Epoch: 151 | Batch_idx: 80 |  Loss: (0.0177) | Acc: (99.36%) (10302/10368)\n",
            "Epoch: 151 | Batch_idx: 90 |  Loss: (0.0181) | Acc: (99.36%) (11573/11648)\n",
            "Epoch: 151 | Batch_idx: 100 |  Loss: (0.0187) | Acc: (99.33%) (12842/12928)\n",
            "Epoch: 151 | Batch_idx: 110 |  Loss: (0.0186) | Acc: (99.32%) (14112/14208)\n",
            "Epoch: 151 | Batch_idx: 120 |  Loss: (0.0190) | Acc: (99.32%) (15383/15488)\n",
            "Epoch: 151 | Batch_idx: 130 |  Loss: (0.0190) | Acc: (99.33%) (16655/16768)\n",
            "Epoch: 151 | Batch_idx: 140 |  Loss: (0.0188) | Acc: (99.34%) (17928/18048)\n",
            "Epoch: 151 | Batch_idx: 150 |  Loss: (0.0182) | Acc: (99.36%) (19204/19328)\n",
            "Epoch: 151 | Batch_idx: 160 |  Loss: (0.0181) | Acc: (99.35%) (20475/20608)\n",
            "Epoch: 151 | Batch_idx: 170 |  Loss: (0.0181) | Acc: (99.34%) (21743/21888)\n",
            "Epoch: 151 | Batch_idx: 180 |  Loss: (0.0188) | Acc: (99.32%) (23011/23168)\n",
            "Epoch: 151 | Batch_idx: 190 |  Loss: (0.0185) | Acc: (99.33%) (24285/24448)\n",
            "Epoch: 151 | Batch_idx: 200 |  Loss: (0.0190) | Acc: (99.33%) (25555/25728)\n",
            "Epoch: 151 | Batch_idx: 210 |  Loss: (0.0188) | Acc: (99.33%) (26826/27008)\n",
            "Epoch: 151 | Batch_idx: 220 |  Loss: (0.0187) | Acc: (99.33%) (28099/28288)\n",
            "Epoch: 151 | Batch_idx: 230 |  Loss: (0.0185) | Acc: (99.34%) (29372/29568)\n",
            "Epoch: 151 | Batch_idx: 240 |  Loss: (0.0188) | Acc: (99.34%) (30643/30848)\n",
            "Epoch: 151 | Batch_idx: 250 |  Loss: (0.0185) | Acc: (99.34%) (31917/32128)\n",
            "Epoch: 151 | Batch_idx: 260 |  Loss: (0.0185) | Acc: (99.34%) (33189/33408)\n",
            "Epoch: 151 | Batch_idx: 270 |  Loss: (0.0185) | Acc: (99.35%) (34462/34688)\n",
            "Epoch: 151 | Batch_idx: 280 |  Loss: (0.0185) | Acc: (99.35%) (35734/35968)\n",
            "Epoch: 151 | Batch_idx: 290 |  Loss: (0.0182) | Acc: (99.36%) (37011/37248)\n",
            "Epoch: 151 | Batch_idx: 300 |  Loss: (0.0181) | Acc: (99.37%) (38284/38528)\n",
            "Epoch: 151 | Batch_idx: 310 |  Loss: (0.0183) | Acc: (99.36%) (39552/39808)\n",
            "Epoch: 151 | Batch_idx: 320 |  Loss: (0.0183) | Acc: (99.35%) (40822/41088)\n",
            "Epoch: 151 | Batch_idx: 330 |  Loss: (0.0184) | Acc: (99.35%) (42093/42368)\n",
            "Epoch: 151 | Batch_idx: 340 |  Loss: (0.0183) | Acc: (99.36%) (43367/43648)\n",
            "Epoch: 151 | Batch_idx: 350 |  Loss: (0.0185) | Acc: (99.36%) (44641/44928)\n",
            "Epoch: 151 | Batch_idx: 360 |  Loss: (0.0185) | Acc: (99.36%) (45914/46208)\n",
            "Epoch: 151 | Batch_idx: 370 |  Loss: (0.0185) | Acc: (99.37%) (47188/47488)\n",
            "Epoch: 151 | Batch_idx: 380 |  Loss: (0.0184) | Acc: (99.37%) (48462/48768)\n",
            "Epoch: 151 | Batch_idx: 390 |  Loss: (0.0182) | Acc: (99.38%) (49688/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3838) | Acc: (91.83%) (9183/10000)\n",
            "Epoch: 152 | Batch_idx: 0 |  Loss: (0.0330) | Acc: (98.44%) (126/128)\n",
            "Epoch: 152 | Batch_idx: 10 |  Loss: (0.0184) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 152 | Batch_idx: 20 |  Loss: (0.0229) | Acc: (99.14%) (2665/2688)\n",
            "Epoch: 152 | Batch_idx: 30 |  Loss: (0.0235) | Acc: (99.17%) (3935/3968)\n",
            "Epoch: 152 | Batch_idx: 40 |  Loss: (0.0212) | Acc: (99.26%) (5209/5248)\n",
            "Epoch: 152 | Batch_idx: 50 |  Loss: (0.0185) | Acc: (99.37%) (6487/6528)\n",
            "Epoch: 152 | Batch_idx: 60 |  Loss: (0.0178) | Acc: (99.39%) (7760/7808)\n",
            "Epoch: 152 | Batch_idx: 70 |  Loss: (0.0166) | Acc: (99.43%) (9036/9088)\n",
            "Epoch: 152 | Batch_idx: 80 |  Loss: (0.0159) | Acc: (99.46%) (10312/10368)\n",
            "Epoch: 152 | Batch_idx: 90 |  Loss: (0.0169) | Acc: (99.42%) (11580/11648)\n",
            "Epoch: 152 | Batch_idx: 100 |  Loss: (0.0166) | Acc: (99.43%) (12854/12928)\n",
            "Epoch: 152 | Batch_idx: 110 |  Loss: (0.0161) | Acc: (99.44%) (14129/14208)\n",
            "Epoch: 152 | Batch_idx: 120 |  Loss: (0.0159) | Acc: (99.44%) (15401/15488)\n",
            "Epoch: 152 | Batch_idx: 130 |  Loss: (0.0168) | Acc: (99.43%) (16672/16768)\n",
            "Epoch: 152 | Batch_idx: 140 |  Loss: (0.0166) | Acc: (99.43%) (17946/18048)\n",
            "Epoch: 152 | Batch_idx: 150 |  Loss: (0.0174) | Acc: (99.41%) (19213/19328)\n",
            "Epoch: 152 | Batch_idx: 160 |  Loss: (0.0179) | Acc: (99.39%) (20483/20608)\n",
            "Epoch: 152 | Batch_idx: 170 |  Loss: (0.0180) | Acc: (99.39%) (21755/21888)\n",
            "Epoch: 152 | Batch_idx: 180 |  Loss: (0.0178) | Acc: (99.40%) (23029/23168)\n",
            "Epoch: 152 | Batch_idx: 190 |  Loss: (0.0180) | Acc: (99.39%) (24300/24448)\n",
            "Epoch: 152 | Batch_idx: 200 |  Loss: (0.0182) | Acc: (99.39%) (25570/25728)\n",
            "Epoch: 152 | Batch_idx: 210 |  Loss: (0.0182) | Acc: (99.40%) (26845/27008)\n",
            "Epoch: 152 | Batch_idx: 220 |  Loss: (0.0182) | Acc: (99.41%) (28120/28288)\n",
            "Epoch: 152 | Batch_idx: 230 |  Loss: (0.0181) | Acc: (99.40%) (29390/29568)\n",
            "Epoch: 152 | Batch_idx: 240 |  Loss: (0.0176) | Acc: (99.41%) (30667/30848)\n",
            "Epoch: 152 | Batch_idx: 250 |  Loss: (0.0173) | Acc: (99.42%) (31943/32128)\n",
            "Epoch: 152 | Batch_idx: 260 |  Loss: (0.0173) | Acc: (99.43%) (33216/33408)\n",
            "Epoch: 152 | Batch_idx: 270 |  Loss: (0.0172) | Acc: (99.43%) (34490/34688)\n",
            "Epoch: 152 | Batch_idx: 280 |  Loss: (0.0171) | Acc: (99.43%) (35764/35968)\n",
            "Epoch: 152 | Batch_idx: 290 |  Loss: (0.0172) | Acc: (99.43%) (37037/37248)\n",
            "Epoch: 152 | Batch_idx: 300 |  Loss: (0.0172) | Acc: (99.43%) (38308/38528)\n",
            "Epoch: 152 | Batch_idx: 310 |  Loss: (0.0172) | Acc: (99.43%) (39580/39808)\n",
            "Epoch: 152 | Batch_idx: 320 |  Loss: (0.0172) | Acc: (99.43%) (40854/41088)\n",
            "Epoch: 152 | Batch_idx: 330 |  Loss: (0.0172) | Acc: (99.43%) (42125/42368)\n",
            "Epoch: 152 | Batch_idx: 340 |  Loss: (0.0176) | Acc: (99.41%) (43390/43648)\n",
            "Epoch: 152 | Batch_idx: 350 |  Loss: (0.0176) | Acc: (99.41%) (44661/44928)\n",
            "Epoch: 152 | Batch_idx: 360 |  Loss: (0.0177) | Acc: (99.40%) (45931/46208)\n",
            "Epoch: 152 | Batch_idx: 370 |  Loss: (0.0176) | Acc: (99.41%) (47206/47488)\n",
            "Epoch: 152 | Batch_idx: 380 |  Loss: (0.0175) | Acc: (99.41%) (48480/48768)\n",
            "Epoch: 152 | Batch_idx: 390 |  Loss: (0.0175) | Acc: (99.41%) (49703/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3874) | Acc: (91.63%) (9163/10000)\n",
            "Epoch: 153 | Batch_idx: 0 |  Loss: (0.0108) | Acc: (100.00%) (128/128)\n",
            "Epoch: 153 | Batch_idx: 10 |  Loss: (0.0122) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 153 | Batch_idx: 20 |  Loss: (0.0148) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 153 | Batch_idx: 30 |  Loss: (0.0161) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 153 | Batch_idx: 40 |  Loss: (0.0154) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 153 | Batch_idx: 50 |  Loss: (0.0154) | Acc: (99.51%) (6496/6528)\n",
            "Epoch: 153 | Batch_idx: 60 |  Loss: (0.0146) | Acc: (99.54%) (7772/7808)\n",
            "Epoch: 153 | Batch_idx: 70 |  Loss: (0.0146) | Acc: (99.54%) (9046/9088)\n",
            "Epoch: 153 | Batch_idx: 80 |  Loss: (0.0150) | Acc: (99.52%) (10318/10368)\n",
            "Epoch: 153 | Batch_idx: 90 |  Loss: (0.0165) | Acc: (99.48%) (11588/11648)\n",
            "Epoch: 153 | Batch_idx: 100 |  Loss: (0.0170) | Acc: (99.47%) (12859/12928)\n",
            "Epoch: 153 | Batch_idx: 110 |  Loss: (0.0164) | Acc: (99.47%) (14132/14208)\n",
            "Epoch: 153 | Batch_idx: 120 |  Loss: (0.0170) | Acc: (99.46%) (15404/15488)\n",
            "Epoch: 153 | Batch_idx: 130 |  Loss: (0.0177) | Acc: (99.44%) (16674/16768)\n",
            "Epoch: 153 | Batch_idx: 140 |  Loss: (0.0172) | Acc: (99.45%) (17948/18048)\n",
            "Epoch: 153 | Batch_idx: 150 |  Loss: (0.0173) | Acc: (99.45%) (19221/19328)\n",
            "Epoch: 153 | Batch_idx: 160 |  Loss: (0.0171) | Acc: (99.44%) (20493/20608)\n",
            "Epoch: 153 | Batch_idx: 170 |  Loss: (0.0169) | Acc: (99.46%) (21769/21888)\n",
            "Epoch: 153 | Batch_idx: 180 |  Loss: (0.0166) | Acc: (99.46%) (23044/23168)\n",
            "Epoch: 153 | Batch_idx: 190 |  Loss: (0.0169) | Acc: (99.46%) (24315/24448)\n",
            "Epoch: 153 | Batch_idx: 200 |  Loss: (0.0170) | Acc: (99.44%) (25585/25728)\n",
            "Epoch: 153 | Batch_idx: 210 |  Loss: (0.0170) | Acc: (99.44%) (26857/27008)\n",
            "Epoch: 153 | Batch_idx: 220 |  Loss: (0.0173) | Acc: (99.42%) (28125/28288)\n",
            "Epoch: 153 | Batch_idx: 230 |  Loss: (0.0175) | Acc: (99.41%) (29395/29568)\n",
            "Epoch: 153 | Batch_idx: 240 |  Loss: (0.0171) | Acc: (99.42%) (30670/30848)\n",
            "Epoch: 153 | Batch_idx: 250 |  Loss: (0.0173) | Acc: (99.42%) (31943/32128)\n",
            "Epoch: 153 | Batch_idx: 260 |  Loss: (0.0172) | Acc: (99.43%) (33217/33408)\n",
            "Epoch: 153 | Batch_idx: 270 |  Loss: (0.0173) | Acc: (99.42%) (34487/34688)\n",
            "Epoch: 153 | Batch_idx: 280 |  Loss: (0.0178) | Acc: (99.41%) (35756/35968)\n",
            "Epoch: 153 | Batch_idx: 290 |  Loss: (0.0178) | Acc: (99.41%) (37027/37248)\n",
            "Epoch: 153 | Batch_idx: 300 |  Loss: (0.0177) | Acc: (99.42%) (38304/38528)\n",
            "Epoch: 153 | Batch_idx: 310 |  Loss: (0.0177) | Acc: (99.42%) (39578/39808)\n",
            "Epoch: 153 | Batch_idx: 320 |  Loss: (0.0177) | Acc: (99.42%) (40851/41088)\n",
            "Epoch: 153 | Batch_idx: 330 |  Loss: (0.0181) | Acc: (99.41%) (42116/42368)\n",
            "Epoch: 153 | Batch_idx: 340 |  Loss: (0.0182) | Acc: (99.39%) (43383/43648)\n",
            "Epoch: 153 | Batch_idx: 350 |  Loss: (0.0182) | Acc: (99.39%) (44655/44928)\n",
            "Epoch: 153 | Batch_idx: 360 |  Loss: (0.0182) | Acc: (99.39%) (45925/46208)\n",
            "Epoch: 153 | Batch_idx: 370 |  Loss: (0.0181) | Acc: (99.39%) (47199/47488)\n",
            "Epoch: 153 | Batch_idx: 380 |  Loss: (0.0183) | Acc: (99.40%) (48473/48768)\n",
            "Epoch: 153 | Batch_idx: 390 |  Loss: (0.0181) | Acc: (99.40%) (49700/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3881) | Acc: (91.86%) (9186/10000)\n",
            "Epoch: 154 | Batch_idx: 0 |  Loss: (0.0203) | Acc: (99.22%) (127/128)\n",
            "Epoch: 154 | Batch_idx: 10 |  Loss: (0.0209) | Acc: (99.22%) (1397/1408)\n",
            "Epoch: 154 | Batch_idx: 20 |  Loss: (0.0172) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 154 | Batch_idx: 30 |  Loss: (0.0175) | Acc: (99.42%) (3945/3968)\n",
            "Epoch: 154 | Batch_idx: 40 |  Loss: (0.0188) | Acc: (99.37%) (5215/5248)\n",
            "Epoch: 154 | Batch_idx: 50 |  Loss: (0.0186) | Acc: (99.33%) (6484/6528)\n",
            "Epoch: 154 | Batch_idx: 60 |  Loss: (0.0177) | Acc: (99.37%) (7759/7808)\n",
            "Epoch: 154 | Batch_idx: 70 |  Loss: (0.0171) | Acc: (99.38%) (9032/9088)\n",
            "Epoch: 154 | Batch_idx: 80 |  Loss: (0.0174) | Acc: (99.41%) (10307/10368)\n",
            "Epoch: 154 | Batch_idx: 90 |  Loss: (0.0172) | Acc: (99.41%) (11579/11648)\n",
            "Epoch: 154 | Batch_idx: 100 |  Loss: (0.0170) | Acc: (99.42%) (12853/12928)\n",
            "Epoch: 154 | Batch_idx: 110 |  Loss: (0.0165) | Acc: (99.45%) (14130/14208)\n",
            "Epoch: 154 | Batch_idx: 120 |  Loss: (0.0168) | Acc: (99.44%) (15401/15488)\n",
            "Epoch: 154 | Batch_idx: 130 |  Loss: (0.0163) | Acc: (99.45%) (16676/16768)\n",
            "Epoch: 154 | Batch_idx: 140 |  Loss: (0.0165) | Acc: (99.43%) (17945/18048)\n",
            "Epoch: 154 | Batch_idx: 150 |  Loss: (0.0168) | Acc: (99.41%) (19213/19328)\n",
            "Epoch: 154 | Batch_idx: 160 |  Loss: (0.0165) | Acc: (99.41%) (20487/20608)\n",
            "Epoch: 154 | Batch_idx: 170 |  Loss: (0.0161) | Acc: (99.42%) (21762/21888)\n",
            "Epoch: 154 | Batch_idx: 180 |  Loss: (0.0165) | Acc: (99.41%) (23032/23168)\n",
            "Epoch: 154 | Batch_idx: 190 |  Loss: (0.0168) | Acc: (99.41%) (24303/24448)\n",
            "Epoch: 154 | Batch_idx: 200 |  Loss: (0.0170) | Acc: (99.41%) (25576/25728)\n",
            "Epoch: 154 | Batch_idx: 210 |  Loss: (0.0171) | Acc: (99.40%) (26846/27008)\n",
            "Epoch: 154 | Batch_idx: 220 |  Loss: (0.0167) | Acc: (99.41%) (28122/28288)\n",
            "Epoch: 154 | Batch_idx: 230 |  Loss: (0.0165) | Acc: (99.42%) (29397/29568)\n",
            "Epoch: 154 | Batch_idx: 240 |  Loss: (0.0168) | Acc: (99.41%) (30666/30848)\n",
            "Epoch: 154 | Batch_idx: 250 |  Loss: (0.0167) | Acc: (99.42%) (31942/32128)\n",
            "Epoch: 154 | Batch_idx: 260 |  Loss: (0.0166) | Acc: (99.42%) (33215/33408)\n",
            "Epoch: 154 | Batch_idx: 270 |  Loss: (0.0162) | Acc: (99.44%) (34494/34688)\n",
            "Epoch: 154 | Batch_idx: 280 |  Loss: (0.0161) | Acc: (99.44%) (35768/35968)\n",
            "Epoch: 154 | Batch_idx: 290 |  Loss: (0.0164) | Acc: (99.43%) (37037/37248)\n",
            "Epoch: 154 | Batch_idx: 300 |  Loss: (0.0163) | Acc: (99.43%) (38310/38528)\n",
            "Epoch: 154 | Batch_idx: 310 |  Loss: (0.0165) | Acc: (99.43%) (39581/39808)\n",
            "Epoch: 154 | Batch_idx: 320 |  Loss: (0.0167) | Acc: (99.43%) (40853/41088)\n",
            "Epoch: 154 | Batch_idx: 330 |  Loss: (0.0167) | Acc: (99.42%) (42124/42368)\n",
            "Epoch: 154 | Batch_idx: 340 |  Loss: (0.0167) | Acc: (99.42%) (43397/43648)\n",
            "Epoch: 154 | Batch_idx: 350 |  Loss: (0.0166) | Acc: (99.43%) (44670/44928)\n",
            "Epoch: 154 | Batch_idx: 360 |  Loss: (0.0167) | Acc: (99.42%) (45941/46208)\n",
            "Epoch: 154 | Batch_idx: 370 |  Loss: (0.0166) | Acc: (99.42%) (47212/47488)\n",
            "Epoch: 154 | Batch_idx: 380 |  Loss: (0.0166) | Acc: (99.43%) (48488/48768)\n",
            "Epoch: 154 | Batch_idx: 390 |  Loss: (0.0164) | Acc: (99.43%) (49717/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3901) | Acc: (91.75%) (9175/10000)\n",
            "Epoch: 155 | Batch_idx: 0 |  Loss: (0.0022) | Acc: (100.00%) (128/128)\n",
            "Epoch: 155 | Batch_idx: 10 |  Loss: (0.0131) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 155 | Batch_idx: 20 |  Loss: (0.0143) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 155 | Batch_idx: 30 |  Loss: (0.0151) | Acc: (99.47%) (3947/3968)\n",
            "Epoch: 155 | Batch_idx: 40 |  Loss: (0.0175) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 155 | Batch_idx: 50 |  Loss: (0.0173) | Acc: (99.46%) (6493/6528)\n",
            "Epoch: 155 | Batch_idx: 60 |  Loss: (0.0180) | Acc: (99.41%) (7762/7808)\n",
            "Epoch: 155 | Batch_idx: 70 |  Loss: (0.0178) | Acc: (99.39%) (9033/9088)\n",
            "Epoch: 155 | Batch_idx: 80 |  Loss: (0.0171) | Acc: (99.40%) (10306/10368)\n",
            "Epoch: 155 | Batch_idx: 90 |  Loss: (0.0189) | Acc: (99.35%) (11572/11648)\n",
            "Epoch: 155 | Batch_idx: 100 |  Loss: (0.0183) | Acc: (99.37%) (12847/12928)\n",
            "Epoch: 155 | Batch_idx: 110 |  Loss: (0.0175) | Acc: (99.41%) (14124/14208)\n",
            "Epoch: 155 | Batch_idx: 120 |  Loss: (0.0173) | Acc: (99.39%) (15394/15488)\n",
            "Epoch: 155 | Batch_idx: 130 |  Loss: (0.0168) | Acc: (99.42%) (16671/16768)\n",
            "Epoch: 155 | Batch_idx: 140 |  Loss: (0.0173) | Acc: (99.41%) (17942/18048)\n",
            "Epoch: 155 | Batch_idx: 150 |  Loss: (0.0174) | Acc: (99.41%) (19213/19328)\n",
            "Epoch: 155 | Batch_idx: 160 |  Loss: (0.0176) | Acc: (99.38%) (20481/20608)\n",
            "Epoch: 155 | Batch_idx: 170 |  Loss: (0.0176) | Acc: (99.38%) (21753/21888)\n",
            "Epoch: 155 | Batch_idx: 180 |  Loss: (0.0182) | Acc: (99.37%) (23022/23168)\n",
            "Epoch: 155 | Batch_idx: 190 |  Loss: (0.0177) | Acc: (99.39%) (24299/24448)\n",
            "Epoch: 155 | Batch_idx: 200 |  Loss: (0.0176) | Acc: (99.39%) (25572/25728)\n",
            "Epoch: 155 | Batch_idx: 210 |  Loss: (0.0173) | Acc: (99.41%) (26848/27008)\n",
            "Epoch: 155 | Batch_idx: 220 |  Loss: (0.0172) | Acc: (99.41%) (28122/28288)\n",
            "Epoch: 155 | Batch_idx: 230 |  Loss: (0.0169) | Acc: (99.42%) (29397/29568)\n",
            "Epoch: 155 | Batch_idx: 240 |  Loss: (0.0167) | Acc: (99.43%) (30672/30848)\n",
            "Epoch: 155 | Batch_idx: 250 |  Loss: (0.0169) | Acc: (99.43%) (31944/32128)\n",
            "Epoch: 155 | Batch_idx: 260 |  Loss: (0.0168) | Acc: (99.43%) (33218/33408)\n",
            "Epoch: 155 | Batch_idx: 270 |  Loss: (0.0170) | Acc: (99.42%) (34487/34688)\n",
            "Epoch: 155 | Batch_idx: 280 |  Loss: (0.0169) | Acc: (99.42%) (35759/35968)\n",
            "Epoch: 155 | Batch_idx: 290 |  Loss: (0.0167) | Acc: (99.43%) (37034/37248)\n",
            "Epoch: 155 | Batch_idx: 300 |  Loss: (0.0166) | Acc: (99.43%) (38310/38528)\n",
            "Epoch: 155 | Batch_idx: 310 |  Loss: (0.0167) | Acc: (99.43%) (39580/39808)\n",
            "Epoch: 155 | Batch_idx: 320 |  Loss: (0.0167) | Acc: (99.43%) (40853/41088)\n",
            "Epoch: 155 | Batch_idx: 330 |  Loss: (0.0168) | Acc: (99.43%) (42126/42368)\n",
            "Epoch: 155 | Batch_idx: 340 |  Loss: (0.0171) | Acc: (99.41%) (43392/43648)\n",
            "Epoch: 155 | Batch_idx: 350 |  Loss: (0.0169) | Acc: (99.42%) (44667/44928)\n",
            "Epoch: 155 | Batch_idx: 360 |  Loss: (0.0171) | Acc: (99.41%) (45937/46208)\n",
            "Epoch: 155 | Batch_idx: 370 |  Loss: (0.0171) | Acc: (99.41%) (47206/47488)\n",
            "Epoch: 155 | Batch_idx: 380 |  Loss: (0.0169) | Acc: (99.41%) (48482/48768)\n",
            "Epoch: 155 | Batch_idx: 390 |  Loss: (0.0167) | Acc: (99.42%) (49710/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3894) | Acc: (91.83%) (9183/10000)\n",
            "Epoch: 156 | Batch_idx: 0 |  Loss: (0.0076) | Acc: (100.00%) (128/128)\n",
            "Epoch: 156 | Batch_idx: 10 |  Loss: (0.0174) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 156 | Batch_idx: 20 |  Loss: (0.0216) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 156 | Batch_idx: 30 |  Loss: (0.0196) | Acc: (99.47%) (3947/3968)\n",
            "Epoch: 156 | Batch_idx: 40 |  Loss: (0.0207) | Acc: (99.39%) (5216/5248)\n",
            "Epoch: 156 | Batch_idx: 50 |  Loss: (0.0191) | Acc: (99.40%) (6489/6528)\n",
            "Epoch: 156 | Batch_idx: 60 |  Loss: (0.0186) | Acc: (99.39%) (7760/7808)\n",
            "Epoch: 156 | Batch_idx: 70 |  Loss: (0.0180) | Acc: (99.41%) (9034/9088)\n",
            "Epoch: 156 | Batch_idx: 80 |  Loss: (0.0174) | Acc: (99.45%) (10311/10368)\n",
            "Epoch: 156 | Batch_idx: 90 |  Loss: (0.0184) | Acc: (99.41%) (11579/11648)\n",
            "Epoch: 156 | Batch_idx: 100 |  Loss: (0.0186) | Acc: (99.39%) (12849/12928)\n",
            "Epoch: 156 | Batch_idx: 110 |  Loss: (0.0192) | Acc: (99.37%) (14119/14208)\n",
            "Epoch: 156 | Batch_idx: 120 |  Loss: (0.0191) | Acc: (99.35%) (15388/15488)\n",
            "Epoch: 156 | Batch_idx: 130 |  Loss: (0.0190) | Acc: (99.36%) (16661/16768)\n",
            "Epoch: 156 | Batch_idx: 140 |  Loss: (0.0194) | Acc: (99.35%) (17930/18048)\n",
            "Epoch: 156 | Batch_idx: 150 |  Loss: (0.0190) | Acc: (99.36%) (19204/19328)\n",
            "Epoch: 156 | Batch_idx: 160 |  Loss: (0.0190) | Acc: (99.36%) (20477/20608)\n",
            "Epoch: 156 | Batch_idx: 170 |  Loss: (0.0187) | Acc: (99.36%) (21748/21888)\n",
            "Epoch: 156 | Batch_idx: 180 |  Loss: (0.0184) | Acc: (99.37%) (23021/23168)\n",
            "Epoch: 156 | Batch_idx: 190 |  Loss: (0.0181) | Acc: (99.37%) (24295/24448)\n",
            "Epoch: 156 | Batch_idx: 200 |  Loss: (0.0182) | Acc: (99.38%) (25568/25728)\n",
            "Epoch: 156 | Batch_idx: 210 |  Loss: (0.0183) | Acc: (99.39%) (26842/27008)\n",
            "Epoch: 156 | Batch_idx: 220 |  Loss: (0.0186) | Acc: (99.38%) (28112/28288)\n",
            "Epoch: 156 | Batch_idx: 230 |  Loss: (0.0188) | Acc: (99.36%) (29380/29568)\n",
            "Epoch: 156 | Batch_idx: 240 |  Loss: (0.0185) | Acc: (99.37%) (30655/30848)\n",
            "Epoch: 156 | Batch_idx: 250 |  Loss: (0.0181) | Acc: (99.39%) (31932/32128)\n",
            "Epoch: 156 | Batch_idx: 260 |  Loss: (0.0180) | Acc: (99.40%) (33206/33408)\n",
            "Epoch: 156 | Batch_idx: 270 |  Loss: (0.0179) | Acc: (99.40%) (34479/34688)\n",
            "Epoch: 156 | Batch_idx: 280 |  Loss: (0.0176) | Acc: (99.41%) (35754/35968)\n",
            "Epoch: 156 | Batch_idx: 290 |  Loss: (0.0173) | Acc: (99.41%) (37030/37248)\n",
            "Epoch: 156 | Batch_idx: 300 |  Loss: (0.0172) | Acc: (99.41%) (38302/38528)\n",
            "Epoch: 156 | Batch_idx: 310 |  Loss: (0.0177) | Acc: (99.40%) (39571/39808)\n",
            "Epoch: 156 | Batch_idx: 320 |  Loss: (0.0180) | Acc: (99.40%) (40842/41088)\n",
            "Epoch: 156 | Batch_idx: 330 |  Loss: (0.0183) | Acc: (99.39%) (42110/42368)\n",
            "Epoch: 156 | Batch_idx: 340 |  Loss: (0.0184) | Acc: (99.39%) (43380/43648)\n",
            "Epoch: 156 | Batch_idx: 350 |  Loss: (0.0183) | Acc: (99.39%) (44652/44928)\n",
            "Epoch: 156 | Batch_idx: 360 |  Loss: (0.0182) | Acc: (99.39%) (45927/46208)\n",
            "Epoch: 156 | Batch_idx: 370 |  Loss: (0.0182) | Acc: (99.39%) (47199/47488)\n",
            "Epoch: 156 | Batch_idx: 380 |  Loss: (0.0181) | Acc: (99.39%) (48472/48768)\n",
            "Epoch: 156 | Batch_idx: 390 |  Loss: (0.0182) | Acc: (99.39%) (49694/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3904) | Acc: (91.81%) (9181/10000)\n",
            "Epoch: 157 | Batch_idx: 0 |  Loss: (0.0340) | Acc: (98.44%) (126/128)\n",
            "Epoch: 157 | Batch_idx: 10 |  Loss: (0.0159) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 157 | Batch_idx: 20 |  Loss: (0.0140) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 157 | Batch_idx: 30 |  Loss: (0.0177) | Acc: (99.27%) (3939/3968)\n",
            "Epoch: 157 | Batch_idx: 40 |  Loss: (0.0166) | Acc: (99.29%) (5211/5248)\n",
            "Epoch: 157 | Batch_idx: 50 |  Loss: (0.0183) | Acc: (99.30%) (6482/6528)\n",
            "Epoch: 157 | Batch_idx: 60 |  Loss: (0.0196) | Acc: (99.27%) (7751/7808)\n",
            "Epoch: 157 | Batch_idx: 70 |  Loss: (0.0187) | Acc: (99.30%) (9024/9088)\n",
            "Epoch: 157 | Batch_idx: 80 |  Loss: (0.0180) | Acc: (99.32%) (10298/10368)\n",
            "Epoch: 157 | Batch_idx: 90 |  Loss: (0.0184) | Acc: (99.33%) (11570/11648)\n",
            "Epoch: 157 | Batch_idx: 100 |  Loss: (0.0182) | Acc: (99.36%) (12845/12928)\n",
            "Epoch: 157 | Batch_idx: 110 |  Loss: (0.0185) | Acc: (99.36%) (14117/14208)\n",
            "Epoch: 157 | Batch_idx: 120 |  Loss: (0.0176) | Acc: (99.39%) (15394/15488)\n",
            "Epoch: 157 | Batch_idx: 130 |  Loss: (0.0184) | Acc: (99.36%) (16660/16768)\n",
            "Epoch: 157 | Batch_idx: 140 |  Loss: (0.0187) | Acc: (99.37%) (17934/18048)\n",
            "Epoch: 157 | Batch_idx: 150 |  Loss: (0.0180) | Acc: (99.38%) (19208/19328)\n",
            "Epoch: 157 | Batch_idx: 160 |  Loss: (0.0179) | Acc: (99.40%) (20484/20608)\n",
            "Epoch: 157 | Batch_idx: 170 |  Loss: (0.0182) | Acc: (99.39%) (21755/21888)\n",
            "Epoch: 157 | Batch_idx: 180 |  Loss: (0.0179) | Acc: (99.41%) (23031/23168)\n",
            "Epoch: 157 | Batch_idx: 190 |  Loss: (0.0175) | Acc: (99.42%) (24306/24448)\n",
            "Epoch: 157 | Batch_idx: 200 |  Loss: (0.0175) | Acc: (99.43%) (25581/25728)\n",
            "Epoch: 157 | Batch_idx: 210 |  Loss: (0.0180) | Acc: (99.41%) (26849/27008)\n",
            "Epoch: 157 | Batch_idx: 220 |  Loss: (0.0178) | Acc: (99.41%) (28122/28288)\n",
            "Epoch: 157 | Batch_idx: 230 |  Loss: (0.0175) | Acc: (99.42%) (29397/29568)\n",
            "Epoch: 157 | Batch_idx: 240 |  Loss: (0.0177) | Acc: (99.42%) (30668/30848)\n",
            "Epoch: 157 | Batch_idx: 250 |  Loss: (0.0175) | Acc: (99.42%) (31941/32128)\n",
            "Epoch: 157 | Batch_idx: 260 |  Loss: (0.0176) | Acc: (99.41%) (33212/33408)\n",
            "Epoch: 157 | Batch_idx: 270 |  Loss: (0.0175) | Acc: (99.41%) (34484/34688)\n",
            "Epoch: 157 | Batch_idx: 280 |  Loss: (0.0175) | Acc: (99.41%) (35757/35968)\n",
            "Epoch: 157 | Batch_idx: 290 |  Loss: (0.0177) | Acc: (99.41%) (37029/37248)\n",
            "Epoch: 157 | Batch_idx: 300 |  Loss: (0.0177) | Acc: (99.42%) (38303/38528)\n",
            "Epoch: 157 | Batch_idx: 310 |  Loss: (0.0176) | Acc: (99.42%) (39577/39808)\n",
            "Epoch: 157 | Batch_idx: 320 |  Loss: (0.0178) | Acc: (99.41%) (40846/41088)\n",
            "Epoch: 157 | Batch_idx: 330 |  Loss: (0.0178) | Acc: (99.40%) (42115/42368)\n",
            "Epoch: 157 | Batch_idx: 340 |  Loss: (0.0175) | Acc: (99.41%) (43392/43648)\n",
            "Epoch: 157 | Batch_idx: 350 |  Loss: (0.0177) | Acc: (99.40%) (44660/44928)\n",
            "Epoch: 157 | Batch_idx: 360 |  Loss: (0.0174) | Acc: (99.41%) (45937/46208)\n",
            "Epoch: 157 | Batch_idx: 370 |  Loss: (0.0173) | Acc: (99.41%) (47209/47488)\n",
            "Epoch: 157 | Batch_idx: 380 |  Loss: (0.0173) | Acc: (99.41%) (48479/48768)\n",
            "Epoch: 157 | Batch_idx: 390 |  Loss: (0.0175) | Acc: (99.40%) (49701/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3909) | Acc: (91.90%) (9190/10000)\n",
            "Epoch: 158 | Batch_idx: 0 |  Loss: (0.0088) | Acc: (99.22%) (127/128)\n",
            "Epoch: 158 | Batch_idx: 10 |  Loss: (0.0151) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 158 | Batch_idx: 20 |  Loss: (0.0158) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 158 | Batch_idx: 30 |  Loss: (0.0159) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 158 | Batch_idx: 40 |  Loss: (0.0162) | Acc: (99.47%) (5220/5248)\n",
            "Epoch: 158 | Batch_idx: 50 |  Loss: (0.0170) | Acc: (99.48%) (6494/6528)\n",
            "Epoch: 158 | Batch_idx: 60 |  Loss: (0.0170) | Acc: (99.46%) (7766/7808)\n",
            "Epoch: 158 | Batch_idx: 70 |  Loss: (0.0158) | Acc: (99.49%) (9042/9088)\n",
            "Epoch: 158 | Batch_idx: 80 |  Loss: (0.0163) | Acc: (99.48%) (10314/10368)\n",
            "Epoch: 158 | Batch_idx: 90 |  Loss: (0.0162) | Acc: (99.46%) (11585/11648)\n",
            "Epoch: 158 | Batch_idx: 100 |  Loss: (0.0166) | Acc: (99.44%) (12856/12928)\n",
            "Epoch: 158 | Batch_idx: 110 |  Loss: (0.0166) | Acc: (99.43%) (14127/14208)\n",
            "Epoch: 158 | Batch_idx: 120 |  Loss: (0.0161) | Acc: (99.45%) (15403/15488)\n",
            "Epoch: 158 | Batch_idx: 130 |  Loss: (0.0162) | Acc: (99.45%) (16675/16768)\n",
            "Epoch: 158 | Batch_idx: 140 |  Loss: (0.0161) | Acc: (99.46%) (17951/18048)\n",
            "Epoch: 158 | Batch_idx: 150 |  Loss: (0.0166) | Acc: (99.45%) (19222/19328)\n",
            "Epoch: 158 | Batch_idx: 160 |  Loss: (0.0170) | Acc: (99.44%) (20493/20608)\n",
            "Epoch: 158 | Batch_idx: 170 |  Loss: (0.0168) | Acc: (99.45%) (21767/21888)\n",
            "Epoch: 158 | Batch_idx: 180 |  Loss: (0.0168) | Acc: (99.45%) (23040/23168)\n",
            "Epoch: 158 | Batch_idx: 190 |  Loss: (0.0167) | Acc: (99.45%) (24314/24448)\n",
            "Epoch: 158 | Batch_idx: 200 |  Loss: (0.0166) | Acc: (99.45%) (25587/25728)\n",
            "Epoch: 158 | Batch_idx: 210 |  Loss: (0.0168) | Acc: (99.44%) (26858/27008)\n",
            "Epoch: 158 | Batch_idx: 220 |  Loss: (0.0170) | Acc: (99.43%) (28128/28288)\n",
            "Epoch: 158 | Batch_idx: 230 |  Loss: (0.0168) | Acc: (99.44%) (29403/29568)\n",
            "Epoch: 158 | Batch_idx: 240 |  Loss: (0.0167) | Acc: (99.45%) (30677/30848)\n",
            "Epoch: 158 | Batch_idx: 250 |  Loss: (0.0173) | Acc: (99.42%) (31942/32128)\n",
            "Epoch: 158 | Batch_idx: 260 |  Loss: (0.0170) | Acc: (99.42%) (33214/33408)\n",
            "Epoch: 158 | Batch_idx: 270 |  Loss: (0.0168) | Acc: (99.42%) (34487/34688)\n",
            "Epoch: 158 | Batch_idx: 280 |  Loss: (0.0169) | Acc: (99.41%) (35757/35968)\n",
            "Epoch: 158 | Batch_idx: 290 |  Loss: (0.0169) | Acc: (99.41%) (37029/37248)\n",
            "Epoch: 158 | Batch_idx: 300 |  Loss: (0.0167) | Acc: (99.42%) (38303/38528)\n",
            "Epoch: 158 | Batch_idx: 310 |  Loss: (0.0169) | Acc: (99.41%) (39575/39808)\n",
            "Epoch: 158 | Batch_idx: 320 |  Loss: (0.0168) | Acc: (99.42%) (40848/41088)\n",
            "Epoch: 158 | Batch_idx: 330 |  Loss: (0.0166) | Acc: (99.42%) (42124/42368)\n",
            "Epoch: 158 | Batch_idx: 340 |  Loss: (0.0167) | Acc: (99.43%) (43398/43648)\n",
            "Epoch: 158 | Batch_idx: 350 |  Loss: (0.0166) | Acc: (99.43%) (44672/44928)\n",
            "Epoch: 158 | Batch_idx: 360 |  Loss: (0.0166) | Acc: (99.43%) (45944/46208)\n",
            "Epoch: 158 | Batch_idx: 370 |  Loss: (0.0166) | Acc: (99.43%) (47218/47488)\n",
            "Epoch: 158 | Batch_idx: 380 |  Loss: (0.0166) | Acc: (99.43%) (48492/48768)\n",
            "Epoch: 158 | Batch_idx: 390 |  Loss: (0.0166) | Acc: (99.43%) (49716/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3880) | Acc: (91.79%) (9179/10000)\n",
            "Epoch: 159 | Batch_idx: 0 |  Loss: (0.0040) | Acc: (100.00%) (128/128)\n",
            "Epoch: 159 | Batch_idx: 10 |  Loss: (0.0211) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 159 | Batch_idx: 20 |  Loss: (0.0203) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 159 | Batch_idx: 30 |  Loss: (0.0185) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 159 | Batch_idx: 40 |  Loss: (0.0183) | Acc: (99.43%) (5218/5248)\n",
            "Epoch: 159 | Batch_idx: 50 |  Loss: (0.0168) | Acc: (99.46%) (6493/6528)\n",
            "Epoch: 159 | Batch_idx: 60 |  Loss: (0.0167) | Acc: (99.47%) (7767/7808)\n",
            "Epoch: 159 | Batch_idx: 70 |  Loss: (0.0163) | Acc: (99.49%) (9042/9088)\n",
            "Epoch: 159 | Batch_idx: 80 |  Loss: (0.0172) | Acc: (99.44%) (10310/10368)\n",
            "Epoch: 159 | Batch_idx: 90 |  Loss: (0.0173) | Acc: (99.43%) (11582/11648)\n",
            "Epoch: 159 | Batch_idx: 100 |  Loss: (0.0183) | Acc: (99.40%) (12851/12928)\n",
            "Epoch: 159 | Batch_idx: 110 |  Loss: (0.0181) | Acc: (99.42%) (14125/14208)\n",
            "Epoch: 159 | Batch_idx: 120 |  Loss: (0.0178) | Acc: (99.41%) (15397/15488)\n",
            "Epoch: 159 | Batch_idx: 130 |  Loss: (0.0174) | Acc: (99.42%) (16671/16768)\n",
            "Epoch: 159 | Batch_idx: 140 |  Loss: (0.0169) | Acc: (99.42%) (17944/18048)\n",
            "Epoch: 159 | Batch_idx: 150 |  Loss: (0.0169) | Acc: (99.43%) (19217/19328)\n",
            "Epoch: 159 | Batch_idx: 160 |  Loss: (0.0168) | Acc: (99.44%) (20492/20608)\n",
            "Epoch: 159 | Batch_idx: 170 |  Loss: (0.0165) | Acc: (99.45%) (21767/21888)\n",
            "Epoch: 159 | Batch_idx: 180 |  Loss: (0.0163) | Acc: (99.46%) (23042/23168)\n",
            "Epoch: 159 | Batch_idx: 190 |  Loss: (0.0167) | Acc: (99.44%) (24310/24448)\n",
            "Epoch: 159 | Batch_idx: 200 |  Loss: (0.0166) | Acc: (99.43%) (25581/25728)\n",
            "Epoch: 159 | Batch_idx: 210 |  Loss: (0.0170) | Acc: (99.42%) (26851/27008)\n",
            "Epoch: 159 | Batch_idx: 220 |  Loss: (0.0167) | Acc: (99.42%) (28125/28288)\n",
            "Epoch: 159 | Batch_idx: 230 |  Loss: (0.0166) | Acc: (99.43%) (29400/29568)\n",
            "Epoch: 159 | Batch_idx: 240 |  Loss: (0.0166) | Acc: (99.43%) (30671/30848)\n",
            "Epoch: 159 | Batch_idx: 250 |  Loss: (0.0164) | Acc: (99.43%) (31945/32128)\n",
            "Epoch: 159 | Batch_idx: 260 |  Loss: (0.0164) | Acc: (99.43%) (33219/33408)\n",
            "Epoch: 159 | Batch_idx: 270 |  Loss: (0.0161) | Acc: (99.44%) (34495/34688)\n",
            "Epoch: 159 | Batch_idx: 280 |  Loss: (0.0160) | Acc: (99.44%) (35765/35968)\n",
            "Epoch: 159 | Batch_idx: 290 |  Loss: (0.0158) | Acc: (99.45%) (37043/37248)\n",
            "Epoch: 159 | Batch_idx: 300 |  Loss: (0.0158) | Acc: (99.45%) (38318/38528)\n",
            "Epoch: 159 | Batch_idx: 310 |  Loss: (0.0158) | Acc: (99.45%) (39591/39808)\n",
            "Epoch: 159 | Batch_idx: 320 |  Loss: (0.0156) | Acc: (99.46%) (40867/41088)\n",
            "Epoch: 159 | Batch_idx: 330 |  Loss: (0.0157) | Acc: (99.46%) (42140/42368)\n",
            "Epoch: 159 | Batch_idx: 340 |  Loss: (0.0157) | Acc: (99.46%) (43414/43648)\n",
            "Epoch: 159 | Batch_idx: 350 |  Loss: (0.0158) | Acc: (99.47%) (44688/44928)\n",
            "Epoch: 159 | Batch_idx: 360 |  Loss: (0.0159) | Acc: (99.47%) (45961/46208)\n",
            "Epoch: 159 | Batch_idx: 370 |  Loss: (0.0159) | Acc: (99.47%) (47234/47488)\n",
            "Epoch: 159 | Batch_idx: 380 |  Loss: (0.0161) | Acc: (99.46%) (48503/48768)\n",
            "Epoch: 159 | Batch_idx: 390 |  Loss: (0.0160) | Acc: (99.46%) (49730/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3884) | Acc: (91.77%) (9177/10000)\n",
            "Epoch: 160 | Batch_idx: 0 |  Loss: (0.0646) | Acc: (98.44%) (126/128)\n",
            "Epoch: 160 | Batch_idx: 10 |  Loss: (0.0270) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 160 | Batch_idx: 20 |  Loss: (0.0255) | Acc: (99.11%) (2664/2688)\n",
            "Epoch: 160 | Batch_idx: 30 |  Loss: (0.0225) | Acc: (99.27%) (3939/3968)\n",
            "Epoch: 160 | Batch_idx: 40 |  Loss: (0.0211) | Acc: (99.35%) (5214/5248)\n",
            "Epoch: 160 | Batch_idx: 50 |  Loss: (0.0195) | Acc: (99.39%) (6488/6528)\n",
            "Epoch: 160 | Batch_idx: 60 |  Loss: (0.0190) | Acc: (99.36%) (7758/7808)\n",
            "Epoch: 160 | Batch_idx: 70 |  Loss: (0.0185) | Acc: (99.36%) (9030/9088)\n",
            "Epoch: 160 | Batch_idx: 80 |  Loss: (0.0190) | Acc: (99.33%) (10299/10368)\n",
            "Epoch: 160 | Batch_idx: 90 |  Loss: (0.0187) | Acc: (99.32%) (11569/11648)\n",
            "Epoch: 160 | Batch_idx: 100 |  Loss: (0.0190) | Acc: (99.31%) (12839/12928)\n",
            "Epoch: 160 | Batch_idx: 110 |  Loss: (0.0181) | Acc: (99.35%) (14115/14208)\n",
            "Epoch: 160 | Batch_idx: 120 |  Loss: (0.0184) | Acc: (99.34%) (15386/15488)\n",
            "Epoch: 160 | Batch_idx: 130 |  Loss: (0.0178) | Acc: (99.36%) (16660/16768)\n",
            "Epoch: 160 | Batch_idx: 140 |  Loss: (0.0173) | Acc: (99.37%) (17935/18048)\n",
            "Epoch: 160 | Batch_idx: 150 |  Loss: (0.0174) | Acc: (99.37%) (19207/19328)\n",
            "Epoch: 160 | Batch_idx: 160 |  Loss: (0.0172) | Acc: (99.38%) (20480/20608)\n",
            "Epoch: 160 | Batch_idx: 170 |  Loss: (0.0168) | Acc: (99.39%) (21755/21888)\n",
            "Epoch: 160 | Batch_idx: 180 |  Loss: (0.0166) | Acc: (99.40%) (23029/23168)\n",
            "Epoch: 160 | Batch_idx: 190 |  Loss: (0.0166) | Acc: (99.39%) (24299/24448)\n",
            "Epoch: 160 | Batch_idx: 200 |  Loss: (0.0162) | Acc: (99.41%) (25576/25728)\n",
            "Epoch: 160 | Batch_idx: 210 |  Loss: (0.0162) | Acc: (99.42%) (26851/27008)\n",
            "Epoch: 160 | Batch_idx: 220 |  Loss: (0.0163) | Acc: (99.42%) (28123/28288)\n",
            "Epoch: 160 | Batch_idx: 230 |  Loss: (0.0162) | Acc: (99.43%) (29398/29568)\n",
            "Epoch: 160 | Batch_idx: 240 |  Loss: (0.0157) | Acc: (99.44%) (30676/30848)\n",
            "Epoch: 160 | Batch_idx: 250 |  Loss: (0.0156) | Acc: (99.44%) (31949/32128)\n",
            "Epoch: 160 | Batch_idx: 260 |  Loss: (0.0157) | Acc: (99.44%) (33221/33408)\n",
            "Epoch: 160 | Batch_idx: 270 |  Loss: (0.0157) | Acc: (99.44%) (34493/34688)\n",
            "Epoch: 160 | Batch_idx: 280 |  Loss: (0.0156) | Acc: (99.44%) (35768/35968)\n",
            "Epoch: 160 | Batch_idx: 290 |  Loss: (0.0157) | Acc: (99.44%) (37041/37248)\n",
            "Epoch: 160 | Batch_idx: 300 |  Loss: (0.0156) | Acc: (99.45%) (38317/38528)\n",
            "Epoch: 160 | Batch_idx: 310 |  Loss: (0.0156) | Acc: (99.45%) (39589/39808)\n",
            "Epoch: 160 | Batch_idx: 320 |  Loss: (0.0159) | Acc: (99.44%) (40858/41088)\n",
            "Epoch: 160 | Batch_idx: 330 |  Loss: (0.0161) | Acc: (99.43%) (42125/42368)\n",
            "Epoch: 160 | Batch_idx: 340 |  Loss: (0.0161) | Acc: (99.42%) (43397/43648)\n",
            "Epoch: 160 | Batch_idx: 350 |  Loss: (0.0166) | Acc: (99.41%) (44664/44928)\n",
            "Epoch: 160 | Batch_idx: 360 |  Loss: (0.0165) | Acc: (99.42%) (45938/46208)\n",
            "Epoch: 160 | Batch_idx: 370 |  Loss: (0.0163) | Acc: (99.43%) (47215/47488)\n",
            "Epoch: 160 | Batch_idx: 380 |  Loss: (0.0162) | Acc: (99.43%) (48488/48768)\n",
            "Epoch: 160 | Batch_idx: 390 |  Loss: (0.0163) | Acc: (99.42%) (49712/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3898) | Acc: (91.83%) (9183/10000)\n",
            "Epoch: 161 | Batch_idx: 0 |  Loss: (0.0052) | Acc: (100.00%) (128/128)\n",
            "Epoch: 161 | Batch_idx: 10 |  Loss: (0.0150) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 161 | Batch_idx: 20 |  Loss: (0.0193) | Acc: (99.26%) (2668/2688)\n",
            "Epoch: 161 | Batch_idx: 30 |  Loss: (0.0186) | Acc: (99.29%) (3940/3968)\n",
            "Epoch: 161 | Batch_idx: 40 |  Loss: (0.0180) | Acc: (99.33%) (5213/5248)\n",
            "Epoch: 161 | Batch_idx: 50 |  Loss: (0.0173) | Acc: (99.39%) (6488/6528)\n",
            "Epoch: 161 | Batch_idx: 60 |  Loss: (0.0163) | Acc: (99.40%) (7761/7808)\n",
            "Epoch: 161 | Batch_idx: 70 |  Loss: (0.0158) | Acc: (99.45%) (9038/9088)\n",
            "Epoch: 161 | Batch_idx: 80 |  Loss: (0.0164) | Acc: (99.43%) (10309/10368)\n",
            "Epoch: 161 | Batch_idx: 90 |  Loss: (0.0176) | Acc: (99.42%) (11580/11648)\n",
            "Epoch: 161 | Batch_idx: 100 |  Loss: (0.0166) | Acc: (99.45%) (12857/12928)\n",
            "Epoch: 161 | Batch_idx: 110 |  Loss: (0.0172) | Acc: (99.44%) (14129/14208)\n",
            "Epoch: 161 | Batch_idx: 120 |  Loss: (0.0168) | Acc: (99.46%) (15405/15488)\n",
            "Epoch: 161 | Batch_idx: 130 |  Loss: (0.0166) | Acc: (99.46%) (16678/16768)\n",
            "Epoch: 161 | Batch_idx: 140 |  Loss: (0.0171) | Acc: (99.46%) (17950/18048)\n",
            "Epoch: 161 | Batch_idx: 150 |  Loss: (0.0169) | Acc: (99.47%) (19225/19328)\n",
            "Epoch: 161 | Batch_idx: 160 |  Loss: (0.0172) | Acc: (99.44%) (20493/20608)\n",
            "Epoch: 161 | Batch_idx: 170 |  Loss: (0.0171) | Acc: (99.44%) (21766/21888)\n",
            "Epoch: 161 | Batch_idx: 180 |  Loss: (0.0168) | Acc: (99.46%) (23042/23168)\n",
            "Epoch: 161 | Batch_idx: 190 |  Loss: (0.0165) | Acc: (99.46%) (24317/24448)\n",
            "Epoch: 161 | Batch_idx: 200 |  Loss: (0.0162) | Acc: (99.47%) (25592/25728)\n",
            "Epoch: 161 | Batch_idx: 210 |  Loss: (0.0165) | Acc: (99.46%) (26863/27008)\n",
            "Epoch: 161 | Batch_idx: 220 |  Loss: (0.0165) | Acc: (99.46%) (28135/28288)\n",
            "Epoch: 161 | Batch_idx: 230 |  Loss: (0.0165) | Acc: (99.46%) (29407/29568)\n",
            "Epoch: 161 | Batch_idx: 240 |  Loss: (0.0166) | Acc: (99.46%) (30680/30848)\n",
            "Epoch: 161 | Batch_idx: 250 |  Loss: (0.0165) | Acc: (99.46%) (31954/32128)\n",
            "Epoch: 161 | Batch_idx: 260 |  Loss: (0.0167) | Acc: (99.45%) (33223/33408)\n",
            "Epoch: 161 | Batch_idx: 270 |  Loss: (0.0167) | Acc: (99.44%) (34494/34688)\n",
            "Epoch: 161 | Batch_idx: 280 |  Loss: (0.0168) | Acc: (99.44%) (35768/35968)\n",
            "Epoch: 161 | Batch_idx: 290 |  Loss: (0.0168) | Acc: (99.44%) (37040/37248)\n",
            "Epoch: 161 | Batch_idx: 300 |  Loss: (0.0171) | Acc: (99.43%) (38310/38528)\n",
            "Epoch: 161 | Batch_idx: 310 |  Loss: (0.0168) | Acc: (99.45%) (39589/39808)\n",
            "Epoch: 161 | Batch_idx: 320 |  Loss: (0.0164) | Acc: (99.46%) (40868/41088)\n",
            "Epoch: 161 | Batch_idx: 330 |  Loss: (0.0164) | Acc: (99.47%) (42142/42368)\n",
            "Epoch: 161 | Batch_idx: 340 |  Loss: (0.0165) | Acc: (99.46%) (43413/43648)\n",
            "Epoch: 161 | Batch_idx: 350 |  Loss: (0.0162) | Acc: (99.47%) (44690/44928)\n",
            "Epoch: 161 | Batch_idx: 360 |  Loss: (0.0162) | Acc: (99.47%) (45964/46208)\n",
            "Epoch: 161 | Batch_idx: 370 |  Loss: (0.0163) | Acc: (99.47%) (47234/47488)\n",
            "Epoch: 161 | Batch_idx: 380 |  Loss: (0.0165) | Acc: (99.46%) (48506/48768)\n",
            "Epoch: 161 | Batch_idx: 390 |  Loss: (0.0165) | Acc: (99.47%) (49733/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3922) | Acc: (91.76%) (9176/10000)\n",
            "Epoch: 162 | Batch_idx: 0 |  Loss: (0.0125) | Acc: (100.00%) (128/128)\n",
            "Epoch: 162 | Batch_idx: 10 |  Loss: (0.0239) | Acc: (99.15%) (1396/1408)\n",
            "Epoch: 162 | Batch_idx: 20 |  Loss: (0.0210) | Acc: (99.22%) (2667/2688)\n",
            "Epoch: 162 | Batch_idx: 30 |  Loss: (0.0175) | Acc: (99.27%) (3939/3968)\n",
            "Epoch: 162 | Batch_idx: 40 |  Loss: (0.0168) | Acc: (99.29%) (5211/5248)\n",
            "Epoch: 162 | Batch_idx: 50 |  Loss: (0.0164) | Acc: (99.33%) (6484/6528)\n",
            "Epoch: 162 | Batch_idx: 60 |  Loss: (0.0155) | Acc: (99.39%) (7760/7808)\n",
            "Epoch: 162 | Batch_idx: 70 |  Loss: (0.0153) | Acc: (99.39%) (9033/9088)\n",
            "Epoch: 162 | Batch_idx: 80 |  Loss: (0.0155) | Acc: (99.41%) (10307/10368)\n",
            "Epoch: 162 | Batch_idx: 90 |  Loss: (0.0153) | Acc: (99.43%) (11582/11648)\n",
            "Epoch: 162 | Batch_idx: 100 |  Loss: (0.0151) | Acc: (99.44%) (12856/12928)\n",
            "Epoch: 162 | Batch_idx: 110 |  Loss: (0.0149) | Acc: (99.46%) (14131/14208)\n",
            "Epoch: 162 | Batch_idx: 120 |  Loss: (0.0144) | Acc: (99.49%) (15409/15488)\n",
            "Epoch: 162 | Batch_idx: 130 |  Loss: (0.0152) | Acc: (99.48%) (16680/16768)\n",
            "Epoch: 162 | Batch_idx: 140 |  Loss: (0.0153) | Acc: (99.47%) (17953/18048)\n",
            "Epoch: 162 | Batch_idx: 150 |  Loss: (0.0149) | Acc: (99.49%) (19230/19328)\n",
            "Epoch: 162 | Batch_idx: 160 |  Loss: (0.0145) | Acc: (99.51%) (20506/20608)\n",
            "Epoch: 162 | Batch_idx: 170 |  Loss: (0.0150) | Acc: (99.49%) (21776/21888)\n",
            "Epoch: 162 | Batch_idx: 180 |  Loss: (0.0152) | Acc: (99.48%) (23047/23168)\n",
            "Epoch: 162 | Batch_idx: 190 |  Loss: (0.0156) | Acc: (99.46%) (24316/24448)\n",
            "Epoch: 162 | Batch_idx: 200 |  Loss: (0.0157) | Acc: (99.46%) (25590/25728)\n",
            "Epoch: 162 | Batch_idx: 210 |  Loss: (0.0160) | Acc: (99.46%) (26861/27008)\n",
            "Epoch: 162 | Batch_idx: 220 |  Loss: (0.0166) | Acc: (99.43%) (28127/28288)\n",
            "Epoch: 162 | Batch_idx: 230 |  Loss: (0.0164) | Acc: (99.44%) (29403/29568)\n",
            "Epoch: 162 | Batch_idx: 240 |  Loss: (0.0162) | Acc: (99.45%) (30679/30848)\n",
            "Epoch: 162 | Batch_idx: 250 |  Loss: (0.0163) | Acc: (99.45%) (31950/32128)\n",
            "Epoch: 162 | Batch_idx: 260 |  Loss: (0.0167) | Acc: (99.45%) (33223/33408)\n",
            "Epoch: 162 | Batch_idx: 270 |  Loss: (0.0163) | Acc: (99.46%) (34500/34688)\n",
            "Epoch: 162 | Batch_idx: 280 |  Loss: (0.0163) | Acc: (99.46%) (35774/35968)\n",
            "Epoch: 162 | Batch_idx: 290 |  Loss: (0.0163) | Acc: (99.46%) (37047/37248)\n",
            "Epoch: 162 | Batch_idx: 300 |  Loss: (0.0163) | Acc: (99.46%) (38321/38528)\n",
            "Epoch: 162 | Batch_idx: 310 |  Loss: (0.0163) | Acc: (99.46%) (39593/39808)\n",
            "Epoch: 162 | Batch_idx: 320 |  Loss: (0.0163) | Acc: (99.46%) (40868/41088)\n",
            "Epoch: 162 | Batch_idx: 330 |  Loss: (0.0163) | Acc: (99.47%) (42143/42368)\n",
            "Epoch: 162 | Batch_idx: 340 |  Loss: (0.0163) | Acc: (99.46%) (43411/43648)\n",
            "Epoch: 162 | Batch_idx: 350 |  Loss: (0.0162) | Acc: (99.45%) (44683/44928)\n",
            "Epoch: 162 | Batch_idx: 360 |  Loss: (0.0164) | Acc: (99.46%) (45957/46208)\n",
            "Epoch: 162 | Batch_idx: 370 |  Loss: (0.0163) | Acc: (99.46%) (47230/47488)\n",
            "Epoch: 162 | Batch_idx: 380 |  Loss: (0.0164) | Acc: (99.45%) (48501/48768)\n",
            "Epoch: 162 | Batch_idx: 390 |  Loss: (0.0165) | Acc: (99.45%) (49724/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3884) | Acc: (91.95%) (9195/10000)\n",
            "Epoch: 163 | Batch_idx: 0 |  Loss: (0.0132) | Acc: (100.00%) (128/128)\n",
            "Epoch: 163 | Batch_idx: 10 |  Loss: (0.0109) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 163 | Batch_idx: 20 |  Loss: (0.0143) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 163 | Batch_idx: 30 |  Loss: (0.0128) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 163 | Batch_idx: 40 |  Loss: (0.0146) | Acc: (99.49%) (5221/5248)\n",
            "Epoch: 163 | Batch_idx: 50 |  Loss: (0.0147) | Acc: (99.48%) (6494/6528)\n",
            "Epoch: 163 | Batch_idx: 60 |  Loss: (0.0142) | Acc: (99.53%) (7771/7808)\n",
            "Epoch: 163 | Batch_idx: 70 |  Loss: (0.0160) | Acc: (99.46%) (9039/9088)\n",
            "Epoch: 163 | Batch_idx: 80 |  Loss: (0.0150) | Acc: (99.49%) (10315/10368)\n",
            "Epoch: 163 | Batch_idx: 90 |  Loss: (0.0154) | Acc: (99.48%) (11588/11648)\n",
            "Epoch: 163 | Batch_idx: 100 |  Loss: (0.0157) | Acc: (99.46%) (12858/12928)\n",
            "Epoch: 163 | Batch_idx: 110 |  Loss: (0.0159) | Acc: (99.47%) (14132/14208)\n",
            "Epoch: 163 | Batch_idx: 120 |  Loss: (0.0158) | Acc: (99.47%) (15406/15488)\n",
            "Epoch: 163 | Batch_idx: 130 |  Loss: (0.0170) | Acc: (99.46%) (16678/16768)\n",
            "Epoch: 163 | Batch_idx: 140 |  Loss: (0.0166) | Acc: (99.48%) (17954/18048)\n",
            "Epoch: 163 | Batch_idx: 150 |  Loss: (0.0168) | Acc: (99.47%) (19226/19328)\n",
            "Epoch: 163 | Batch_idx: 160 |  Loss: (0.0165) | Acc: (99.48%) (20501/20608)\n",
            "Epoch: 163 | Batch_idx: 170 |  Loss: (0.0161) | Acc: (99.49%) (21776/21888)\n",
            "Epoch: 163 | Batch_idx: 180 |  Loss: (0.0161) | Acc: (99.49%) (23050/23168)\n",
            "Epoch: 163 | Batch_idx: 190 |  Loss: (0.0160) | Acc: (99.49%) (24324/24448)\n",
            "Epoch: 163 | Batch_idx: 200 |  Loss: (0.0163) | Acc: (99.48%) (25594/25728)\n",
            "Epoch: 163 | Batch_idx: 210 |  Loss: (0.0164) | Acc: (99.49%) (26869/27008)\n",
            "Epoch: 163 | Batch_idx: 220 |  Loss: (0.0166) | Acc: (99.48%) (28142/28288)\n",
            "Epoch: 163 | Batch_idx: 230 |  Loss: (0.0166) | Acc: (99.49%) (29416/29568)\n",
            "Epoch: 163 | Batch_idx: 240 |  Loss: (0.0163) | Acc: (99.49%) (30692/30848)\n",
            "Epoch: 163 | Batch_idx: 250 |  Loss: (0.0162) | Acc: (99.49%) (31964/32128)\n",
            "Epoch: 163 | Batch_idx: 260 |  Loss: (0.0161) | Acc: (99.49%) (33239/33408)\n",
            "Epoch: 163 | Batch_idx: 270 |  Loss: (0.0165) | Acc: (99.49%) (34511/34688)\n",
            "Epoch: 163 | Batch_idx: 280 |  Loss: (0.0162) | Acc: (99.50%) (35787/35968)\n",
            "Epoch: 163 | Batch_idx: 290 |  Loss: (0.0161) | Acc: (99.50%) (37061/37248)\n",
            "Epoch: 163 | Batch_idx: 300 |  Loss: (0.0160) | Acc: (99.51%) (38338/38528)\n",
            "Epoch: 163 | Batch_idx: 310 |  Loss: (0.0159) | Acc: (99.51%) (39614/39808)\n",
            "Epoch: 163 | Batch_idx: 320 |  Loss: (0.0159) | Acc: (99.51%) (40887/41088)\n",
            "Epoch: 163 | Batch_idx: 330 |  Loss: (0.0160) | Acc: (99.50%) (42157/42368)\n",
            "Epoch: 163 | Batch_idx: 340 |  Loss: (0.0160) | Acc: (99.50%) (43429/43648)\n",
            "Epoch: 163 | Batch_idx: 350 |  Loss: (0.0159) | Acc: (99.50%) (44705/44928)\n",
            "Epoch: 163 | Batch_idx: 360 |  Loss: (0.0158) | Acc: (99.50%) (45979/46208)\n",
            "Epoch: 163 | Batch_idx: 370 |  Loss: (0.0156) | Acc: (99.51%) (47253/47488)\n",
            "Epoch: 163 | Batch_idx: 380 |  Loss: (0.0155) | Acc: (99.51%) (48529/48768)\n",
            "Epoch: 163 | Batch_idx: 390 |  Loss: (0.0155) | Acc: (99.51%) (49754/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3917) | Acc: (91.89%) (9189/10000)\n",
            "Epoch: 164 | Batch_idx: 0 |  Loss: (0.0094) | Acc: (99.22%) (127/128)\n",
            "Epoch: 164 | Batch_idx: 10 |  Loss: (0.0120) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 164 | Batch_idx: 20 |  Loss: (0.0115) | Acc: (99.52%) (2675/2688)\n",
            "Epoch: 164 | Batch_idx: 30 |  Loss: (0.0160) | Acc: (99.32%) (3941/3968)\n",
            "Epoch: 164 | Batch_idx: 40 |  Loss: (0.0153) | Acc: (99.37%) (5215/5248)\n",
            "Epoch: 164 | Batch_idx: 50 |  Loss: (0.0152) | Acc: (99.40%) (6489/6528)\n",
            "Epoch: 164 | Batch_idx: 60 |  Loss: (0.0159) | Acc: (99.40%) (7761/7808)\n",
            "Epoch: 164 | Batch_idx: 70 |  Loss: (0.0155) | Acc: (99.42%) (9035/9088)\n",
            "Epoch: 164 | Batch_idx: 80 |  Loss: (0.0156) | Acc: (99.43%) (10309/10368)\n",
            "Epoch: 164 | Batch_idx: 90 |  Loss: (0.0160) | Acc: (99.40%) (11578/11648)\n",
            "Epoch: 164 | Batch_idx: 100 |  Loss: (0.0159) | Acc: (99.40%) (12851/12928)\n",
            "Epoch: 164 | Batch_idx: 110 |  Loss: (0.0151) | Acc: (99.44%) (14129/14208)\n",
            "Epoch: 164 | Batch_idx: 120 |  Loss: (0.0149) | Acc: (99.46%) (15404/15488)\n",
            "Epoch: 164 | Batch_idx: 130 |  Loss: (0.0154) | Acc: (99.43%) (16673/16768)\n",
            "Epoch: 164 | Batch_idx: 140 |  Loss: (0.0153) | Acc: (99.43%) (17945/18048)\n",
            "Epoch: 164 | Batch_idx: 150 |  Loss: (0.0155) | Acc: (99.43%) (19217/19328)\n",
            "Epoch: 164 | Batch_idx: 160 |  Loss: (0.0160) | Acc: (99.42%) (20488/20608)\n",
            "Epoch: 164 | Batch_idx: 170 |  Loss: (0.0157) | Acc: (99.42%) (21762/21888)\n",
            "Epoch: 164 | Batch_idx: 180 |  Loss: (0.0157) | Acc: (99.44%) (23038/23168)\n",
            "Epoch: 164 | Batch_idx: 190 |  Loss: (0.0155) | Acc: (99.44%) (24312/24448)\n",
            "Epoch: 164 | Batch_idx: 200 |  Loss: (0.0154) | Acc: (99.45%) (25587/25728)\n",
            "Epoch: 164 | Batch_idx: 210 |  Loss: (0.0156) | Acc: (99.45%) (26859/27008)\n",
            "Epoch: 164 | Batch_idx: 220 |  Loss: (0.0155) | Acc: (99.46%) (28134/28288)\n",
            "Epoch: 164 | Batch_idx: 230 |  Loss: (0.0154) | Acc: (99.46%) (29409/29568)\n",
            "Epoch: 164 | Batch_idx: 240 |  Loss: (0.0156) | Acc: (99.45%) (30679/30848)\n",
            "Epoch: 164 | Batch_idx: 250 |  Loss: (0.0154) | Acc: (99.46%) (31956/32128)\n",
            "Epoch: 164 | Batch_idx: 260 |  Loss: (0.0152) | Acc: (99.48%) (33233/33408)\n",
            "Epoch: 164 | Batch_idx: 270 |  Loss: (0.0154) | Acc: (99.47%) (34505/34688)\n",
            "Epoch: 164 | Batch_idx: 280 |  Loss: (0.0152) | Acc: (99.48%) (35782/35968)\n",
            "Epoch: 164 | Batch_idx: 290 |  Loss: (0.0155) | Acc: (99.47%) (37052/37248)\n",
            "Epoch: 164 | Batch_idx: 300 |  Loss: (0.0154) | Acc: (99.47%) (38324/38528)\n",
            "Epoch: 164 | Batch_idx: 310 |  Loss: (0.0153) | Acc: (99.47%) (39598/39808)\n",
            "Epoch: 164 | Batch_idx: 320 |  Loss: (0.0155) | Acc: (99.47%) (40872/41088)\n",
            "Epoch: 164 | Batch_idx: 330 |  Loss: (0.0156) | Acc: (99.48%) (42146/42368)\n",
            "Epoch: 164 | Batch_idx: 340 |  Loss: (0.0156) | Acc: (99.48%) (43420/43648)\n",
            "Epoch: 164 | Batch_idx: 350 |  Loss: (0.0155) | Acc: (99.48%) (44694/44928)\n",
            "Epoch: 164 | Batch_idx: 360 |  Loss: (0.0155) | Acc: (99.48%) (45968/46208)\n",
            "Epoch: 164 | Batch_idx: 370 |  Loss: (0.0153) | Acc: (99.49%) (47244/47488)\n",
            "Epoch: 164 | Batch_idx: 380 |  Loss: (0.0151) | Acc: (99.49%) (48521/48768)\n",
            "Epoch: 164 | Batch_idx: 390 |  Loss: (0.0153) | Acc: (99.49%) (49743/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3904) | Acc: (91.92%) (9192/10000)\n",
            "Epoch: 165 | Batch_idx: 0 |  Loss: (0.0553) | Acc: (98.44%) (126/128)\n",
            "Epoch: 165 | Batch_idx: 10 |  Loss: (0.0130) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 165 | Batch_idx: 20 |  Loss: (0.0138) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 165 | Batch_idx: 30 |  Loss: (0.0141) | Acc: (99.62%) (3953/3968)\n",
            "Epoch: 165 | Batch_idx: 40 |  Loss: (0.0141) | Acc: (99.60%) (5227/5248)\n",
            "Epoch: 165 | Batch_idx: 50 |  Loss: (0.0153) | Acc: (99.54%) (6498/6528)\n",
            "Epoch: 165 | Batch_idx: 60 |  Loss: (0.0155) | Acc: (99.54%) (7772/7808)\n",
            "Epoch: 165 | Batch_idx: 70 |  Loss: (0.0160) | Acc: (99.50%) (9043/9088)\n",
            "Epoch: 165 | Batch_idx: 80 |  Loss: (0.0166) | Acc: (99.49%) (10315/10368)\n",
            "Epoch: 165 | Batch_idx: 90 |  Loss: (0.0163) | Acc: (99.48%) (11587/11648)\n",
            "Epoch: 165 | Batch_idx: 100 |  Loss: (0.0159) | Acc: (99.47%) (12860/12928)\n",
            "Epoch: 165 | Batch_idx: 110 |  Loss: (0.0157) | Acc: (99.48%) (14134/14208)\n",
            "Epoch: 165 | Batch_idx: 120 |  Loss: (0.0160) | Acc: (99.44%) (15402/15488)\n",
            "Epoch: 165 | Batch_idx: 130 |  Loss: (0.0154) | Acc: (99.47%) (16679/16768)\n",
            "Epoch: 165 | Batch_idx: 140 |  Loss: (0.0160) | Acc: (99.45%) (17949/18048)\n",
            "Epoch: 165 | Batch_idx: 150 |  Loss: (0.0157) | Acc: (99.46%) (19223/19328)\n",
            "Epoch: 165 | Batch_idx: 160 |  Loss: (0.0162) | Acc: (99.44%) (20493/20608)\n",
            "Epoch: 165 | Batch_idx: 170 |  Loss: (0.0165) | Acc: (99.44%) (21765/21888)\n",
            "Epoch: 165 | Batch_idx: 180 |  Loss: (0.0164) | Acc: (99.43%) (23037/23168)\n",
            "Epoch: 165 | Batch_idx: 190 |  Loss: (0.0162) | Acc: (99.44%) (24312/24448)\n",
            "Epoch: 165 | Batch_idx: 200 |  Loss: (0.0162) | Acc: (99.46%) (25588/25728)\n",
            "Epoch: 165 | Batch_idx: 210 |  Loss: (0.0163) | Acc: (99.46%) (26863/27008)\n",
            "Epoch: 165 | Batch_idx: 220 |  Loss: (0.0163) | Acc: (99.46%) (28135/28288)\n",
            "Epoch: 165 | Batch_idx: 230 |  Loss: (0.0162) | Acc: (99.47%) (29412/29568)\n",
            "Epoch: 165 | Batch_idx: 240 |  Loss: (0.0160) | Acc: (99.47%) (30684/30848)\n",
            "Epoch: 165 | Batch_idx: 250 |  Loss: (0.0159) | Acc: (99.47%) (31958/32128)\n",
            "Epoch: 165 | Batch_idx: 260 |  Loss: (0.0158) | Acc: (99.47%) (33231/33408)\n",
            "Epoch: 165 | Batch_idx: 270 |  Loss: (0.0158) | Acc: (99.47%) (34504/34688)\n",
            "Epoch: 165 | Batch_idx: 280 |  Loss: (0.0159) | Acc: (99.46%) (35773/35968)\n",
            "Epoch: 165 | Batch_idx: 290 |  Loss: (0.0162) | Acc: (99.45%) (37044/37248)\n",
            "Epoch: 165 | Batch_idx: 300 |  Loss: (0.0164) | Acc: (99.45%) (38315/38528)\n",
            "Epoch: 165 | Batch_idx: 310 |  Loss: (0.0162) | Acc: (99.45%) (39590/39808)\n",
            "Epoch: 165 | Batch_idx: 320 |  Loss: (0.0166) | Acc: (99.45%) (40861/41088)\n",
            "Epoch: 165 | Batch_idx: 330 |  Loss: (0.0167) | Acc: (99.44%) (42132/42368)\n",
            "Epoch: 165 | Batch_idx: 340 |  Loss: (0.0168) | Acc: (99.44%) (43402/43648)\n",
            "Epoch: 165 | Batch_idx: 350 |  Loss: (0.0170) | Acc: (99.43%) (44672/44928)\n",
            "Epoch: 165 | Batch_idx: 360 |  Loss: (0.0170) | Acc: (99.43%) (45946/46208)\n",
            "Epoch: 165 | Batch_idx: 370 |  Loss: (0.0170) | Acc: (99.43%) (47218/47488)\n",
            "Epoch: 165 | Batch_idx: 380 |  Loss: (0.0171) | Acc: (99.43%) (48491/48768)\n",
            "Epoch: 165 | Batch_idx: 390 |  Loss: (0.0174) | Acc: (99.42%) (49711/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3930) | Acc: (92.03%) (9203/10000)\n",
            "Epoch: 166 | Batch_idx: 0 |  Loss: (0.0279) | Acc: (99.22%) (127/128)\n",
            "Epoch: 166 | Batch_idx: 10 |  Loss: (0.0163) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 166 | Batch_idx: 20 |  Loss: (0.0147) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 166 | Batch_idx: 30 |  Loss: (0.0150) | Acc: (99.47%) (3947/3968)\n",
            "Epoch: 166 | Batch_idx: 40 |  Loss: (0.0157) | Acc: (99.41%) (5217/5248)\n",
            "Epoch: 166 | Batch_idx: 50 |  Loss: (0.0158) | Acc: (99.45%) (6492/6528)\n",
            "Epoch: 166 | Batch_idx: 60 |  Loss: (0.0148) | Acc: (99.49%) (7768/7808)\n",
            "Epoch: 166 | Batch_idx: 70 |  Loss: (0.0158) | Acc: (99.45%) (9038/9088)\n",
            "Epoch: 166 | Batch_idx: 80 |  Loss: (0.0162) | Acc: (99.42%) (10308/10368)\n",
            "Epoch: 166 | Batch_idx: 90 |  Loss: (0.0158) | Acc: (99.42%) (11581/11648)\n",
            "Epoch: 166 | Batch_idx: 100 |  Loss: (0.0157) | Acc: (99.42%) (12853/12928)\n",
            "Epoch: 166 | Batch_idx: 110 |  Loss: (0.0154) | Acc: (99.44%) (14128/14208)\n",
            "Epoch: 166 | Batch_idx: 120 |  Loss: (0.0152) | Acc: (99.46%) (15405/15488)\n",
            "Epoch: 166 | Batch_idx: 130 |  Loss: (0.0158) | Acc: (99.43%) (16672/16768)\n",
            "Epoch: 166 | Batch_idx: 140 |  Loss: (0.0152) | Acc: (99.45%) (17949/18048)\n",
            "Epoch: 166 | Batch_idx: 150 |  Loss: (0.0151) | Acc: (99.45%) (19221/19328)\n",
            "Epoch: 166 | Batch_idx: 160 |  Loss: (0.0157) | Acc: (99.42%) (20489/20608)\n",
            "Epoch: 166 | Batch_idx: 170 |  Loss: (0.0157) | Acc: (99.42%) (21760/21888)\n",
            "Epoch: 166 | Batch_idx: 180 |  Loss: (0.0154) | Acc: (99.43%) (23037/23168)\n",
            "Epoch: 166 | Batch_idx: 190 |  Loss: (0.0155) | Acc: (99.43%) (24309/24448)\n",
            "Epoch: 166 | Batch_idx: 200 |  Loss: (0.0153) | Acc: (99.44%) (25583/25728)\n",
            "Epoch: 166 | Batch_idx: 210 |  Loss: (0.0150) | Acc: (99.44%) (26858/27008)\n",
            "Epoch: 166 | Batch_idx: 220 |  Loss: (0.0153) | Acc: (99.44%) (28131/28288)\n",
            "Epoch: 166 | Batch_idx: 230 |  Loss: (0.0156) | Acc: (99.44%) (29403/29568)\n",
            "Epoch: 166 | Batch_idx: 240 |  Loss: (0.0154) | Acc: (99.45%) (30678/30848)\n",
            "Epoch: 166 | Batch_idx: 250 |  Loss: (0.0153) | Acc: (99.45%) (31952/32128)\n",
            "Epoch: 166 | Batch_idx: 260 |  Loss: (0.0152) | Acc: (99.46%) (33228/33408)\n",
            "Epoch: 166 | Batch_idx: 270 |  Loss: (0.0149) | Acc: (99.47%) (34505/34688)\n",
            "Epoch: 166 | Batch_idx: 280 |  Loss: (0.0152) | Acc: (99.46%) (35775/35968)\n",
            "Epoch: 166 | Batch_idx: 290 |  Loss: (0.0153) | Acc: (99.45%) (37044/37248)\n",
            "Epoch: 166 | Batch_idx: 300 |  Loss: (0.0154) | Acc: (99.45%) (38317/38528)\n",
            "Epoch: 166 | Batch_idx: 310 |  Loss: (0.0153) | Acc: (99.45%) (39590/39808)\n",
            "Epoch: 166 | Batch_idx: 320 |  Loss: (0.0152) | Acc: (99.46%) (40866/41088)\n",
            "Epoch: 166 | Batch_idx: 330 |  Loss: (0.0153) | Acc: (99.45%) (42137/42368)\n",
            "Epoch: 166 | Batch_idx: 340 |  Loss: (0.0155) | Acc: (99.45%) (43408/43648)\n",
            "Epoch: 166 | Batch_idx: 350 |  Loss: (0.0156) | Acc: (99.45%) (44681/44928)\n",
            "Epoch: 166 | Batch_idx: 360 |  Loss: (0.0155) | Acc: (99.45%) (45956/46208)\n",
            "Epoch: 166 | Batch_idx: 370 |  Loss: (0.0153) | Acc: (99.46%) (47231/47488)\n",
            "Epoch: 166 | Batch_idx: 380 |  Loss: (0.0153) | Acc: (99.46%) (48506/48768)\n",
            "Epoch: 166 | Batch_idx: 390 |  Loss: (0.0153) | Acc: (99.46%) (49730/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3951) | Acc: (91.94%) (9194/10000)\n",
            "Epoch: 167 | Batch_idx: 0 |  Loss: (0.0455) | Acc: (98.44%) (126/128)\n",
            "Epoch: 167 | Batch_idx: 10 |  Loss: (0.0244) | Acc: (99.01%) (1394/1408)\n",
            "Epoch: 167 | Batch_idx: 20 |  Loss: (0.0271) | Acc: (99.11%) (2664/2688)\n",
            "Epoch: 167 | Batch_idx: 30 |  Loss: (0.0213) | Acc: (99.29%) (3940/3968)\n",
            "Epoch: 167 | Batch_idx: 40 |  Loss: (0.0255) | Acc: (99.26%) (5209/5248)\n",
            "Epoch: 167 | Batch_idx: 50 |  Loss: (0.0249) | Acc: (99.28%) (6481/6528)\n",
            "Epoch: 167 | Batch_idx: 60 |  Loss: (0.0232) | Acc: (99.30%) (7753/7808)\n",
            "Epoch: 167 | Batch_idx: 70 |  Loss: (0.0219) | Acc: (99.32%) (9026/9088)\n",
            "Epoch: 167 | Batch_idx: 80 |  Loss: (0.0209) | Acc: (99.34%) (10300/10368)\n",
            "Epoch: 167 | Batch_idx: 90 |  Loss: (0.0201) | Acc: (99.38%) (11576/11648)\n",
            "Epoch: 167 | Batch_idx: 100 |  Loss: (0.0194) | Acc: (99.41%) (12852/12928)\n",
            "Epoch: 167 | Batch_idx: 110 |  Loss: (0.0190) | Acc: (99.42%) (14125/14208)\n",
            "Epoch: 167 | Batch_idx: 120 |  Loss: (0.0185) | Acc: (99.44%) (15401/15488)\n",
            "Epoch: 167 | Batch_idx: 130 |  Loss: (0.0191) | Acc: (99.43%) (16672/16768)\n",
            "Epoch: 167 | Batch_idx: 140 |  Loss: (0.0194) | Acc: (99.40%) (17940/18048)\n",
            "Epoch: 167 | Batch_idx: 150 |  Loss: (0.0186) | Acc: (99.43%) (19217/19328)\n",
            "Epoch: 167 | Batch_idx: 160 |  Loss: (0.0183) | Acc: (99.43%) (20491/20608)\n",
            "Epoch: 167 | Batch_idx: 170 |  Loss: (0.0183) | Acc: (99.43%) (21764/21888)\n",
            "Epoch: 167 | Batch_idx: 180 |  Loss: (0.0183) | Acc: (99.42%) (23034/23168)\n",
            "Epoch: 167 | Batch_idx: 190 |  Loss: (0.0179) | Acc: (99.43%) (24308/24448)\n",
            "Epoch: 167 | Batch_idx: 200 |  Loss: (0.0181) | Acc: (99.42%) (25579/25728)\n",
            "Epoch: 167 | Batch_idx: 210 |  Loss: (0.0184) | Acc: (99.41%) (26849/27008)\n",
            "Epoch: 167 | Batch_idx: 220 |  Loss: (0.0190) | Acc: (99.38%) (28114/28288)\n",
            "Epoch: 167 | Batch_idx: 230 |  Loss: (0.0190) | Acc: (99.39%) (29387/29568)\n",
            "Epoch: 167 | Batch_idx: 240 |  Loss: (0.0186) | Acc: (99.40%) (30662/30848)\n",
            "Epoch: 167 | Batch_idx: 250 |  Loss: (0.0185) | Acc: (99.40%) (31935/32128)\n",
            "Epoch: 167 | Batch_idx: 260 |  Loss: (0.0182) | Acc: (99.41%) (33211/33408)\n",
            "Epoch: 167 | Batch_idx: 270 |  Loss: (0.0182) | Acc: (99.41%) (34484/34688)\n",
            "Epoch: 167 | Batch_idx: 280 |  Loss: (0.0184) | Acc: (99.40%) (35753/35968)\n",
            "Epoch: 167 | Batch_idx: 290 |  Loss: (0.0183) | Acc: (99.41%) (37027/37248)\n",
            "Epoch: 167 | Batch_idx: 300 |  Loss: (0.0180) | Acc: (99.42%) (38304/38528)\n",
            "Epoch: 167 | Batch_idx: 310 |  Loss: (0.0181) | Acc: (99.41%) (39573/39808)\n",
            "Epoch: 167 | Batch_idx: 320 |  Loss: (0.0181) | Acc: (99.40%) (40842/41088)\n",
            "Epoch: 167 | Batch_idx: 330 |  Loss: (0.0179) | Acc: (99.41%) (42118/42368)\n",
            "Epoch: 167 | Batch_idx: 340 |  Loss: (0.0178) | Acc: (99.41%) (43392/43648)\n",
            "Epoch: 167 | Batch_idx: 350 |  Loss: (0.0178) | Acc: (99.41%) (44665/44928)\n",
            "Epoch: 167 | Batch_idx: 360 |  Loss: (0.0179) | Acc: (99.41%) (45935/46208)\n",
            "Epoch: 167 | Batch_idx: 370 |  Loss: (0.0180) | Acc: (99.41%) (47206/47488)\n",
            "Epoch: 167 | Batch_idx: 380 |  Loss: (0.0180) | Acc: (99.40%) (48476/48768)\n",
            "Epoch: 167 | Batch_idx: 390 |  Loss: (0.0179) | Acc: (99.40%) (49702/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3910) | Acc: (91.90%) (9190/10000)\n",
            "Epoch: 168 | Batch_idx: 0 |  Loss: (0.0135) | Acc: (99.22%) (127/128)\n",
            "Epoch: 168 | Batch_idx: 10 |  Loss: (0.0158) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 168 | Batch_idx: 20 |  Loss: (0.0166) | Acc: (99.29%) (2669/2688)\n",
            "Epoch: 168 | Batch_idx: 30 |  Loss: (0.0166) | Acc: (99.29%) (3940/3968)\n",
            "Epoch: 168 | Batch_idx: 40 |  Loss: (0.0158) | Acc: (99.37%) (5215/5248)\n",
            "Epoch: 168 | Batch_idx: 50 |  Loss: (0.0161) | Acc: (99.36%) (6486/6528)\n",
            "Epoch: 168 | Batch_idx: 60 |  Loss: (0.0166) | Acc: (99.39%) (7760/7808)\n",
            "Epoch: 168 | Batch_idx: 70 |  Loss: (0.0166) | Acc: (99.38%) (9032/9088)\n",
            "Epoch: 168 | Batch_idx: 80 |  Loss: (0.0152) | Acc: (99.45%) (10311/10368)\n",
            "Epoch: 168 | Batch_idx: 90 |  Loss: (0.0145) | Acc: (99.47%) (11586/11648)\n",
            "Epoch: 168 | Batch_idx: 100 |  Loss: (0.0148) | Acc: (99.46%) (12858/12928)\n",
            "Epoch: 168 | Batch_idx: 110 |  Loss: (0.0148) | Acc: (99.44%) (14129/14208)\n",
            "Epoch: 168 | Batch_idx: 120 |  Loss: (0.0148) | Acc: (99.46%) (15405/15488)\n",
            "Epoch: 168 | Batch_idx: 130 |  Loss: (0.0160) | Acc: (99.43%) (16673/16768)\n",
            "Epoch: 168 | Batch_idx: 140 |  Loss: (0.0168) | Acc: (99.42%) (17944/18048)\n",
            "Epoch: 168 | Batch_idx: 150 |  Loss: (0.0166) | Acc: (99.43%) (19217/19328)\n",
            "Epoch: 168 | Batch_idx: 160 |  Loss: (0.0164) | Acc: (99.43%) (20491/20608)\n",
            "Epoch: 168 | Batch_idx: 170 |  Loss: (0.0166) | Acc: (99.42%) (21761/21888)\n",
            "Epoch: 168 | Batch_idx: 180 |  Loss: (0.0165) | Acc: (99.42%) (23033/23168)\n",
            "Epoch: 168 | Batch_idx: 190 |  Loss: (0.0165) | Acc: (99.42%) (24306/24448)\n",
            "Epoch: 168 | Batch_idx: 200 |  Loss: (0.0167) | Acc: (99.42%) (25578/25728)\n",
            "Epoch: 168 | Batch_idx: 210 |  Loss: (0.0168) | Acc: (99.41%) (26849/27008)\n",
            "Epoch: 168 | Batch_idx: 220 |  Loss: (0.0169) | Acc: (99.41%) (28121/28288)\n",
            "Epoch: 168 | Batch_idx: 230 |  Loss: (0.0168) | Acc: (99.41%) (29394/29568)\n",
            "Epoch: 168 | Batch_idx: 240 |  Loss: (0.0169) | Acc: (99.41%) (30665/30848)\n",
            "Epoch: 168 | Batch_idx: 250 |  Loss: (0.0168) | Acc: (99.41%) (31938/32128)\n",
            "Epoch: 168 | Batch_idx: 260 |  Loss: (0.0167) | Acc: (99.41%) (33211/33408)\n",
            "Epoch: 168 | Batch_idx: 270 |  Loss: (0.0164) | Acc: (99.42%) (34488/34688)\n",
            "Epoch: 168 | Batch_idx: 280 |  Loss: (0.0164) | Acc: (99.43%) (35762/35968)\n",
            "Epoch: 168 | Batch_idx: 290 |  Loss: (0.0168) | Acc: (99.42%) (37032/37248)\n",
            "Epoch: 168 | Batch_idx: 300 |  Loss: (0.0168) | Acc: (99.42%) (38303/38528)\n",
            "Epoch: 168 | Batch_idx: 310 |  Loss: (0.0167) | Acc: (99.42%) (39577/39808)\n",
            "Epoch: 168 | Batch_idx: 320 |  Loss: (0.0167) | Acc: (99.42%) (40850/41088)\n",
            "Epoch: 168 | Batch_idx: 330 |  Loss: (0.0163) | Acc: (99.44%) (42130/42368)\n",
            "Epoch: 168 | Batch_idx: 340 |  Loss: (0.0161) | Acc: (99.45%) (43407/43648)\n",
            "Epoch: 168 | Batch_idx: 350 |  Loss: (0.0161) | Acc: (99.45%) (44679/44928)\n",
            "Epoch: 168 | Batch_idx: 360 |  Loss: (0.0161) | Acc: (99.45%) (45952/46208)\n",
            "Epoch: 168 | Batch_idx: 370 |  Loss: (0.0162) | Acc: (99.44%) (47223/47488)\n",
            "Epoch: 168 | Batch_idx: 380 |  Loss: (0.0163) | Acc: (99.44%) (48493/48768)\n",
            "Epoch: 168 | Batch_idx: 390 |  Loss: (0.0163) | Acc: (99.43%) (49717/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3898) | Acc: (91.88%) (9188/10000)\n",
            "Epoch: 169 | Batch_idx: 0 |  Loss: (0.0040) | Acc: (100.00%) (128/128)\n",
            "Epoch: 169 | Batch_idx: 10 |  Loss: (0.0150) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 169 | Batch_idx: 20 |  Loss: (0.0132) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 169 | Batch_idx: 30 |  Loss: (0.0142) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 169 | Batch_idx: 40 |  Loss: (0.0146) | Acc: (99.54%) (5224/5248)\n",
            "Epoch: 169 | Batch_idx: 50 |  Loss: (0.0137) | Acc: (99.56%) (6499/6528)\n",
            "Epoch: 169 | Batch_idx: 60 |  Loss: (0.0140) | Acc: (99.55%) (7773/7808)\n",
            "Epoch: 169 | Batch_idx: 70 |  Loss: (0.0141) | Acc: (99.55%) (9047/9088)\n",
            "Epoch: 169 | Batch_idx: 80 |  Loss: (0.0138) | Acc: (99.57%) (10323/10368)\n",
            "Epoch: 169 | Batch_idx: 90 |  Loss: (0.0140) | Acc: (99.55%) (11596/11648)\n",
            "Epoch: 169 | Batch_idx: 100 |  Loss: (0.0134) | Acc: (99.57%) (12872/12928)\n",
            "Epoch: 169 | Batch_idx: 110 |  Loss: (0.0141) | Acc: (99.56%) (14145/14208)\n",
            "Epoch: 169 | Batch_idx: 120 |  Loss: (0.0147) | Acc: (99.54%) (15416/15488)\n",
            "Epoch: 169 | Batch_idx: 130 |  Loss: (0.0149) | Acc: (99.52%) (16687/16768)\n",
            "Epoch: 169 | Batch_idx: 140 |  Loss: (0.0152) | Acc: (99.51%) (17959/18048)\n",
            "Epoch: 169 | Batch_idx: 150 |  Loss: (0.0151) | Acc: (99.50%) (19232/19328)\n",
            "Epoch: 169 | Batch_idx: 160 |  Loss: (0.0154) | Acc: (99.48%) (20501/20608)\n",
            "Epoch: 169 | Batch_idx: 170 |  Loss: (0.0151) | Acc: (99.48%) (21774/21888)\n",
            "Epoch: 169 | Batch_idx: 180 |  Loss: (0.0151) | Acc: (99.49%) (23049/23168)\n",
            "Epoch: 169 | Batch_idx: 190 |  Loss: (0.0151) | Acc: (99.50%) (24325/24448)\n",
            "Epoch: 169 | Batch_idx: 200 |  Loss: (0.0153) | Acc: (99.50%) (25599/25728)\n",
            "Epoch: 169 | Batch_idx: 210 |  Loss: (0.0153) | Acc: (99.50%) (26872/27008)\n",
            "Epoch: 169 | Batch_idx: 220 |  Loss: (0.0154) | Acc: (99.48%) (28142/28288)\n",
            "Epoch: 169 | Batch_idx: 230 |  Loss: (0.0152) | Acc: (99.50%) (29419/29568)\n",
            "Epoch: 169 | Batch_idx: 240 |  Loss: (0.0150) | Acc: (99.50%) (30695/30848)\n",
            "Epoch: 169 | Batch_idx: 250 |  Loss: (0.0148) | Acc: (99.52%) (31973/32128)\n",
            "Epoch: 169 | Batch_idx: 260 |  Loss: (0.0150) | Acc: (99.51%) (33245/33408)\n",
            "Epoch: 169 | Batch_idx: 270 |  Loss: (0.0152) | Acc: (99.51%) (34519/34688)\n",
            "Epoch: 169 | Batch_idx: 280 |  Loss: (0.0149) | Acc: (99.52%) (35796/35968)\n",
            "Epoch: 169 | Batch_idx: 290 |  Loss: (0.0148) | Acc: (99.53%) (37072/37248)\n",
            "Epoch: 169 | Batch_idx: 300 |  Loss: (0.0148) | Acc: (99.53%) (38346/38528)\n",
            "Epoch: 169 | Batch_idx: 310 |  Loss: (0.0149) | Acc: (99.52%) (39617/39808)\n",
            "Epoch: 169 | Batch_idx: 320 |  Loss: (0.0150) | Acc: (99.51%) (40887/41088)\n",
            "Epoch: 169 | Batch_idx: 330 |  Loss: (0.0151) | Acc: (99.50%) (42157/42368)\n",
            "Epoch: 169 | Batch_idx: 340 |  Loss: (0.0149) | Acc: (99.51%) (43432/43648)\n",
            "Epoch: 169 | Batch_idx: 350 |  Loss: (0.0151) | Acc: (99.49%) (44701/44928)\n",
            "Epoch: 169 | Batch_idx: 360 |  Loss: (0.0147) | Acc: (99.51%) (45981/46208)\n",
            "Epoch: 169 | Batch_idx: 370 |  Loss: (0.0148) | Acc: (99.51%) (47254/47488)\n",
            "Epoch: 169 | Batch_idx: 380 |  Loss: (0.0148) | Acc: (99.51%) (48527/48768)\n",
            "Epoch: 169 | Batch_idx: 390 |  Loss: (0.0147) | Acc: (99.51%) (49754/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3935) | Acc: (91.77%) (9177/10000)\n",
            "Epoch: 170 | Batch_idx: 0 |  Loss: (0.0153) | Acc: (99.22%) (127/128)\n",
            "Epoch: 170 | Batch_idx: 10 |  Loss: (0.0120) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 170 | Batch_idx: 20 |  Loss: (0.0092) | Acc: (99.81%) (2683/2688)\n",
            "Epoch: 170 | Batch_idx: 30 |  Loss: (0.0110) | Acc: (99.72%) (3957/3968)\n",
            "Epoch: 170 | Batch_idx: 40 |  Loss: (0.0117) | Acc: (99.70%) (5232/5248)\n",
            "Epoch: 170 | Batch_idx: 50 |  Loss: (0.0126) | Acc: (99.59%) (6501/6528)\n",
            "Epoch: 170 | Batch_idx: 60 |  Loss: (0.0124) | Acc: (99.55%) (7773/7808)\n",
            "Epoch: 170 | Batch_idx: 70 |  Loss: (0.0131) | Acc: (99.55%) (9047/9088)\n",
            "Epoch: 170 | Batch_idx: 80 |  Loss: (0.0140) | Acc: (99.55%) (10321/10368)\n",
            "Epoch: 170 | Batch_idx: 90 |  Loss: (0.0136) | Acc: (99.55%) (11596/11648)\n",
            "Epoch: 170 | Batch_idx: 100 |  Loss: (0.0142) | Acc: (99.51%) (12865/12928)\n",
            "Epoch: 170 | Batch_idx: 110 |  Loss: (0.0152) | Acc: (99.47%) (14133/14208)\n",
            "Epoch: 170 | Batch_idx: 120 |  Loss: (0.0153) | Acc: (99.47%) (15406/15488)\n",
            "Epoch: 170 | Batch_idx: 130 |  Loss: (0.0158) | Acc: (99.47%) (16679/16768)\n",
            "Epoch: 170 | Batch_idx: 140 |  Loss: (0.0154) | Acc: (99.49%) (17956/18048)\n",
            "Epoch: 170 | Batch_idx: 150 |  Loss: (0.0155) | Acc: (99.49%) (19229/19328)\n",
            "Epoch: 170 | Batch_idx: 160 |  Loss: (0.0155) | Acc: (99.50%) (20504/20608)\n",
            "Epoch: 170 | Batch_idx: 170 |  Loss: (0.0153) | Acc: (99.49%) (21777/21888)\n",
            "Epoch: 170 | Batch_idx: 180 |  Loss: (0.0155) | Acc: (99.49%) (23049/23168)\n",
            "Epoch: 170 | Batch_idx: 190 |  Loss: (0.0151) | Acc: (99.50%) (24326/24448)\n",
            "Epoch: 170 | Batch_idx: 200 |  Loss: (0.0154) | Acc: (99.49%) (25597/25728)\n",
            "Epoch: 170 | Batch_idx: 210 |  Loss: (0.0158) | Acc: (99.47%) (26866/27008)\n",
            "Epoch: 170 | Batch_idx: 220 |  Loss: (0.0156) | Acc: (99.49%) (28143/28288)\n",
            "Epoch: 170 | Batch_idx: 230 |  Loss: (0.0153) | Acc: (99.50%) (29419/29568)\n",
            "Epoch: 170 | Batch_idx: 240 |  Loss: (0.0155) | Acc: (99.48%) (30688/30848)\n",
            "Epoch: 170 | Batch_idx: 250 |  Loss: (0.0160) | Acc: (99.47%) (31958/32128)\n",
            "Epoch: 170 | Batch_idx: 260 |  Loss: (0.0162) | Acc: (99.46%) (33228/33408)\n",
            "Epoch: 170 | Batch_idx: 270 |  Loss: (0.0163) | Acc: (99.46%) (34499/34688)\n",
            "Epoch: 170 | Batch_idx: 280 |  Loss: (0.0162) | Acc: (99.46%) (35772/35968)\n",
            "Epoch: 170 | Batch_idx: 290 |  Loss: (0.0162) | Acc: (99.45%) (37044/37248)\n",
            "Epoch: 170 | Batch_idx: 300 |  Loss: (0.0165) | Acc: (99.44%) (38312/38528)\n",
            "Epoch: 170 | Batch_idx: 310 |  Loss: (0.0166) | Acc: (99.43%) (39583/39808)\n",
            "Epoch: 170 | Batch_idx: 320 |  Loss: (0.0164) | Acc: (99.45%) (40860/41088)\n",
            "Epoch: 170 | Batch_idx: 330 |  Loss: (0.0165) | Acc: (99.44%) (42132/42368)\n",
            "Epoch: 170 | Batch_idx: 340 |  Loss: (0.0168) | Acc: (99.43%) (43400/43648)\n",
            "Epoch: 170 | Batch_idx: 350 |  Loss: (0.0168) | Acc: (99.43%) (44674/44928)\n",
            "Epoch: 170 | Batch_idx: 360 |  Loss: (0.0171) | Acc: (99.43%) (45944/46208)\n",
            "Epoch: 170 | Batch_idx: 370 |  Loss: (0.0171) | Acc: (99.43%) (47217/47488)\n",
            "Epoch: 170 | Batch_idx: 380 |  Loss: (0.0170) | Acc: (99.43%) (48490/48768)\n",
            "Epoch: 170 | Batch_idx: 390 |  Loss: (0.0169) | Acc: (99.43%) (49715/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3925) | Acc: (91.87%) (9187/10000)\n",
            "Epoch: 171 | Batch_idx: 0 |  Loss: (0.0075) | Acc: (99.22%) (127/128)\n",
            "Epoch: 171 | Batch_idx: 10 |  Loss: (0.0079) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 171 | Batch_idx: 20 |  Loss: (0.0078) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 171 | Batch_idx: 30 |  Loss: (0.0099) | Acc: (99.65%) (3954/3968)\n",
            "Epoch: 171 | Batch_idx: 40 |  Loss: (0.0111) | Acc: (99.66%) (5230/5248)\n",
            "Epoch: 171 | Batch_idx: 50 |  Loss: (0.0115) | Acc: (99.62%) (6503/6528)\n",
            "Epoch: 171 | Batch_idx: 60 |  Loss: (0.0113) | Acc: (99.63%) (7779/7808)\n",
            "Epoch: 171 | Batch_idx: 70 |  Loss: (0.0127) | Acc: (99.59%) (9051/9088)\n",
            "Epoch: 171 | Batch_idx: 80 |  Loss: (0.0132) | Acc: (99.57%) (10323/10368)\n",
            "Epoch: 171 | Batch_idx: 90 |  Loss: (0.0131) | Acc: (99.56%) (11597/11648)\n",
            "Epoch: 171 | Batch_idx: 100 |  Loss: (0.0133) | Acc: (99.55%) (12870/12928)\n",
            "Epoch: 171 | Batch_idx: 110 |  Loss: (0.0135) | Acc: (99.54%) (14143/14208)\n",
            "Epoch: 171 | Batch_idx: 120 |  Loss: (0.0130) | Acc: (99.57%) (15421/15488)\n",
            "Epoch: 171 | Batch_idx: 130 |  Loss: (0.0137) | Acc: (99.52%) (16687/16768)\n",
            "Epoch: 171 | Batch_idx: 140 |  Loss: (0.0137) | Acc: (99.53%) (17964/18048)\n",
            "Epoch: 171 | Batch_idx: 150 |  Loss: (0.0140) | Acc: (99.52%) (19235/19328)\n",
            "Epoch: 171 | Batch_idx: 160 |  Loss: (0.0141) | Acc: (99.51%) (20507/20608)\n",
            "Epoch: 171 | Batch_idx: 170 |  Loss: (0.0141) | Acc: (99.52%) (21782/21888)\n",
            "Epoch: 171 | Batch_idx: 180 |  Loss: (0.0144) | Acc: (99.51%) (23054/23168)\n",
            "Epoch: 171 | Batch_idx: 190 |  Loss: (0.0143) | Acc: (99.52%) (24330/24448)\n",
            "Epoch: 171 | Batch_idx: 200 |  Loss: (0.0142) | Acc: (99.51%) (25603/25728)\n",
            "Epoch: 171 | Batch_idx: 210 |  Loss: (0.0142) | Acc: (99.51%) (26877/27008)\n",
            "Epoch: 171 | Batch_idx: 220 |  Loss: (0.0138) | Acc: (99.53%) (28154/28288)\n",
            "Epoch: 171 | Batch_idx: 230 |  Loss: (0.0136) | Acc: (99.54%) (29431/29568)\n",
            "Epoch: 171 | Batch_idx: 240 |  Loss: (0.0137) | Acc: (99.54%) (30706/30848)\n",
            "Epoch: 171 | Batch_idx: 250 |  Loss: (0.0138) | Acc: (99.54%) (31981/32128)\n",
            "Epoch: 171 | Batch_idx: 260 |  Loss: (0.0138) | Acc: (99.54%) (33255/33408)\n",
            "Epoch: 171 | Batch_idx: 270 |  Loss: (0.0142) | Acc: (99.53%) (34526/34688)\n",
            "Epoch: 171 | Batch_idx: 280 |  Loss: (0.0141) | Acc: (99.53%) (35799/35968)\n",
            "Epoch: 171 | Batch_idx: 290 |  Loss: (0.0145) | Acc: (99.51%) (37066/37248)\n",
            "Epoch: 171 | Batch_idx: 300 |  Loss: (0.0145) | Acc: (99.51%) (38339/38528)\n",
            "Epoch: 171 | Batch_idx: 310 |  Loss: (0.0146) | Acc: (99.51%) (39612/39808)\n",
            "Epoch: 171 | Batch_idx: 320 |  Loss: (0.0145) | Acc: (99.51%) (40887/41088)\n",
            "Epoch: 171 | Batch_idx: 330 |  Loss: (0.0146) | Acc: (99.51%) (42160/42368)\n",
            "Epoch: 171 | Batch_idx: 340 |  Loss: (0.0145) | Acc: (99.51%) (43434/43648)\n",
            "Epoch: 171 | Batch_idx: 350 |  Loss: (0.0145) | Acc: (99.51%) (44710/44928)\n",
            "Epoch: 171 | Batch_idx: 360 |  Loss: (0.0146) | Acc: (99.51%) (45981/46208)\n",
            "Epoch: 171 | Batch_idx: 370 |  Loss: (0.0146) | Acc: (99.51%) (47256/47488)\n",
            "Epoch: 171 | Batch_idx: 380 |  Loss: (0.0147) | Acc: (99.50%) (48524/48768)\n",
            "Epoch: 171 | Batch_idx: 390 |  Loss: (0.0146) | Acc: (99.51%) (49753/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3919) | Acc: (91.79%) (9179/10000)\n",
            "Epoch: 172 | Batch_idx: 0 |  Loss: (0.0026) | Acc: (100.00%) (128/128)\n",
            "Epoch: 172 | Batch_idx: 10 |  Loss: (0.0247) | Acc: (99.15%) (1396/1408)\n",
            "Epoch: 172 | Batch_idx: 20 |  Loss: (0.0196) | Acc: (99.33%) (2670/2688)\n",
            "Epoch: 172 | Batch_idx: 30 |  Loss: (0.0177) | Acc: (99.40%) (3944/3968)\n",
            "Epoch: 172 | Batch_idx: 40 |  Loss: (0.0172) | Acc: (99.41%) (5217/5248)\n",
            "Epoch: 172 | Batch_idx: 50 |  Loss: (0.0173) | Acc: (99.37%) (6487/6528)\n",
            "Epoch: 172 | Batch_idx: 60 |  Loss: (0.0170) | Acc: (99.39%) (7760/7808)\n",
            "Epoch: 172 | Batch_idx: 70 |  Loss: (0.0163) | Acc: (99.41%) (9034/9088)\n",
            "Epoch: 172 | Batch_idx: 80 |  Loss: (0.0155) | Acc: (99.44%) (10310/10368)\n",
            "Epoch: 172 | Batch_idx: 90 |  Loss: (0.0154) | Acc: (99.48%) (11587/11648)\n",
            "Epoch: 172 | Batch_idx: 100 |  Loss: (0.0146) | Acc: (99.51%) (12865/12928)\n",
            "Epoch: 172 | Batch_idx: 110 |  Loss: (0.0148) | Acc: (99.50%) (14137/14208)\n",
            "Epoch: 172 | Batch_idx: 120 |  Loss: (0.0155) | Acc: (99.48%) (15408/15488)\n",
            "Epoch: 172 | Batch_idx: 130 |  Loss: (0.0152) | Acc: (99.50%) (16684/16768)\n",
            "Epoch: 172 | Batch_idx: 140 |  Loss: (0.0152) | Acc: (99.50%) (17957/18048)\n",
            "Epoch: 172 | Batch_idx: 150 |  Loss: (0.0151) | Acc: (99.50%) (19231/19328)\n",
            "Epoch: 172 | Batch_idx: 160 |  Loss: (0.0152) | Acc: (99.49%) (20503/20608)\n",
            "Epoch: 172 | Batch_idx: 170 |  Loss: (0.0154) | Acc: (99.48%) (21774/21888)\n",
            "Epoch: 172 | Batch_idx: 180 |  Loss: (0.0153) | Acc: (99.49%) (23050/23168)\n",
            "Epoch: 172 | Batch_idx: 190 |  Loss: (0.0154) | Acc: (99.48%) (24320/24448)\n",
            "Epoch: 172 | Batch_idx: 200 |  Loss: (0.0152) | Acc: (99.49%) (25597/25728)\n",
            "Epoch: 172 | Batch_idx: 210 |  Loss: (0.0154) | Acc: (99.48%) (26868/27008)\n",
            "Epoch: 172 | Batch_idx: 220 |  Loss: (0.0154) | Acc: (99.49%) (28144/28288)\n",
            "Epoch: 172 | Batch_idx: 230 |  Loss: (0.0156) | Acc: (99.48%) (29414/29568)\n",
            "Epoch: 172 | Batch_idx: 240 |  Loss: (0.0153) | Acc: (99.48%) (30689/30848)\n",
            "Epoch: 172 | Batch_idx: 250 |  Loss: (0.0152) | Acc: (99.49%) (31964/32128)\n",
            "Epoch: 172 | Batch_idx: 260 |  Loss: (0.0153) | Acc: (99.49%) (33237/33408)\n",
            "Epoch: 172 | Batch_idx: 270 |  Loss: (0.0156) | Acc: (99.48%) (34508/34688)\n",
            "Epoch: 172 | Batch_idx: 280 |  Loss: (0.0156) | Acc: (99.48%) (35782/35968)\n",
            "Epoch: 172 | Batch_idx: 290 |  Loss: (0.0156) | Acc: (99.48%) (37054/37248)\n",
            "Epoch: 172 | Batch_idx: 300 |  Loss: (0.0159) | Acc: (99.46%) (38321/38528)\n",
            "Epoch: 172 | Batch_idx: 310 |  Loss: (0.0156) | Acc: (99.47%) (39599/39808)\n",
            "Epoch: 172 | Batch_idx: 320 |  Loss: (0.0156) | Acc: (99.48%) (40874/41088)\n",
            "Epoch: 172 | Batch_idx: 330 |  Loss: (0.0154) | Acc: (99.49%) (42151/42368)\n",
            "Epoch: 172 | Batch_idx: 340 |  Loss: (0.0153) | Acc: (99.49%) (43427/43648)\n",
            "Epoch: 172 | Batch_idx: 350 |  Loss: (0.0154) | Acc: (99.49%) (44698/44928)\n",
            "Epoch: 172 | Batch_idx: 360 |  Loss: (0.0153) | Acc: (99.50%) (45975/46208)\n",
            "Epoch: 172 | Batch_idx: 370 |  Loss: (0.0153) | Acc: (99.49%) (47247/47488)\n",
            "Epoch: 172 | Batch_idx: 380 |  Loss: (0.0151) | Acc: (99.50%) (48525/48768)\n",
            "Epoch: 172 | Batch_idx: 390 |  Loss: (0.0150) | Acc: (99.51%) (49753/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3946) | Acc: (91.83%) (9183/10000)\n",
            "Epoch: 173 | Batch_idx: 0 |  Loss: (0.0146) | Acc: (99.22%) (127/128)\n",
            "Epoch: 173 | Batch_idx: 10 |  Loss: (0.0205) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 173 | Batch_idx: 20 |  Loss: (0.0200) | Acc: (99.11%) (2664/2688)\n",
            "Epoch: 173 | Batch_idx: 30 |  Loss: (0.0187) | Acc: (99.29%) (3940/3968)\n",
            "Epoch: 173 | Batch_idx: 40 |  Loss: (0.0179) | Acc: (99.35%) (5214/5248)\n",
            "Epoch: 173 | Batch_idx: 50 |  Loss: (0.0168) | Acc: (99.39%) (6488/6528)\n",
            "Epoch: 173 | Batch_idx: 60 |  Loss: (0.0167) | Acc: (99.40%) (7761/7808)\n",
            "Epoch: 173 | Batch_idx: 70 |  Loss: (0.0167) | Acc: (99.38%) (9032/9088)\n",
            "Epoch: 173 | Batch_idx: 80 |  Loss: (0.0166) | Acc: (99.37%) (10303/10368)\n",
            "Epoch: 173 | Batch_idx: 90 |  Loss: (0.0166) | Acc: (99.39%) (11577/11648)\n",
            "Epoch: 173 | Batch_idx: 100 |  Loss: (0.0156) | Acc: (99.44%) (12855/12928)\n",
            "Epoch: 173 | Batch_idx: 110 |  Loss: (0.0165) | Acc: (99.42%) (14125/14208)\n",
            "Epoch: 173 | Batch_idx: 120 |  Loss: (0.0166) | Acc: (99.41%) (15397/15488)\n",
            "Epoch: 173 | Batch_idx: 130 |  Loss: (0.0162) | Acc: (99.42%) (16670/16768)\n",
            "Epoch: 173 | Batch_idx: 140 |  Loss: (0.0166) | Acc: (99.42%) (17944/18048)\n",
            "Epoch: 173 | Batch_idx: 150 |  Loss: (0.0167) | Acc: (99.42%) (19216/19328)\n",
            "Epoch: 173 | Batch_idx: 160 |  Loss: (0.0162) | Acc: (99.44%) (20493/20608)\n",
            "Epoch: 173 | Batch_idx: 170 |  Loss: (0.0159) | Acc: (99.45%) (21767/21888)\n",
            "Epoch: 173 | Batch_idx: 180 |  Loss: (0.0162) | Acc: (99.45%) (23040/23168)\n",
            "Epoch: 173 | Batch_idx: 190 |  Loss: (0.0164) | Acc: (99.44%) (24312/24448)\n",
            "Epoch: 173 | Batch_idx: 200 |  Loss: (0.0164) | Acc: (99.44%) (25585/25728)\n",
            "Epoch: 173 | Batch_idx: 210 |  Loss: (0.0163) | Acc: (99.45%) (26860/27008)\n",
            "Epoch: 173 | Batch_idx: 220 |  Loss: (0.0167) | Acc: (99.43%) (28128/28288)\n",
            "Epoch: 173 | Batch_idx: 230 |  Loss: (0.0164) | Acc: (99.45%) (29404/29568)\n",
            "Epoch: 173 | Batch_idx: 240 |  Loss: (0.0163) | Acc: (99.45%) (30678/30848)\n",
            "Epoch: 173 | Batch_idx: 250 |  Loss: (0.0165) | Acc: (99.44%) (31949/32128)\n",
            "Epoch: 173 | Batch_idx: 260 |  Loss: (0.0163) | Acc: (99.45%) (33224/33408)\n",
            "Epoch: 173 | Batch_idx: 270 |  Loss: (0.0160) | Acc: (99.45%) (34498/34688)\n",
            "Epoch: 173 | Batch_idx: 280 |  Loss: (0.0158) | Acc: (99.46%) (35775/35968)\n",
            "Epoch: 173 | Batch_idx: 290 |  Loss: (0.0158) | Acc: (99.47%) (37049/37248)\n",
            "Epoch: 173 | Batch_idx: 300 |  Loss: (0.0157) | Acc: (99.47%) (38324/38528)\n",
            "Epoch: 173 | Batch_idx: 310 |  Loss: (0.0155) | Acc: (99.48%) (39600/39808)\n",
            "Epoch: 173 | Batch_idx: 320 |  Loss: (0.0154) | Acc: (99.48%) (40874/41088)\n",
            "Epoch: 173 | Batch_idx: 330 |  Loss: (0.0152) | Acc: (99.49%) (42151/42368)\n",
            "Epoch: 173 | Batch_idx: 340 |  Loss: (0.0153) | Acc: (99.49%) (43424/43648)\n",
            "Epoch: 173 | Batch_idx: 350 |  Loss: (0.0153) | Acc: (99.48%) (44695/44928)\n",
            "Epoch: 173 | Batch_idx: 360 |  Loss: (0.0152) | Acc: (99.48%) (45968/46208)\n",
            "Epoch: 173 | Batch_idx: 370 |  Loss: (0.0152) | Acc: (99.48%) (47242/47488)\n",
            "Epoch: 173 | Batch_idx: 380 |  Loss: (0.0152) | Acc: (99.49%) (48517/48768)\n",
            "Epoch: 173 | Batch_idx: 390 |  Loss: (0.0153) | Acc: (99.48%) (49740/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3945) | Acc: (91.94%) (9194/10000)\n",
            "Epoch: 174 | Batch_idx: 0 |  Loss: (0.0019) | Acc: (100.00%) (128/128)\n",
            "Epoch: 174 | Batch_idx: 10 |  Loss: (0.0094) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 174 | Batch_idx: 20 |  Loss: (0.0131) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 174 | Batch_idx: 30 |  Loss: (0.0128) | Acc: (99.62%) (3953/3968)\n",
            "Epoch: 174 | Batch_idx: 40 |  Loss: (0.0160) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 174 | Batch_idx: 50 |  Loss: (0.0155) | Acc: (99.46%) (6493/6528)\n",
            "Epoch: 174 | Batch_idx: 60 |  Loss: (0.0166) | Acc: (99.44%) (7764/7808)\n",
            "Epoch: 174 | Batch_idx: 70 |  Loss: (0.0165) | Acc: (99.42%) (9035/9088)\n",
            "Epoch: 174 | Batch_idx: 80 |  Loss: (0.0158) | Acc: (99.45%) (10311/10368)\n",
            "Epoch: 174 | Batch_idx: 90 |  Loss: (0.0156) | Acc: (99.46%) (11585/11648)\n",
            "Epoch: 174 | Batch_idx: 100 |  Loss: (0.0167) | Acc: (99.45%) (12857/12928)\n",
            "Epoch: 174 | Batch_idx: 110 |  Loss: (0.0162) | Acc: (99.46%) (14131/14208)\n",
            "Epoch: 174 | Batch_idx: 120 |  Loss: (0.0167) | Acc: (99.43%) (15400/15488)\n",
            "Epoch: 174 | Batch_idx: 130 |  Loss: (0.0161) | Acc: (99.44%) (16674/16768)\n",
            "Epoch: 174 | Batch_idx: 140 |  Loss: (0.0164) | Acc: (99.45%) (17948/18048)\n",
            "Epoch: 174 | Batch_idx: 150 |  Loss: (0.0159) | Acc: (99.47%) (19225/19328)\n",
            "Epoch: 174 | Batch_idx: 160 |  Loss: (0.0162) | Acc: (99.47%) (20499/20608)\n",
            "Epoch: 174 | Batch_idx: 170 |  Loss: (0.0161) | Acc: (99.48%) (21774/21888)\n",
            "Epoch: 174 | Batch_idx: 180 |  Loss: (0.0161) | Acc: (99.47%) (23046/23168)\n",
            "Epoch: 174 | Batch_idx: 190 |  Loss: (0.0164) | Acc: (99.46%) (24316/24448)\n",
            "Epoch: 174 | Batch_idx: 200 |  Loss: (0.0167) | Acc: (99.44%) (25585/25728)\n",
            "Epoch: 174 | Batch_idx: 210 |  Loss: (0.0165) | Acc: (99.44%) (26858/27008)\n",
            "Epoch: 174 | Batch_idx: 220 |  Loss: (0.0166) | Acc: (99.44%) (28130/28288)\n",
            "Epoch: 174 | Batch_idx: 230 |  Loss: (0.0164) | Acc: (99.45%) (29405/29568)\n",
            "Epoch: 174 | Batch_idx: 240 |  Loss: (0.0168) | Acc: (99.44%) (30674/30848)\n",
            "Epoch: 174 | Batch_idx: 250 |  Loss: (0.0165) | Acc: (99.44%) (31949/32128)\n",
            "Epoch: 174 | Batch_idx: 260 |  Loss: (0.0163) | Acc: (99.45%) (33224/33408)\n",
            "Epoch: 174 | Batch_idx: 270 |  Loss: (0.0161) | Acc: (99.46%) (34499/34688)\n",
            "Epoch: 174 | Batch_idx: 280 |  Loss: (0.0158) | Acc: (99.46%) (35775/35968)\n",
            "Epoch: 174 | Batch_idx: 290 |  Loss: (0.0159) | Acc: (99.46%) (37046/37248)\n",
            "Epoch: 174 | Batch_idx: 300 |  Loss: (0.0157) | Acc: (99.46%) (38321/38528)\n",
            "Epoch: 174 | Batch_idx: 310 |  Loss: (0.0158) | Acc: (99.46%) (39594/39808)\n",
            "Epoch: 174 | Batch_idx: 320 |  Loss: (0.0158) | Acc: (99.45%) (40864/41088)\n",
            "Epoch: 174 | Batch_idx: 330 |  Loss: (0.0160) | Acc: (99.45%) (42135/42368)\n",
            "Epoch: 174 | Batch_idx: 340 |  Loss: (0.0162) | Acc: (99.43%) (43401/43648)\n",
            "Epoch: 174 | Batch_idx: 350 |  Loss: (0.0164) | Acc: (99.44%) (44675/44928)\n",
            "Epoch: 174 | Batch_idx: 360 |  Loss: (0.0164) | Acc: (99.44%) (45948/46208)\n",
            "Epoch: 174 | Batch_idx: 370 |  Loss: (0.0165) | Acc: (99.44%) (47221/47488)\n",
            "Epoch: 174 | Batch_idx: 380 |  Loss: (0.0165) | Acc: (99.43%) (48492/48768)\n",
            "Epoch: 174 | Batch_idx: 390 |  Loss: (0.0167) | Acc: (99.43%) (49714/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3912) | Acc: (91.92%) (9192/10000)\n",
            "Epoch: 175 | Batch_idx: 0 |  Loss: (0.0052) | Acc: (100.00%) (128/128)\n",
            "Epoch: 175 | Batch_idx: 10 |  Loss: (0.0102) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 175 | Batch_idx: 20 |  Loss: (0.0103) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 175 | Batch_idx: 30 |  Loss: (0.0141) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 175 | Batch_idx: 40 |  Loss: (0.0147) | Acc: (99.47%) (5220/5248)\n",
            "Epoch: 175 | Batch_idx: 50 |  Loss: (0.0139) | Acc: (99.49%) (6495/6528)\n",
            "Epoch: 175 | Batch_idx: 60 |  Loss: (0.0134) | Acc: (99.50%) (7769/7808)\n",
            "Epoch: 175 | Batch_idx: 70 |  Loss: (0.0132) | Acc: (99.49%) (9042/9088)\n",
            "Epoch: 175 | Batch_idx: 80 |  Loss: (0.0128) | Acc: (99.53%) (10319/10368)\n",
            "Epoch: 175 | Batch_idx: 90 |  Loss: (0.0125) | Acc: (99.54%) (11594/11648)\n",
            "Epoch: 175 | Batch_idx: 100 |  Loss: (0.0122) | Acc: (99.54%) (12869/12928)\n",
            "Epoch: 175 | Batch_idx: 110 |  Loss: (0.0125) | Acc: (99.55%) (14144/14208)\n",
            "Epoch: 175 | Batch_idx: 120 |  Loss: (0.0125) | Acc: (99.54%) (15417/15488)\n",
            "Epoch: 175 | Batch_idx: 130 |  Loss: (0.0128) | Acc: (99.53%) (16690/16768)\n",
            "Epoch: 175 | Batch_idx: 140 |  Loss: (0.0129) | Acc: (99.52%) (17961/18048)\n",
            "Epoch: 175 | Batch_idx: 150 |  Loss: (0.0130) | Acc: (99.52%) (19236/19328)\n",
            "Epoch: 175 | Batch_idx: 160 |  Loss: (0.0131) | Acc: (99.51%) (20508/20608)\n",
            "Epoch: 175 | Batch_idx: 170 |  Loss: (0.0131) | Acc: (99.50%) (21778/21888)\n",
            "Epoch: 175 | Batch_idx: 180 |  Loss: (0.0129) | Acc: (99.51%) (23054/23168)\n",
            "Epoch: 175 | Batch_idx: 190 |  Loss: (0.0128) | Acc: (99.52%) (24331/24448)\n",
            "Epoch: 175 | Batch_idx: 200 |  Loss: (0.0127) | Acc: (99.53%) (25608/25728)\n",
            "Epoch: 175 | Batch_idx: 210 |  Loss: (0.0131) | Acc: (99.52%) (26878/27008)\n",
            "Epoch: 175 | Batch_idx: 220 |  Loss: (0.0131) | Acc: (99.53%) (28154/28288)\n",
            "Epoch: 175 | Batch_idx: 230 |  Loss: (0.0128) | Acc: (99.53%) (29430/29568)\n",
            "Epoch: 175 | Batch_idx: 240 |  Loss: (0.0130) | Acc: (99.53%) (30702/30848)\n",
            "Epoch: 175 | Batch_idx: 250 |  Loss: (0.0130) | Acc: (99.53%) (31976/32128)\n",
            "Epoch: 175 | Batch_idx: 260 |  Loss: (0.0133) | Acc: (99.53%) (33252/33408)\n",
            "Epoch: 175 | Batch_idx: 270 |  Loss: (0.0132) | Acc: (99.54%) (34528/34688)\n",
            "Epoch: 175 | Batch_idx: 280 |  Loss: (0.0131) | Acc: (99.55%) (35805/35968)\n",
            "Epoch: 175 | Batch_idx: 290 |  Loss: (0.0129) | Acc: (99.55%) (37081/37248)\n",
            "Epoch: 175 | Batch_idx: 300 |  Loss: (0.0129) | Acc: (99.55%) (38355/38528)\n",
            "Epoch: 175 | Batch_idx: 310 |  Loss: (0.0132) | Acc: (99.55%) (39628/39808)\n",
            "Epoch: 175 | Batch_idx: 320 |  Loss: (0.0133) | Acc: (99.55%) (40902/41088)\n",
            "Epoch: 175 | Batch_idx: 330 |  Loss: (0.0132) | Acc: (99.55%) (42176/42368)\n",
            "Epoch: 175 | Batch_idx: 340 |  Loss: (0.0133) | Acc: (99.54%) (43447/43648)\n",
            "Epoch: 175 | Batch_idx: 350 |  Loss: (0.0135) | Acc: (99.54%) (44721/44928)\n",
            "Epoch: 175 | Batch_idx: 360 |  Loss: (0.0135) | Acc: (99.54%) (45994/46208)\n",
            "Epoch: 175 | Batch_idx: 370 |  Loss: (0.0136) | Acc: (99.53%) (47264/47488)\n",
            "Epoch: 175 | Batch_idx: 380 |  Loss: (0.0137) | Acc: (99.53%) (48539/48768)\n",
            "Epoch: 175 | Batch_idx: 390 |  Loss: (0.0137) | Acc: (99.53%) (49766/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3949) | Acc: (91.86%) (9186/10000)\n",
            "Epoch: 176 | Batch_idx: 0 |  Loss: (0.0413) | Acc: (98.44%) (126/128)\n",
            "Epoch: 176 | Batch_idx: 10 |  Loss: (0.0131) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 176 | Batch_idx: 20 |  Loss: (0.0165) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 176 | Batch_idx: 30 |  Loss: (0.0170) | Acc: (99.42%) (3945/3968)\n",
            "Epoch: 176 | Batch_idx: 40 |  Loss: (0.0173) | Acc: (99.41%) (5217/5248)\n",
            "Epoch: 176 | Batch_idx: 50 |  Loss: (0.0175) | Acc: (99.39%) (6488/6528)\n",
            "Epoch: 176 | Batch_idx: 60 |  Loss: (0.0166) | Acc: (99.44%) (7764/7808)\n",
            "Epoch: 176 | Batch_idx: 70 |  Loss: (0.0171) | Acc: (99.44%) (9037/9088)\n",
            "Epoch: 176 | Batch_idx: 80 |  Loss: (0.0174) | Acc: (99.44%) (10310/10368)\n",
            "Epoch: 176 | Batch_idx: 90 |  Loss: (0.0189) | Acc: (99.40%) (11578/11648)\n",
            "Epoch: 176 | Batch_idx: 100 |  Loss: (0.0187) | Acc: (99.42%) (12853/12928)\n",
            "Epoch: 176 | Batch_idx: 110 |  Loss: (0.0181) | Acc: (99.43%) (14127/14208)\n",
            "Epoch: 176 | Batch_idx: 120 |  Loss: (0.0173) | Acc: (99.46%) (15405/15488)\n",
            "Epoch: 176 | Batch_idx: 130 |  Loss: (0.0168) | Acc: (99.48%) (16681/16768)\n",
            "Epoch: 176 | Batch_idx: 140 |  Loss: (0.0164) | Acc: (99.48%) (17955/18048)\n",
            "Epoch: 176 | Batch_idx: 150 |  Loss: (0.0162) | Acc: (99.49%) (19230/19328)\n",
            "Epoch: 176 | Batch_idx: 160 |  Loss: (0.0159) | Acc: (99.49%) (20503/20608)\n",
            "Epoch: 176 | Batch_idx: 170 |  Loss: (0.0156) | Acc: (99.51%) (21780/21888)\n",
            "Epoch: 176 | Batch_idx: 180 |  Loss: (0.0158) | Acc: (99.49%) (23051/23168)\n",
            "Epoch: 176 | Batch_idx: 190 |  Loss: (0.0154) | Acc: (99.52%) (24330/24448)\n",
            "Epoch: 176 | Batch_idx: 200 |  Loss: (0.0154) | Acc: (99.51%) (25603/25728)\n",
            "Epoch: 176 | Batch_idx: 210 |  Loss: (0.0156) | Acc: (99.51%) (26875/27008)\n",
            "Epoch: 176 | Batch_idx: 220 |  Loss: (0.0154) | Acc: (99.52%) (28152/28288)\n",
            "Epoch: 176 | Batch_idx: 230 |  Loss: (0.0153) | Acc: (99.53%) (29428/29568)\n",
            "Epoch: 176 | Batch_idx: 240 |  Loss: (0.0155) | Acc: (99.52%) (30699/30848)\n",
            "Epoch: 176 | Batch_idx: 250 |  Loss: (0.0156) | Acc: (99.51%) (31970/32128)\n",
            "Epoch: 176 | Batch_idx: 260 |  Loss: (0.0156) | Acc: (99.50%) (33242/33408)\n",
            "Epoch: 176 | Batch_idx: 270 |  Loss: (0.0154) | Acc: (99.51%) (34518/34688)\n",
            "Epoch: 176 | Batch_idx: 280 |  Loss: (0.0155) | Acc: (99.51%) (35791/35968)\n",
            "Epoch: 176 | Batch_idx: 290 |  Loss: (0.0154) | Acc: (99.50%) (37062/37248)\n",
            "Epoch: 176 | Batch_idx: 300 |  Loss: (0.0154) | Acc: (99.50%) (38334/38528)\n",
            "Epoch: 176 | Batch_idx: 310 |  Loss: (0.0153) | Acc: (99.50%) (39610/39808)\n",
            "Epoch: 176 | Batch_idx: 320 |  Loss: (0.0154) | Acc: (99.50%) (40881/41088)\n",
            "Epoch: 176 | Batch_idx: 330 |  Loss: (0.0153) | Acc: (99.50%) (42156/42368)\n",
            "Epoch: 176 | Batch_idx: 340 |  Loss: (0.0153) | Acc: (99.50%) (43428/43648)\n",
            "Epoch: 176 | Batch_idx: 350 |  Loss: (0.0152) | Acc: (99.50%) (44704/44928)\n",
            "Epoch: 176 | Batch_idx: 360 |  Loss: (0.0150) | Acc: (99.51%) (45982/46208)\n",
            "Epoch: 176 | Batch_idx: 370 |  Loss: (0.0153) | Acc: (99.50%) (47249/47488)\n",
            "Epoch: 176 | Batch_idx: 380 |  Loss: (0.0151) | Acc: (99.50%) (48524/48768)\n",
            "Epoch: 176 | Batch_idx: 390 |  Loss: (0.0151) | Acc: (99.50%) (49751/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3949) | Acc: (91.89%) (9189/10000)\n",
            "Epoch: 177 | Batch_idx: 0 |  Loss: (0.0122) | Acc: (100.00%) (128/128)\n",
            "Epoch: 177 | Batch_idx: 10 |  Loss: (0.0182) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 177 | Batch_idx: 20 |  Loss: (0.0188) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 177 | Batch_idx: 30 |  Loss: (0.0165) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 177 | Batch_idx: 40 |  Loss: (0.0216) | Acc: (99.35%) (5214/5248)\n",
            "Epoch: 177 | Batch_idx: 50 |  Loss: (0.0199) | Acc: (99.42%) (6490/6528)\n",
            "Epoch: 177 | Batch_idx: 60 |  Loss: (0.0182) | Acc: (99.46%) (7766/7808)\n",
            "Epoch: 177 | Batch_idx: 70 |  Loss: (0.0176) | Acc: (99.47%) (9040/9088)\n",
            "Epoch: 177 | Batch_idx: 80 |  Loss: (0.0170) | Acc: (99.48%) (10314/10368)\n",
            "Epoch: 177 | Batch_idx: 90 |  Loss: (0.0171) | Acc: (99.45%) (11584/11648)\n",
            "Epoch: 177 | Batch_idx: 100 |  Loss: (0.0175) | Acc: (99.43%) (12854/12928)\n",
            "Epoch: 177 | Batch_idx: 110 |  Loss: (0.0170) | Acc: (99.42%) (14126/14208)\n",
            "Epoch: 177 | Batch_idx: 120 |  Loss: (0.0164) | Acc: (99.46%) (15404/15488)\n",
            "Epoch: 177 | Batch_idx: 130 |  Loss: (0.0162) | Acc: (99.47%) (16679/16768)\n",
            "Epoch: 177 | Batch_idx: 140 |  Loss: (0.0163) | Acc: (99.47%) (17953/18048)\n",
            "Epoch: 177 | Batch_idx: 150 |  Loss: (0.0164) | Acc: (99.48%) (19228/19328)\n",
            "Epoch: 177 | Batch_idx: 160 |  Loss: (0.0165) | Acc: (99.47%) (20498/20608)\n",
            "Epoch: 177 | Batch_idx: 170 |  Loss: (0.0163) | Acc: (99.47%) (21771/21888)\n",
            "Epoch: 177 | Batch_idx: 180 |  Loss: (0.0165) | Acc: (99.46%) (23043/23168)\n",
            "Epoch: 177 | Batch_idx: 190 |  Loss: (0.0161) | Acc: (99.47%) (24319/24448)\n",
            "Epoch: 177 | Batch_idx: 200 |  Loss: (0.0157) | Acc: (99.49%) (25596/25728)\n",
            "Epoch: 177 | Batch_idx: 210 |  Loss: (0.0155) | Acc: (99.50%) (26873/27008)\n",
            "Epoch: 177 | Batch_idx: 220 |  Loss: (0.0150) | Acc: (99.52%) (28151/28288)\n",
            "Epoch: 177 | Batch_idx: 230 |  Loss: (0.0152) | Acc: (99.51%) (29422/29568)\n",
            "Epoch: 177 | Batch_idx: 240 |  Loss: (0.0153) | Acc: (99.50%) (30695/30848)\n",
            "Epoch: 177 | Batch_idx: 250 |  Loss: (0.0151) | Acc: (99.51%) (31972/32128)\n",
            "Epoch: 177 | Batch_idx: 260 |  Loss: (0.0152) | Acc: (99.51%) (33245/33408)\n",
            "Epoch: 177 | Batch_idx: 270 |  Loss: (0.0151) | Acc: (99.51%) (34519/34688)\n",
            "Epoch: 177 | Batch_idx: 280 |  Loss: (0.0150) | Acc: (99.52%) (35795/35968)\n",
            "Epoch: 177 | Batch_idx: 290 |  Loss: (0.0148) | Acc: (99.52%) (37071/37248)\n",
            "Epoch: 177 | Batch_idx: 300 |  Loss: (0.0149) | Acc: (99.52%) (38343/38528)\n",
            "Epoch: 177 | Batch_idx: 310 |  Loss: (0.0149) | Acc: (99.52%) (39617/39808)\n",
            "Epoch: 177 | Batch_idx: 320 |  Loss: (0.0149) | Acc: (99.52%) (40890/41088)\n",
            "Epoch: 177 | Batch_idx: 330 |  Loss: (0.0154) | Acc: (99.50%) (42157/42368)\n",
            "Epoch: 177 | Batch_idx: 340 |  Loss: (0.0155) | Acc: (99.50%) (43429/43648)\n",
            "Epoch: 177 | Batch_idx: 350 |  Loss: (0.0154) | Acc: (99.50%) (44703/44928)\n",
            "Epoch: 177 | Batch_idx: 360 |  Loss: (0.0153) | Acc: (99.50%) (45978/46208)\n",
            "Epoch: 177 | Batch_idx: 370 |  Loss: (0.0153) | Acc: (99.51%) (47254/47488)\n",
            "Epoch: 177 | Batch_idx: 380 |  Loss: (0.0152) | Acc: (99.51%) (48529/48768)\n",
            "Epoch: 177 | Batch_idx: 390 |  Loss: (0.0151) | Acc: (99.51%) (49756/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3978) | Acc: (91.73%) (9173/10000)\n",
            "Epoch: 178 | Batch_idx: 0 |  Loss: (0.0237) | Acc: (99.22%) (127/128)\n",
            "Epoch: 178 | Batch_idx: 10 |  Loss: (0.0086) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 178 | Batch_idx: 20 |  Loss: (0.0084) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 178 | Batch_idx: 30 |  Loss: (0.0112) | Acc: (99.65%) (3954/3968)\n",
            "Epoch: 178 | Batch_idx: 40 |  Loss: (0.0113) | Acc: (99.64%) (5229/5248)\n",
            "Epoch: 178 | Batch_idx: 50 |  Loss: (0.0116) | Acc: (99.62%) (6503/6528)\n",
            "Epoch: 178 | Batch_idx: 60 |  Loss: (0.0136) | Acc: (99.55%) (7773/7808)\n",
            "Epoch: 178 | Batch_idx: 70 |  Loss: (0.0155) | Acc: (99.53%) (9045/9088)\n",
            "Epoch: 178 | Batch_idx: 80 |  Loss: (0.0164) | Acc: (99.47%) (10313/10368)\n",
            "Epoch: 178 | Batch_idx: 90 |  Loss: (0.0168) | Acc: (99.45%) (11584/11648)\n",
            "Epoch: 178 | Batch_idx: 100 |  Loss: (0.0169) | Acc: (99.44%) (12855/12928)\n",
            "Epoch: 178 | Batch_idx: 110 |  Loss: (0.0176) | Acc: (99.42%) (14126/14208)\n",
            "Epoch: 178 | Batch_idx: 120 |  Loss: (0.0170) | Acc: (99.44%) (15401/15488)\n",
            "Epoch: 178 | Batch_idx: 130 |  Loss: (0.0173) | Acc: (99.42%) (16671/16768)\n",
            "Epoch: 178 | Batch_idx: 140 |  Loss: (0.0167) | Acc: (99.43%) (17946/18048)\n",
            "Epoch: 178 | Batch_idx: 150 |  Loss: (0.0165) | Acc: (99.44%) (19219/19328)\n",
            "Epoch: 178 | Batch_idx: 160 |  Loss: (0.0164) | Acc: (99.42%) (20488/20608)\n",
            "Epoch: 178 | Batch_idx: 170 |  Loss: (0.0165) | Acc: (99.41%) (21759/21888)\n",
            "Epoch: 178 | Batch_idx: 180 |  Loss: (0.0165) | Acc: (99.40%) (23030/23168)\n",
            "Epoch: 178 | Batch_idx: 190 |  Loss: (0.0167) | Acc: (99.40%) (24301/24448)\n",
            "Epoch: 178 | Batch_idx: 200 |  Loss: (0.0166) | Acc: (99.40%) (25574/25728)\n",
            "Epoch: 178 | Batch_idx: 210 |  Loss: (0.0165) | Acc: (99.40%) (26847/27008)\n",
            "Epoch: 178 | Batch_idx: 220 |  Loss: (0.0162) | Acc: (99.42%) (28123/28288)\n",
            "Epoch: 178 | Batch_idx: 230 |  Loss: (0.0164) | Acc: (99.41%) (29393/29568)\n",
            "Epoch: 178 | Batch_idx: 240 |  Loss: (0.0163) | Acc: (99.41%) (30665/30848)\n",
            "Epoch: 178 | Batch_idx: 250 |  Loss: (0.0162) | Acc: (99.42%) (31941/32128)\n",
            "Epoch: 178 | Batch_idx: 260 |  Loss: (0.0163) | Acc: (99.41%) (33212/33408)\n",
            "Epoch: 178 | Batch_idx: 270 |  Loss: (0.0161) | Acc: (99.42%) (34488/34688)\n",
            "Epoch: 178 | Batch_idx: 280 |  Loss: (0.0161) | Acc: (99.43%) (35762/35968)\n",
            "Epoch: 178 | Batch_idx: 290 |  Loss: (0.0163) | Acc: (99.43%) (37034/37248)\n",
            "Epoch: 178 | Batch_idx: 300 |  Loss: (0.0164) | Acc: (99.42%) (38306/38528)\n",
            "Epoch: 178 | Batch_idx: 310 |  Loss: (0.0165) | Acc: (99.42%) (39579/39808)\n",
            "Epoch: 178 | Batch_idx: 320 |  Loss: (0.0164) | Acc: (99.44%) (40856/41088)\n",
            "Epoch: 178 | Batch_idx: 330 |  Loss: (0.0163) | Acc: (99.44%) (42131/42368)\n",
            "Epoch: 178 | Batch_idx: 340 |  Loss: (0.0163) | Acc: (99.44%) (43404/43648)\n",
            "Epoch: 178 | Batch_idx: 350 |  Loss: (0.0160) | Acc: (99.45%) (44681/44928)\n",
            "Epoch: 178 | Batch_idx: 360 |  Loss: (0.0161) | Acc: (99.45%) (45953/46208)\n",
            "Epoch: 178 | Batch_idx: 370 |  Loss: (0.0162) | Acc: (99.45%) (47225/47488)\n",
            "Epoch: 178 | Batch_idx: 380 |  Loss: (0.0163) | Acc: (99.44%) (48494/48768)\n",
            "Epoch: 178 | Batch_idx: 390 |  Loss: (0.0164) | Acc: (99.43%) (49716/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3989) | Acc: (91.73%) (9173/10000)\n",
            "Epoch: 179 | Batch_idx: 0 |  Loss: (0.0199) | Acc: (99.22%) (127/128)\n",
            "Epoch: 179 | Batch_idx: 10 |  Loss: (0.0140) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 179 | Batch_idx: 20 |  Loss: (0.0122) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 179 | Batch_idx: 30 |  Loss: (0.0124) | Acc: (99.60%) (3952/3968)\n",
            "Epoch: 179 | Batch_idx: 40 |  Loss: (0.0115) | Acc: (99.62%) (5228/5248)\n",
            "Epoch: 179 | Batch_idx: 50 |  Loss: (0.0114) | Acc: (99.60%) (6502/6528)\n",
            "Epoch: 179 | Batch_idx: 60 |  Loss: (0.0110) | Acc: (99.62%) (7778/7808)\n",
            "Epoch: 179 | Batch_idx: 70 |  Loss: (0.0110) | Acc: (99.63%) (9054/9088)\n",
            "Epoch: 179 | Batch_idx: 80 |  Loss: (0.0106) | Acc: (99.64%) (10331/10368)\n",
            "Epoch: 179 | Batch_idx: 90 |  Loss: (0.0104) | Acc: (99.66%) (11608/11648)\n",
            "Epoch: 179 | Batch_idx: 100 |  Loss: (0.0107) | Acc: (99.65%) (12883/12928)\n",
            "Epoch: 179 | Batch_idx: 110 |  Loss: (0.0110) | Acc: (99.66%) (14159/14208)\n",
            "Epoch: 179 | Batch_idx: 120 |  Loss: (0.0109) | Acc: (99.66%) (15435/15488)\n",
            "Epoch: 179 | Batch_idx: 130 |  Loss: (0.0111) | Acc: (99.64%) (16707/16768)\n",
            "Epoch: 179 | Batch_idx: 140 |  Loss: (0.0116) | Acc: (99.62%) (17980/18048)\n",
            "Epoch: 179 | Batch_idx: 150 |  Loss: (0.0117) | Acc: (99.60%) (19251/19328)\n",
            "Epoch: 179 | Batch_idx: 160 |  Loss: (0.0116) | Acc: (99.60%) (20525/20608)\n",
            "Epoch: 179 | Batch_idx: 170 |  Loss: (0.0119) | Acc: (99.58%) (21797/21888)\n",
            "Epoch: 179 | Batch_idx: 180 |  Loss: (0.0119) | Acc: (99.59%) (23072/23168)\n",
            "Epoch: 179 | Batch_idx: 190 |  Loss: (0.0119) | Acc: (99.59%) (24347/24448)\n",
            "Epoch: 179 | Batch_idx: 200 |  Loss: (0.0119) | Acc: (99.59%) (25622/25728)\n",
            "Epoch: 179 | Batch_idx: 210 |  Loss: (0.0122) | Acc: (99.57%) (26892/27008)\n",
            "Epoch: 179 | Batch_idx: 220 |  Loss: (0.0121) | Acc: (99.57%) (28167/28288)\n",
            "Epoch: 179 | Batch_idx: 230 |  Loss: (0.0119) | Acc: (99.59%) (29446/29568)\n",
            "Epoch: 179 | Batch_idx: 240 |  Loss: (0.0123) | Acc: (99.57%) (30715/30848)\n",
            "Epoch: 179 | Batch_idx: 250 |  Loss: (0.0127) | Acc: (99.55%) (31984/32128)\n",
            "Epoch: 179 | Batch_idx: 260 |  Loss: (0.0126) | Acc: (99.56%) (33260/33408)\n",
            "Epoch: 179 | Batch_idx: 270 |  Loss: (0.0127) | Acc: (99.55%) (34533/34688)\n",
            "Epoch: 179 | Batch_idx: 280 |  Loss: (0.0130) | Acc: (99.55%) (35805/35968)\n",
            "Epoch: 179 | Batch_idx: 290 |  Loss: (0.0131) | Acc: (99.54%) (37077/37248)\n",
            "Epoch: 179 | Batch_idx: 300 |  Loss: (0.0130) | Acc: (99.55%) (38353/38528)\n",
            "Epoch: 179 | Batch_idx: 310 |  Loss: (0.0129) | Acc: (99.55%) (39629/39808)\n",
            "Epoch: 179 | Batch_idx: 320 |  Loss: (0.0129) | Acc: (99.55%) (40902/41088)\n",
            "Epoch: 179 | Batch_idx: 330 |  Loss: (0.0130) | Acc: (99.54%) (42174/42368)\n",
            "Epoch: 179 | Batch_idx: 340 |  Loss: (0.0130) | Acc: (99.54%) (43448/43648)\n",
            "Epoch: 179 | Batch_idx: 350 |  Loss: (0.0128) | Acc: (99.55%) (44725/44928)\n",
            "Epoch: 179 | Batch_idx: 360 |  Loss: (0.0130) | Acc: (99.54%) (45997/46208)\n",
            "Epoch: 179 | Batch_idx: 370 |  Loss: (0.0129) | Acc: (99.55%) (47274/47488)\n",
            "Epoch: 179 | Batch_idx: 380 |  Loss: (0.0130) | Acc: (99.54%) (48546/48768)\n",
            "Epoch: 179 | Batch_idx: 390 |  Loss: (0.0130) | Acc: (99.54%) (49768/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3950) | Acc: (91.95%) (9195/10000)\n",
            "Epoch: 180 | Batch_idx: 0 |  Loss: (0.0809) | Acc: (98.44%) (126/128)\n",
            "Epoch: 180 | Batch_idx: 10 |  Loss: (0.0252) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 180 | Batch_idx: 20 |  Loss: (0.0217) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 180 | Batch_idx: 30 |  Loss: (0.0209) | Acc: (99.40%) (3944/3968)\n",
            "Epoch: 180 | Batch_idx: 40 |  Loss: (0.0194) | Acc: (99.43%) (5218/5248)\n",
            "Epoch: 180 | Batch_idx: 50 |  Loss: (0.0189) | Acc: (99.42%) (6490/6528)\n",
            "Epoch: 180 | Batch_idx: 60 |  Loss: (0.0178) | Acc: (99.46%) (7766/7808)\n",
            "Epoch: 180 | Batch_idx: 70 |  Loss: (0.0174) | Acc: (99.46%) (9039/9088)\n",
            "Epoch: 180 | Batch_idx: 80 |  Loss: (0.0165) | Acc: (99.47%) (10313/10368)\n",
            "Epoch: 180 | Batch_idx: 90 |  Loss: (0.0158) | Acc: (99.48%) (11588/11648)\n",
            "Epoch: 180 | Batch_idx: 100 |  Loss: (0.0153) | Acc: (99.50%) (12864/12928)\n",
            "Epoch: 180 | Batch_idx: 110 |  Loss: (0.0149) | Acc: (99.52%) (14140/14208)\n",
            "Epoch: 180 | Batch_idx: 120 |  Loss: (0.0147) | Acc: (99.52%) (15413/15488)\n",
            "Epoch: 180 | Batch_idx: 130 |  Loss: (0.0142) | Acc: (99.53%) (16690/16768)\n",
            "Epoch: 180 | Batch_idx: 140 |  Loss: (0.0142) | Acc: (99.54%) (17965/18048)\n",
            "Epoch: 180 | Batch_idx: 150 |  Loss: (0.0143) | Acc: (99.53%) (19238/19328)\n",
            "Epoch: 180 | Batch_idx: 160 |  Loss: (0.0142) | Acc: (99.53%) (20512/20608)\n",
            "Epoch: 180 | Batch_idx: 170 |  Loss: (0.0146) | Acc: (99.53%) (21785/21888)\n",
            "Epoch: 180 | Batch_idx: 180 |  Loss: (0.0147) | Acc: (99.53%) (23058/23168)\n",
            "Epoch: 180 | Batch_idx: 190 |  Loss: (0.0148) | Acc: (99.53%) (24333/24448)\n",
            "Epoch: 180 | Batch_idx: 200 |  Loss: (0.0148) | Acc: (99.52%) (25605/25728)\n",
            "Epoch: 180 | Batch_idx: 210 |  Loss: (0.0145) | Acc: (99.53%) (26882/27008)\n",
            "Epoch: 180 | Batch_idx: 220 |  Loss: (0.0147) | Acc: (99.51%) (28150/28288)\n",
            "Epoch: 180 | Batch_idx: 230 |  Loss: (0.0146) | Acc: (99.51%) (29424/29568)\n",
            "Epoch: 180 | Batch_idx: 240 |  Loss: (0.0146) | Acc: (99.51%) (30698/30848)\n",
            "Epoch: 180 | Batch_idx: 250 |  Loss: (0.0143) | Acc: (99.52%) (31975/32128)\n",
            "Epoch: 180 | Batch_idx: 260 |  Loss: (0.0142) | Acc: (99.53%) (33250/33408)\n",
            "Epoch: 180 | Batch_idx: 270 |  Loss: (0.0141) | Acc: (99.53%) (34526/34688)\n",
            "Epoch: 180 | Batch_idx: 280 |  Loss: (0.0141) | Acc: (99.53%) (35799/35968)\n",
            "Epoch: 180 | Batch_idx: 290 |  Loss: (0.0140) | Acc: (99.53%) (37073/37248)\n",
            "Epoch: 180 | Batch_idx: 300 |  Loss: (0.0140) | Acc: (99.53%) (38345/38528)\n",
            "Epoch: 180 | Batch_idx: 310 |  Loss: (0.0142) | Acc: (99.52%) (39616/39808)\n",
            "Epoch: 180 | Batch_idx: 320 |  Loss: (0.0144) | Acc: (99.51%) (40886/41088)\n",
            "Epoch: 180 | Batch_idx: 330 |  Loss: (0.0144) | Acc: (99.51%) (42159/42368)\n",
            "Epoch: 180 | Batch_idx: 340 |  Loss: (0.0145) | Acc: (99.50%) (43431/43648)\n",
            "Epoch: 180 | Batch_idx: 350 |  Loss: (0.0143) | Acc: (99.51%) (44706/44928)\n",
            "Epoch: 180 | Batch_idx: 360 |  Loss: (0.0144) | Acc: (99.50%) (45975/46208)\n",
            "Epoch: 180 | Batch_idx: 370 |  Loss: (0.0144) | Acc: (99.49%) (47248/47488)\n",
            "Epoch: 180 | Batch_idx: 380 |  Loss: (0.0142) | Acc: (99.50%) (48523/48768)\n",
            "Epoch: 180 | Batch_idx: 390 |  Loss: (0.0143) | Acc: (99.49%) (49747/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3949) | Acc: (91.87%) (9187/10000)\n",
            "Epoch: 181 | Batch_idx: 0 |  Loss: (0.0028) | Acc: (100.00%) (128/128)\n",
            "Epoch: 181 | Batch_idx: 10 |  Loss: (0.0117) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 181 | Batch_idx: 20 |  Loss: (0.0145) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 181 | Batch_idx: 30 |  Loss: (0.0144) | Acc: (99.55%) (3950/3968)\n",
            "Epoch: 181 | Batch_idx: 40 |  Loss: (0.0188) | Acc: (99.43%) (5218/5248)\n",
            "Epoch: 181 | Batch_idx: 50 |  Loss: (0.0174) | Acc: (99.42%) (6490/6528)\n",
            "Epoch: 181 | Batch_idx: 60 |  Loss: (0.0167) | Acc: (99.44%) (7764/7808)\n",
            "Epoch: 181 | Batch_idx: 70 |  Loss: (0.0155) | Acc: (99.48%) (9041/9088)\n",
            "Epoch: 181 | Batch_idx: 80 |  Loss: (0.0152) | Acc: (99.52%) (10318/10368)\n",
            "Epoch: 181 | Batch_idx: 90 |  Loss: (0.0145) | Acc: (99.54%) (11595/11648)\n",
            "Epoch: 181 | Batch_idx: 100 |  Loss: (0.0152) | Acc: (99.49%) (12862/12928)\n",
            "Epoch: 181 | Batch_idx: 110 |  Loss: (0.0155) | Acc: (99.47%) (14133/14208)\n",
            "Epoch: 181 | Batch_idx: 120 |  Loss: (0.0151) | Acc: (99.50%) (15410/15488)\n",
            "Epoch: 181 | Batch_idx: 130 |  Loss: (0.0145) | Acc: (99.52%) (16688/16768)\n",
            "Epoch: 181 | Batch_idx: 140 |  Loss: (0.0149) | Acc: (99.50%) (17957/18048)\n",
            "Epoch: 181 | Batch_idx: 150 |  Loss: (0.0150) | Acc: (99.50%) (19231/19328)\n",
            "Epoch: 181 | Batch_idx: 160 |  Loss: (0.0148) | Acc: (99.50%) (20504/20608)\n",
            "Epoch: 181 | Batch_idx: 170 |  Loss: (0.0148) | Acc: (99.49%) (21777/21888)\n",
            "Epoch: 181 | Batch_idx: 180 |  Loss: (0.0148) | Acc: (99.49%) (23051/23168)\n",
            "Epoch: 181 | Batch_idx: 190 |  Loss: (0.0147) | Acc: (99.50%) (24325/24448)\n",
            "Epoch: 181 | Batch_idx: 200 |  Loss: (0.0145) | Acc: (99.50%) (25600/25728)\n",
            "Epoch: 181 | Batch_idx: 210 |  Loss: (0.0145) | Acc: (99.50%) (26872/27008)\n",
            "Epoch: 181 | Batch_idx: 220 |  Loss: (0.0142) | Acc: (99.52%) (28151/28288)\n",
            "Epoch: 181 | Batch_idx: 230 |  Loss: (0.0143) | Acc: (99.51%) (29424/29568)\n",
            "Epoch: 181 | Batch_idx: 240 |  Loss: (0.0144) | Acc: (99.51%) (30696/30848)\n",
            "Epoch: 181 | Batch_idx: 250 |  Loss: (0.0146) | Acc: (99.50%) (31967/32128)\n",
            "Epoch: 181 | Batch_idx: 260 |  Loss: (0.0143) | Acc: (99.51%) (33244/33408)\n",
            "Epoch: 181 | Batch_idx: 270 |  Loss: (0.0145) | Acc: (99.50%) (34514/34688)\n",
            "Epoch: 181 | Batch_idx: 280 |  Loss: (0.0146) | Acc: (99.50%) (35789/35968)\n",
            "Epoch: 181 | Batch_idx: 290 |  Loss: (0.0144) | Acc: (99.50%) (37063/37248)\n",
            "Epoch: 181 | Batch_idx: 300 |  Loss: (0.0148) | Acc: (99.49%) (38333/38528)\n",
            "Epoch: 181 | Batch_idx: 310 |  Loss: (0.0148) | Acc: (99.50%) (39607/39808)\n",
            "Epoch: 181 | Batch_idx: 320 |  Loss: (0.0145) | Acc: (99.50%) (40884/41088)\n",
            "Epoch: 181 | Batch_idx: 330 |  Loss: (0.0145) | Acc: (99.51%) (42160/42368)\n",
            "Epoch: 181 | Batch_idx: 340 |  Loss: (0.0145) | Acc: (99.51%) (43435/43648)\n",
            "Epoch: 181 | Batch_idx: 350 |  Loss: (0.0146) | Acc: (99.52%) (44711/44928)\n",
            "Epoch: 181 | Batch_idx: 360 |  Loss: (0.0146) | Acc: (99.51%) (45980/46208)\n",
            "Epoch: 181 | Batch_idx: 370 |  Loss: (0.0146) | Acc: (99.50%) (47251/47488)\n",
            "Epoch: 181 | Batch_idx: 380 |  Loss: (0.0145) | Acc: (99.50%) (48524/48768)\n",
            "Epoch: 181 | Batch_idx: 390 |  Loss: (0.0145) | Acc: (99.50%) (49750/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3973) | Acc: (91.85%) (9185/10000)\n",
            "Epoch: 182 | Batch_idx: 0 |  Loss: (0.0063) | Acc: (100.00%) (128/128)\n",
            "Epoch: 182 | Batch_idx: 10 |  Loss: (0.0117) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 182 | Batch_idx: 20 |  Loss: (0.0125) | Acc: (99.70%) (2680/2688)\n",
            "Epoch: 182 | Batch_idx: 30 |  Loss: (0.0105) | Acc: (99.72%) (3957/3968)\n",
            "Epoch: 182 | Batch_idx: 40 |  Loss: (0.0118) | Acc: (99.64%) (5229/5248)\n",
            "Epoch: 182 | Batch_idx: 50 |  Loss: (0.0115) | Acc: (99.60%) (6502/6528)\n",
            "Epoch: 182 | Batch_idx: 60 |  Loss: (0.0120) | Acc: (99.60%) (7777/7808)\n",
            "Epoch: 182 | Batch_idx: 70 |  Loss: (0.0131) | Acc: (99.56%) (9048/9088)\n",
            "Epoch: 182 | Batch_idx: 80 |  Loss: (0.0133) | Acc: (99.56%) (10322/10368)\n",
            "Epoch: 182 | Batch_idx: 90 |  Loss: (0.0130) | Acc: (99.58%) (11599/11648)\n",
            "Epoch: 182 | Batch_idx: 100 |  Loss: (0.0130) | Acc: (99.58%) (12874/12928)\n",
            "Epoch: 182 | Batch_idx: 110 |  Loss: (0.0131) | Acc: (99.58%) (14148/14208)\n",
            "Epoch: 182 | Batch_idx: 120 |  Loss: (0.0136) | Acc: (99.57%) (15422/15488)\n",
            "Epoch: 182 | Batch_idx: 130 |  Loss: (0.0136) | Acc: (99.56%) (16695/16768)\n",
            "Epoch: 182 | Batch_idx: 140 |  Loss: (0.0138) | Acc: (99.56%) (17968/18048)\n",
            "Epoch: 182 | Batch_idx: 150 |  Loss: (0.0139) | Acc: (99.57%) (19245/19328)\n",
            "Epoch: 182 | Batch_idx: 160 |  Loss: (0.0135) | Acc: (99.59%) (20523/20608)\n",
            "Epoch: 182 | Batch_idx: 170 |  Loss: (0.0132) | Acc: (99.58%) (21797/21888)\n",
            "Epoch: 182 | Batch_idx: 180 |  Loss: (0.0129) | Acc: (99.59%) (23073/23168)\n",
            "Epoch: 182 | Batch_idx: 190 |  Loss: (0.0132) | Acc: (99.58%) (24345/24448)\n",
            "Epoch: 182 | Batch_idx: 200 |  Loss: (0.0130) | Acc: (99.59%) (25622/25728)\n",
            "Epoch: 182 | Batch_idx: 210 |  Loss: (0.0129) | Acc: (99.59%) (26896/27008)\n",
            "Epoch: 182 | Batch_idx: 220 |  Loss: (0.0133) | Acc: (99.57%) (28166/28288)\n",
            "Epoch: 182 | Batch_idx: 230 |  Loss: (0.0131) | Acc: (99.58%) (29443/29568)\n",
            "Epoch: 182 | Batch_idx: 240 |  Loss: (0.0129) | Acc: (99.59%) (30721/30848)\n",
            "Epoch: 182 | Batch_idx: 250 |  Loss: (0.0131) | Acc: (99.58%) (31993/32128)\n",
            "Epoch: 182 | Batch_idx: 260 |  Loss: (0.0131) | Acc: (99.59%) (33271/33408)\n",
            "Epoch: 182 | Batch_idx: 270 |  Loss: (0.0131) | Acc: (99.59%) (34546/34688)\n",
            "Epoch: 182 | Batch_idx: 280 |  Loss: (0.0130) | Acc: (99.59%) (35820/35968)\n",
            "Epoch: 182 | Batch_idx: 290 |  Loss: (0.0132) | Acc: (99.58%) (37090/37248)\n",
            "Epoch: 182 | Batch_idx: 300 |  Loss: (0.0132) | Acc: (99.57%) (38363/38528)\n",
            "Epoch: 182 | Batch_idx: 310 |  Loss: (0.0132) | Acc: (99.57%) (39636/39808)\n",
            "Epoch: 182 | Batch_idx: 320 |  Loss: (0.0133) | Acc: (99.56%) (40909/41088)\n",
            "Epoch: 182 | Batch_idx: 330 |  Loss: (0.0132) | Acc: (99.57%) (42185/42368)\n",
            "Epoch: 182 | Batch_idx: 340 |  Loss: (0.0131) | Acc: (99.57%) (43462/43648)\n",
            "Epoch: 182 | Batch_idx: 350 |  Loss: (0.0132) | Acc: (99.57%) (44737/44928)\n",
            "Epoch: 182 | Batch_idx: 360 |  Loss: (0.0134) | Acc: (99.57%) (46008/46208)\n",
            "Epoch: 182 | Batch_idx: 370 |  Loss: (0.0134) | Acc: (99.57%) (47282/47488)\n",
            "Epoch: 182 | Batch_idx: 380 |  Loss: (0.0142) | Acc: (99.55%) (48547/48768)\n",
            "Epoch: 182 | Batch_idx: 390 |  Loss: (0.0142) | Acc: (99.54%) (49772/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3995) | Acc: (91.72%) (9172/10000)\n",
            "Epoch: 183 | Batch_idx: 0 |  Loss: (0.0027) | Acc: (100.00%) (128/128)\n",
            "Epoch: 183 | Batch_idx: 10 |  Loss: (0.0119) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 183 | Batch_idx: 20 |  Loss: (0.0127) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 183 | Batch_idx: 30 |  Loss: (0.0151) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 183 | Batch_idx: 40 |  Loss: (0.0136) | Acc: (99.54%) (5224/5248)\n",
            "Epoch: 183 | Batch_idx: 50 |  Loss: (0.0131) | Acc: (99.53%) (6497/6528)\n",
            "Epoch: 183 | Batch_idx: 60 |  Loss: (0.0136) | Acc: (99.50%) (7769/7808)\n",
            "Epoch: 183 | Batch_idx: 70 |  Loss: (0.0152) | Acc: (99.48%) (9041/9088)\n",
            "Epoch: 183 | Batch_idx: 80 |  Loss: (0.0166) | Acc: (99.39%) (10305/10368)\n",
            "Epoch: 183 | Batch_idx: 90 |  Loss: (0.0162) | Acc: (99.39%) (11577/11648)\n",
            "Epoch: 183 | Batch_idx: 100 |  Loss: (0.0164) | Acc: (99.39%) (12849/12928)\n",
            "Epoch: 183 | Batch_idx: 110 |  Loss: (0.0160) | Acc: (99.39%) (14122/14208)\n",
            "Epoch: 183 | Batch_idx: 120 |  Loss: (0.0156) | Acc: (99.41%) (15396/15488)\n",
            "Epoch: 183 | Batch_idx: 130 |  Loss: (0.0154) | Acc: (99.43%) (16672/16768)\n",
            "Epoch: 183 | Batch_idx: 140 |  Loss: (0.0151) | Acc: (99.45%) (17948/18048)\n",
            "Epoch: 183 | Batch_idx: 150 |  Loss: (0.0149) | Acc: (99.46%) (19224/19328)\n",
            "Epoch: 183 | Batch_idx: 160 |  Loss: (0.0149) | Acc: (99.48%) (20500/20608)\n",
            "Epoch: 183 | Batch_idx: 170 |  Loss: (0.0146) | Acc: (99.49%) (21777/21888)\n",
            "Epoch: 183 | Batch_idx: 180 |  Loss: (0.0149) | Acc: (99.48%) (23048/23168)\n",
            "Epoch: 183 | Batch_idx: 190 |  Loss: (0.0145) | Acc: (99.50%) (24325/24448)\n",
            "Epoch: 183 | Batch_idx: 200 |  Loss: (0.0143) | Acc: (99.51%) (25603/25728)\n",
            "Epoch: 183 | Batch_idx: 210 |  Loss: (0.0149) | Acc: (99.50%) (26874/27008)\n",
            "Epoch: 183 | Batch_idx: 220 |  Loss: (0.0145) | Acc: (99.51%) (28150/28288)\n",
            "Epoch: 183 | Batch_idx: 230 |  Loss: (0.0143) | Acc: (99.52%) (29426/29568)\n",
            "Epoch: 183 | Batch_idx: 240 |  Loss: (0.0140) | Acc: (99.53%) (30703/30848)\n",
            "Epoch: 183 | Batch_idx: 250 |  Loss: (0.0140) | Acc: (99.54%) (31979/32128)\n",
            "Epoch: 183 | Batch_idx: 260 |  Loss: (0.0142) | Acc: (99.52%) (33249/33408)\n",
            "Epoch: 183 | Batch_idx: 270 |  Loss: (0.0146) | Acc: (99.51%) (34519/34688)\n",
            "Epoch: 183 | Batch_idx: 280 |  Loss: (0.0147) | Acc: (99.50%) (35788/35968)\n",
            "Epoch: 183 | Batch_idx: 290 |  Loss: (0.0147) | Acc: (99.50%) (37061/37248)\n",
            "Epoch: 183 | Batch_idx: 300 |  Loss: (0.0146) | Acc: (99.50%) (38335/38528)\n",
            "Epoch: 183 | Batch_idx: 310 |  Loss: (0.0146) | Acc: (99.49%) (39606/39808)\n",
            "Epoch: 183 | Batch_idx: 320 |  Loss: (0.0147) | Acc: (99.48%) (40876/41088)\n",
            "Epoch: 183 | Batch_idx: 330 |  Loss: (0.0148) | Acc: (99.48%) (42147/42368)\n",
            "Epoch: 183 | Batch_idx: 340 |  Loss: (0.0148) | Acc: (99.48%) (43422/43648)\n",
            "Epoch: 183 | Batch_idx: 350 |  Loss: (0.0148) | Acc: (99.48%) (44695/44928)\n",
            "Epoch: 183 | Batch_idx: 360 |  Loss: (0.0150) | Acc: (99.47%) (45965/46208)\n",
            "Epoch: 183 | Batch_idx: 370 |  Loss: (0.0152) | Acc: (99.47%) (47235/47488)\n",
            "Epoch: 183 | Batch_idx: 380 |  Loss: (0.0153) | Acc: (99.46%) (48507/48768)\n",
            "Epoch: 183 | Batch_idx: 390 |  Loss: (0.0153) | Acc: (99.47%) (49734/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3992) | Acc: (91.87%) (9187/10000)\n",
            "Epoch: 184 | Batch_idx: 0 |  Loss: (0.0130) | Acc: (99.22%) (127/128)\n",
            "Epoch: 184 | Batch_idx: 10 |  Loss: (0.0094) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 184 | Batch_idx: 20 |  Loss: (0.0102) | Acc: (99.63%) (2678/2688)\n",
            "Epoch: 184 | Batch_idx: 30 |  Loss: (0.0112) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 184 | Batch_idx: 40 |  Loss: (0.0104) | Acc: (99.58%) (5226/5248)\n",
            "Epoch: 184 | Batch_idx: 50 |  Loss: (0.0120) | Acc: (99.56%) (6499/6528)\n",
            "Epoch: 184 | Batch_idx: 60 |  Loss: (0.0135) | Acc: (99.51%) (7770/7808)\n",
            "Epoch: 184 | Batch_idx: 70 |  Loss: (0.0135) | Acc: (99.52%) (9044/9088)\n",
            "Epoch: 184 | Batch_idx: 80 |  Loss: (0.0131) | Acc: (99.54%) (10320/10368)\n",
            "Epoch: 184 | Batch_idx: 90 |  Loss: (0.0143) | Acc: (99.49%) (11589/11648)\n",
            "Epoch: 184 | Batch_idx: 100 |  Loss: (0.0139) | Acc: (99.50%) (12864/12928)\n",
            "Epoch: 184 | Batch_idx: 110 |  Loss: (0.0148) | Acc: (99.47%) (14133/14208)\n",
            "Epoch: 184 | Batch_idx: 120 |  Loss: (0.0147) | Acc: (99.46%) (15405/15488)\n",
            "Epoch: 184 | Batch_idx: 130 |  Loss: (0.0148) | Acc: (99.46%) (16678/16768)\n",
            "Epoch: 184 | Batch_idx: 140 |  Loss: (0.0144) | Acc: (99.48%) (17954/18048)\n",
            "Epoch: 184 | Batch_idx: 150 |  Loss: (0.0141) | Acc: (99.48%) (19228/19328)\n",
            "Epoch: 184 | Batch_idx: 160 |  Loss: (0.0145) | Acc: (99.47%) (20499/20608)\n",
            "Epoch: 184 | Batch_idx: 170 |  Loss: (0.0143) | Acc: (99.48%) (21774/21888)\n",
            "Epoch: 184 | Batch_idx: 180 |  Loss: (0.0143) | Acc: (99.47%) (23046/23168)\n",
            "Epoch: 184 | Batch_idx: 190 |  Loss: (0.0141) | Acc: (99.48%) (24322/24448)\n",
            "Epoch: 184 | Batch_idx: 200 |  Loss: (0.0138) | Acc: (99.49%) (25598/25728)\n",
            "Epoch: 184 | Batch_idx: 210 |  Loss: (0.0142) | Acc: (99.49%) (26870/27008)\n",
            "Epoch: 184 | Batch_idx: 220 |  Loss: (0.0139) | Acc: (99.50%) (28147/28288)\n",
            "Epoch: 184 | Batch_idx: 230 |  Loss: (0.0137) | Acc: (99.51%) (29422/29568)\n",
            "Epoch: 184 | Batch_idx: 240 |  Loss: (0.0137) | Acc: (99.50%) (30695/30848)\n",
            "Epoch: 184 | Batch_idx: 250 |  Loss: (0.0135) | Acc: (99.51%) (31970/32128)\n",
            "Epoch: 184 | Batch_idx: 260 |  Loss: (0.0136) | Acc: (99.50%) (33241/33408)\n",
            "Epoch: 184 | Batch_idx: 270 |  Loss: (0.0135) | Acc: (99.50%) (34516/34688)\n",
            "Epoch: 184 | Batch_idx: 280 |  Loss: (0.0135) | Acc: (99.51%) (35790/35968)\n",
            "Epoch: 184 | Batch_idx: 290 |  Loss: (0.0139) | Acc: (99.49%) (37059/37248)\n",
            "Epoch: 184 | Batch_idx: 300 |  Loss: (0.0137) | Acc: (99.50%) (38335/38528)\n",
            "Epoch: 184 | Batch_idx: 310 |  Loss: (0.0135) | Acc: (99.51%) (39612/39808)\n",
            "Epoch: 184 | Batch_idx: 320 |  Loss: (0.0135) | Acc: (99.50%) (40884/41088)\n",
            "Epoch: 184 | Batch_idx: 330 |  Loss: (0.0135) | Acc: (99.50%) (42157/42368)\n",
            "Epoch: 184 | Batch_idx: 340 |  Loss: (0.0137) | Acc: (99.50%) (43428/43648)\n",
            "Epoch: 184 | Batch_idx: 350 |  Loss: (0.0138) | Acc: (99.49%) (44700/44928)\n",
            "Epoch: 184 | Batch_idx: 360 |  Loss: (0.0137) | Acc: (99.50%) (45978/46208)\n",
            "Epoch: 184 | Batch_idx: 370 |  Loss: (0.0137) | Acc: (99.51%) (47254/47488)\n",
            "Epoch: 184 | Batch_idx: 380 |  Loss: (0.0135) | Acc: (99.51%) (48530/48768)\n",
            "Epoch: 184 | Batch_idx: 390 |  Loss: (0.0135) | Acc: (99.51%) (49754/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3962) | Acc: (91.87%) (9187/10000)\n",
            "Epoch: 185 | Batch_idx: 0 |  Loss: (0.0065) | Acc: (100.00%) (128/128)\n",
            "Epoch: 185 | Batch_idx: 10 |  Loss: (0.0115) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 185 | Batch_idx: 20 |  Loss: (0.0125) | Acc: (99.52%) (2675/2688)\n",
            "Epoch: 185 | Batch_idx: 30 |  Loss: (0.0149) | Acc: (99.55%) (3950/3968)\n",
            "Epoch: 185 | Batch_idx: 40 |  Loss: (0.0146) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 185 | Batch_idx: 50 |  Loss: (0.0129) | Acc: (99.59%) (6501/6528)\n",
            "Epoch: 185 | Batch_idx: 60 |  Loss: (0.0124) | Acc: (99.59%) (7776/7808)\n",
            "Epoch: 185 | Batch_idx: 70 |  Loss: (0.0132) | Acc: (99.57%) (9049/9088)\n",
            "Epoch: 185 | Batch_idx: 80 |  Loss: (0.0136) | Acc: (99.56%) (10322/10368)\n",
            "Epoch: 185 | Batch_idx: 90 |  Loss: (0.0135) | Acc: (99.56%) (11597/11648)\n",
            "Epoch: 185 | Batch_idx: 100 |  Loss: (0.0135) | Acc: (99.57%) (12872/12928)\n",
            "Epoch: 185 | Batch_idx: 110 |  Loss: (0.0131) | Acc: (99.58%) (14148/14208)\n",
            "Epoch: 185 | Batch_idx: 120 |  Loss: (0.0131) | Acc: (99.57%) (15421/15488)\n",
            "Epoch: 185 | Batch_idx: 130 |  Loss: (0.0137) | Acc: (99.55%) (16693/16768)\n",
            "Epoch: 185 | Batch_idx: 140 |  Loss: (0.0141) | Acc: (99.55%) (17967/18048)\n",
            "Epoch: 185 | Batch_idx: 150 |  Loss: (0.0141) | Acc: (99.52%) (19236/19328)\n",
            "Epoch: 185 | Batch_idx: 160 |  Loss: (0.0150) | Acc: (99.51%) (20507/20608)\n",
            "Epoch: 185 | Batch_idx: 170 |  Loss: (0.0154) | Acc: (99.48%) (21775/21888)\n",
            "Epoch: 185 | Batch_idx: 180 |  Loss: (0.0157) | Acc: (99.47%) (23046/23168)\n",
            "Epoch: 185 | Batch_idx: 190 |  Loss: (0.0156) | Acc: (99.47%) (24319/24448)\n",
            "Epoch: 185 | Batch_idx: 200 |  Loss: (0.0159) | Acc: (99.45%) (25587/25728)\n",
            "Epoch: 185 | Batch_idx: 210 |  Loss: (0.0162) | Acc: (99.46%) (26861/27008)\n",
            "Epoch: 185 | Batch_idx: 220 |  Loss: (0.0161) | Acc: (99.46%) (28134/28288)\n",
            "Epoch: 185 | Batch_idx: 230 |  Loss: (0.0158) | Acc: (99.47%) (29411/29568)\n",
            "Epoch: 185 | Batch_idx: 240 |  Loss: (0.0155) | Acc: (99.48%) (30687/30848)\n",
            "Epoch: 185 | Batch_idx: 250 |  Loss: (0.0155) | Acc: (99.48%) (31961/32128)\n",
            "Epoch: 185 | Batch_idx: 260 |  Loss: (0.0152) | Acc: (99.49%) (33238/33408)\n",
            "Epoch: 185 | Batch_idx: 270 |  Loss: (0.0151) | Acc: (99.50%) (34513/34688)\n",
            "Epoch: 185 | Batch_idx: 280 |  Loss: (0.0150) | Acc: (99.51%) (35790/35968)\n",
            "Epoch: 185 | Batch_idx: 290 |  Loss: (0.0151) | Acc: (99.50%) (37061/37248)\n",
            "Epoch: 185 | Batch_idx: 300 |  Loss: (0.0148) | Acc: (99.51%) (38339/38528)\n",
            "Epoch: 185 | Batch_idx: 310 |  Loss: (0.0148) | Acc: (99.51%) (39613/39808)\n",
            "Epoch: 185 | Batch_idx: 320 |  Loss: (0.0149) | Acc: (99.51%) (40886/41088)\n",
            "Epoch: 185 | Batch_idx: 330 |  Loss: (0.0151) | Acc: (99.50%) (42155/42368)\n",
            "Epoch: 185 | Batch_idx: 340 |  Loss: (0.0154) | Acc: (99.49%) (43427/43648)\n",
            "Epoch: 185 | Batch_idx: 350 |  Loss: (0.0155) | Acc: (99.49%) (44701/44928)\n",
            "Epoch: 185 | Batch_idx: 360 |  Loss: (0.0153) | Acc: (99.50%) (45978/46208)\n",
            "Epoch: 185 | Batch_idx: 370 |  Loss: (0.0151) | Acc: (99.51%) (47254/47488)\n",
            "Epoch: 185 | Batch_idx: 380 |  Loss: (0.0150) | Acc: (99.51%) (48528/48768)\n",
            "Epoch: 185 | Batch_idx: 390 |  Loss: (0.0149) | Acc: (99.51%) (49755/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4001) | Acc: (91.85%) (9185/10000)\n",
            "Epoch: 186 | Batch_idx: 0 |  Loss: (0.0045) | Acc: (100.00%) (128/128)\n",
            "Epoch: 186 | Batch_idx: 10 |  Loss: (0.0134) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 186 | Batch_idx: 20 |  Loss: (0.0104) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 186 | Batch_idx: 30 |  Loss: (0.0102) | Acc: (99.62%) (3953/3968)\n",
            "Epoch: 186 | Batch_idx: 40 |  Loss: (0.0123) | Acc: (99.58%) (5226/5248)\n",
            "Epoch: 186 | Batch_idx: 50 |  Loss: (0.0121) | Acc: (99.62%) (6503/6528)\n",
            "Epoch: 186 | Batch_idx: 60 |  Loss: (0.0131) | Acc: (99.56%) (7774/7808)\n",
            "Epoch: 186 | Batch_idx: 70 |  Loss: (0.0126) | Acc: (99.59%) (9051/9088)\n",
            "Epoch: 186 | Batch_idx: 80 |  Loss: (0.0117) | Acc: (99.63%) (10330/10368)\n",
            "Epoch: 186 | Batch_idx: 90 |  Loss: (0.0111) | Acc: (99.64%) (11606/11648)\n",
            "Epoch: 186 | Batch_idx: 100 |  Loss: (0.0110) | Acc: (99.64%) (12882/12928)\n",
            "Epoch: 186 | Batch_idx: 110 |  Loss: (0.0111) | Acc: (99.63%) (14156/14208)\n",
            "Epoch: 186 | Batch_idx: 120 |  Loss: (0.0109) | Acc: (99.64%) (15433/15488)\n",
            "Epoch: 186 | Batch_idx: 130 |  Loss: (0.0111) | Acc: (99.63%) (16706/16768)\n",
            "Epoch: 186 | Batch_idx: 140 |  Loss: (0.0112) | Acc: (99.63%) (17981/18048)\n",
            "Epoch: 186 | Batch_idx: 150 |  Loss: (0.0114) | Acc: (99.62%) (19255/19328)\n",
            "Epoch: 186 | Batch_idx: 160 |  Loss: (0.0118) | Acc: (99.61%) (20528/20608)\n",
            "Epoch: 186 | Batch_idx: 170 |  Loss: (0.0114) | Acc: (99.63%) (21808/21888)\n",
            "Epoch: 186 | Batch_idx: 180 |  Loss: (0.0114) | Acc: (99.63%) (23083/23168)\n",
            "Epoch: 186 | Batch_idx: 190 |  Loss: (0.0116) | Acc: (99.64%) (24359/24448)\n",
            "Epoch: 186 | Batch_idx: 200 |  Loss: (0.0120) | Acc: (99.62%) (25630/25728)\n",
            "Epoch: 186 | Batch_idx: 210 |  Loss: (0.0120) | Acc: (99.62%) (26906/27008)\n",
            "Epoch: 186 | Batch_idx: 220 |  Loss: (0.0119) | Acc: (99.63%) (28184/28288)\n",
            "Epoch: 186 | Batch_idx: 230 |  Loss: (0.0122) | Acc: (99.61%) (29453/29568)\n",
            "Epoch: 186 | Batch_idx: 240 |  Loss: (0.0122) | Acc: (99.60%) (30725/30848)\n",
            "Epoch: 186 | Batch_idx: 250 |  Loss: (0.0123) | Acc: (99.60%) (32000/32128)\n",
            "Epoch: 186 | Batch_idx: 260 |  Loss: (0.0124) | Acc: (99.60%) (33275/33408)\n",
            "Epoch: 186 | Batch_idx: 270 |  Loss: (0.0131) | Acc: (99.58%) (34542/34688)\n",
            "Epoch: 186 | Batch_idx: 280 |  Loss: (0.0132) | Acc: (99.57%) (35815/35968)\n",
            "Epoch: 186 | Batch_idx: 290 |  Loss: (0.0131) | Acc: (99.57%) (37089/37248)\n",
            "Epoch: 186 | Batch_idx: 300 |  Loss: (0.0131) | Acc: (99.57%) (38364/38528)\n",
            "Epoch: 186 | Batch_idx: 310 |  Loss: (0.0131) | Acc: (99.57%) (39637/39808)\n",
            "Epoch: 186 | Batch_idx: 320 |  Loss: (0.0131) | Acc: (99.56%) (40909/41088)\n",
            "Epoch: 186 | Batch_idx: 330 |  Loss: (0.0133) | Acc: (99.56%) (42182/42368)\n",
            "Epoch: 186 | Batch_idx: 340 |  Loss: (0.0131) | Acc: (99.57%) (43459/43648)\n",
            "Epoch: 186 | Batch_idx: 350 |  Loss: (0.0132) | Acc: (99.55%) (44728/44928)\n",
            "Epoch: 186 | Batch_idx: 360 |  Loss: (0.0132) | Acc: (99.55%) (46000/46208)\n",
            "Epoch: 186 | Batch_idx: 370 |  Loss: (0.0129) | Acc: (99.56%) (47277/47488)\n",
            "Epoch: 186 | Batch_idx: 380 |  Loss: (0.0128) | Acc: (99.56%) (48553/48768)\n",
            "Epoch: 186 | Batch_idx: 390 |  Loss: (0.0128) | Acc: (99.56%) (49781/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4022) | Acc: (91.76%) (9176/10000)\n",
            "Epoch: 187 | Batch_idx: 0 |  Loss: (0.0047) | Acc: (100.00%) (128/128)\n",
            "Epoch: 187 | Batch_idx: 10 |  Loss: (0.0152) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 187 | Batch_idx: 20 |  Loss: (0.0175) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 187 | Batch_idx: 30 |  Loss: (0.0160) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 187 | Batch_idx: 40 |  Loss: (0.0159) | Acc: (99.43%) (5218/5248)\n",
            "Epoch: 187 | Batch_idx: 50 |  Loss: (0.0149) | Acc: (99.48%) (6494/6528)\n",
            "Epoch: 187 | Batch_idx: 60 |  Loss: (0.0147) | Acc: (99.47%) (7767/7808)\n",
            "Epoch: 187 | Batch_idx: 70 |  Loss: (0.0151) | Acc: (99.45%) (9038/9088)\n",
            "Epoch: 187 | Batch_idx: 80 |  Loss: (0.0147) | Acc: (99.46%) (10312/10368)\n",
            "Epoch: 187 | Batch_idx: 90 |  Loss: (0.0144) | Acc: (99.48%) (11587/11648)\n",
            "Epoch: 187 | Batch_idx: 100 |  Loss: (0.0146) | Acc: (99.47%) (12859/12928)\n",
            "Epoch: 187 | Batch_idx: 110 |  Loss: (0.0150) | Acc: (99.47%) (14132/14208)\n",
            "Epoch: 187 | Batch_idx: 120 |  Loss: (0.0148) | Acc: (99.48%) (15407/15488)\n",
            "Epoch: 187 | Batch_idx: 130 |  Loss: (0.0147) | Acc: (99.46%) (16678/16768)\n",
            "Epoch: 187 | Batch_idx: 140 |  Loss: (0.0147) | Acc: (99.46%) (17950/18048)\n",
            "Epoch: 187 | Batch_idx: 150 |  Loss: (0.0144) | Acc: (99.46%) (19224/19328)\n",
            "Epoch: 187 | Batch_idx: 160 |  Loss: (0.0153) | Acc: (99.43%) (20491/20608)\n",
            "Epoch: 187 | Batch_idx: 170 |  Loss: (0.0149) | Acc: (99.45%) (21768/21888)\n",
            "Epoch: 187 | Batch_idx: 180 |  Loss: (0.0155) | Acc: (99.44%) (23038/23168)\n",
            "Epoch: 187 | Batch_idx: 190 |  Loss: (0.0157) | Acc: (99.43%) (24308/24448)\n",
            "Epoch: 187 | Batch_idx: 200 |  Loss: (0.0154) | Acc: (99.44%) (25584/25728)\n",
            "Epoch: 187 | Batch_idx: 210 |  Loss: (0.0151) | Acc: (99.46%) (26862/27008)\n",
            "Epoch: 187 | Batch_idx: 220 |  Loss: (0.0151) | Acc: (99.47%) (28137/28288)\n",
            "Epoch: 187 | Batch_idx: 230 |  Loss: (0.0152) | Acc: (99.48%) (29413/29568)\n",
            "Epoch: 187 | Batch_idx: 240 |  Loss: (0.0152) | Acc: (99.47%) (30686/30848)\n",
            "Epoch: 187 | Batch_idx: 250 |  Loss: (0.0154) | Acc: (99.47%) (31957/32128)\n",
            "Epoch: 187 | Batch_idx: 260 |  Loss: (0.0154) | Acc: (99.47%) (33231/33408)\n",
            "Epoch: 187 | Batch_idx: 270 |  Loss: (0.0150) | Acc: (99.48%) (34509/34688)\n",
            "Epoch: 187 | Batch_idx: 280 |  Loss: (0.0150) | Acc: (99.48%) (35781/35968)\n",
            "Epoch: 187 | Batch_idx: 290 |  Loss: (0.0149) | Acc: (99.49%) (37058/37248)\n",
            "Epoch: 187 | Batch_idx: 300 |  Loss: (0.0150) | Acc: (99.48%) (38329/38528)\n",
            "Epoch: 187 | Batch_idx: 310 |  Loss: (0.0150) | Acc: (99.49%) (39604/39808)\n",
            "Epoch: 187 | Batch_idx: 320 |  Loss: (0.0150) | Acc: (99.48%) (40876/41088)\n",
            "Epoch: 187 | Batch_idx: 330 |  Loss: (0.0151) | Acc: (99.48%) (42149/42368)\n",
            "Epoch: 187 | Batch_idx: 340 |  Loss: (0.0151) | Acc: (99.49%) (43424/43648)\n",
            "Epoch: 187 | Batch_idx: 350 |  Loss: (0.0151) | Acc: (99.49%) (44700/44928)\n",
            "Epoch: 187 | Batch_idx: 360 |  Loss: (0.0152) | Acc: (99.49%) (45972/46208)\n",
            "Epoch: 187 | Batch_idx: 370 |  Loss: (0.0151) | Acc: (99.50%) (47249/47488)\n",
            "Epoch: 187 | Batch_idx: 380 |  Loss: (0.0150) | Acc: (99.50%) (48524/48768)\n",
            "Epoch: 187 | Batch_idx: 390 |  Loss: (0.0150) | Acc: (99.50%) (49749/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4037) | Acc: (91.72%) (9172/10000)\n",
            "Epoch: 188 | Batch_idx: 0 |  Loss: (0.0126) | Acc: (100.00%) (128/128)\n",
            "Epoch: 188 | Batch_idx: 10 |  Loss: (0.0118) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 188 | Batch_idx: 20 |  Loss: (0.0127) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 188 | Batch_idx: 30 |  Loss: (0.0143) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 188 | Batch_idx: 40 |  Loss: (0.0142) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 188 | Batch_idx: 50 |  Loss: (0.0135) | Acc: (99.48%) (6494/6528)\n",
            "Epoch: 188 | Batch_idx: 60 |  Loss: (0.0139) | Acc: (99.49%) (7768/7808)\n",
            "Epoch: 188 | Batch_idx: 70 |  Loss: (0.0141) | Acc: (99.50%) (9043/9088)\n",
            "Epoch: 188 | Batch_idx: 80 |  Loss: (0.0142) | Acc: (99.51%) (10317/10368)\n",
            "Epoch: 188 | Batch_idx: 90 |  Loss: (0.0145) | Acc: (99.49%) (11589/11648)\n",
            "Epoch: 188 | Batch_idx: 100 |  Loss: (0.0154) | Acc: (99.47%) (12859/12928)\n",
            "Epoch: 188 | Batch_idx: 110 |  Loss: (0.0153) | Acc: (99.49%) (14136/14208)\n",
            "Epoch: 188 | Batch_idx: 120 |  Loss: (0.0151) | Acc: (99.50%) (15411/15488)\n",
            "Epoch: 188 | Batch_idx: 130 |  Loss: (0.0152) | Acc: (99.51%) (16685/16768)\n",
            "Epoch: 188 | Batch_idx: 140 |  Loss: (0.0154) | Acc: (99.51%) (17959/18048)\n",
            "Epoch: 188 | Batch_idx: 150 |  Loss: (0.0155) | Acc: (99.51%) (19234/19328)\n",
            "Epoch: 188 | Batch_idx: 160 |  Loss: (0.0155) | Acc: (99.52%) (20510/20608)\n",
            "Epoch: 188 | Batch_idx: 170 |  Loss: (0.0154) | Acc: (99.53%) (21785/21888)\n",
            "Epoch: 188 | Batch_idx: 180 |  Loss: (0.0158) | Acc: (99.52%) (23057/23168)\n",
            "Epoch: 188 | Batch_idx: 190 |  Loss: (0.0157) | Acc: (99.52%) (24330/24448)\n",
            "Epoch: 188 | Batch_idx: 200 |  Loss: (0.0162) | Acc: (99.50%) (25600/25728)\n",
            "Epoch: 188 | Batch_idx: 210 |  Loss: (0.0164) | Acc: (99.49%) (26870/27008)\n",
            "Epoch: 188 | Batch_idx: 220 |  Loss: (0.0165) | Acc: (99.48%) (28142/28288)\n",
            "Epoch: 188 | Batch_idx: 230 |  Loss: (0.0162) | Acc: (99.49%) (29416/29568)\n",
            "Epoch: 188 | Batch_idx: 240 |  Loss: (0.0160) | Acc: (99.49%) (30691/30848)\n",
            "Epoch: 188 | Batch_idx: 250 |  Loss: (0.0158) | Acc: (99.50%) (31967/32128)\n",
            "Epoch: 188 | Batch_idx: 260 |  Loss: (0.0158) | Acc: (99.50%) (33240/33408)\n",
            "Epoch: 188 | Batch_idx: 270 |  Loss: (0.0160) | Acc: (99.50%) (34513/34688)\n",
            "Epoch: 188 | Batch_idx: 280 |  Loss: (0.0159) | Acc: (99.50%) (35787/35968)\n",
            "Epoch: 188 | Batch_idx: 290 |  Loss: (0.0156) | Acc: (99.51%) (37064/37248)\n",
            "Epoch: 188 | Batch_idx: 300 |  Loss: (0.0155) | Acc: (99.51%) (38340/38528)\n",
            "Epoch: 188 | Batch_idx: 310 |  Loss: (0.0155) | Acc: (99.51%) (39612/39808)\n",
            "Epoch: 188 | Batch_idx: 320 |  Loss: (0.0157) | Acc: (99.50%) (40881/41088)\n",
            "Epoch: 188 | Batch_idx: 330 |  Loss: (0.0155) | Acc: (99.50%) (42158/42368)\n",
            "Epoch: 188 | Batch_idx: 340 |  Loss: (0.0155) | Acc: (99.50%) (43429/43648)\n",
            "Epoch: 188 | Batch_idx: 350 |  Loss: (0.0153) | Acc: (99.50%) (44705/44928)\n",
            "Epoch: 188 | Batch_idx: 360 |  Loss: (0.0154) | Acc: (99.50%) (45977/46208)\n",
            "Epoch: 188 | Batch_idx: 370 |  Loss: (0.0154) | Acc: (99.50%) (47250/47488)\n",
            "Epoch: 188 | Batch_idx: 380 |  Loss: (0.0152) | Acc: (99.50%) (48526/48768)\n",
            "Epoch: 188 | Batch_idx: 390 |  Loss: (0.0153) | Acc: (99.50%) (49751/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4016) | Acc: (91.64%) (9164/10000)\n",
            "Epoch: 189 | Batch_idx: 0 |  Loss: (0.0157) | Acc: (99.22%) (127/128)\n",
            "Epoch: 189 | Batch_idx: 10 |  Loss: (0.0134) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 189 | Batch_idx: 20 |  Loss: (0.0118) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 189 | Batch_idx: 30 |  Loss: (0.0126) | Acc: (99.62%) (3953/3968)\n",
            "Epoch: 189 | Batch_idx: 40 |  Loss: (0.0146) | Acc: (99.54%) (5224/5248)\n",
            "Epoch: 189 | Batch_idx: 50 |  Loss: (0.0142) | Acc: (99.54%) (6498/6528)\n",
            "Epoch: 189 | Batch_idx: 60 |  Loss: (0.0135) | Acc: (99.56%) (7774/7808)\n",
            "Epoch: 189 | Batch_idx: 70 |  Loss: (0.0144) | Acc: (99.54%) (9046/9088)\n",
            "Epoch: 189 | Batch_idx: 80 |  Loss: (0.0141) | Acc: (99.55%) (10321/10368)\n",
            "Epoch: 189 | Batch_idx: 90 |  Loss: (0.0148) | Acc: (99.54%) (11594/11648)\n",
            "Epoch: 189 | Batch_idx: 100 |  Loss: (0.0145) | Acc: (99.56%) (12871/12928)\n",
            "Epoch: 189 | Batch_idx: 110 |  Loss: (0.0153) | Acc: (99.54%) (14143/14208)\n",
            "Epoch: 189 | Batch_idx: 120 |  Loss: (0.0158) | Acc: (99.53%) (15415/15488)\n",
            "Epoch: 189 | Batch_idx: 130 |  Loss: (0.0159) | Acc: (99.52%) (16688/16768)\n",
            "Epoch: 189 | Batch_idx: 140 |  Loss: (0.0154) | Acc: (99.54%) (17965/18048)\n",
            "Epoch: 189 | Batch_idx: 150 |  Loss: (0.0156) | Acc: (99.52%) (19235/19328)\n",
            "Epoch: 189 | Batch_idx: 160 |  Loss: (0.0159) | Acc: (99.52%) (20509/20608)\n",
            "Epoch: 189 | Batch_idx: 170 |  Loss: (0.0158) | Acc: (99.51%) (21780/21888)\n",
            "Epoch: 189 | Batch_idx: 180 |  Loss: (0.0162) | Acc: (99.49%) (23049/23168)\n",
            "Epoch: 189 | Batch_idx: 190 |  Loss: (0.0165) | Acc: (99.48%) (24322/24448)\n",
            "Epoch: 189 | Batch_idx: 200 |  Loss: (0.0161) | Acc: (99.49%) (25598/25728)\n",
            "Epoch: 189 | Batch_idx: 210 |  Loss: (0.0159) | Acc: (99.51%) (26875/27008)\n",
            "Epoch: 189 | Batch_idx: 220 |  Loss: (0.0156) | Acc: (99.52%) (28152/28288)\n",
            "Epoch: 189 | Batch_idx: 230 |  Loss: (0.0154) | Acc: (99.52%) (29425/29568)\n",
            "Epoch: 189 | Batch_idx: 240 |  Loss: (0.0152) | Acc: (99.53%) (30703/30848)\n",
            "Epoch: 189 | Batch_idx: 250 |  Loss: (0.0153) | Acc: (99.52%) (31974/32128)\n",
            "Epoch: 189 | Batch_idx: 260 |  Loss: (0.0151) | Acc: (99.53%) (33250/33408)\n",
            "Epoch: 189 | Batch_idx: 270 |  Loss: (0.0149) | Acc: (99.53%) (34526/34688)\n",
            "Epoch: 189 | Batch_idx: 280 |  Loss: (0.0149) | Acc: (99.54%) (35802/35968)\n",
            "Epoch: 189 | Batch_idx: 290 |  Loss: (0.0152) | Acc: (99.52%) (37070/37248)\n",
            "Epoch: 189 | Batch_idx: 300 |  Loss: (0.0151) | Acc: (99.52%) (38344/38528)\n",
            "Epoch: 189 | Batch_idx: 310 |  Loss: (0.0152) | Acc: (99.52%) (39615/39808)\n",
            "Epoch: 189 | Batch_idx: 320 |  Loss: (0.0154) | Acc: (99.51%) (40887/41088)\n",
            "Epoch: 189 | Batch_idx: 330 |  Loss: (0.0154) | Acc: (99.52%) (42163/42368)\n",
            "Epoch: 189 | Batch_idx: 340 |  Loss: (0.0152) | Acc: (99.52%) (43440/43648)\n",
            "Epoch: 189 | Batch_idx: 350 |  Loss: (0.0151) | Acc: (99.53%) (44716/44928)\n",
            "Epoch: 189 | Batch_idx: 360 |  Loss: (0.0151) | Acc: (99.53%) (45991/46208)\n",
            "Epoch: 189 | Batch_idx: 370 |  Loss: (0.0150) | Acc: (99.53%) (47267/47488)\n",
            "Epoch: 189 | Batch_idx: 380 |  Loss: (0.0149) | Acc: (99.54%) (48543/48768)\n",
            "Epoch: 189 | Batch_idx: 390 |  Loss: (0.0149) | Acc: (99.54%) (49769/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3997) | Acc: (91.81%) (9181/10000)\n",
            "Epoch: 190 | Batch_idx: 0 |  Loss: (0.0174) | Acc: (99.22%) (127/128)\n",
            "Epoch: 190 | Batch_idx: 10 |  Loss: (0.0183) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 190 | Batch_idx: 20 |  Loss: (0.0177) | Acc: (99.33%) (2670/2688)\n",
            "Epoch: 190 | Batch_idx: 30 |  Loss: (0.0171) | Acc: (99.29%) (3940/3968)\n",
            "Epoch: 190 | Batch_idx: 40 |  Loss: (0.0171) | Acc: (99.35%) (5214/5248)\n",
            "Epoch: 190 | Batch_idx: 50 |  Loss: (0.0169) | Acc: (99.39%) (6488/6528)\n",
            "Epoch: 190 | Batch_idx: 60 |  Loss: (0.0166) | Acc: (99.44%) (7764/7808)\n",
            "Epoch: 190 | Batch_idx: 70 |  Loss: (0.0166) | Acc: (99.44%) (9037/9088)\n",
            "Epoch: 190 | Batch_idx: 80 |  Loss: (0.0167) | Acc: (99.45%) (10311/10368)\n",
            "Epoch: 190 | Batch_idx: 90 |  Loss: (0.0155) | Acc: (99.49%) (11589/11648)\n",
            "Epoch: 190 | Batch_idx: 100 |  Loss: (0.0152) | Acc: (99.51%) (12865/12928)\n",
            "Epoch: 190 | Batch_idx: 110 |  Loss: (0.0149) | Acc: (99.53%) (14141/14208)\n",
            "Epoch: 190 | Batch_idx: 120 |  Loss: (0.0149) | Acc: (99.55%) (15418/15488)\n",
            "Epoch: 190 | Batch_idx: 130 |  Loss: (0.0146) | Acc: (99.56%) (16694/16768)\n",
            "Epoch: 190 | Batch_idx: 140 |  Loss: (0.0149) | Acc: (99.56%) (17968/18048)\n",
            "Epoch: 190 | Batch_idx: 150 |  Loss: (0.0151) | Acc: (99.54%) (19240/19328)\n",
            "Epoch: 190 | Batch_idx: 160 |  Loss: (0.0149) | Acc: (99.54%) (20514/20608)\n",
            "Epoch: 190 | Batch_idx: 170 |  Loss: (0.0145) | Acc: (99.56%) (21792/21888)\n",
            "Epoch: 190 | Batch_idx: 180 |  Loss: (0.0145) | Acc: (99.56%) (23065/23168)\n",
            "Epoch: 190 | Batch_idx: 190 |  Loss: (0.0145) | Acc: (99.57%) (24342/24448)\n",
            "Epoch: 190 | Batch_idx: 200 |  Loss: (0.0145) | Acc: (99.57%) (25617/25728)\n",
            "Epoch: 190 | Batch_idx: 210 |  Loss: (0.0146) | Acc: (99.55%) (26887/27008)\n",
            "Epoch: 190 | Batch_idx: 220 |  Loss: (0.0146) | Acc: (99.55%) (28161/28288)\n",
            "Epoch: 190 | Batch_idx: 230 |  Loss: (0.0146) | Acc: (99.54%) (29432/29568)\n",
            "Epoch: 190 | Batch_idx: 240 |  Loss: (0.0146) | Acc: (99.54%) (30706/30848)\n",
            "Epoch: 190 | Batch_idx: 250 |  Loss: (0.0146) | Acc: (99.54%) (31979/32128)\n",
            "Epoch: 190 | Batch_idx: 260 |  Loss: (0.0147) | Acc: (99.53%) (33251/33408)\n",
            "Epoch: 190 | Batch_idx: 270 |  Loss: (0.0146) | Acc: (99.53%) (34525/34688)\n",
            "Epoch: 190 | Batch_idx: 280 |  Loss: (0.0145) | Acc: (99.53%) (35800/35968)\n",
            "Epoch: 190 | Batch_idx: 290 |  Loss: (0.0147) | Acc: (99.53%) (37073/37248)\n",
            "Epoch: 190 | Batch_idx: 300 |  Loss: (0.0144) | Acc: (99.54%) (38351/38528)\n",
            "Epoch: 190 | Batch_idx: 310 |  Loss: (0.0144) | Acc: (99.54%) (39625/39808)\n",
            "Epoch: 190 | Batch_idx: 320 |  Loss: (0.0144) | Acc: (99.54%) (40899/41088)\n",
            "Epoch: 190 | Batch_idx: 330 |  Loss: (0.0148) | Acc: (99.54%) (42171/42368)\n",
            "Epoch: 190 | Batch_idx: 340 |  Loss: (0.0151) | Acc: (99.52%) (43439/43648)\n",
            "Epoch: 190 | Batch_idx: 350 |  Loss: (0.0151) | Acc: (99.53%) (44715/44928)\n",
            "Epoch: 190 | Batch_idx: 360 |  Loss: (0.0150) | Acc: (99.53%) (45989/46208)\n",
            "Epoch: 190 | Batch_idx: 370 |  Loss: (0.0149) | Acc: (99.53%) (47263/47488)\n",
            "Epoch: 190 | Batch_idx: 380 |  Loss: (0.0151) | Acc: (99.52%) (48532/48768)\n",
            "Epoch: 190 | Batch_idx: 390 |  Loss: (0.0151) | Acc: (99.52%) (49759/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3998) | Acc: (91.83%) (9183/10000)\n",
            "Epoch: 191 | Batch_idx: 0 |  Loss: (0.0112) | Acc: (99.22%) (127/128)\n",
            "Epoch: 191 | Batch_idx: 10 |  Loss: (0.0109) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 191 | Batch_idx: 20 |  Loss: (0.0112) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 191 | Batch_idx: 30 |  Loss: (0.0130) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 191 | Batch_idx: 40 |  Loss: (0.0133) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 191 | Batch_idx: 50 |  Loss: (0.0137) | Acc: (99.53%) (6497/6528)\n",
            "Epoch: 191 | Batch_idx: 60 |  Loss: (0.0136) | Acc: (99.53%) (7771/7808)\n",
            "Epoch: 191 | Batch_idx: 70 |  Loss: (0.0135) | Acc: (99.55%) (9047/9088)\n",
            "Epoch: 191 | Batch_idx: 80 |  Loss: (0.0141) | Acc: (99.55%) (10321/10368)\n",
            "Epoch: 191 | Batch_idx: 90 |  Loss: (0.0136) | Acc: (99.55%) (11596/11648)\n",
            "Epoch: 191 | Batch_idx: 100 |  Loss: (0.0141) | Acc: (99.55%) (12870/12928)\n",
            "Epoch: 191 | Batch_idx: 110 |  Loss: (0.0139) | Acc: (99.56%) (14145/14208)\n",
            "Epoch: 191 | Batch_idx: 120 |  Loss: (0.0143) | Acc: (99.55%) (15418/15488)\n",
            "Epoch: 191 | Batch_idx: 130 |  Loss: (0.0142) | Acc: (99.55%) (16693/16768)\n",
            "Epoch: 191 | Batch_idx: 140 |  Loss: (0.0139) | Acc: (99.56%) (17968/18048)\n",
            "Epoch: 191 | Batch_idx: 150 |  Loss: (0.0138) | Acc: (99.56%) (19242/19328)\n",
            "Epoch: 191 | Batch_idx: 160 |  Loss: (0.0133) | Acc: (99.58%) (20521/20608)\n",
            "Epoch: 191 | Batch_idx: 170 |  Loss: (0.0136) | Acc: (99.57%) (21794/21888)\n",
            "Epoch: 191 | Batch_idx: 180 |  Loss: (0.0140) | Acc: (99.56%) (23065/23168)\n",
            "Epoch: 191 | Batch_idx: 190 |  Loss: (0.0142) | Acc: (99.55%) (24339/24448)\n",
            "Epoch: 191 | Batch_idx: 200 |  Loss: (0.0144) | Acc: (99.54%) (25610/25728)\n",
            "Epoch: 191 | Batch_idx: 210 |  Loss: (0.0150) | Acc: (99.53%) (26880/27008)\n",
            "Epoch: 191 | Batch_idx: 220 |  Loss: (0.0155) | Acc: (99.50%) (28147/28288)\n",
            "Epoch: 191 | Batch_idx: 230 |  Loss: (0.0154) | Acc: (99.50%) (29421/29568)\n",
            "Epoch: 191 | Batch_idx: 240 |  Loss: (0.0152) | Acc: (99.51%) (30697/30848)\n",
            "Epoch: 191 | Batch_idx: 250 |  Loss: (0.0153) | Acc: (99.51%) (31970/32128)\n",
            "Epoch: 191 | Batch_idx: 260 |  Loss: (0.0150) | Acc: (99.52%) (33248/33408)\n",
            "Epoch: 191 | Batch_idx: 270 |  Loss: (0.0153) | Acc: (99.51%) (34518/34688)\n",
            "Epoch: 191 | Batch_idx: 280 |  Loss: (0.0151) | Acc: (99.52%) (35795/35968)\n",
            "Epoch: 191 | Batch_idx: 290 |  Loss: (0.0149) | Acc: (99.53%) (37072/37248)\n",
            "Epoch: 191 | Batch_idx: 300 |  Loss: (0.0147) | Acc: (99.54%) (38349/38528)\n",
            "Epoch: 191 | Batch_idx: 310 |  Loss: (0.0148) | Acc: (99.53%) (39619/39808)\n",
            "Epoch: 191 | Batch_idx: 320 |  Loss: (0.0147) | Acc: (99.53%) (40895/41088)\n",
            "Epoch: 191 | Batch_idx: 330 |  Loss: (0.0149) | Acc: (99.52%) (42166/42368)\n",
            "Epoch: 191 | Batch_idx: 340 |  Loss: (0.0149) | Acc: (99.52%) (43440/43648)\n",
            "Epoch: 191 | Batch_idx: 350 |  Loss: (0.0149) | Acc: (99.53%) (44715/44928)\n",
            "Epoch: 191 | Batch_idx: 360 |  Loss: (0.0149) | Acc: (99.52%) (45986/46208)\n",
            "Epoch: 191 | Batch_idx: 370 |  Loss: (0.0150) | Acc: (99.51%) (47256/47488)\n",
            "Epoch: 191 | Batch_idx: 380 |  Loss: (0.0150) | Acc: (99.51%) (48529/48768)\n",
            "Epoch: 191 | Batch_idx: 390 |  Loss: (0.0151) | Acc: (99.50%) (49752/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4028) | Acc: (91.73%) (9173/10000)\n",
            "Epoch: 192 | Batch_idx: 0 |  Loss: (0.0126) | Acc: (99.22%) (127/128)\n",
            "Epoch: 192 | Batch_idx: 10 |  Loss: (0.0127) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 192 | Batch_idx: 20 |  Loss: (0.0119) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 192 | Batch_idx: 30 |  Loss: (0.0114) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 192 | Batch_idx: 40 |  Loss: (0.0113) | Acc: (99.56%) (5225/5248)\n",
            "Epoch: 192 | Batch_idx: 50 |  Loss: (0.0111) | Acc: (99.57%) (6500/6528)\n",
            "Epoch: 192 | Batch_idx: 60 |  Loss: (0.0115) | Acc: (99.58%) (7775/7808)\n",
            "Epoch: 192 | Batch_idx: 70 |  Loss: (0.0114) | Acc: (99.57%) (9049/9088)\n",
            "Epoch: 192 | Batch_idx: 80 |  Loss: (0.0113) | Acc: (99.59%) (10326/10368)\n",
            "Epoch: 192 | Batch_idx: 90 |  Loss: (0.0117) | Acc: (99.61%) (11602/11648)\n",
            "Epoch: 192 | Batch_idx: 100 |  Loss: (0.0122) | Acc: (99.58%) (12874/12928)\n",
            "Epoch: 192 | Batch_idx: 110 |  Loss: (0.0119) | Acc: (99.59%) (14150/14208)\n",
            "Epoch: 192 | Batch_idx: 120 |  Loss: (0.0113) | Acc: (99.62%) (15429/15488)\n",
            "Epoch: 192 | Batch_idx: 130 |  Loss: (0.0116) | Acc: (99.59%) (16699/16768)\n",
            "Epoch: 192 | Batch_idx: 140 |  Loss: (0.0118) | Acc: (99.58%) (17972/18048)\n",
            "Epoch: 192 | Batch_idx: 150 |  Loss: (0.0117) | Acc: (99.58%) (19247/19328)\n",
            "Epoch: 192 | Batch_idx: 160 |  Loss: (0.0121) | Acc: (99.55%) (20516/20608)\n",
            "Epoch: 192 | Batch_idx: 170 |  Loss: (0.0121) | Acc: (99.56%) (21791/21888)\n",
            "Epoch: 192 | Batch_idx: 180 |  Loss: (0.0125) | Acc: (99.54%) (23062/23168)\n",
            "Epoch: 192 | Batch_idx: 190 |  Loss: (0.0124) | Acc: (99.55%) (24339/24448)\n",
            "Epoch: 192 | Batch_idx: 200 |  Loss: (0.0126) | Acc: (99.55%) (25612/25728)\n",
            "Epoch: 192 | Batch_idx: 210 |  Loss: (0.0127) | Acc: (99.54%) (26883/27008)\n",
            "Epoch: 192 | Batch_idx: 220 |  Loss: (0.0124) | Acc: (99.55%) (28162/28288)\n",
            "Epoch: 192 | Batch_idx: 230 |  Loss: (0.0125) | Acc: (99.56%) (29437/29568)\n",
            "Epoch: 192 | Batch_idx: 240 |  Loss: (0.0126) | Acc: (99.55%) (30710/30848)\n",
            "Epoch: 192 | Batch_idx: 250 |  Loss: (0.0126) | Acc: (99.55%) (31982/32128)\n",
            "Epoch: 192 | Batch_idx: 260 |  Loss: (0.0128) | Acc: (99.54%) (33253/33408)\n",
            "Epoch: 192 | Batch_idx: 270 |  Loss: (0.0127) | Acc: (99.54%) (34529/34688)\n",
            "Epoch: 192 | Batch_idx: 280 |  Loss: (0.0126) | Acc: (99.55%) (35806/35968)\n",
            "Epoch: 192 | Batch_idx: 290 |  Loss: (0.0125) | Acc: (99.56%) (37084/37248)\n",
            "Epoch: 192 | Batch_idx: 300 |  Loss: (0.0123) | Acc: (99.57%) (38362/38528)\n",
            "Epoch: 192 | Batch_idx: 310 |  Loss: (0.0122) | Acc: (99.57%) (39637/39808)\n",
            "Epoch: 192 | Batch_idx: 320 |  Loss: (0.0122) | Acc: (99.58%) (40914/41088)\n",
            "Epoch: 192 | Batch_idx: 330 |  Loss: (0.0126) | Acc: (99.57%) (42184/42368)\n",
            "Epoch: 192 | Batch_idx: 340 |  Loss: (0.0126) | Acc: (99.56%) (43457/43648)\n",
            "Epoch: 192 | Batch_idx: 350 |  Loss: (0.0125) | Acc: (99.57%) (44733/44928)\n",
            "Epoch: 192 | Batch_idx: 360 |  Loss: (0.0125) | Acc: (99.57%) (46007/46208)\n",
            "Epoch: 192 | Batch_idx: 370 |  Loss: (0.0127) | Acc: (99.56%) (47280/47488)\n",
            "Epoch: 192 | Batch_idx: 380 |  Loss: (0.0127) | Acc: (99.56%) (48554/48768)\n",
            "Epoch: 192 | Batch_idx: 390 |  Loss: (0.0128) | Acc: (99.56%) (49780/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3973) | Acc: (91.79%) (9179/10000)\n",
            "Epoch: 193 | Batch_idx: 0 |  Loss: (0.0071) | Acc: (99.22%) (127/128)\n",
            "Epoch: 193 | Batch_idx: 10 |  Loss: (0.0074) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 193 | Batch_idx: 20 |  Loss: (0.0086) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 193 | Batch_idx: 30 |  Loss: (0.0112) | Acc: (99.65%) (3954/3968)\n",
            "Epoch: 193 | Batch_idx: 40 |  Loss: (0.0118) | Acc: (99.64%) (5229/5248)\n",
            "Epoch: 193 | Batch_idx: 50 |  Loss: (0.0129) | Acc: (99.62%) (6503/6528)\n",
            "Epoch: 193 | Batch_idx: 60 |  Loss: (0.0123) | Acc: (99.63%) (7779/7808)\n",
            "Epoch: 193 | Batch_idx: 70 |  Loss: (0.0119) | Acc: (99.65%) (9056/9088)\n",
            "Epoch: 193 | Batch_idx: 80 |  Loss: (0.0118) | Acc: (99.65%) (10332/10368)\n",
            "Epoch: 193 | Batch_idx: 90 |  Loss: (0.0122) | Acc: (99.63%) (11605/11648)\n",
            "Epoch: 193 | Batch_idx: 100 |  Loss: (0.0119) | Acc: (99.64%) (12881/12928)\n",
            "Epoch: 193 | Batch_idx: 110 |  Loss: (0.0114) | Acc: (99.65%) (14158/14208)\n",
            "Epoch: 193 | Batch_idx: 120 |  Loss: (0.0110) | Acc: (99.65%) (15434/15488)\n",
            "Epoch: 193 | Batch_idx: 130 |  Loss: (0.0118) | Acc: (99.61%) (16702/16768)\n",
            "Epoch: 193 | Batch_idx: 140 |  Loss: (0.0116) | Acc: (99.62%) (17979/18048)\n",
            "Epoch: 193 | Batch_idx: 150 |  Loss: (0.0116) | Acc: (99.62%) (19254/19328)\n",
            "Epoch: 193 | Batch_idx: 160 |  Loss: (0.0118) | Acc: (99.61%) (20527/20608)\n",
            "Epoch: 193 | Batch_idx: 170 |  Loss: (0.0115) | Acc: (99.62%) (21805/21888)\n",
            "Epoch: 193 | Batch_idx: 180 |  Loss: (0.0114) | Acc: (99.62%) (23080/23168)\n",
            "Epoch: 193 | Batch_idx: 190 |  Loss: (0.0118) | Acc: (99.60%) (24351/24448)\n",
            "Epoch: 193 | Batch_idx: 200 |  Loss: (0.0117) | Acc: (99.59%) (25622/25728)\n",
            "Epoch: 193 | Batch_idx: 210 |  Loss: (0.0117) | Acc: (99.59%) (26897/27008)\n",
            "Epoch: 193 | Batch_idx: 220 |  Loss: (0.0116) | Acc: (99.59%) (28172/28288)\n",
            "Epoch: 193 | Batch_idx: 230 |  Loss: (0.0116) | Acc: (99.59%) (29447/29568)\n",
            "Epoch: 193 | Batch_idx: 240 |  Loss: (0.0115) | Acc: (99.60%) (30724/30848)\n",
            "Epoch: 193 | Batch_idx: 250 |  Loss: (0.0117) | Acc: (99.60%) (31998/32128)\n",
            "Epoch: 193 | Batch_idx: 260 |  Loss: (0.0114) | Acc: (99.60%) (33276/33408)\n",
            "Epoch: 193 | Batch_idx: 270 |  Loss: (0.0116) | Acc: (99.61%) (34551/34688)\n",
            "Epoch: 193 | Batch_idx: 280 |  Loss: (0.0118) | Acc: (99.59%) (35822/35968)\n",
            "Epoch: 193 | Batch_idx: 290 |  Loss: (0.0117) | Acc: (99.60%) (37099/37248)\n",
            "Epoch: 193 | Batch_idx: 300 |  Loss: (0.0115) | Acc: (99.61%) (38376/38528)\n",
            "Epoch: 193 | Batch_idx: 310 |  Loss: (0.0114) | Acc: (99.61%) (39651/39808)\n",
            "Epoch: 193 | Batch_idx: 320 |  Loss: (0.0114) | Acc: (99.60%) (40924/41088)\n",
            "Epoch: 193 | Batch_idx: 330 |  Loss: (0.0114) | Acc: (99.60%) (42198/42368)\n",
            "Epoch: 193 | Batch_idx: 340 |  Loss: (0.0114) | Acc: (99.60%) (43475/43648)\n",
            "Epoch: 193 | Batch_idx: 350 |  Loss: (0.0114) | Acc: (99.60%) (44748/44928)\n",
            "Epoch: 193 | Batch_idx: 360 |  Loss: (0.0113) | Acc: (99.60%) (46024/46208)\n",
            "Epoch: 193 | Batch_idx: 370 |  Loss: (0.0115) | Acc: (99.60%) (47299/47488)\n",
            "Epoch: 193 | Batch_idx: 380 |  Loss: (0.0115) | Acc: (99.60%) (48573/48768)\n",
            "Epoch: 193 | Batch_idx: 390 |  Loss: (0.0115) | Acc: (99.60%) (49800/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3990) | Acc: (91.71%) (9171/10000)\n",
            "Epoch: 194 | Batch_idx: 0 |  Loss: (0.0127) | Acc: (99.22%) (127/128)\n",
            "Epoch: 194 | Batch_idx: 10 |  Loss: (0.0168) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 194 | Batch_idx: 20 |  Loss: (0.0158) | Acc: (99.37%) (2671/2688)\n",
            "Epoch: 194 | Batch_idx: 30 |  Loss: (0.0143) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 194 | Batch_idx: 40 |  Loss: (0.0128) | Acc: (99.56%) (5225/5248)\n",
            "Epoch: 194 | Batch_idx: 50 |  Loss: (0.0149) | Acc: (99.54%) (6498/6528)\n",
            "Epoch: 194 | Batch_idx: 60 |  Loss: (0.0140) | Acc: (99.55%) (7773/7808)\n",
            "Epoch: 194 | Batch_idx: 70 |  Loss: (0.0141) | Acc: (99.54%) (9046/9088)\n",
            "Epoch: 194 | Batch_idx: 80 |  Loss: (0.0149) | Acc: (99.52%) (10318/10368)\n",
            "Epoch: 194 | Batch_idx: 90 |  Loss: (0.0151) | Acc: (99.52%) (11592/11648)\n",
            "Epoch: 194 | Batch_idx: 100 |  Loss: (0.0159) | Acc: (99.47%) (12860/12928)\n",
            "Epoch: 194 | Batch_idx: 110 |  Loss: (0.0158) | Acc: (99.49%) (14136/14208)\n",
            "Epoch: 194 | Batch_idx: 120 |  Loss: (0.0157) | Acc: (99.50%) (15410/15488)\n",
            "Epoch: 194 | Batch_idx: 130 |  Loss: (0.0154) | Acc: (99.51%) (16686/16768)\n",
            "Epoch: 194 | Batch_idx: 140 |  Loss: (0.0152) | Acc: (99.52%) (17961/18048)\n",
            "Epoch: 194 | Batch_idx: 150 |  Loss: (0.0152) | Acc: (99.51%) (19234/19328)\n",
            "Epoch: 194 | Batch_idx: 160 |  Loss: (0.0155) | Acc: (99.49%) (20502/20608)\n",
            "Epoch: 194 | Batch_idx: 170 |  Loss: (0.0153) | Acc: (99.48%) (21775/21888)\n",
            "Epoch: 194 | Batch_idx: 180 |  Loss: (0.0157) | Acc: (99.48%) (23047/23168)\n",
            "Epoch: 194 | Batch_idx: 190 |  Loss: (0.0155) | Acc: (99.48%) (24320/24448)\n",
            "Epoch: 194 | Batch_idx: 200 |  Loss: (0.0151) | Acc: (99.49%) (25598/25728)\n",
            "Epoch: 194 | Batch_idx: 210 |  Loss: (0.0148) | Acc: (99.51%) (26875/27008)\n",
            "Epoch: 194 | Batch_idx: 220 |  Loss: (0.0146) | Acc: (99.52%) (28152/28288)\n",
            "Epoch: 194 | Batch_idx: 230 |  Loss: (0.0142) | Acc: (99.54%) (29432/29568)\n",
            "Epoch: 194 | Batch_idx: 240 |  Loss: (0.0141) | Acc: (99.54%) (30705/30848)\n",
            "Epoch: 194 | Batch_idx: 250 |  Loss: (0.0137) | Acc: (99.55%) (31984/32128)\n",
            "Epoch: 194 | Batch_idx: 260 |  Loss: (0.0137) | Acc: (99.55%) (33259/33408)\n",
            "Epoch: 194 | Batch_idx: 270 |  Loss: (0.0139) | Acc: (99.56%) (34534/34688)\n",
            "Epoch: 194 | Batch_idx: 280 |  Loss: (0.0141) | Acc: (99.54%) (35802/35968)\n",
            "Epoch: 194 | Batch_idx: 290 |  Loss: (0.0142) | Acc: (99.54%) (37075/37248)\n",
            "Epoch: 194 | Batch_idx: 300 |  Loss: (0.0141) | Acc: (99.54%) (38351/38528)\n",
            "Epoch: 194 | Batch_idx: 310 |  Loss: (0.0142) | Acc: (99.54%) (39624/39808)\n",
            "Epoch: 194 | Batch_idx: 320 |  Loss: (0.0142) | Acc: (99.54%) (40897/41088)\n",
            "Epoch: 194 | Batch_idx: 330 |  Loss: (0.0140) | Acc: (99.54%) (42174/42368)\n",
            "Epoch: 194 | Batch_idx: 340 |  Loss: (0.0140) | Acc: (99.54%) (43448/43648)\n",
            "Epoch: 194 | Batch_idx: 350 |  Loss: (0.0142) | Acc: (99.54%) (44720/44928)\n",
            "Epoch: 194 | Batch_idx: 360 |  Loss: (0.0141) | Acc: (99.54%) (45997/46208)\n",
            "Epoch: 194 | Batch_idx: 370 |  Loss: (0.0140) | Acc: (99.55%) (47272/47488)\n",
            "Epoch: 194 | Batch_idx: 380 |  Loss: (0.0140) | Acc: (99.54%) (48546/48768)\n",
            "Epoch: 194 | Batch_idx: 390 |  Loss: (0.0138) | Acc: (99.55%) (49777/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4007) | Acc: (91.65%) (9165/10000)\n",
            "Epoch: 195 | Batch_idx: 0 |  Loss: (0.0046) | Acc: (100.00%) (128/128)\n",
            "Epoch: 195 | Batch_idx: 10 |  Loss: (0.0114) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 195 | Batch_idx: 20 |  Loss: (0.0143) | Acc: (99.52%) (2675/2688)\n",
            "Epoch: 195 | Batch_idx: 30 |  Loss: (0.0149) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 195 | Batch_idx: 40 |  Loss: (0.0150) | Acc: (99.50%) (5222/5248)\n",
            "Epoch: 195 | Batch_idx: 50 |  Loss: (0.0134) | Acc: (99.59%) (6501/6528)\n",
            "Epoch: 195 | Batch_idx: 60 |  Loss: (0.0149) | Acc: (99.49%) (7768/7808)\n",
            "Epoch: 195 | Batch_idx: 70 |  Loss: (0.0148) | Acc: (99.48%) (9041/9088)\n",
            "Epoch: 195 | Batch_idx: 80 |  Loss: (0.0144) | Acc: (99.50%) (10316/10368)\n",
            "Epoch: 195 | Batch_idx: 90 |  Loss: (0.0149) | Acc: (99.48%) (11588/11648)\n",
            "Epoch: 195 | Batch_idx: 100 |  Loss: (0.0162) | Acc: (99.44%) (12856/12928)\n",
            "Epoch: 195 | Batch_idx: 110 |  Loss: (0.0166) | Acc: (99.44%) (14128/14208)\n",
            "Epoch: 195 | Batch_idx: 120 |  Loss: (0.0162) | Acc: (99.45%) (15403/15488)\n",
            "Epoch: 195 | Batch_idx: 130 |  Loss: (0.0159) | Acc: (99.46%) (16678/16768)\n",
            "Epoch: 195 | Batch_idx: 140 |  Loss: (0.0159) | Acc: (99.45%) (17948/18048)\n",
            "Epoch: 195 | Batch_idx: 150 |  Loss: (0.0160) | Acc: (99.44%) (19220/19328)\n",
            "Epoch: 195 | Batch_idx: 160 |  Loss: (0.0161) | Acc: (99.43%) (20491/20608)\n",
            "Epoch: 195 | Batch_idx: 170 |  Loss: (0.0162) | Acc: (99.41%) (21759/21888)\n",
            "Epoch: 195 | Batch_idx: 180 |  Loss: (0.0160) | Acc: (99.41%) (23032/23168)\n",
            "Epoch: 195 | Batch_idx: 190 |  Loss: (0.0156) | Acc: (99.43%) (24309/24448)\n",
            "Epoch: 195 | Batch_idx: 200 |  Loss: (0.0156) | Acc: (99.42%) (25579/25728)\n",
            "Epoch: 195 | Batch_idx: 210 |  Loss: (0.0153) | Acc: (99.43%) (26855/27008)\n",
            "Epoch: 195 | Batch_idx: 220 |  Loss: (0.0153) | Acc: (99.43%) (28127/28288)\n",
            "Epoch: 195 | Batch_idx: 230 |  Loss: (0.0151) | Acc: (99.44%) (29402/29568)\n",
            "Epoch: 195 | Batch_idx: 240 |  Loss: (0.0152) | Acc: (99.44%) (30675/30848)\n",
            "Epoch: 195 | Batch_idx: 250 |  Loss: (0.0152) | Acc: (99.43%) (31946/32128)\n",
            "Epoch: 195 | Batch_idx: 260 |  Loss: (0.0150) | Acc: (99.44%) (33220/33408)\n",
            "Epoch: 195 | Batch_idx: 270 |  Loss: (0.0149) | Acc: (99.45%) (34496/34688)\n",
            "Epoch: 195 | Batch_idx: 280 |  Loss: (0.0146) | Acc: (99.46%) (35773/35968)\n",
            "Epoch: 195 | Batch_idx: 290 |  Loss: (0.0148) | Acc: (99.45%) (37043/37248)\n",
            "Epoch: 195 | Batch_idx: 300 |  Loss: (0.0145) | Acc: (99.46%) (38320/38528)\n",
            "Epoch: 195 | Batch_idx: 310 |  Loss: (0.0144) | Acc: (99.47%) (39597/39808)\n",
            "Epoch: 195 | Batch_idx: 320 |  Loss: (0.0142) | Acc: (99.47%) (40871/41088)\n",
            "Epoch: 195 | Batch_idx: 330 |  Loss: (0.0142) | Acc: (99.48%) (42146/42368)\n",
            "Epoch: 195 | Batch_idx: 340 |  Loss: (0.0143) | Acc: (99.48%) (43420/43648)\n",
            "Epoch: 195 | Batch_idx: 350 |  Loss: (0.0142) | Acc: (99.48%) (44693/44928)\n",
            "Epoch: 195 | Batch_idx: 360 |  Loss: (0.0140) | Acc: (99.49%) (45971/46208)\n",
            "Epoch: 195 | Batch_idx: 370 |  Loss: (0.0138) | Acc: (99.49%) (47246/47488)\n",
            "Epoch: 195 | Batch_idx: 380 |  Loss: (0.0139) | Acc: (99.49%) (48518/48768)\n",
            "Epoch: 195 | Batch_idx: 390 |  Loss: (0.0141) | Acc: (99.48%) (49741/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4021) | Acc: (91.73%) (9173/10000)\n",
            "Epoch: 196 | Batch_idx: 0 |  Loss: (0.0425) | Acc: (99.22%) (127/128)\n",
            "Epoch: 196 | Batch_idx: 10 |  Loss: (0.0164) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 196 | Batch_idx: 20 |  Loss: (0.0161) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 196 | Batch_idx: 30 |  Loss: (0.0194) | Acc: (99.37%) (3943/3968)\n",
            "Epoch: 196 | Batch_idx: 40 |  Loss: (0.0165) | Acc: (99.47%) (5220/5248)\n",
            "Epoch: 196 | Batch_idx: 50 |  Loss: (0.0171) | Acc: (99.43%) (6491/6528)\n",
            "Epoch: 196 | Batch_idx: 60 |  Loss: (0.0170) | Acc: (99.42%) (7763/7808)\n",
            "Epoch: 196 | Batch_idx: 70 |  Loss: (0.0163) | Acc: (99.43%) (9036/9088)\n",
            "Epoch: 196 | Batch_idx: 80 |  Loss: (0.0152) | Acc: (99.47%) (10313/10368)\n",
            "Epoch: 196 | Batch_idx: 90 |  Loss: (0.0146) | Acc: (99.50%) (11590/11648)\n",
            "Epoch: 196 | Batch_idx: 100 |  Loss: (0.0147) | Acc: (99.47%) (12859/12928)\n",
            "Epoch: 196 | Batch_idx: 110 |  Loss: (0.0142) | Acc: (99.49%) (14136/14208)\n",
            "Epoch: 196 | Batch_idx: 120 |  Loss: (0.0146) | Acc: (99.46%) (15405/15488)\n",
            "Epoch: 196 | Batch_idx: 130 |  Loss: (0.0147) | Acc: (99.46%) (16678/16768)\n",
            "Epoch: 196 | Batch_idx: 140 |  Loss: (0.0146) | Acc: (99.46%) (17951/18048)\n",
            "Epoch: 196 | Batch_idx: 150 |  Loss: (0.0142) | Acc: (99.48%) (19228/19328)\n",
            "Epoch: 196 | Batch_idx: 160 |  Loss: (0.0144) | Acc: (99.49%) (20503/20608)\n",
            "Epoch: 196 | Batch_idx: 170 |  Loss: (0.0147) | Acc: (99.48%) (21775/21888)\n",
            "Epoch: 196 | Batch_idx: 180 |  Loss: (0.0144) | Acc: (99.50%) (23052/23168)\n",
            "Epoch: 196 | Batch_idx: 190 |  Loss: (0.0148) | Acc: (99.48%) (24322/24448)\n",
            "Epoch: 196 | Batch_idx: 200 |  Loss: (0.0151) | Acc: (99.47%) (25592/25728)\n",
            "Epoch: 196 | Batch_idx: 210 |  Loss: (0.0148) | Acc: (99.48%) (26867/27008)\n",
            "Epoch: 196 | Batch_idx: 220 |  Loss: (0.0145) | Acc: (99.49%) (28144/28288)\n",
            "Epoch: 196 | Batch_idx: 230 |  Loss: (0.0146) | Acc: (99.48%) (29415/29568)\n",
            "Epoch: 196 | Batch_idx: 240 |  Loss: (0.0144) | Acc: (99.49%) (30690/30848)\n",
            "Epoch: 196 | Batch_idx: 250 |  Loss: (0.0144) | Acc: (99.48%) (31962/32128)\n",
            "Epoch: 196 | Batch_idx: 260 |  Loss: (0.0145) | Acc: (99.48%) (33235/33408)\n",
            "Epoch: 196 | Batch_idx: 270 |  Loss: (0.0149) | Acc: (99.47%) (34504/34688)\n",
            "Epoch: 196 | Batch_idx: 280 |  Loss: (0.0146) | Acc: (99.49%) (35783/35968)\n",
            "Epoch: 196 | Batch_idx: 290 |  Loss: (0.0149) | Acc: (99.48%) (37054/37248)\n",
            "Epoch: 196 | Batch_idx: 300 |  Loss: (0.0151) | Acc: (99.48%) (38328/38528)\n",
            "Epoch: 196 | Batch_idx: 310 |  Loss: (0.0150) | Acc: (99.49%) (39603/39808)\n",
            "Epoch: 196 | Batch_idx: 320 |  Loss: (0.0148) | Acc: (99.49%) (40879/41088)\n",
            "Epoch: 196 | Batch_idx: 330 |  Loss: (0.0148) | Acc: (99.49%) (42151/42368)\n",
            "Epoch: 196 | Batch_idx: 340 |  Loss: (0.0149) | Acc: (99.48%) (43423/43648)\n",
            "Epoch: 196 | Batch_idx: 350 |  Loss: (0.0148) | Acc: (99.49%) (44698/44928)\n",
            "Epoch: 196 | Batch_idx: 360 |  Loss: (0.0147) | Acc: (99.49%) (45972/46208)\n",
            "Epoch: 196 | Batch_idx: 370 |  Loss: (0.0147) | Acc: (99.49%) (47245/47488)\n",
            "Epoch: 196 | Batch_idx: 380 |  Loss: (0.0148) | Acc: (99.49%) (48518/48768)\n",
            "Epoch: 196 | Batch_idx: 390 |  Loss: (0.0149) | Acc: (99.49%) (49743/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3998) | Acc: (91.84%) (9184/10000)\n",
            "Epoch: 197 | Batch_idx: 0 |  Loss: (0.0312) | Acc: (98.44%) (126/128)\n",
            "Epoch: 197 | Batch_idx: 10 |  Loss: (0.0086) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 197 | Batch_idx: 20 |  Loss: (0.0119) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 197 | Batch_idx: 30 |  Loss: (0.0130) | Acc: (99.60%) (3952/3968)\n",
            "Epoch: 197 | Batch_idx: 40 |  Loss: (0.0132) | Acc: (99.56%) (5225/5248)\n",
            "Epoch: 197 | Batch_idx: 50 |  Loss: (0.0125) | Acc: (99.57%) (6500/6528)\n",
            "Epoch: 197 | Batch_idx: 60 |  Loss: (0.0120) | Acc: (99.59%) (7776/7808)\n",
            "Epoch: 197 | Batch_idx: 70 |  Loss: (0.0129) | Acc: (99.57%) (9049/9088)\n",
            "Epoch: 197 | Batch_idx: 80 |  Loss: (0.0140) | Acc: (99.55%) (10321/10368)\n",
            "Epoch: 197 | Batch_idx: 90 |  Loss: (0.0140) | Acc: (99.54%) (11595/11648)\n",
            "Epoch: 197 | Batch_idx: 100 |  Loss: (0.0136) | Acc: (99.54%) (12869/12928)\n",
            "Epoch: 197 | Batch_idx: 110 |  Loss: (0.0133) | Acc: (99.55%) (14144/14208)\n",
            "Epoch: 197 | Batch_idx: 120 |  Loss: (0.0128) | Acc: (99.58%) (15423/15488)\n",
            "Epoch: 197 | Batch_idx: 130 |  Loss: (0.0126) | Acc: (99.58%) (16697/16768)\n",
            "Epoch: 197 | Batch_idx: 140 |  Loss: (0.0125) | Acc: (99.58%) (17972/18048)\n",
            "Epoch: 197 | Batch_idx: 150 |  Loss: (0.0127) | Acc: (99.58%) (19247/19328)\n",
            "Epoch: 197 | Batch_idx: 160 |  Loss: (0.0128) | Acc: (99.55%) (20515/20608)\n",
            "Epoch: 197 | Batch_idx: 170 |  Loss: (0.0131) | Acc: (99.54%) (21788/21888)\n",
            "Epoch: 197 | Batch_idx: 180 |  Loss: (0.0131) | Acc: (99.53%) (23060/23168)\n",
            "Epoch: 197 | Batch_idx: 190 |  Loss: (0.0134) | Acc: (99.52%) (24331/24448)\n",
            "Epoch: 197 | Batch_idx: 200 |  Loss: (0.0131) | Acc: (99.53%) (25608/25728)\n",
            "Epoch: 197 | Batch_idx: 210 |  Loss: (0.0133) | Acc: (99.53%) (26881/27008)\n",
            "Epoch: 197 | Batch_idx: 220 |  Loss: (0.0131) | Acc: (99.54%) (28158/28288)\n",
            "Epoch: 197 | Batch_idx: 230 |  Loss: (0.0134) | Acc: (99.53%) (29428/29568)\n",
            "Epoch: 197 | Batch_idx: 240 |  Loss: (0.0131) | Acc: (99.54%) (30707/30848)\n",
            "Epoch: 197 | Batch_idx: 250 |  Loss: (0.0132) | Acc: (99.54%) (31980/32128)\n",
            "Epoch: 197 | Batch_idx: 260 |  Loss: (0.0131) | Acc: (99.54%) (33253/33408)\n",
            "Epoch: 197 | Batch_idx: 270 |  Loss: (0.0131) | Acc: (99.54%) (34527/34688)\n",
            "Epoch: 197 | Batch_idx: 280 |  Loss: (0.0131) | Acc: (99.54%) (35801/35968)\n",
            "Epoch: 197 | Batch_idx: 290 |  Loss: (0.0134) | Acc: (99.52%) (37069/37248)\n",
            "Epoch: 197 | Batch_idx: 300 |  Loss: (0.0133) | Acc: (99.53%) (38345/38528)\n",
            "Epoch: 197 | Batch_idx: 310 |  Loss: (0.0135) | Acc: (99.52%) (39617/39808)\n",
            "Epoch: 197 | Batch_idx: 320 |  Loss: (0.0136) | Acc: (99.52%) (40891/41088)\n",
            "Epoch: 197 | Batch_idx: 330 |  Loss: (0.0135) | Acc: (99.52%) (42165/42368)\n",
            "Epoch: 197 | Batch_idx: 340 |  Loss: (0.0136) | Acc: (99.52%) (43438/43648)\n",
            "Epoch: 197 | Batch_idx: 350 |  Loss: (0.0135) | Acc: (99.52%) (44714/44928)\n",
            "Epoch: 197 | Batch_idx: 360 |  Loss: (0.0139) | Acc: (99.51%) (45981/46208)\n",
            "Epoch: 197 | Batch_idx: 370 |  Loss: (0.0139) | Acc: (99.51%) (47254/47488)\n",
            "Epoch: 197 | Batch_idx: 380 |  Loss: (0.0138) | Acc: (99.51%) (48530/48768)\n",
            "Epoch: 197 | Batch_idx: 390 |  Loss: (0.0138) | Acc: (99.51%) (49754/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4017) | Acc: (91.82%) (9182/10000)\n",
            "Epoch: 198 | Batch_idx: 0 |  Loss: (0.0088) | Acc: (99.22%) (127/128)\n",
            "Epoch: 198 | Batch_idx: 10 |  Loss: (0.0105) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 198 | Batch_idx: 20 |  Loss: (0.0108) | Acc: (99.63%) (2678/2688)\n",
            "Epoch: 198 | Batch_idx: 30 |  Loss: (0.0131) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 198 | Batch_idx: 40 |  Loss: (0.0121) | Acc: (99.62%) (5228/5248)\n",
            "Epoch: 198 | Batch_idx: 50 |  Loss: (0.0110) | Acc: (99.65%) (6505/6528)\n",
            "Epoch: 198 | Batch_idx: 60 |  Loss: (0.0113) | Acc: (99.64%) (7780/7808)\n",
            "Epoch: 198 | Batch_idx: 70 |  Loss: (0.0126) | Acc: (99.58%) (9050/9088)\n",
            "Epoch: 198 | Batch_idx: 80 |  Loss: (0.0121) | Acc: (99.59%) (10326/10368)\n",
            "Epoch: 198 | Batch_idx: 90 |  Loss: (0.0121) | Acc: (99.61%) (11602/11648)\n",
            "Epoch: 198 | Batch_idx: 100 |  Loss: (0.0121) | Acc: (99.61%) (12877/12928)\n",
            "Epoch: 198 | Batch_idx: 110 |  Loss: (0.0119) | Acc: (99.61%) (14153/14208)\n",
            "Epoch: 198 | Batch_idx: 120 |  Loss: (0.0120) | Acc: (99.61%) (15428/15488)\n",
            "Epoch: 198 | Batch_idx: 130 |  Loss: (0.0119) | Acc: (99.62%) (16704/16768)\n",
            "Epoch: 198 | Batch_idx: 140 |  Loss: (0.0118) | Acc: (99.62%) (17980/18048)\n",
            "Epoch: 198 | Batch_idx: 150 |  Loss: (0.0122) | Acc: (99.60%) (19251/19328)\n",
            "Epoch: 198 | Batch_idx: 160 |  Loss: (0.0126) | Acc: (99.58%) (20521/20608)\n",
            "Epoch: 198 | Batch_idx: 170 |  Loss: (0.0135) | Acc: (99.57%) (21793/21888)\n",
            "Epoch: 198 | Batch_idx: 180 |  Loss: (0.0132) | Acc: (99.58%) (23070/23168)\n",
            "Epoch: 198 | Batch_idx: 190 |  Loss: (0.0136) | Acc: (99.57%) (24342/24448)\n",
            "Epoch: 198 | Batch_idx: 200 |  Loss: (0.0138) | Acc: (99.55%) (25612/25728)\n",
            "Epoch: 198 | Batch_idx: 210 |  Loss: (0.0137) | Acc: (99.56%) (26888/27008)\n",
            "Epoch: 198 | Batch_idx: 220 |  Loss: (0.0140) | Acc: (99.55%) (28160/28288)\n",
            "Epoch: 198 | Batch_idx: 230 |  Loss: (0.0142) | Acc: (99.53%) (29430/29568)\n",
            "Epoch: 198 | Batch_idx: 240 |  Loss: (0.0142) | Acc: (99.53%) (30703/30848)\n",
            "Epoch: 198 | Batch_idx: 250 |  Loss: (0.0142) | Acc: (99.53%) (31978/32128)\n",
            "Epoch: 198 | Batch_idx: 260 |  Loss: (0.0144) | Acc: (99.53%) (33251/33408)\n",
            "Epoch: 198 | Batch_idx: 270 |  Loss: (0.0147) | Acc: (99.52%) (34522/34688)\n",
            "Epoch: 198 | Batch_idx: 280 |  Loss: (0.0146) | Acc: (99.51%) (35793/35968)\n",
            "Epoch: 198 | Batch_idx: 290 |  Loss: (0.0147) | Acc: (99.51%) (37065/37248)\n",
            "Epoch: 198 | Batch_idx: 300 |  Loss: (0.0146) | Acc: (99.51%) (38340/38528)\n",
            "Epoch: 198 | Batch_idx: 310 |  Loss: (0.0145) | Acc: (99.52%) (39618/39808)\n",
            "Epoch: 198 | Batch_idx: 320 |  Loss: (0.0145) | Acc: (99.51%) (40888/41088)\n",
            "Epoch: 198 | Batch_idx: 330 |  Loss: (0.0143) | Acc: (99.52%) (42165/42368)\n",
            "Epoch: 198 | Batch_idx: 340 |  Loss: (0.0145) | Acc: (99.52%) (43438/43648)\n",
            "Epoch: 198 | Batch_idx: 350 |  Loss: (0.0145) | Acc: (99.52%) (44713/44928)\n",
            "Epoch: 198 | Batch_idx: 360 |  Loss: (0.0144) | Acc: (99.52%) (45986/46208)\n",
            "Epoch: 198 | Batch_idx: 370 |  Loss: (0.0147) | Acc: (99.51%) (47257/47488)\n",
            "Epoch: 198 | Batch_idx: 380 |  Loss: (0.0148) | Acc: (99.51%) (48531/48768)\n",
            "Epoch: 198 | Batch_idx: 390 |  Loss: (0.0146) | Acc: (99.52%) (49759/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4015) | Acc: (91.74%) (9174/10000)\n",
            "Epoch: 199 | Batch_idx: 0 |  Loss: (0.0065) | Acc: (100.00%) (128/128)\n",
            "Epoch: 199 | Batch_idx: 10 |  Loss: (0.0159) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 199 | Batch_idx: 20 |  Loss: (0.0183) | Acc: (99.29%) (2669/2688)\n",
            "Epoch: 199 | Batch_idx: 30 |  Loss: (0.0141) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 199 | Batch_idx: 40 |  Loss: (0.0149) | Acc: (99.49%) (5221/5248)\n",
            "Epoch: 199 | Batch_idx: 50 |  Loss: (0.0141) | Acc: (99.53%) (6497/6528)\n",
            "Epoch: 199 | Batch_idx: 60 |  Loss: (0.0128) | Acc: (99.58%) (7775/7808)\n",
            "Epoch: 199 | Batch_idx: 70 |  Loss: (0.0133) | Acc: (99.53%) (9045/9088)\n",
            "Epoch: 199 | Batch_idx: 80 |  Loss: (0.0140) | Acc: (99.53%) (10319/10368)\n",
            "Epoch: 199 | Batch_idx: 90 |  Loss: (0.0138) | Acc: (99.52%) (11592/11648)\n",
            "Epoch: 199 | Batch_idx: 100 |  Loss: (0.0138) | Acc: (99.53%) (12867/12928)\n",
            "Epoch: 199 | Batch_idx: 110 |  Loss: (0.0134) | Acc: (99.54%) (14142/14208)\n",
            "Epoch: 199 | Batch_idx: 120 |  Loss: (0.0130) | Acc: (99.55%) (15418/15488)\n",
            "Epoch: 199 | Batch_idx: 130 |  Loss: (0.0134) | Acc: (99.55%) (16692/16768)\n",
            "Epoch: 199 | Batch_idx: 140 |  Loss: (0.0138) | Acc: (99.55%) (17967/18048)\n",
            "Epoch: 199 | Batch_idx: 150 |  Loss: (0.0136) | Acc: (99.57%) (19245/19328)\n",
            "Epoch: 199 | Batch_idx: 160 |  Loss: (0.0138) | Acc: (99.56%) (20517/20608)\n",
            "Epoch: 199 | Batch_idx: 170 |  Loss: (0.0136) | Acc: (99.56%) (21792/21888)\n",
            "Epoch: 199 | Batch_idx: 180 |  Loss: (0.0140) | Acc: (99.56%) (23066/23168)\n",
            "Epoch: 199 | Batch_idx: 190 |  Loss: (0.0140) | Acc: (99.57%) (24342/24448)\n",
            "Epoch: 199 | Batch_idx: 200 |  Loss: (0.0140) | Acc: (99.56%) (25616/25728)\n",
            "Epoch: 199 | Batch_idx: 210 |  Loss: (0.0137) | Acc: (99.57%) (26892/27008)\n",
            "Epoch: 199 | Batch_idx: 220 |  Loss: (0.0139) | Acc: (99.58%) (28168/28288)\n",
            "Epoch: 199 | Batch_idx: 230 |  Loss: (0.0139) | Acc: (99.58%) (29443/29568)\n",
            "Epoch: 199 | Batch_idx: 240 |  Loss: (0.0136) | Acc: (99.59%) (30720/30848)\n",
            "Epoch: 199 | Batch_idx: 250 |  Loss: (0.0137) | Acc: (99.58%) (31994/32128)\n",
            "Epoch: 199 | Batch_idx: 260 |  Loss: (0.0136) | Acc: (99.58%) (33269/33408)\n",
            "Epoch: 199 | Batch_idx: 270 |  Loss: (0.0135) | Acc: (99.59%) (34545/34688)\n",
            "Epoch: 199 | Batch_idx: 280 |  Loss: (0.0135) | Acc: (99.58%) (35817/35968)\n",
            "Epoch: 199 | Batch_idx: 290 |  Loss: (0.0136) | Acc: (99.58%) (37090/37248)\n",
            "Epoch: 199 | Batch_idx: 300 |  Loss: (0.0135) | Acc: (99.57%) (38363/38528)\n",
            "Epoch: 199 | Batch_idx: 310 |  Loss: (0.0134) | Acc: (99.58%) (39640/39808)\n",
            "Epoch: 199 | Batch_idx: 320 |  Loss: (0.0134) | Acc: (99.57%) (40911/41088)\n",
            "Epoch: 199 | Batch_idx: 330 |  Loss: (0.0136) | Acc: (99.57%) (42184/42368)\n",
            "Epoch: 199 | Batch_idx: 340 |  Loss: (0.0134) | Acc: (99.56%) (43458/43648)\n",
            "Epoch: 199 | Batch_idx: 350 |  Loss: (0.0134) | Acc: (99.57%) (44733/44928)\n",
            "Epoch: 199 | Batch_idx: 360 |  Loss: (0.0136) | Acc: (99.55%) (46001/46208)\n",
            "Epoch: 199 | Batch_idx: 370 |  Loss: (0.0134) | Acc: (99.56%) (47278/47488)\n",
            "Epoch: 199 | Batch_idx: 380 |  Loss: (0.0135) | Acc: (99.55%) (48550/48768)\n",
            "Epoch: 199 | Batch_idx: 390 |  Loss: (0.0134) | Acc: (99.56%) (49779/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4039) | Acc: (91.79%) (9179/10000)\n",
            "Epoch: 200 | Batch_idx: 0 |  Loss: (0.0193) | Acc: (99.22%) (127/128)\n",
            "Epoch: 200 | Batch_idx: 10 |  Loss: (0.0151) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 200 | Batch_idx: 20 |  Loss: (0.0172) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 200 | Batch_idx: 30 |  Loss: (0.0145) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 200 | Batch_idx: 40 |  Loss: (0.0141) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 200 | Batch_idx: 50 |  Loss: (0.0142) | Acc: (99.53%) (6497/6528)\n",
            "Epoch: 200 | Batch_idx: 60 |  Loss: (0.0161) | Acc: (99.46%) (7766/7808)\n",
            "Epoch: 200 | Batch_idx: 70 |  Loss: (0.0156) | Acc: (99.46%) (9039/9088)\n",
            "Epoch: 200 | Batch_idx: 80 |  Loss: (0.0154) | Acc: (99.45%) (10311/10368)\n",
            "Epoch: 200 | Batch_idx: 90 |  Loss: (0.0160) | Acc: (99.40%) (11578/11648)\n",
            "Epoch: 200 | Batch_idx: 100 |  Loss: (0.0159) | Acc: (99.42%) (12853/12928)\n",
            "Epoch: 200 | Batch_idx: 110 |  Loss: (0.0172) | Acc: (99.40%) (14123/14208)\n",
            "Epoch: 200 | Batch_idx: 120 |  Loss: (0.0168) | Acc: (99.43%) (15399/15488)\n",
            "Epoch: 200 | Batch_idx: 130 |  Loss: (0.0167) | Acc: (99.43%) (16672/16768)\n",
            "Epoch: 200 | Batch_idx: 140 |  Loss: (0.0166) | Acc: (99.45%) (17948/18048)\n",
            "Epoch: 200 | Batch_idx: 150 |  Loss: (0.0165) | Acc: (99.45%) (19221/19328)\n",
            "Epoch: 200 | Batch_idx: 160 |  Loss: (0.0164) | Acc: (99.45%) (20495/20608)\n",
            "Epoch: 200 | Batch_idx: 170 |  Loss: (0.0161) | Acc: (99.46%) (21770/21888)\n",
            "Epoch: 200 | Batch_idx: 180 |  Loss: (0.0165) | Acc: (99.45%) (23041/23168)\n",
            "Epoch: 200 | Batch_idx: 190 |  Loss: (0.0162) | Acc: (99.46%) (24317/24448)\n",
            "Epoch: 200 | Batch_idx: 200 |  Loss: (0.0162) | Acc: (99.46%) (25590/25728)\n",
            "Epoch: 200 | Batch_idx: 210 |  Loss: (0.0157) | Acc: (99.48%) (26868/27008)\n",
            "Epoch: 200 | Batch_idx: 220 |  Loss: (0.0155) | Acc: (99.48%) (28142/28288)\n",
            "Epoch: 200 | Batch_idx: 230 |  Loss: (0.0156) | Acc: (99.48%) (29414/29568)\n",
            "Epoch: 200 | Batch_idx: 240 |  Loss: (0.0153) | Acc: (99.49%) (30690/30848)\n",
            "Epoch: 200 | Batch_idx: 250 |  Loss: (0.0151) | Acc: (99.49%) (31965/32128)\n",
            "Epoch: 200 | Batch_idx: 260 |  Loss: (0.0151) | Acc: (99.50%) (33241/33408)\n",
            "Epoch: 200 | Batch_idx: 270 |  Loss: (0.0150) | Acc: (99.50%) (34515/34688)\n",
            "Epoch: 200 | Batch_idx: 280 |  Loss: (0.0149) | Acc: (99.50%) (35788/35968)\n",
            "Epoch: 200 | Batch_idx: 290 |  Loss: (0.0149) | Acc: (99.50%) (37062/37248)\n",
            "Epoch: 200 | Batch_idx: 300 |  Loss: (0.0148) | Acc: (99.50%) (38335/38528)\n",
            "Epoch: 200 | Batch_idx: 310 |  Loss: (0.0146) | Acc: (99.51%) (39612/39808)\n",
            "Epoch: 200 | Batch_idx: 320 |  Loss: (0.0145) | Acc: (99.51%) (40887/41088)\n",
            "Epoch: 200 | Batch_idx: 330 |  Loss: (0.0143) | Acc: (99.52%) (42165/42368)\n",
            "Epoch: 200 | Batch_idx: 340 |  Loss: (0.0142) | Acc: (99.52%) (43439/43648)\n",
            "Epoch: 200 | Batch_idx: 350 |  Loss: (0.0141) | Acc: (99.52%) (44714/44928)\n",
            "Epoch: 200 | Batch_idx: 360 |  Loss: (0.0143) | Acc: (99.52%) (45986/46208)\n",
            "Epoch: 200 | Batch_idx: 370 |  Loss: (0.0141) | Acc: (99.53%) (47263/47488)\n",
            "Epoch: 200 | Batch_idx: 380 |  Loss: (0.0140) | Acc: (99.53%) (48539/48768)\n",
            "Epoch: 200 | Batch_idx: 390 |  Loss: (0.0140) | Acc: (99.53%) (49764/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4034) | Acc: (91.88%) (9188/10000)\n",
            "Epoch: 201 | Batch_idx: 0 |  Loss: (0.0103) | Acc: (99.22%) (127/128)\n",
            "Epoch: 201 | Batch_idx: 10 |  Loss: (0.0061) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 201 | Batch_idx: 20 |  Loss: (0.0105) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 201 | Batch_idx: 30 |  Loss: (0.0102) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 201 | Batch_idx: 40 |  Loss: (0.0092) | Acc: (99.64%) (5229/5248)\n",
            "Epoch: 201 | Batch_idx: 50 |  Loss: (0.0094) | Acc: (99.65%) (6505/6528)\n",
            "Epoch: 201 | Batch_idx: 60 |  Loss: (0.0110) | Acc: (99.60%) (7777/7808)\n",
            "Epoch: 201 | Batch_idx: 70 |  Loss: (0.0114) | Acc: (99.59%) (9051/9088)\n",
            "Epoch: 201 | Batch_idx: 80 |  Loss: (0.0118) | Acc: (99.60%) (10327/10368)\n",
            "Epoch: 201 | Batch_idx: 90 |  Loss: (0.0121) | Acc: (99.60%) (11601/11648)\n",
            "Epoch: 201 | Batch_idx: 100 |  Loss: (0.0122) | Acc: (99.59%) (12875/12928)\n",
            "Epoch: 201 | Batch_idx: 110 |  Loss: (0.0127) | Acc: (99.58%) (14149/14208)\n",
            "Epoch: 201 | Batch_idx: 120 |  Loss: (0.0123) | Acc: (99.59%) (15425/15488)\n",
            "Epoch: 201 | Batch_idx: 130 |  Loss: (0.0126) | Acc: (99.59%) (16699/16768)\n",
            "Epoch: 201 | Batch_idx: 140 |  Loss: (0.0133) | Acc: (99.57%) (17970/18048)\n",
            "Epoch: 201 | Batch_idx: 150 |  Loss: (0.0135) | Acc: (99.57%) (19245/19328)\n",
            "Epoch: 201 | Batch_idx: 160 |  Loss: (0.0136) | Acc: (99.57%) (20519/20608)\n",
            "Epoch: 201 | Batch_idx: 170 |  Loss: (0.0141) | Acc: (99.54%) (21788/21888)\n",
            "Epoch: 201 | Batch_idx: 180 |  Loss: (0.0144) | Acc: (99.53%) (23058/23168)\n",
            "Epoch: 201 | Batch_idx: 190 |  Loss: (0.0142) | Acc: (99.53%) (24334/24448)\n",
            "Epoch: 201 | Batch_idx: 200 |  Loss: (0.0140) | Acc: (99.53%) (25608/25728)\n",
            "Epoch: 201 | Batch_idx: 210 |  Loss: (0.0138) | Acc: (99.54%) (26883/27008)\n",
            "Epoch: 201 | Batch_idx: 220 |  Loss: (0.0134) | Acc: (99.55%) (28161/28288)\n",
            "Epoch: 201 | Batch_idx: 230 |  Loss: (0.0136) | Acc: (99.55%) (29435/29568)\n",
            "Epoch: 201 | Batch_idx: 240 |  Loss: (0.0140) | Acc: (99.53%) (30703/30848)\n",
            "Epoch: 201 | Batch_idx: 250 |  Loss: (0.0139) | Acc: (99.53%) (31978/32128)\n",
            "Epoch: 201 | Batch_idx: 260 |  Loss: (0.0139) | Acc: (99.53%) (33252/33408)\n",
            "Epoch: 201 | Batch_idx: 270 |  Loss: (0.0138) | Acc: (99.54%) (34528/34688)\n",
            "Epoch: 201 | Batch_idx: 280 |  Loss: (0.0138) | Acc: (99.54%) (35801/35968)\n",
            "Epoch: 201 | Batch_idx: 290 |  Loss: (0.0140) | Acc: (99.53%) (37072/37248)\n",
            "Epoch: 201 | Batch_idx: 300 |  Loss: (0.0143) | Acc: (99.52%) (38344/38528)\n",
            "Epoch: 201 | Batch_idx: 310 |  Loss: (0.0143) | Acc: (99.53%) (39619/39808)\n",
            "Epoch: 201 | Batch_idx: 320 |  Loss: (0.0146) | Acc: (99.52%) (40892/41088)\n",
            "Epoch: 201 | Batch_idx: 330 |  Loss: (0.0146) | Acc: (99.52%) (42164/42368)\n",
            "Epoch: 201 | Batch_idx: 340 |  Loss: (0.0147) | Acc: (99.51%) (43436/43648)\n",
            "Epoch: 201 | Batch_idx: 350 |  Loss: (0.0147) | Acc: (99.51%) (44708/44928)\n",
            "Epoch: 201 | Batch_idx: 360 |  Loss: (0.0147) | Acc: (99.51%) (45982/46208)\n",
            "Epoch: 201 | Batch_idx: 370 |  Loss: (0.0147) | Acc: (99.52%) (47258/47488)\n",
            "Epoch: 201 | Batch_idx: 380 |  Loss: (0.0147) | Acc: (99.52%) (48532/48768)\n",
            "Epoch: 201 | Batch_idx: 390 |  Loss: (0.0146) | Acc: (99.52%) (49758/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4001) | Acc: (91.86%) (9186/10000)\n",
            "Epoch: 202 | Batch_idx: 0 |  Loss: (0.0087) | Acc: (100.00%) (128/128)\n",
            "Epoch: 202 | Batch_idx: 10 |  Loss: (0.0142) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 202 | Batch_idx: 20 |  Loss: (0.0144) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 202 | Batch_idx: 30 |  Loss: (0.0161) | Acc: (99.37%) (3943/3968)\n",
            "Epoch: 202 | Batch_idx: 40 |  Loss: (0.0173) | Acc: (99.41%) (5217/5248)\n",
            "Epoch: 202 | Batch_idx: 50 |  Loss: (0.0179) | Acc: (99.43%) (6491/6528)\n",
            "Epoch: 202 | Batch_idx: 60 |  Loss: (0.0209) | Acc: (99.35%) (7757/7808)\n",
            "Epoch: 202 | Batch_idx: 70 |  Loss: (0.0195) | Acc: (99.38%) (9032/9088)\n",
            "Epoch: 202 | Batch_idx: 80 |  Loss: (0.0181) | Acc: (99.44%) (10310/10368)\n",
            "Epoch: 202 | Batch_idx: 90 |  Loss: (0.0178) | Acc: (99.43%) (11582/11648)\n",
            "Epoch: 202 | Batch_idx: 100 |  Loss: (0.0175) | Acc: (99.44%) (12856/12928)\n",
            "Epoch: 202 | Batch_idx: 110 |  Loss: (0.0165) | Acc: (99.48%) (14134/14208)\n",
            "Epoch: 202 | Batch_idx: 120 |  Loss: (0.0160) | Acc: (99.50%) (15411/15488)\n",
            "Epoch: 202 | Batch_idx: 130 |  Loss: (0.0160) | Acc: (99.51%) (16685/16768)\n",
            "Epoch: 202 | Batch_idx: 140 |  Loss: (0.0156) | Acc: (99.51%) (17960/18048)\n",
            "Epoch: 202 | Batch_idx: 150 |  Loss: (0.0165) | Acc: (99.47%) (19225/19328)\n",
            "Epoch: 202 | Batch_idx: 160 |  Loss: (0.0161) | Acc: (99.48%) (20501/20608)\n",
            "Epoch: 202 | Batch_idx: 170 |  Loss: (0.0162) | Acc: (99.47%) (21772/21888)\n",
            "Epoch: 202 | Batch_idx: 180 |  Loss: (0.0163) | Acc: (99.45%) (23041/23168)\n",
            "Epoch: 202 | Batch_idx: 190 |  Loss: (0.0159) | Acc: (99.47%) (24318/24448)\n",
            "Epoch: 202 | Batch_idx: 200 |  Loss: (0.0159) | Acc: (99.48%) (25593/25728)\n",
            "Epoch: 202 | Batch_idx: 210 |  Loss: (0.0160) | Acc: (99.47%) (26864/27008)\n",
            "Epoch: 202 | Batch_idx: 220 |  Loss: (0.0158) | Acc: (99.47%) (28139/28288)\n",
            "Epoch: 202 | Batch_idx: 230 |  Loss: (0.0154) | Acc: (99.49%) (29416/29568)\n",
            "Epoch: 202 | Batch_idx: 240 |  Loss: (0.0154) | Acc: (99.48%) (30689/30848)\n",
            "Epoch: 202 | Batch_idx: 250 |  Loss: (0.0153) | Acc: (99.49%) (31964/32128)\n",
            "Epoch: 202 | Batch_idx: 260 |  Loss: (0.0154) | Acc: (99.48%) (33235/33408)\n",
            "Epoch: 202 | Batch_idx: 270 |  Loss: (0.0154) | Acc: (99.48%) (34508/34688)\n",
            "Epoch: 202 | Batch_idx: 280 |  Loss: (0.0154) | Acc: (99.48%) (35780/35968)\n",
            "Epoch: 202 | Batch_idx: 290 |  Loss: (0.0150) | Acc: (99.49%) (37058/37248)\n",
            "Epoch: 202 | Batch_idx: 300 |  Loss: (0.0151) | Acc: (99.48%) (38326/38528)\n",
            "Epoch: 202 | Batch_idx: 310 |  Loss: (0.0149) | Acc: (99.49%) (39604/39808)\n",
            "Epoch: 202 | Batch_idx: 320 |  Loss: (0.0148) | Acc: (99.49%) (40879/41088)\n",
            "Epoch: 202 | Batch_idx: 330 |  Loss: (0.0147) | Acc: (99.50%) (42155/42368)\n",
            "Epoch: 202 | Batch_idx: 340 |  Loss: (0.0148) | Acc: (99.50%) (43429/43648)\n",
            "Epoch: 202 | Batch_idx: 350 |  Loss: (0.0147) | Acc: (99.50%) (44702/44928)\n",
            "Epoch: 202 | Batch_idx: 360 |  Loss: (0.0147) | Acc: (99.50%) (45976/46208)\n",
            "Epoch: 202 | Batch_idx: 370 |  Loss: (0.0147) | Acc: (99.50%) (47250/47488)\n",
            "Epoch: 202 | Batch_idx: 380 |  Loss: (0.0148) | Acc: (99.50%) (48522/48768)\n",
            "Epoch: 202 | Batch_idx: 390 |  Loss: (0.0149) | Acc: (99.50%) (49750/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3990) | Acc: (91.80%) (9180/10000)\n",
            "Epoch: 203 | Batch_idx: 0 |  Loss: (0.0085) | Acc: (100.00%) (128/128)\n",
            "Epoch: 203 | Batch_idx: 10 |  Loss: (0.0104) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 203 | Batch_idx: 20 |  Loss: (0.0132) | Acc: (99.52%) (2675/2688)\n",
            "Epoch: 203 | Batch_idx: 30 |  Loss: (0.0122) | Acc: (99.55%) (3950/3968)\n",
            "Epoch: 203 | Batch_idx: 40 |  Loss: (0.0124) | Acc: (99.58%) (5226/5248)\n",
            "Epoch: 203 | Batch_idx: 50 |  Loss: (0.0136) | Acc: (99.57%) (6500/6528)\n",
            "Epoch: 203 | Batch_idx: 60 |  Loss: (0.0126) | Acc: (99.60%) (7777/7808)\n",
            "Epoch: 203 | Batch_idx: 70 |  Loss: (0.0124) | Acc: (99.63%) (9054/9088)\n",
            "Epoch: 203 | Batch_idx: 80 |  Loss: (0.0132) | Acc: (99.59%) (10325/10368)\n",
            "Epoch: 203 | Batch_idx: 90 |  Loss: (0.0126) | Acc: (99.59%) (11600/11648)\n",
            "Epoch: 203 | Batch_idx: 100 |  Loss: (0.0132) | Acc: (99.56%) (12871/12928)\n",
            "Epoch: 203 | Batch_idx: 110 |  Loss: (0.0127) | Acc: (99.58%) (14149/14208)\n",
            "Epoch: 203 | Batch_idx: 120 |  Loss: (0.0130) | Acc: (99.57%) (15421/15488)\n",
            "Epoch: 203 | Batch_idx: 130 |  Loss: (0.0134) | Acc: (99.55%) (16692/16768)\n",
            "Epoch: 203 | Batch_idx: 140 |  Loss: (0.0135) | Acc: (99.53%) (17964/18048)\n",
            "Epoch: 203 | Batch_idx: 150 |  Loss: (0.0136) | Acc: (99.53%) (19238/19328)\n",
            "Epoch: 203 | Batch_idx: 160 |  Loss: (0.0135) | Acc: (99.54%) (20513/20608)\n",
            "Epoch: 203 | Batch_idx: 170 |  Loss: (0.0137) | Acc: (99.53%) (21785/21888)\n",
            "Epoch: 203 | Batch_idx: 180 |  Loss: (0.0137) | Acc: (99.53%) (23059/23168)\n",
            "Epoch: 203 | Batch_idx: 190 |  Loss: (0.0134) | Acc: (99.54%) (24335/24448)\n",
            "Epoch: 203 | Batch_idx: 200 |  Loss: (0.0133) | Acc: (99.54%) (25610/25728)\n",
            "Epoch: 203 | Batch_idx: 210 |  Loss: (0.0130) | Acc: (99.54%) (26885/27008)\n",
            "Epoch: 203 | Batch_idx: 220 |  Loss: (0.0132) | Acc: (99.54%) (28158/28288)\n",
            "Epoch: 203 | Batch_idx: 230 |  Loss: (0.0133) | Acc: (99.54%) (29431/29568)\n",
            "Epoch: 203 | Batch_idx: 240 |  Loss: (0.0134) | Acc: (99.54%) (30705/30848)\n",
            "Epoch: 203 | Batch_idx: 250 |  Loss: (0.0133) | Acc: (99.54%) (31980/32128)\n",
            "Epoch: 203 | Batch_idx: 260 |  Loss: (0.0132) | Acc: (99.55%) (33257/33408)\n",
            "Epoch: 203 | Batch_idx: 270 |  Loss: (0.0131) | Acc: (99.55%) (34533/34688)\n",
            "Epoch: 203 | Batch_idx: 280 |  Loss: (0.0130) | Acc: (99.56%) (35810/35968)\n",
            "Epoch: 203 | Batch_idx: 290 |  Loss: (0.0129) | Acc: (99.56%) (37083/37248)\n",
            "Epoch: 203 | Batch_idx: 300 |  Loss: (0.0132) | Acc: (99.55%) (38355/38528)\n",
            "Epoch: 203 | Batch_idx: 310 |  Loss: (0.0133) | Acc: (99.54%) (39625/39808)\n",
            "Epoch: 203 | Batch_idx: 320 |  Loss: (0.0131) | Acc: (99.55%) (40902/41088)\n",
            "Epoch: 203 | Batch_idx: 330 |  Loss: (0.0132) | Acc: (99.54%) (42172/42368)\n",
            "Epoch: 203 | Batch_idx: 340 |  Loss: (0.0131) | Acc: (99.54%) (43446/43648)\n",
            "Epoch: 203 | Batch_idx: 350 |  Loss: (0.0131) | Acc: (99.54%) (44720/44928)\n",
            "Epoch: 203 | Batch_idx: 360 |  Loss: (0.0130) | Acc: (99.54%) (45994/46208)\n",
            "Epoch: 203 | Batch_idx: 370 |  Loss: (0.0130) | Acc: (99.53%) (47265/47488)\n",
            "Epoch: 203 | Batch_idx: 380 |  Loss: (0.0130) | Acc: (99.53%) (48540/48768)\n",
            "Epoch: 203 | Batch_idx: 390 |  Loss: (0.0131) | Acc: (99.53%) (49764/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3999) | Acc: (91.80%) (9180/10000)\n",
            "Epoch: 204 | Batch_idx: 0 |  Loss: (0.0063) | Acc: (100.00%) (128/128)\n",
            "Epoch: 204 | Batch_idx: 10 |  Loss: (0.0133) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 204 | Batch_idx: 20 |  Loss: (0.0104) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 204 | Batch_idx: 30 |  Loss: (0.0106) | Acc: (99.72%) (3957/3968)\n",
            "Epoch: 204 | Batch_idx: 40 |  Loss: (0.0124) | Acc: (99.62%) (5228/5248)\n",
            "Epoch: 204 | Batch_idx: 50 |  Loss: (0.0115) | Acc: (99.63%) (6504/6528)\n",
            "Epoch: 204 | Batch_idx: 60 |  Loss: (0.0117) | Acc: (99.65%) (7781/7808)\n",
            "Epoch: 204 | Batch_idx: 70 |  Loss: (0.0115) | Acc: (99.66%) (9057/9088)\n",
            "Epoch: 204 | Batch_idx: 80 |  Loss: (0.0128) | Acc: (99.61%) (10328/10368)\n",
            "Epoch: 204 | Batch_idx: 90 |  Loss: (0.0133) | Acc: (99.61%) (11602/11648)\n",
            "Epoch: 204 | Batch_idx: 100 |  Loss: (0.0128) | Acc: (99.62%) (12879/12928)\n",
            "Epoch: 204 | Batch_idx: 110 |  Loss: (0.0129) | Acc: (99.61%) (14153/14208)\n",
            "Epoch: 204 | Batch_idx: 120 |  Loss: (0.0128) | Acc: (99.61%) (15428/15488)\n",
            "Epoch: 204 | Batch_idx: 130 |  Loss: (0.0128) | Acc: (99.60%) (16701/16768)\n",
            "Epoch: 204 | Batch_idx: 140 |  Loss: (0.0127) | Acc: (99.60%) (17975/18048)\n",
            "Epoch: 204 | Batch_idx: 150 |  Loss: (0.0127) | Acc: (99.60%) (19251/19328)\n",
            "Epoch: 204 | Batch_idx: 160 |  Loss: (0.0125) | Acc: (99.62%) (20529/20608)\n",
            "Epoch: 204 | Batch_idx: 170 |  Loss: (0.0124) | Acc: (99.62%) (21804/21888)\n",
            "Epoch: 204 | Batch_idx: 180 |  Loss: (0.0123) | Acc: (99.62%) (23080/23168)\n",
            "Epoch: 204 | Batch_idx: 190 |  Loss: (0.0123) | Acc: (99.62%) (24355/24448)\n",
            "Epoch: 204 | Batch_idx: 200 |  Loss: (0.0124) | Acc: (99.62%) (25630/25728)\n",
            "Epoch: 204 | Batch_idx: 210 |  Loss: (0.0128) | Acc: (99.61%) (26902/27008)\n",
            "Epoch: 204 | Batch_idx: 220 |  Loss: (0.0130) | Acc: (99.60%) (28174/28288)\n",
            "Epoch: 204 | Batch_idx: 230 |  Loss: (0.0133) | Acc: (99.59%) (29446/29568)\n",
            "Epoch: 204 | Batch_idx: 240 |  Loss: (0.0132) | Acc: (99.59%) (30721/30848)\n",
            "Epoch: 204 | Batch_idx: 250 |  Loss: (0.0133) | Acc: (99.58%) (31994/32128)\n",
            "Epoch: 204 | Batch_idx: 260 |  Loss: (0.0130) | Acc: (99.59%) (33271/33408)\n",
            "Epoch: 204 | Batch_idx: 270 |  Loss: (0.0128) | Acc: (99.59%) (34547/34688)\n",
            "Epoch: 204 | Batch_idx: 280 |  Loss: (0.0129) | Acc: (99.59%) (35822/35968)\n",
            "Epoch: 204 | Batch_idx: 290 |  Loss: (0.0134) | Acc: (99.57%) (37088/37248)\n",
            "Epoch: 204 | Batch_idx: 300 |  Loss: (0.0136) | Acc: (99.56%) (38357/38528)\n",
            "Epoch: 204 | Batch_idx: 310 |  Loss: (0.0137) | Acc: (99.55%) (39630/39808)\n",
            "Epoch: 204 | Batch_idx: 320 |  Loss: (0.0139) | Acc: (99.54%) (40901/41088)\n",
            "Epoch: 204 | Batch_idx: 330 |  Loss: (0.0139) | Acc: (99.54%) (42175/42368)\n",
            "Epoch: 204 | Batch_idx: 340 |  Loss: (0.0138) | Acc: (99.55%) (43450/43648)\n",
            "Epoch: 204 | Batch_idx: 350 |  Loss: (0.0136) | Acc: (99.55%) (44726/44928)\n",
            "Epoch: 204 | Batch_idx: 360 |  Loss: (0.0136) | Acc: (99.55%) (46001/46208)\n",
            "Epoch: 204 | Batch_idx: 370 |  Loss: (0.0135) | Acc: (99.55%) (47275/47488)\n",
            "Epoch: 204 | Batch_idx: 380 |  Loss: (0.0136) | Acc: (99.54%) (48545/48768)\n",
            "Epoch: 204 | Batch_idx: 390 |  Loss: (0.0137) | Acc: (99.54%) (49771/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3996) | Acc: (91.88%) (9188/10000)\n",
            "Epoch: 205 | Batch_idx: 0 |  Loss: (0.0186) | Acc: (99.22%) (127/128)\n",
            "Epoch: 205 | Batch_idx: 10 |  Loss: (0.0212) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 205 | Batch_idx: 20 |  Loss: (0.0211) | Acc: (99.29%) (2669/2688)\n",
            "Epoch: 205 | Batch_idx: 30 |  Loss: (0.0202) | Acc: (99.37%) (3943/3968)\n",
            "Epoch: 205 | Batch_idx: 40 |  Loss: (0.0189) | Acc: (99.43%) (5218/5248)\n",
            "Epoch: 205 | Batch_idx: 50 |  Loss: (0.0193) | Acc: (99.33%) (6484/6528)\n",
            "Epoch: 205 | Batch_idx: 60 |  Loss: (0.0183) | Acc: (99.39%) (7760/7808)\n",
            "Epoch: 205 | Batch_idx: 70 |  Loss: (0.0182) | Acc: (99.35%) (9029/9088)\n",
            "Epoch: 205 | Batch_idx: 80 |  Loss: (0.0183) | Acc: (99.38%) (10304/10368)\n",
            "Epoch: 205 | Batch_idx: 90 |  Loss: (0.0170) | Acc: (99.42%) (11580/11648)\n",
            "Epoch: 205 | Batch_idx: 100 |  Loss: (0.0163) | Acc: (99.43%) (12854/12928)\n",
            "Epoch: 205 | Batch_idx: 110 |  Loss: (0.0156) | Acc: (99.46%) (14131/14208)\n",
            "Epoch: 205 | Batch_idx: 120 |  Loss: (0.0154) | Acc: (99.46%) (15404/15488)\n",
            "Epoch: 205 | Batch_idx: 130 |  Loss: (0.0146) | Acc: (99.49%) (16682/16768)\n",
            "Epoch: 205 | Batch_idx: 140 |  Loss: (0.0149) | Acc: (99.48%) (17955/18048)\n",
            "Epoch: 205 | Batch_idx: 150 |  Loss: (0.0149) | Acc: (99.49%) (19229/19328)\n",
            "Epoch: 205 | Batch_idx: 160 |  Loss: (0.0147) | Acc: (99.49%) (20503/20608)\n",
            "Epoch: 205 | Batch_idx: 170 |  Loss: (0.0146) | Acc: (99.49%) (21777/21888)\n",
            "Epoch: 205 | Batch_idx: 180 |  Loss: (0.0147) | Acc: (99.49%) (23051/23168)\n",
            "Epoch: 205 | Batch_idx: 190 |  Loss: (0.0144) | Acc: (99.50%) (24326/24448)\n",
            "Epoch: 205 | Batch_idx: 200 |  Loss: (0.0143) | Acc: (99.51%) (25601/25728)\n",
            "Epoch: 205 | Batch_idx: 210 |  Loss: (0.0142) | Acc: (99.51%) (26875/27008)\n",
            "Epoch: 205 | Batch_idx: 220 |  Loss: (0.0140) | Acc: (99.52%) (28152/28288)\n",
            "Epoch: 205 | Batch_idx: 230 |  Loss: (0.0140) | Acc: (99.53%) (29428/29568)\n",
            "Epoch: 205 | Batch_idx: 240 |  Loss: (0.0139) | Acc: (99.52%) (30701/30848)\n",
            "Epoch: 205 | Batch_idx: 250 |  Loss: (0.0139) | Acc: (99.52%) (31974/32128)\n",
            "Epoch: 205 | Batch_idx: 260 |  Loss: (0.0139) | Acc: (99.52%) (33249/33408)\n",
            "Epoch: 205 | Batch_idx: 270 |  Loss: (0.0138) | Acc: (99.52%) (34522/34688)\n",
            "Epoch: 205 | Batch_idx: 280 |  Loss: (0.0136) | Acc: (99.53%) (35798/35968)\n",
            "Epoch: 205 | Batch_idx: 290 |  Loss: (0.0133) | Acc: (99.54%) (37075/37248)\n",
            "Epoch: 205 | Batch_idx: 300 |  Loss: (0.0131) | Acc: (99.54%) (38352/38528)\n",
            "Epoch: 205 | Batch_idx: 310 |  Loss: (0.0132) | Acc: (99.54%) (39624/39808)\n",
            "Epoch: 205 | Batch_idx: 320 |  Loss: (0.0130) | Acc: (99.54%) (40901/41088)\n",
            "Epoch: 205 | Batch_idx: 330 |  Loss: (0.0130) | Acc: (99.55%) (42176/42368)\n",
            "Epoch: 205 | Batch_idx: 340 |  Loss: (0.0131) | Acc: (99.54%) (43449/43648)\n",
            "Epoch: 205 | Batch_idx: 350 |  Loss: (0.0130) | Acc: (99.55%) (44724/44928)\n",
            "Epoch: 205 | Batch_idx: 360 |  Loss: (0.0130) | Acc: (99.54%) (45997/46208)\n",
            "Epoch: 205 | Batch_idx: 370 |  Loss: (0.0129) | Acc: (99.54%) (47271/47488)\n",
            "Epoch: 205 | Batch_idx: 380 |  Loss: (0.0133) | Acc: (99.53%) (48541/48768)\n",
            "Epoch: 205 | Batch_idx: 390 |  Loss: (0.0130) | Acc: (99.55%) (49773/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4002) | Acc: (91.79%) (9179/10000)\n",
            "Epoch: 206 | Batch_idx: 0 |  Loss: (0.0049) | Acc: (100.00%) (128/128)\n",
            "Epoch: 206 | Batch_idx: 10 |  Loss: (0.0090) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 206 | Batch_idx: 20 |  Loss: (0.0105) | Acc: (99.63%) (2678/2688)\n",
            "Epoch: 206 | Batch_idx: 30 |  Loss: (0.0108) | Acc: (99.62%) (3953/3968)\n",
            "Epoch: 206 | Batch_idx: 40 |  Loss: (0.0111) | Acc: (99.62%) (5228/5248)\n",
            "Epoch: 206 | Batch_idx: 50 |  Loss: (0.0137) | Acc: (99.53%) (6497/6528)\n",
            "Epoch: 206 | Batch_idx: 60 |  Loss: (0.0128) | Acc: (99.55%) (7773/7808)\n",
            "Epoch: 206 | Batch_idx: 70 |  Loss: (0.0137) | Acc: (99.56%) (9048/9088)\n",
            "Epoch: 206 | Batch_idx: 80 |  Loss: (0.0133) | Acc: (99.57%) (10323/10368)\n",
            "Epoch: 206 | Batch_idx: 90 |  Loss: (0.0133) | Acc: (99.57%) (11598/11648)\n",
            "Epoch: 206 | Batch_idx: 100 |  Loss: (0.0131) | Acc: (99.57%) (12873/12928)\n",
            "Epoch: 206 | Batch_idx: 110 |  Loss: (0.0139) | Acc: (99.54%) (14142/14208)\n",
            "Epoch: 206 | Batch_idx: 120 |  Loss: (0.0138) | Acc: (99.53%) (15415/15488)\n",
            "Epoch: 206 | Batch_idx: 130 |  Loss: (0.0131) | Acc: (99.55%) (16692/16768)\n",
            "Epoch: 206 | Batch_idx: 140 |  Loss: (0.0131) | Acc: (99.55%) (17967/18048)\n",
            "Epoch: 206 | Batch_idx: 150 |  Loss: (0.0145) | Acc: (99.52%) (19235/19328)\n",
            "Epoch: 206 | Batch_idx: 160 |  Loss: (0.0142) | Acc: (99.52%) (20509/20608)\n",
            "Epoch: 206 | Batch_idx: 170 |  Loss: (0.0140) | Acc: (99.52%) (21782/21888)\n",
            "Epoch: 206 | Batch_idx: 180 |  Loss: (0.0140) | Acc: (99.53%) (23058/23168)\n",
            "Epoch: 206 | Batch_idx: 190 |  Loss: (0.0139) | Acc: (99.53%) (24333/24448)\n",
            "Epoch: 206 | Batch_idx: 200 |  Loss: (0.0137) | Acc: (99.54%) (25610/25728)\n",
            "Epoch: 206 | Batch_idx: 210 |  Loss: (0.0135) | Acc: (99.55%) (26886/27008)\n",
            "Epoch: 206 | Batch_idx: 220 |  Loss: (0.0140) | Acc: (99.54%) (28159/28288)\n",
            "Epoch: 206 | Batch_idx: 230 |  Loss: (0.0136) | Acc: (99.56%) (29438/29568)\n",
            "Epoch: 206 | Batch_idx: 240 |  Loss: (0.0137) | Acc: (99.57%) (30714/30848)\n",
            "Epoch: 206 | Batch_idx: 250 |  Loss: (0.0138) | Acc: (99.57%) (31989/32128)\n",
            "Epoch: 206 | Batch_idx: 260 |  Loss: (0.0143) | Acc: (99.55%) (33259/33408)\n",
            "Epoch: 206 | Batch_idx: 270 |  Loss: (0.0140) | Acc: (99.56%) (34536/34688)\n",
            "Epoch: 206 | Batch_idx: 280 |  Loss: (0.0142) | Acc: (99.56%) (35809/35968)\n",
            "Epoch: 206 | Batch_idx: 290 |  Loss: (0.0140) | Acc: (99.56%) (37084/37248)\n",
            "Epoch: 206 | Batch_idx: 300 |  Loss: (0.0139) | Acc: (99.56%) (38359/38528)\n",
            "Epoch: 206 | Batch_idx: 310 |  Loss: (0.0139) | Acc: (99.56%) (39634/39808)\n",
            "Epoch: 206 | Batch_idx: 320 |  Loss: (0.0139) | Acc: (99.56%) (40909/41088)\n",
            "Epoch: 206 | Batch_idx: 330 |  Loss: (0.0141) | Acc: (99.55%) (42179/42368)\n",
            "Epoch: 206 | Batch_idx: 340 |  Loss: (0.0140) | Acc: (99.56%) (43454/43648)\n",
            "Epoch: 206 | Batch_idx: 350 |  Loss: (0.0140) | Acc: (99.55%) (44728/44928)\n",
            "Epoch: 206 | Batch_idx: 360 |  Loss: (0.0140) | Acc: (99.55%) (46000/46208)\n",
            "Epoch: 206 | Batch_idx: 370 |  Loss: (0.0141) | Acc: (99.55%) (47275/47488)\n",
            "Epoch: 206 | Batch_idx: 380 |  Loss: (0.0141) | Acc: (99.56%) (48551/48768)\n",
            "Epoch: 206 | Batch_idx: 390 |  Loss: (0.0141) | Acc: (99.55%) (49777/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4050) | Acc: (91.63%) (9163/10000)\n",
            "Epoch: 207 | Batch_idx: 0 |  Loss: (0.0658) | Acc: (98.44%) (126/128)\n",
            "Epoch: 207 | Batch_idx: 10 |  Loss: (0.0189) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 207 | Batch_idx: 20 |  Loss: (0.0170) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 207 | Batch_idx: 30 |  Loss: (0.0149) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 207 | Batch_idx: 40 |  Loss: (0.0130) | Acc: (99.47%) (5220/5248)\n",
            "Epoch: 207 | Batch_idx: 50 |  Loss: (0.0121) | Acc: (99.54%) (6498/6528)\n",
            "Epoch: 207 | Batch_idx: 60 |  Loss: (0.0118) | Acc: (99.55%) (7773/7808)\n",
            "Epoch: 207 | Batch_idx: 70 |  Loss: (0.0117) | Acc: (99.56%) (9048/9088)\n",
            "Epoch: 207 | Batch_idx: 80 |  Loss: (0.0113) | Acc: (99.56%) (10322/10368)\n",
            "Epoch: 207 | Batch_idx: 90 |  Loss: (0.0118) | Acc: (99.53%) (11593/11648)\n",
            "Epoch: 207 | Batch_idx: 100 |  Loss: (0.0117) | Acc: (99.54%) (12869/12928)\n",
            "Epoch: 207 | Batch_idx: 110 |  Loss: (0.0120) | Acc: (99.53%) (14141/14208)\n",
            "Epoch: 207 | Batch_idx: 120 |  Loss: (0.0123) | Acc: (99.52%) (15413/15488)\n",
            "Epoch: 207 | Batch_idx: 130 |  Loss: (0.0126) | Acc: (99.52%) (16688/16768)\n",
            "Epoch: 207 | Batch_idx: 140 |  Loss: (0.0124) | Acc: (99.54%) (17965/18048)\n",
            "Epoch: 207 | Batch_idx: 150 |  Loss: (0.0122) | Acc: (99.56%) (19243/19328)\n",
            "Epoch: 207 | Batch_idx: 160 |  Loss: (0.0124) | Acc: (99.55%) (20516/20608)\n",
            "Epoch: 207 | Batch_idx: 170 |  Loss: (0.0125) | Acc: (99.55%) (21789/21888)\n",
            "Epoch: 207 | Batch_idx: 180 |  Loss: (0.0128) | Acc: (99.54%) (23062/23168)\n",
            "Epoch: 207 | Batch_idx: 190 |  Loss: (0.0124) | Acc: (99.55%) (24339/24448)\n",
            "Epoch: 207 | Batch_idx: 200 |  Loss: (0.0122) | Acc: (99.56%) (25616/25728)\n",
            "Epoch: 207 | Batch_idx: 210 |  Loss: (0.0121) | Acc: (99.57%) (26892/27008)\n",
            "Epoch: 207 | Batch_idx: 220 |  Loss: (0.0121) | Acc: (99.57%) (28166/28288)\n",
            "Epoch: 207 | Batch_idx: 230 |  Loss: (0.0122) | Acc: (99.56%) (29438/29568)\n",
            "Epoch: 207 | Batch_idx: 240 |  Loss: (0.0122) | Acc: (99.57%) (30714/30848)\n",
            "Epoch: 207 | Batch_idx: 250 |  Loss: (0.0123) | Acc: (99.55%) (31984/32128)\n",
            "Epoch: 207 | Batch_idx: 260 |  Loss: (0.0122) | Acc: (99.56%) (33261/33408)\n",
            "Epoch: 207 | Batch_idx: 270 |  Loss: (0.0122) | Acc: (99.56%) (34535/34688)\n",
            "Epoch: 207 | Batch_idx: 280 |  Loss: (0.0121) | Acc: (99.57%) (35812/35968)\n",
            "Epoch: 207 | Batch_idx: 290 |  Loss: (0.0120) | Acc: (99.57%) (37089/37248)\n",
            "Epoch: 207 | Batch_idx: 300 |  Loss: (0.0119) | Acc: (99.58%) (38367/38528)\n",
            "Epoch: 207 | Batch_idx: 310 |  Loss: (0.0121) | Acc: (99.58%) (39640/39808)\n",
            "Epoch: 207 | Batch_idx: 320 |  Loss: (0.0121) | Acc: (99.58%) (40917/41088)\n",
            "Epoch: 207 | Batch_idx: 330 |  Loss: (0.0122) | Acc: (99.58%) (42189/42368)\n",
            "Epoch: 207 | Batch_idx: 340 |  Loss: (0.0123) | Acc: (99.57%) (43460/43648)\n",
            "Epoch: 207 | Batch_idx: 350 |  Loss: (0.0127) | Acc: (99.55%) (44728/44928)\n",
            "Epoch: 207 | Batch_idx: 360 |  Loss: (0.0127) | Acc: (99.56%) (46005/46208)\n",
            "Epoch: 207 | Batch_idx: 370 |  Loss: (0.0126) | Acc: (99.56%) (47281/47488)\n",
            "Epoch: 207 | Batch_idx: 380 |  Loss: (0.0127) | Acc: (99.56%) (48553/48768)\n",
            "Epoch: 207 | Batch_idx: 390 |  Loss: (0.0128) | Acc: (99.56%) (49778/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4013) | Acc: (91.82%) (9182/10000)\n",
            "Epoch: 208 | Batch_idx: 0 |  Loss: (0.0219) | Acc: (98.44%) (126/128)\n",
            "Epoch: 208 | Batch_idx: 10 |  Loss: (0.0138) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 208 | Batch_idx: 20 |  Loss: (0.0098) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 208 | Batch_idx: 30 |  Loss: (0.0117) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 208 | Batch_idx: 40 |  Loss: (0.0115) | Acc: (99.54%) (5224/5248)\n",
            "Epoch: 208 | Batch_idx: 50 |  Loss: (0.0130) | Acc: (99.54%) (6498/6528)\n",
            "Epoch: 208 | Batch_idx: 60 |  Loss: (0.0114) | Acc: (99.60%) (7777/7808)\n",
            "Epoch: 208 | Batch_idx: 70 |  Loss: (0.0115) | Acc: (99.60%) (9052/9088)\n",
            "Epoch: 208 | Batch_idx: 80 |  Loss: (0.0111) | Acc: (99.63%) (10330/10368)\n",
            "Epoch: 208 | Batch_idx: 90 |  Loss: (0.0113) | Acc: (99.62%) (11604/11648)\n",
            "Epoch: 208 | Batch_idx: 100 |  Loss: (0.0117) | Acc: (99.61%) (12878/12928)\n",
            "Epoch: 208 | Batch_idx: 110 |  Loss: (0.0120) | Acc: (99.61%) (14152/14208)\n",
            "Epoch: 208 | Batch_idx: 120 |  Loss: (0.0124) | Acc: (99.59%) (15425/15488)\n",
            "Epoch: 208 | Batch_idx: 130 |  Loss: (0.0124) | Acc: (99.59%) (16700/16768)\n",
            "Epoch: 208 | Batch_idx: 140 |  Loss: (0.0122) | Acc: (99.60%) (17976/18048)\n",
            "Epoch: 208 | Batch_idx: 150 |  Loss: (0.0123) | Acc: (99.62%) (19254/19328)\n",
            "Epoch: 208 | Batch_idx: 160 |  Loss: (0.0122) | Acc: (99.61%) (20527/20608)\n",
            "Epoch: 208 | Batch_idx: 170 |  Loss: (0.0121) | Acc: (99.61%) (21802/21888)\n",
            "Epoch: 208 | Batch_idx: 180 |  Loss: (0.0122) | Acc: (99.60%) (23075/23168)\n",
            "Epoch: 208 | Batch_idx: 190 |  Loss: (0.0119) | Acc: (99.60%) (24351/24448)\n",
            "Epoch: 208 | Batch_idx: 200 |  Loss: (0.0117) | Acc: (99.61%) (25627/25728)\n",
            "Epoch: 208 | Batch_idx: 210 |  Loss: (0.0115) | Acc: (99.61%) (26902/27008)\n",
            "Epoch: 208 | Batch_idx: 220 |  Loss: (0.0120) | Acc: (99.59%) (28171/28288)\n",
            "Epoch: 208 | Batch_idx: 230 |  Loss: (0.0118) | Acc: (99.60%) (29449/29568)\n",
            "Epoch: 208 | Batch_idx: 240 |  Loss: (0.0121) | Acc: (99.58%) (30719/30848)\n",
            "Epoch: 208 | Batch_idx: 250 |  Loss: (0.0122) | Acc: (99.58%) (31993/32128)\n",
            "Epoch: 208 | Batch_idx: 260 |  Loss: (0.0124) | Acc: (99.57%) (33265/33408)\n",
            "Epoch: 208 | Batch_idx: 270 |  Loss: (0.0121) | Acc: (99.58%) (34544/34688)\n",
            "Epoch: 208 | Batch_idx: 280 |  Loss: (0.0121) | Acc: (99.59%) (35820/35968)\n",
            "Epoch: 208 | Batch_idx: 290 |  Loss: (0.0122) | Acc: (99.59%) (37094/37248)\n",
            "Epoch: 208 | Batch_idx: 300 |  Loss: (0.0121) | Acc: (99.59%) (38371/38528)\n",
            "Epoch: 208 | Batch_idx: 310 |  Loss: (0.0122) | Acc: (99.59%) (39644/39808)\n",
            "Epoch: 208 | Batch_idx: 320 |  Loss: (0.0121) | Acc: (99.59%) (40920/41088)\n",
            "Epoch: 208 | Batch_idx: 330 |  Loss: (0.0129) | Acc: (99.58%) (42189/42368)\n",
            "Epoch: 208 | Batch_idx: 340 |  Loss: (0.0130) | Acc: (99.57%) (43461/43648)\n",
            "Epoch: 208 | Batch_idx: 350 |  Loss: (0.0130) | Acc: (99.57%) (44736/44928)\n",
            "Epoch: 208 | Batch_idx: 360 |  Loss: (0.0130) | Acc: (99.57%) (46010/46208)\n",
            "Epoch: 208 | Batch_idx: 370 |  Loss: (0.0130) | Acc: (99.57%) (47284/47488)\n",
            "Epoch: 208 | Batch_idx: 380 |  Loss: (0.0129) | Acc: (99.57%) (48560/48768)\n",
            "Epoch: 208 | Batch_idx: 390 |  Loss: (0.0130) | Acc: (99.57%) (49785/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4039) | Acc: (91.73%) (9173/10000)\n",
            "Epoch: 209 | Batch_idx: 0 |  Loss: (0.0147) | Acc: (99.22%) (127/128)\n",
            "Epoch: 209 | Batch_idx: 10 |  Loss: (0.0065) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 209 | Batch_idx: 20 |  Loss: (0.0092) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 209 | Batch_idx: 30 |  Loss: (0.0079) | Acc: (99.67%) (3955/3968)\n",
            "Epoch: 209 | Batch_idx: 40 |  Loss: (0.0106) | Acc: (99.58%) (5226/5248)\n",
            "Epoch: 209 | Batch_idx: 50 |  Loss: (0.0114) | Acc: (99.56%) (6499/6528)\n",
            "Epoch: 209 | Batch_idx: 60 |  Loss: (0.0109) | Acc: (99.58%) (7775/7808)\n",
            "Epoch: 209 | Batch_idx: 70 |  Loss: (0.0105) | Acc: (99.60%) (9052/9088)\n",
            "Epoch: 209 | Batch_idx: 80 |  Loss: (0.0102) | Acc: (99.61%) (10328/10368)\n",
            "Epoch: 209 | Batch_idx: 90 |  Loss: (0.0119) | Acc: (99.58%) (11599/11648)\n",
            "Epoch: 209 | Batch_idx: 100 |  Loss: (0.0126) | Acc: (99.59%) (12875/12928)\n",
            "Epoch: 209 | Batch_idx: 110 |  Loss: (0.0125) | Acc: (99.59%) (14150/14208)\n",
            "Epoch: 209 | Batch_idx: 120 |  Loss: (0.0125) | Acc: (99.59%) (15424/15488)\n",
            "Epoch: 209 | Batch_idx: 130 |  Loss: (0.0132) | Acc: (99.58%) (16698/16768)\n",
            "Epoch: 209 | Batch_idx: 140 |  Loss: (0.0128) | Acc: (99.59%) (17974/18048)\n",
            "Epoch: 209 | Batch_idx: 150 |  Loss: (0.0129) | Acc: (99.60%) (19251/19328)\n",
            "Epoch: 209 | Batch_idx: 160 |  Loss: (0.0126) | Acc: (99.61%) (20528/20608)\n",
            "Epoch: 209 | Batch_idx: 170 |  Loss: (0.0125) | Acc: (99.61%) (21802/21888)\n",
            "Epoch: 209 | Batch_idx: 180 |  Loss: (0.0129) | Acc: (99.59%) (23073/23168)\n",
            "Epoch: 209 | Batch_idx: 190 |  Loss: (0.0128) | Acc: (99.59%) (24348/24448)\n",
            "Epoch: 209 | Batch_idx: 200 |  Loss: (0.0126) | Acc: (99.60%) (25625/25728)\n",
            "Epoch: 209 | Batch_idx: 210 |  Loss: (0.0127) | Acc: (99.60%) (26900/27008)\n",
            "Epoch: 209 | Batch_idx: 220 |  Loss: (0.0127) | Acc: (99.60%) (28174/28288)\n",
            "Epoch: 209 | Batch_idx: 230 |  Loss: (0.0124) | Acc: (99.60%) (29451/29568)\n",
            "Epoch: 209 | Batch_idx: 240 |  Loss: (0.0125) | Acc: (99.60%) (30725/30848)\n",
            "Epoch: 209 | Batch_idx: 250 |  Loss: (0.0124) | Acc: (99.60%) (32000/32128)\n",
            "Epoch: 209 | Batch_idx: 260 |  Loss: (0.0125) | Acc: (99.60%) (33275/33408)\n",
            "Epoch: 209 | Batch_idx: 270 |  Loss: (0.0124) | Acc: (99.60%) (34549/34688)\n",
            "Epoch: 209 | Batch_idx: 280 |  Loss: (0.0126) | Acc: (99.59%) (35822/35968)\n",
            "Epoch: 209 | Batch_idx: 290 |  Loss: (0.0125) | Acc: (99.59%) (37097/37248)\n",
            "Epoch: 209 | Batch_idx: 300 |  Loss: (0.0126) | Acc: (99.59%) (38371/38528)\n",
            "Epoch: 209 | Batch_idx: 310 |  Loss: (0.0124) | Acc: (99.60%) (39650/39808)\n",
            "Epoch: 209 | Batch_idx: 320 |  Loss: (0.0126) | Acc: (99.59%) (40921/41088)\n",
            "Epoch: 209 | Batch_idx: 330 |  Loss: (0.0126) | Acc: (99.59%) (42194/42368)\n",
            "Epoch: 209 | Batch_idx: 340 |  Loss: (0.0125) | Acc: (99.59%) (43470/43648)\n",
            "Epoch: 209 | Batch_idx: 350 |  Loss: (0.0124) | Acc: (99.59%) (44746/44928)\n",
            "Epoch: 209 | Batch_idx: 360 |  Loss: (0.0126) | Acc: (99.59%) (46018/46208)\n",
            "Epoch: 209 | Batch_idx: 370 |  Loss: (0.0125) | Acc: (99.59%) (47292/47488)\n",
            "Epoch: 209 | Batch_idx: 380 |  Loss: (0.0125) | Acc: (99.59%) (48567/48768)\n",
            "Epoch: 209 | Batch_idx: 390 |  Loss: (0.0127) | Acc: (99.58%) (49788/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4036) | Acc: (91.77%) (9177/10000)\n",
            "Epoch: 210 | Batch_idx: 0 |  Loss: (0.0017) | Acc: (100.00%) (128/128)\n",
            "Epoch: 210 | Batch_idx: 10 |  Loss: (0.0149) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 210 | Batch_idx: 20 |  Loss: (0.0154) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 210 | Batch_idx: 30 |  Loss: (0.0152) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 210 | Batch_idx: 40 |  Loss: (0.0144) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 210 | Batch_idx: 50 |  Loss: (0.0129) | Acc: (99.53%) (6497/6528)\n",
            "Epoch: 210 | Batch_idx: 60 |  Loss: (0.0132) | Acc: (99.53%) (7771/7808)\n",
            "Epoch: 210 | Batch_idx: 70 |  Loss: (0.0147) | Acc: (99.49%) (9042/9088)\n",
            "Epoch: 210 | Batch_idx: 80 |  Loss: (0.0146) | Acc: (99.47%) (10313/10368)\n",
            "Epoch: 210 | Batch_idx: 90 |  Loss: (0.0155) | Acc: (99.44%) (11583/11648)\n",
            "Epoch: 210 | Batch_idx: 100 |  Loss: (0.0159) | Acc: (99.45%) (12857/12928)\n",
            "Epoch: 210 | Batch_idx: 110 |  Loss: (0.0149) | Acc: (99.49%) (14136/14208)\n",
            "Epoch: 210 | Batch_idx: 120 |  Loss: (0.0141) | Acc: (99.52%) (15413/15488)\n",
            "Epoch: 210 | Batch_idx: 130 |  Loss: (0.0136) | Acc: (99.53%) (16690/16768)\n",
            "Epoch: 210 | Batch_idx: 140 |  Loss: (0.0134) | Acc: (99.55%) (17966/18048)\n",
            "Epoch: 210 | Batch_idx: 150 |  Loss: (0.0140) | Acc: (99.53%) (19238/19328)\n",
            "Epoch: 210 | Batch_idx: 160 |  Loss: (0.0141) | Acc: (99.54%) (20513/20608)\n",
            "Epoch: 210 | Batch_idx: 170 |  Loss: (0.0140) | Acc: (99.55%) (21789/21888)\n",
            "Epoch: 210 | Batch_idx: 180 |  Loss: (0.0137) | Acc: (99.55%) (23064/23168)\n",
            "Epoch: 210 | Batch_idx: 190 |  Loss: (0.0134) | Acc: (99.56%) (24341/24448)\n",
            "Epoch: 210 | Batch_idx: 200 |  Loss: (0.0133) | Acc: (99.57%) (25617/25728)\n",
            "Epoch: 210 | Batch_idx: 210 |  Loss: (0.0133) | Acc: (99.56%) (26889/27008)\n",
            "Epoch: 210 | Batch_idx: 220 |  Loss: (0.0133) | Acc: (99.56%) (28164/28288)\n",
            "Epoch: 210 | Batch_idx: 230 |  Loss: (0.0136) | Acc: (99.55%) (29436/29568)\n",
            "Epoch: 210 | Batch_idx: 240 |  Loss: (0.0135) | Acc: (99.56%) (30712/30848)\n",
            "Epoch: 210 | Batch_idx: 250 |  Loss: (0.0136) | Acc: (99.55%) (31983/32128)\n",
            "Epoch: 210 | Batch_idx: 260 |  Loss: (0.0135) | Acc: (99.55%) (33257/33408)\n",
            "Epoch: 210 | Batch_idx: 270 |  Loss: (0.0135) | Acc: (99.55%) (34532/34688)\n",
            "Epoch: 210 | Batch_idx: 280 |  Loss: (0.0136) | Acc: (99.54%) (35803/35968)\n",
            "Epoch: 210 | Batch_idx: 290 |  Loss: (0.0138) | Acc: (99.54%) (37078/37248)\n",
            "Epoch: 210 | Batch_idx: 300 |  Loss: (0.0140) | Acc: (99.53%) (38347/38528)\n",
            "Epoch: 210 | Batch_idx: 310 |  Loss: (0.0141) | Acc: (99.53%) (39620/39808)\n",
            "Epoch: 210 | Batch_idx: 320 |  Loss: (0.0140) | Acc: (99.53%) (40894/41088)\n",
            "Epoch: 210 | Batch_idx: 330 |  Loss: (0.0142) | Acc: (99.52%) (42166/42368)\n",
            "Epoch: 210 | Batch_idx: 340 |  Loss: (0.0142) | Acc: (99.53%) (43442/43648)\n",
            "Epoch: 210 | Batch_idx: 350 |  Loss: (0.0141) | Acc: (99.53%) (44717/44928)\n",
            "Epoch: 210 | Batch_idx: 360 |  Loss: (0.0141) | Acc: (99.53%) (45993/46208)\n",
            "Epoch: 210 | Batch_idx: 370 |  Loss: (0.0142) | Acc: (99.53%) (47263/47488)\n",
            "Epoch: 210 | Batch_idx: 380 |  Loss: (0.0143) | Acc: (99.52%) (48535/48768)\n",
            "Epoch: 210 | Batch_idx: 390 |  Loss: (0.0145) | Acc: (99.51%) (49754/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4028) | Acc: (91.77%) (9177/10000)\n",
            "Epoch: 211 | Batch_idx: 0 |  Loss: (0.0041) | Acc: (100.00%) (128/128)\n",
            "Epoch: 211 | Batch_idx: 10 |  Loss: (0.0080) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 211 | Batch_idx: 20 |  Loss: (0.0115) | Acc: (99.70%) (2680/2688)\n",
            "Epoch: 211 | Batch_idx: 30 |  Loss: (0.0133) | Acc: (99.62%) (3953/3968)\n",
            "Epoch: 211 | Batch_idx: 40 |  Loss: (0.0128) | Acc: (99.64%) (5229/5248)\n",
            "Epoch: 211 | Batch_idx: 50 |  Loss: (0.0134) | Acc: (99.59%) (6501/6528)\n",
            "Epoch: 211 | Batch_idx: 60 |  Loss: (0.0136) | Acc: (99.58%) (7775/7808)\n",
            "Epoch: 211 | Batch_idx: 70 |  Loss: (0.0134) | Acc: (99.59%) (9051/9088)\n",
            "Epoch: 211 | Batch_idx: 80 |  Loss: (0.0139) | Acc: (99.58%) (10324/10368)\n",
            "Epoch: 211 | Batch_idx: 90 |  Loss: (0.0142) | Acc: (99.59%) (11600/11648)\n",
            "Epoch: 211 | Batch_idx: 100 |  Loss: (0.0140) | Acc: (99.58%) (12874/12928)\n",
            "Epoch: 211 | Batch_idx: 110 |  Loss: (0.0142) | Acc: (99.57%) (14147/14208)\n",
            "Epoch: 211 | Batch_idx: 120 |  Loss: (0.0136) | Acc: (99.59%) (15425/15488)\n",
            "Epoch: 211 | Batch_idx: 130 |  Loss: (0.0130) | Acc: (99.61%) (16702/16768)\n",
            "Epoch: 211 | Batch_idx: 140 |  Loss: (0.0124) | Acc: (99.62%) (17980/18048)\n",
            "Epoch: 211 | Batch_idx: 150 |  Loss: (0.0120) | Acc: (99.64%) (19259/19328)\n",
            "Epoch: 211 | Batch_idx: 160 |  Loss: (0.0118) | Acc: (99.65%) (20535/20608)\n",
            "Epoch: 211 | Batch_idx: 170 |  Loss: (0.0118) | Acc: (99.64%) (21809/21888)\n",
            "Epoch: 211 | Batch_idx: 180 |  Loss: (0.0115) | Acc: (99.65%) (23086/23168)\n",
            "Epoch: 211 | Batch_idx: 190 |  Loss: (0.0116) | Acc: (99.64%) (24360/24448)\n",
            "Epoch: 211 | Batch_idx: 200 |  Loss: (0.0116) | Acc: (99.63%) (25634/25728)\n",
            "Epoch: 211 | Batch_idx: 210 |  Loss: (0.0118) | Acc: (99.64%) (26910/27008)\n",
            "Epoch: 211 | Batch_idx: 220 |  Loss: (0.0122) | Acc: (99.61%) (28178/28288)\n",
            "Epoch: 211 | Batch_idx: 230 |  Loss: (0.0120) | Acc: (99.62%) (29455/29568)\n",
            "Epoch: 211 | Batch_idx: 240 |  Loss: (0.0122) | Acc: (99.60%) (30725/30848)\n",
            "Epoch: 211 | Batch_idx: 250 |  Loss: (0.0122) | Acc: (99.60%) (32000/32128)\n",
            "Epoch: 211 | Batch_idx: 260 |  Loss: (0.0125) | Acc: (99.60%) (33274/33408)\n",
            "Epoch: 211 | Batch_idx: 270 |  Loss: (0.0127) | Acc: (99.58%) (34544/34688)\n",
            "Epoch: 211 | Batch_idx: 280 |  Loss: (0.0125) | Acc: (99.59%) (35822/35968)\n",
            "Epoch: 211 | Batch_idx: 290 |  Loss: (0.0125) | Acc: (99.59%) (37095/37248)\n",
            "Epoch: 211 | Batch_idx: 300 |  Loss: (0.0124) | Acc: (99.60%) (38372/38528)\n",
            "Epoch: 211 | Batch_idx: 310 |  Loss: (0.0125) | Acc: (99.59%) (39646/39808)\n",
            "Epoch: 211 | Batch_idx: 320 |  Loss: (0.0123) | Acc: (99.60%) (40922/41088)\n",
            "Epoch: 211 | Batch_idx: 330 |  Loss: (0.0124) | Acc: (99.59%) (42196/42368)\n",
            "Epoch: 211 | Batch_idx: 340 |  Loss: (0.0124) | Acc: (99.60%) (43472/43648)\n",
            "Epoch: 211 | Batch_idx: 350 |  Loss: (0.0123) | Acc: (99.60%) (44750/44928)\n",
            "Epoch: 211 | Batch_idx: 360 |  Loss: (0.0123) | Acc: (99.60%) (46025/46208)\n",
            "Epoch: 211 | Batch_idx: 370 |  Loss: (0.0122) | Acc: (99.61%) (47303/47488)\n",
            "Epoch: 211 | Batch_idx: 380 |  Loss: (0.0122) | Acc: (99.61%) (48578/48768)\n",
            "Epoch: 211 | Batch_idx: 390 |  Loss: (0.0122) | Acc: (99.61%) (49806/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4013) | Acc: (91.90%) (9190/10000)\n",
            "Epoch: 212 | Batch_idx: 0 |  Loss: (0.0028) | Acc: (100.00%) (128/128)\n",
            "Epoch: 212 | Batch_idx: 10 |  Loss: (0.0218) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 212 | Batch_idx: 20 |  Loss: (0.0175) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 212 | Batch_idx: 30 |  Loss: (0.0155) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 212 | Batch_idx: 40 |  Loss: (0.0176) | Acc: (99.47%) (5220/5248)\n",
            "Epoch: 212 | Batch_idx: 50 |  Loss: (0.0155) | Acc: (99.51%) (6496/6528)\n",
            "Epoch: 212 | Batch_idx: 60 |  Loss: (0.0158) | Acc: (99.53%) (7771/7808)\n",
            "Epoch: 212 | Batch_idx: 70 |  Loss: (0.0149) | Acc: (99.56%) (9048/9088)\n",
            "Epoch: 212 | Batch_idx: 80 |  Loss: (0.0147) | Acc: (99.57%) (10323/10368)\n",
            "Epoch: 212 | Batch_idx: 90 |  Loss: (0.0149) | Acc: (99.56%) (11597/11648)\n",
            "Epoch: 212 | Batch_idx: 100 |  Loss: (0.0149) | Acc: (99.54%) (12868/12928)\n",
            "Epoch: 212 | Batch_idx: 110 |  Loss: (0.0157) | Acc: (99.51%) (14139/14208)\n",
            "Epoch: 212 | Batch_idx: 120 |  Loss: (0.0152) | Acc: (99.53%) (15415/15488)\n",
            "Epoch: 212 | Batch_idx: 130 |  Loss: (0.0148) | Acc: (99.53%) (16689/16768)\n",
            "Epoch: 212 | Batch_idx: 140 |  Loss: (0.0144) | Acc: (99.54%) (17965/18048)\n",
            "Epoch: 212 | Batch_idx: 150 |  Loss: (0.0144) | Acc: (99.54%) (19240/19328)\n",
            "Epoch: 212 | Batch_idx: 160 |  Loss: (0.0143) | Acc: (99.54%) (20514/20608)\n",
            "Epoch: 212 | Batch_idx: 170 |  Loss: (0.0147) | Acc: (99.53%) (21786/21888)\n",
            "Epoch: 212 | Batch_idx: 180 |  Loss: (0.0144) | Acc: (99.54%) (23062/23168)\n",
            "Epoch: 212 | Batch_idx: 190 |  Loss: (0.0145) | Acc: (99.54%) (24336/24448)\n",
            "Epoch: 212 | Batch_idx: 200 |  Loss: (0.0144) | Acc: (99.55%) (25611/25728)\n",
            "Epoch: 212 | Batch_idx: 210 |  Loss: (0.0144) | Acc: (99.53%) (26882/27008)\n",
            "Epoch: 212 | Batch_idx: 220 |  Loss: (0.0144) | Acc: (99.53%) (28154/28288)\n",
            "Epoch: 212 | Batch_idx: 230 |  Loss: (0.0143) | Acc: (99.53%) (29429/29568)\n",
            "Epoch: 212 | Batch_idx: 240 |  Loss: (0.0144) | Acc: (99.53%) (30703/30848)\n",
            "Epoch: 212 | Batch_idx: 250 |  Loss: (0.0142) | Acc: (99.53%) (31977/32128)\n",
            "Epoch: 212 | Batch_idx: 260 |  Loss: (0.0142) | Acc: (99.52%) (33249/33408)\n",
            "Epoch: 212 | Batch_idx: 270 |  Loss: (0.0145) | Acc: (99.52%) (34523/34688)\n",
            "Epoch: 212 | Batch_idx: 280 |  Loss: (0.0143) | Acc: (99.53%) (35799/35968)\n",
            "Epoch: 212 | Batch_idx: 290 |  Loss: (0.0141) | Acc: (99.54%) (37076/37248)\n",
            "Epoch: 212 | Batch_idx: 300 |  Loss: (0.0143) | Acc: (99.53%) (38346/38528)\n",
            "Epoch: 212 | Batch_idx: 310 |  Loss: (0.0142) | Acc: (99.53%) (39620/39808)\n",
            "Epoch: 212 | Batch_idx: 320 |  Loss: (0.0142) | Acc: (99.54%) (40897/41088)\n",
            "Epoch: 212 | Batch_idx: 330 |  Loss: (0.0141) | Acc: (99.54%) (42174/42368)\n",
            "Epoch: 212 | Batch_idx: 340 |  Loss: (0.0140) | Acc: (99.54%) (43449/43648)\n",
            "Epoch: 212 | Batch_idx: 350 |  Loss: (0.0139) | Acc: (99.55%) (44724/44928)\n",
            "Epoch: 212 | Batch_idx: 360 |  Loss: (0.0139) | Acc: (99.55%) (45998/46208)\n",
            "Epoch: 212 | Batch_idx: 370 |  Loss: (0.0137) | Acc: (99.55%) (47276/47488)\n",
            "Epoch: 212 | Batch_idx: 380 |  Loss: (0.0138) | Acc: (99.55%) (48547/48768)\n",
            "Epoch: 212 | Batch_idx: 390 |  Loss: (0.0138) | Acc: (99.55%) (49773/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4028) | Acc: (91.79%) (9179/10000)\n",
            "Epoch: 213 | Batch_idx: 0 |  Loss: (0.0024) | Acc: (100.00%) (128/128)\n",
            "Epoch: 213 | Batch_idx: 10 |  Loss: (0.0062) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 213 | Batch_idx: 20 |  Loss: (0.0076) | Acc: (99.81%) (2683/2688)\n",
            "Epoch: 213 | Batch_idx: 30 |  Loss: (0.0104) | Acc: (99.72%) (3957/3968)\n",
            "Epoch: 213 | Batch_idx: 40 |  Loss: (0.0115) | Acc: (99.62%) (5228/5248)\n",
            "Epoch: 213 | Batch_idx: 50 |  Loss: (0.0111) | Acc: (99.60%) (6502/6528)\n",
            "Epoch: 213 | Batch_idx: 60 |  Loss: (0.0141) | Acc: (99.49%) (7768/7808)\n",
            "Epoch: 213 | Batch_idx: 70 |  Loss: (0.0145) | Acc: (99.48%) (9041/9088)\n",
            "Epoch: 213 | Batch_idx: 80 |  Loss: (0.0141) | Acc: (99.51%) (10317/10368)\n",
            "Epoch: 213 | Batch_idx: 90 |  Loss: (0.0139) | Acc: (99.53%) (11593/11648)\n",
            "Epoch: 213 | Batch_idx: 100 |  Loss: (0.0138) | Acc: (99.51%) (12865/12928)\n",
            "Epoch: 213 | Batch_idx: 110 |  Loss: (0.0138) | Acc: (99.52%) (14140/14208)\n",
            "Epoch: 213 | Batch_idx: 120 |  Loss: (0.0136) | Acc: (99.53%) (15415/15488)\n",
            "Epoch: 213 | Batch_idx: 130 |  Loss: (0.0140) | Acc: (99.49%) (16683/16768)\n",
            "Epoch: 213 | Batch_idx: 140 |  Loss: (0.0135) | Acc: (99.51%) (17960/18048)\n",
            "Epoch: 213 | Batch_idx: 150 |  Loss: (0.0132) | Acc: (99.52%) (19236/19328)\n",
            "Epoch: 213 | Batch_idx: 160 |  Loss: (0.0131) | Acc: (99.53%) (20512/20608)\n",
            "Epoch: 213 | Batch_idx: 170 |  Loss: (0.0132) | Acc: (99.54%) (21787/21888)\n",
            "Epoch: 213 | Batch_idx: 180 |  Loss: (0.0135) | Acc: (99.53%) (23058/23168)\n",
            "Epoch: 213 | Batch_idx: 190 |  Loss: (0.0142) | Acc: (99.51%) (24327/24448)\n",
            "Epoch: 213 | Batch_idx: 200 |  Loss: (0.0138) | Acc: (99.51%) (25603/25728)\n",
            "Epoch: 213 | Batch_idx: 210 |  Loss: (0.0136) | Acc: (99.53%) (26881/27008)\n",
            "Epoch: 213 | Batch_idx: 220 |  Loss: (0.0137) | Acc: (99.52%) (28152/28288)\n",
            "Epoch: 213 | Batch_idx: 230 |  Loss: (0.0138) | Acc: (99.51%) (29423/29568)\n",
            "Epoch: 213 | Batch_idx: 240 |  Loss: (0.0137) | Acc: (99.51%) (30697/30848)\n",
            "Epoch: 213 | Batch_idx: 250 |  Loss: (0.0136) | Acc: (99.51%) (31972/32128)\n",
            "Epoch: 213 | Batch_idx: 260 |  Loss: (0.0134) | Acc: (99.52%) (33247/33408)\n",
            "Epoch: 213 | Batch_idx: 270 |  Loss: (0.0134) | Acc: (99.52%) (34523/34688)\n",
            "Epoch: 213 | Batch_idx: 280 |  Loss: (0.0134) | Acc: (99.52%) (35794/35968)\n",
            "Epoch: 213 | Batch_idx: 290 |  Loss: (0.0134) | Acc: (99.52%) (37071/37248)\n",
            "Epoch: 213 | Batch_idx: 300 |  Loss: (0.0132) | Acc: (99.53%) (38346/38528)\n",
            "Epoch: 213 | Batch_idx: 310 |  Loss: (0.0132) | Acc: (99.53%) (39621/39808)\n",
            "Epoch: 213 | Batch_idx: 320 |  Loss: (0.0132) | Acc: (99.54%) (40898/41088)\n",
            "Epoch: 213 | Batch_idx: 330 |  Loss: (0.0131) | Acc: (99.54%) (42173/42368)\n",
            "Epoch: 213 | Batch_idx: 340 |  Loss: (0.0135) | Acc: (99.53%) (43442/43648)\n",
            "Epoch: 213 | Batch_idx: 350 |  Loss: (0.0137) | Acc: (99.53%) (44715/44928)\n",
            "Epoch: 213 | Batch_idx: 360 |  Loss: (0.0139) | Acc: (99.52%) (45987/46208)\n",
            "Epoch: 213 | Batch_idx: 370 |  Loss: (0.0137) | Acc: (99.53%) (47265/47488)\n",
            "Epoch: 213 | Batch_idx: 380 |  Loss: (0.0137) | Acc: (99.53%) (48541/48768)\n",
            "Epoch: 213 | Batch_idx: 390 |  Loss: (0.0136) | Acc: (99.54%) (49769/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3994) | Acc: (91.94%) (9194/10000)\n",
            "Epoch: 214 | Batch_idx: 0 |  Loss: (0.0368) | Acc: (98.44%) (126/128)\n",
            "Epoch: 214 | Batch_idx: 10 |  Loss: (0.0158) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 214 | Batch_idx: 20 |  Loss: (0.0193) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 214 | Batch_idx: 30 |  Loss: (0.0179) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 214 | Batch_idx: 40 |  Loss: (0.0155) | Acc: (99.49%) (5221/5248)\n",
            "Epoch: 214 | Batch_idx: 50 |  Loss: (0.0153) | Acc: (99.51%) (6496/6528)\n",
            "Epoch: 214 | Batch_idx: 60 |  Loss: (0.0154) | Acc: (99.50%) (7769/7808)\n",
            "Epoch: 214 | Batch_idx: 70 |  Loss: (0.0147) | Acc: (99.53%) (9045/9088)\n",
            "Epoch: 214 | Batch_idx: 80 |  Loss: (0.0148) | Acc: (99.51%) (10317/10368)\n",
            "Epoch: 214 | Batch_idx: 90 |  Loss: (0.0143) | Acc: (99.52%) (11592/11648)\n",
            "Epoch: 214 | Batch_idx: 100 |  Loss: (0.0148) | Acc: (99.52%) (12866/12928)\n",
            "Epoch: 214 | Batch_idx: 110 |  Loss: (0.0149) | Acc: (99.51%) (14139/14208)\n",
            "Epoch: 214 | Batch_idx: 120 |  Loss: (0.0148) | Acc: (99.49%) (15409/15488)\n",
            "Epoch: 214 | Batch_idx: 130 |  Loss: (0.0150) | Acc: (99.48%) (16681/16768)\n",
            "Epoch: 214 | Batch_idx: 140 |  Loss: (0.0151) | Acc: (99.48%) (17955/18048)\n",
            "Epoch: 214 | Batch_idx: 150 |  Loss: (0.0148) | Acc: (99.48%) (19228/19328)\n",
            "Epoch: 214 | Batch_idx: 160 |  Loss: (0.0146) | Acc: (99.49%) (20502/20608)\n",
            "Epoch: 214 | Batch_idx: 170 |  Loss: (0.0142) | Acc: (99.51%) (21780/21888)\n",
            "Epoch: 214 | Batch_idx: 180 |  Loss: (0.0138) | Acc: (99.52%) (23056/23168)\n",
            "Epoch: 214 | Batch_idx: 190 |  Loss: (0.0146) | Acc: (99.49%) (24324/24448)\n",
            "Epoch: 214 | Batch_idx: 200 |  Loss: (0.0145) | Acc: (99.50%) (25599/25728)\n",
            "Epoch: 214 | Batch_idx: 210 |  Loss: (0.0147) | Acc: (99.49%) (26870/27008)\n",
            "Epoch: 214 | Batch_idx: 220 |  Loss: (0.0145) | Acc: (99.49%) (28143/28288)\n",
            "Epoch: 214 | Batch_idx: 230 |  Loss: (0.0144) | Acc: (99.49%) (29418/29568)\n",
            "Epoch: 214 | Batch_idx: 240 |  Loss: (0.0144) | Acc: (99.50%) (30693/30848)\n",
            "Epoch: 214 | Batch_idx: 250 |  Loss: (0.0141) | Acc: (99.51%) (31969/32128)\n",
            "Epoch: 214 | Batch_idx: 260 |  Loss: (0.0140) | Acc: (99.51%) (33243/33408)\n",
            "Epoch: 214 | Batch_idx: 270 |  Loss: (0.0143) | Acc: (99.49%) (34511/34688)\n",
            "Epoch: 214 | Batch_idx: 280 |  Loss: (0.0142) | Acc: (99.49%) (35786/35968)\n",
            "Epoch: 214 | Batch_idx: 290 |  Loss: (0.0141) | Acc: (99.50%) (37060/37248)\n",
            "Epoch: 214 | Batch_idx: 300 |  Loss: (0.0141) | Acc: (99.50%) (38335/38528)\n",
            "Epoch: 214 | Batch_idx: 310 |  Loss: (0.0141) | Acc: (99.50%) (39610/39808)\n",
            "Epoch: 214 | Batch_idx: 320 |  Loss: (0.0140) | Acc: (99.50%) (40884/41088)\n",
            "Epoch: 214 | Batch_idx: 330 |  Loss: (0.0139) | Acc: (99.50%) (42158/42368)\n",
            "Epoch: 214 | Batch_idx: 340 |  Loss: (0.0139) | Acc: (99.51%) (43434/43648)\n",
            "Epoch: 214 | Batch_idx: 350 |  Loss: (0.0137) | Acc: (99.52%) (44713/44928)\n",
            "Epoch: 214 | Batch_idx: 360 |  Loss: (0.0136) | Acc: (99.52%) (45988/46208)\n",
            "Epoch: 214 | Batch_idx: 370 |  Loss: (0.0136) | Acc: (99.52%) (47261/47488)\n",
            "Epoch: 214 | Batch_idx: 380 |  Loss: (0.0136) | Acc: (99.52%) (48534/48768)\n",
            "Epoch: 214 | Batch_idx: 390 |  Loss: (0.0136) | Acc: (99.52%) (49759/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4021) | Acc: (91.75%) (9175/10000)\n",
            "Epoch: 215 | Batch_idx: 0 |  Loss: (0.0036) | Acc: (100.00%) (128/128)\n",
            "Epoch: 215 | Batch_idx: 10 |  Loss: (0.0159) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 215 | Batch_idx: 20 |  Loss: (0.0176) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 215 | Batch_idx: 30 |  Loss: (0.0145) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 215 | Batch_idx: 40 |  Loss: (0.0134) | Acc: (99.54%) (5224/5248)\n",
            "Epoch: 215 | Batch_idx: 50 |  Loss: (0.0141) | Acc: (99.51%) (6496/6528)\n",
            "Epoch: 215 | Batch_idx: 60 |  Loss: (0.0131) | Acc: (99.55%) (7773/7808)\n",
            "Epoch: 215 | Batch_idx: 70 |  Loss: (0.0145) | Acc: (99.53%) (9045/9088)\n",
            "Epoch: 215 | Batch_idx: 80 |  Loss: (0.0149) | Acc: (99.54%) (10320/10368)\n",
            "Epoch: 215 | Batch_idx: 90 |  Loss: (0.0145) | Acc: (99.54%) (11595/11648)\n",
            "Epoch: 215 | Batch_idx: 100 |  Loss: (0.0136) | Acc: (99.57%) (12872/12928)\n",
            "Epoch: 215 | Batch_idx: 110 |  Loss: (0.0132) | Acc: (99.58%) (14148/14208)\n",
            "Epoch: 215 | Batch_idx: 120 |  Loss: (0.0127) | Acc: (99.59%) (15425/15488)\n",
            "Epoch: 215 | Batch_idx: 130 |  Loss: (0.0127) | Acc: (99.59%) (16700/16768)\n",
            "Epoch: 215 | Batch_idx: 140 |  Loss: (0.0125) | Acc: (99.60%) (17975/18048)\n",
            "Epoch: 215 | Batch_idx: 150 |  Loss: (0.0126) | Acc: (99.59%) (19248/19328)\n",
            "Epoch: 215 | Batch_idx: 160 |  Loss: (0.0128) | Acc: (99.58%) (20521/20608)\n",
            "Epoch: 215 | Batch_idx: 170 |  Loss: (0.0126) | Acc: (99.58%) (21797/21888)\n",
            "Epoch: 215 | Batch_idx: 180 |  Loss: (0.0123) | Acc: (99.59%) (23073/23168)\n",
            "Epoch: 215 | Batch_idx: 190 |  Loss: (0.0121) | Acc: (99.59%) (24348/24448)\n",
            "Epoch: 215 | Batch_idx: 200 |  Loss: (0.0121) | Acc: (99.60%) (25624/25728)\n",
            "Epoch: 215 | Batch_idx: 210 |  Loss: (0.0120) | Acc: (99.60%) (26900/27008)\n",
            "Epoch: 215 | Batch_idx: 220 |  Loss: (0.0123) | Acc: (99.60%) (28174/28288)\n",
            "Epoch: 215 | Batch_idx: 230 |  Loss: (0.0124) | Acc: (99.59%) (29447/29568)\n",
            "Epoch: 215 | Batch_idx: 240 |  Loss: (0.0130) | Acc: (99.57%) (30716/30848)\n",
            "Epoch: 215 | Batch_idx: 250 |  Loss: (0.0134) | Acc: (99.57%) (31989/32128)\n",
            "Epoch: 215 | Batch_idx: 260 |  Loss: (0.0133) | Acc: (99.57%) (33263/33408)\n",
            "Epoch: 215 | Batch_idx: 270 |  Loss: (0.0136) | Acc: (99.55%) (34533/34688)\n",
            "Epoch: 215 | Batch_idx: 280 |  Loss: (0.0135) | Acc: (99.55%) (35807/35968)\n",
            "Epoch: 215 | Batch_idx: 290 |  Loss: (0.0136) | Acc: (99.55%) (37080/37248)\n",
            "Epoch: 215 | Batch_idx: 300 |  Loss: (0.0134) | Acc: (99.56%) (38358/38528)\n",
            "Epoch: 215 | Batch_idx: 310 |  Loss: (0.0132) | Acc: (99.57%) (39635/39808)\n",
            "Epoch: 215 | Batch_idx: 320 |  Loss: (0.0132) | Acc: (99.56%) (40908/41088)\n",
            "Epoch: 215 | Batch_idx: 330 |  Loss: (0.0136) | Acc: (99.55%) (42176/42368)\n",
            "Epoch: 215 | Batch_idx: 340 |  Loss: (0.0136) | Acc: (99.54%) (43446/43648)\n",
            "Epoch: 215 | Batch_idx: 350 |  Loss: (0.0135) | Acc: (99.54%) (44720/44928)\n",
            "Epoch: 215 | Batch_idx: 360 |  Loss: (0.0134) | Acc: (99.54%) (45997/46208)\n",
            "Epoch: 215 | Batch_idx: 370 |  Loss: (0.0133) | Acc: (99.55%) (47273/47488)\n",
            "Epoch: 215 | Batch_idx: 380 |  Loss: (0.0133) | Acc: (99.54%) (48546/48768)\n",
            "Epoch: 215 | Batch_idx: 390 |  Loss: (0.0132) | Acc: (99.54%) (49772/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4034) | Acc: (91.83%) (9183/10000)\n",
            "Epoch: 216 | Batch_idx: 0 |  Loss: (0.0059) | Acc: (100.00%) (128/128)\n",
            "Epoch: 216 | Batch_idx: 10 |  Loss: (0.0083) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 216 | Batch_idx: 20 |  Loss: (0.0097) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 216 | Batch_idx: 30 |  Loss: (0.0093) | Acc: (99.80%) (3960/3968)\n",
            "Epoch: 216 | Batch_idx: 40 |  Loss: (0.0110) | Acc: (99.70%) (5232/5248)\n",
            "Epoch: 216 | Batch_idx: 50 |  Loss: (0.0115) | Acc: (99.68%) (6507/6528)\n",
            "Epoch: 216 | Batch_idx: 60 |  Loss: (0.0116) | Acc: (99.67%) (7782/7808)\n",
            "Epoch: 216 | Batch_idx: 70 |  Loss: (0.0124) | Acc: (99.60%) (9052/9088)\n",
            "Epoch: 216 | Batch_idx: 80 |  Loss: (0.0126) | Acc: (99.59%) (10326/10368)\n",
            "Epoch: 216 | Batch_idx: 90 |  Loss: (0.0116) | Acc: (99.63%) (11605/11648)\n",
            "Epoch: 216 | Batch_idx: 100 |  Loss: (0.0113) | Acc: (99.64%) (12882/12928)\n",
            "Epoch: 216 | Batch_idx: 110 |  Loss: (0.0111) | Acc: (99.66%) (14159/14208)\n",
            "Epoch: 216 | Batch_idx: 120 |  Loss: (0.0112) | Acc: (99.63%) (15431/15488)\n",
            "Epoch: 216 | Batch_idx: 130 |  Loss: (0.0113) | Acc: (99.62%) (16704/16768)\n",
            "Epoch: 216 | Batch_idx: 140 |  Loss: (0.0116) | Acc: (99.60%) (17976/18048)\n",
            "Epoch: 216 | Batch_idx: 150 |  Loss: (0.0117) | Acc: (99.60%) (19251/19328)\n",
            "Epoch: 216 | Batch_idx: 160 |  Loss: (0.0114) | Acc: (99.61%) (20527/20608)\n",
            "Epoch: 216 | Batch_idx: 170 |  Loss: (0.0118) | Acc: (99.59%) (21799/21888)\n",
            "Epoch: 216 | Batch_idx: 180 |  Loss: (0.0124) | Acc: (99.57%) (23069/23168)\n",
            "Epoch: 216 | Batch_idx: 190 |  Loss: (0.0123) | Acc: (99.58%) (24345/24448)\n",
            "Epoch: 216 | Batch_idx: 200 |  Loss: (0.0126) | Acc: (99.56%) (25616/25728)\n",
            "Epoch: 216 | Batch_idx: 210 |  Loss: (0.0128) | Acc: (99.57%) (26891/27008)\n",
            "Epoch: 216 | Batch_idx: 220 |  Loss: (0.0127) | Acc: (99.56%) (28163/28288)\n",
            "Epoch: 216 | Batch_idx: 230 |  Loss: (0.0127) | Acc: (99.56%) (29438/29568)\n",
            "Epoch: 216 | Batch_idx: 240 |  Loss: (0.0128) | Acc: (99.56%) (30711/30848)\n",
            "Epoch: 216 | Batch_idx: 250 |  Loss: (0.0131) | Acc: (99.55%) (31983/32128)\n",
            "Epoch: 216 | Batch_idx: 260 |  Loss: (0.0130) | Acc: (99.55%) (33259/33408)\n",
            "Epoch: 216 | Batch_idx: 270 |  Loss: (0.0132) | Acc: (99.55%) (34531/34688)\n",
            "Epoch: 216 | Batch_idx: 280 |  Loss: (0.0131) | Acc: (99.55%) (35806/35968)\n",
            "Epoch: 216 | Batch_idx: 290 |  Loss: (0.0130) | Acc: (99.55%) (37080/37248)\n",
            "Epoch: 216 | Batch_idx: 300 |  Loss: (0.0131) | Acc: (99.54%) (38352/38528)\n",
            "Epoch: 216 | Batch_idx: 310 |  Loss: (0.0134) | Acc: (99.53%) (39619/39808)\n",
            "Epoch: 216 | Batch_idx: 320 |  Loss: (0.0134) | Acc: (99.53%) (40894/41088)\n",
            "Epoch: 216 | Batch_idx: 330 |  Loss: (0.0132) | Acc: (99.54%) (42171/42368)\n",
            "Epoch: 216 | Batch_idx: 340 |  Loss: (0.0135) | Acc: (99.53%) (43443/43648)\n",
            "Epoch: 216 | Batch_idx: 350 |  Loss: (0.0135) | Acc: (99.53%) (44718/44928)\n",
            "Epoch: 216 | Batch_idx: 360 |  Loss: (0.0135) | Acc: (99.53%) (45990/46208)\n",
            "Epoch: 216 | Batch_idx: 370 |  Loss: (0.0136) | Acc: (99.53%) (47264/47488)\n",
            "Epoch: 216 | Batch_idx: 380 |  Loss: (0.0137) | Acc: (99.52%) (48535/48768)\n",
            "Epoch: 216 | Batch_idx: 390 |  Loss: (0.0135) | Acc: (99.53%) (49765/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4005) | Acc: (91.77%) (9177/10000)\n",
            "Epoch: 217 | Batch_idx: 0 |  Loss: (0.0077) | Acc: (100.00%) (128/128)\n",
            "Epoch: 217 | Batch_idx: 10 |  Loss: (0.0051) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 217 | Batch_idx: 20 |  Loss: (0.0045) | Acc: (100.00%) (2688/2688)\n",
            "Epoch: 217 | Batch_idx: 30 |  Loss: (0.0090) | Acc: (99.75%) (3958/3968)\n",
            "Epoch: 217 | Batch_idx: 40 |  Loss: (0.0086) | Acc: (99.75%) (5235/5248)\n",
            "Epoch: 217 | Batch_idx: 50 |  Loss: (0.0098) | Acc: (99.72%) (6510/6528)\n",
            "Epoch: 217 | Batch_idx: 60 |  Loss: (0.0100) | Acc: (99.69%) (7784/7808)\n",
            "Epoch: 217 | Batch_idx: 70 |  Loss: (0.0101) | Acc: (99.68%) (9059/9088)\n",
            "Epoch: 217 | Batch_idx: 80 |  Loss: (0.0095) | Acc: (99.70%) (10337/10368)\n",
            "Epoch: 217 | Batch_idx: 90 |  Loss: (0.0107) | Acc: (99.66%) (11608/11648)\n",
            "Epoch: 217 | Batch_idx: 100 |  Loss: (0.0114) | Acc: (99.63%) (12880/12928)\n",
            "Epoch: 217 | Batch_idx: 110 |  Loss: (0.0117) | Acc: (99.62%) (14154/14208)\n",
            "Epoch: 217 | Batch_idx: 120 |  Loss: (0.0120) | Acc: (99.60%) (15426/15488)\n",
            "Epoch: 217 | Batch_idx: 130 |  Loss: (0.0119) | Acc: (99.61%) (16703/16768)\n",
            "Epoch: 217 | Batch_idx: 140 |  Loss: (0.0117) | Acc: (99.62%) (17980/18048)\n",
            "Epoch: 217 | Batch_idx: 150 |  Loss: (0.0122) | Acc: (99.59%) (19249/19328)\n",
            "Epoch: 217 | Batch_idx: 160 |  Loss: (0.0129) | Acc: (99.56%) (20518/20608)\n",
            "Epoch: 217 | Batch_idx: 170 |  Loss: (0.0132) | Acc: (99.55%) (21789/21888)\n",
            "Epoch: 217 | Batch_idx: 180 |  Loss: (0.0135) | Acc: (99.55%) (23063/23168)\n",
            "Epoch: 217 | Batch_idx: 190 |  Loss: (0.0134) | Acc: (99.55%) (24338/24448)\n",
            "Epoch: 217 | Batch_idx: 200 |  Loss: (0.0130) | Acc: (99.56%) (25615/25728)\n",
            "Epoch: 217 | Batch_idx: 210 |  Loss: (0.0130) | Acc: (99.57%) (26892/27008)\n",
            "Epoch: 217 | Batch_idx: 220 |  Loss: (0.0130) | Acc: (99.57%) (28165/28288)\n",
            "Epoch: 217 | Batch_idx: 230 |  Loss: (0.0128) | Acc: (99.57%) (29442/29568)\n",
            "Epoch: 217 | Batch_idx: 240 |  Loss: (0.0129) | Acc: (99.58%) (30717/30848)\n",
            "Epoch: 217 | Batch_idx: 250 |  Loss: (0.0128) | Acc: (99.58%) (31994/32128)\n",
            "Epoch: 217 | Batch_idx: 260 |  Loss: (0.0129) | Acc: (99.58%) (33267/33408)\n",
            "Epoch: 217 | Batch_idx: 270 |  Loss: (0.0127) | Acc: (99.59%) (34545/34688)\n",
            "Epoch: 217 | Batch_idx: 280 |  Loss: (0.0125) | Acc: (99.59%) (35821/35968)\n",
            "Epoch: 217 | Batch_idx: 290 |  Loss: (0.0124) | Acc: (99.59%) (37097/37248)\n",
            "Epoch: 217 | Batch_idx: 300 |  Loss: (0.0125) | Acc: (99.59%) (38369/38528)\n",
            "Epoch: 217 | Batch_idx: 310 |  Loss: (0.0127) | Acc: (99.59%) (39644/39808)\n",
            "Epoch: 217 | Batch_idx: 320 |  Loss: (0.0126) | Acc: (99.59%) (40920/41088)\n",
            "Epoch: 217 | Batch_idx: 330 |  Loss: (0.0125) | Acc: (99.59%) (42195/42368)\n",
            "Epoch: 217 | Batch_idx: 340 |  Loss: (0.0125) | Acc: (99.59%) (43470/43648)\n",
            "Epoch: 217 | Batch_idx: 350 |  Loss: (0.0126) | Acc: (99.59%) (44744/44928)\n",
            "Epoch: 217 | Batch_idx: 360 |  Loss: (0.0126) | Acc: (99.58%) (46016/46208)\n",
            "Epoch: 217 | Batch_idx: 370 |  Loss: (0.0126) | Acc: (99.58%) (47289/47488)\n",
            "Epoch: 217 | Batch_idx: 380 |  Loss: (0.0127) | Acc: (99.58%) (48565/48768)\n",
            "Epoch: 217 | Batch_idx: 390 |  Loss: (0.0126) | Acc: (99.58%) (49792/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4027) | Acc: (91.85%) (9185/10000)\n",
            "Epoch: 218 | Batch_idx: 0 |  Loss: (0.0042) | Acc: (100.00%) (128/128)\n",
            "Epoch: 218 | Batch_idx: 10 |  Loss: (0.0085) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 218 | Batch_idx: 20 |  Loss: (0.0070) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 218 | Batch_idx: 30 |  Loss: (0.0072) | Acc: (99.77%) (3959/3968)\n",
            "Epoch: 218 | Batch_idx: 40 |  Loss: (0.0088) | Acc: (99.71%) (5233/5248)\n",
            "Epoch: 218 | Batch_idx: 50 |  Loss: (0.0089) | Acc: (99.72%) (6510/6528)\n",
            "Epoch: 218 | Batch_idx: 60 |  Loss: (0.0103) | Acc: (99.64%) (7780/7808)\n",
            "Epoch: 218 | Batch_idx: 70 |  Loss: (0.0095) | Acc: (99.67%) (9058/9088)\n",
            "Epoch: 218 | Batch_idx: 80 |  Loss: (0.0096) | Acc: (99.65%) (10332/10368)\n",
            "Epoch: 218 | Batch_idx: 90 |  Loss: (0.0098) | Acc: (99.65%) (11607/11648)\n",
            "Epoch: 218 | Batch_idx: 100 |  Loss: (0.0107) | Acc: (99.64%) (12882/12928)\n",
            "Epoch: 218 | Batch_idx: 110 |  Loss: (0.0107) | Acc: (99.65%) (14158/14208)\n",
            "Epoch: 218 | Batch_idx: 120 |  Loss: (0.0108) | Acc: (99.64%) (15432/15488)\n",
            "Epoch: 218 | Batch_idx: 130 |  Loss: (0.0108) | Acc: (99.64%) (16707/16768)\n",
            "Epoch: 218 | Batch_idx: 140 |  Loss: (0.0110) | Acc: (99.65%) (17984/18048)\n",
            "Epoch: 218 | Batch_idx: 150 |  Loss: (0.0118) | Acc: (99.62%) (19255/19328)\n",
            "Epoch: 218 | Batch_idx: 160 |  Loss: (0.0121) | Acc: (99.60%) (20526/20608)\n",
            "Epoch: 218 | Batch_idx: 170 |  Loss: (0.0120) | Acc: (99.61%) (21802/21888)\n",
            "Epoch: 218 | Batch_idx: 180 |  Loss: (0.0119) | Acc: (99.62%) (23079/23168)\n",
            "Epoch: 218 | Batch_idx: 190 |  Loss: (0.0122) | Acc: (99.61%) (24352/24448)\n",
            "Epoch: 218 | Batch_idx: 200 |  Loss: (0.0125) | Acc: (99.59%) (25623/25728)\n",
            "Epoch: 218 | Batch_idx: 210 |  Loss: (0.0129) | Acc: (99.58%) (26894/27008)\n",
            "Epoch: 218 | Batch_idx: 220 |  Loss: (0.0131) | Acc: (99.58%) (28169/28288)\n",
            "Epoch: 218 | Batch_idx: 230 |  Loss: (0.0129) | Acc: (99.59%) (29446/29568)\n",
            "Epoch: 218 | Batch_idx: 240 |  Loss: (0.0127) | Acc: (99.59%) (30721/30848)\n",
            "Epoch: 218 | Batch_idx: 250 |  Loss: (0.0126) | Acc: (99.59%) (31997/32128)\n",
            "Epoch: 218 | Batch_idx: 260 |  Loss: (0.0126) | Acc: (99.60%) (33273/33408)\n",
            "Epoch: 218 | Batch_idx: 270 |  Loss: (0.0128) | Acc: (99.59%) (34545/34688)\n",
            "Epoch: 218 | Batch_idx: 280 |  Loss: (0.0131) | Acc: (99.58%) (35817/35968)\n",
            "Epoch: 218 | Batch_idx: 290 |  Loss: (0.0131) | Acc: (99.58%) (37093/37248)\n",
            "Epoch: 218 | Batch_idx: 300 |  Loss: (0.0135) | Acc: (99.58%) (38365/38528)\n",
            "Epoch: 218 | Batch_idx: 310 |  Loss: (0.0133) | Acc: (99.57%) (39638/39808)\n",
            "Epoch: 218 | Batch_idx: 320 |  Loss: (0.0132) | Acc: (99.57%) (40913/41088)\n",
            "Epoch: 218 | Batch_idx: 330 |  Loss: (0.0133) | Acc: (99.58%) (42190/42368)\n",
            "Epoch: 218 | Batch_idx: 340 |  Loss: (0.0132) | Acc: (99.58%) (43464/43648)\n",
            "Epoch: 218 | Batch_idx: 350 |  Loss: (0.0132) | Acc: (99.58%) (44738/44928)\n",
            "Epoch: 218 | Batch_idx: 360 |  Loss: (0.0130) | Acc: (99.59%) (46017/46208)\n",
            "Epoch: 218 | Batch_idx: 370 |  Loss: (0.0129) | Acc: (99.58%) (47290/47488)\n",
            "Epoch: 218 | Batch_idx: 380 |  Loss: (0.0130) | Acc: (99.58%) (48562/48768)\n",
            "Epoch: 218 | Batch_idx: 390 |  Loss: (0.0129) | Acc: (99.58%) (49790/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4008) | Acc: (91.75%) (9175/10000)\n",
            "Epoch: 219 | Batch_idx: 0 |  Loss: (0.0011) | Acc: (100.00%) (128/128)\n",
            "Epoch: 219 | Batch_idx: 10 |  Loss: (0.0124) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 219 | Batch_idx: 20 |  Loss: (0.0146) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 219 | Batch_idx: 30 |  Loss: (0.0114) | Acc: (99.75%) (3958/3968)\n",
            "Epoch: 219 | Batch_idx: 40 |  Loss: (0.0169) | Acc: (99.62%) (5228/5248)\n",
            "Epoch: 219 | Batch_idx: 50 |  Loss: (0.0147) | Acc: (99.68%) (6507/6528)\n",
            "Epoch: 219 | Batch_idx: 60 |  Loss: (0.0145) | Acc: (99.68%) (7783/7808)\n",
            "Epoch: 219 | Batch_idx: 70 |  Loss: (0.0138) | Acc: (99.69%) (9060/9088)\n",
            "Epoch: 219 | Batch_idx: 80 |  Loss: (0.0141) | Acc: (99.66%) (10333/10368)\n",
            "Epoch: 219 | Batch_idx: 90 |  Loss: (0.0135) | Acc: (99.67%) (11610/11648)\n",
            "Epoch: 219 | Batch_idx: 100 |  Loss: (0.0134) | Acc: (99.67%) (12885/12928)\n",
            "Epoch: 219 | Batch_idx: 110 |  Loss: (0.0132) | Acc: (99.66%) (14160/14208)\n",
            "Epoch: 219 | Batch_idx: 120 |  Loss: (0.0140) | Acc: (99.63%) (15430/15488)\n",
            "Epoch: 219 | Batch_idx: 130 |  Loss: (0.0141) | Acc: (99.61%) (16702/16768)\n",
            "Epoch: 219 | Batch_idx: 140 |  Loss: (0.0144) | Acc: (99.60%) (17976/18048)\n",
            "Epoch: 219 | Batch_idx: 150 |  Loss: (0.0142) | Acc: (99.61%) (19252/19328)\n",
            "Epoch: 219 | Batch_idx: 160 |  Loss: (0.0140) | Acc: (99.61%) (20527/20608)\n",
            "Epoch: 219 | Batch_idx: 170 |  Loss: (0.0143) | Acc: (99.60%) (21801/21888)\n",
            "Epoch: 219 | Batch_idx: 180 |  Loss: (0.0147) | Acc: (99.59%) (23072/23168)\n",
            "Epoch: 219 | Batch_idx: 190 |  Loss: (0.0144) | Acc: (99.58%) (24346/24448)\n",
            "Epoch: 219 | Batch_idx: 200 |  Loss: (0.0143) | Acc: (99.58%) (25621/25728)\n",
            "Epoch: 219 | Batch_idx: 210 |  Loss: (0.0145) | Acc: (99.58%) (26894/27008)\n",
            "Epoch: 219 | Batch_idx: 220 |  Loss: (0.0142) | Acc: (99.58%) (28170/28288)\n",
            "Epoch: 219 | Batch_idx: 230 |  Loss: (0.0139) | Acc: (99.60%) (29449/29568)\n",
            "Epoch: 219 | Batch_idx: 240 |  Loss: (0.0137) | Acc: (99.60%) (30725/30848)\n",
            "Epoch: 219 | Batch_idx: 250 |  Loss: (0.0136) | Acc: (99.60%) (32001/32128)\n",
            "Epoch: 219 | Batch_idx: 260 |  Loss: (0.0135) | Acc: (99.60%) (33276/33408)\n",
            "Epoch: 219 | Batch_idx: 270 |  Loss: (0.0138) | Acc: (99.59%) (34547/34688)\n",
            "Epoch: 219 | Batch_idx: 280 |  Loss: (0.0140) | Acc: (99.57%) (35815/35968)\n",
            "Epoch: 219 | Batch_idx: 290 |  Loss: (0.0139) | Acc: (99.58%) (37090/37248)\n",
            "Epoch: 219 | Batch_idx: 300 |  Loss: (0.0143) | Acc: (99.56%) (38360/38528)\n",
            "Epoch: 219 | Batch_idx: 310 |  Loss: (0.0143) | Acc: (99.57%) (39636/39808)\n",
            "Epoch: 219 | Batch_idx: 320 |  Loss: (0.0143) | Acc: (99.57%) (40911/41088)\n",
            "Epoch: 219 | Batch_idx: 330 |  Loss: (0.0142) | Acc: (99.57%) (42187/42368)\n",
            "Epoch: 219 | Batch_idx: 340 |  Loss: (0.0144) | Acc: (99.56%) (43456/43648)\n",
            "Epoch: 219 | Batch_idx: 350 |  Loss: (0.0145) | Acc: (99.56%) (44729/44928)\n",
            "Epoch: 219 | Batch_idx: 360 |  Loss: (0.0143) | Acc: (99.56%) (46006/46208)\n",
            "Epoch: 219 | Batch_idx: 370 |  Loss: (0.0140) | Acc: (99.57%) (47284/47488)\n",
            "Epoch: 219 | Batch_idx: 380 |  Loss: (0.0140) | Acc: (99.57%) (48559/48768)\n",
            "Epoch: 219 | Batch_idx: 390 |  Loss: (0.0140) | Acc: (99.57%) (49783/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4004) | Acc: (91.75%) (9175/10000)\n",
            "Epoch: 220 | Batch_idx: 0 |  Loss: (0.0471) | Acc: (99.22%) (127/128)\n",
            "Epoch: 220 | Batch_idx: 10 |  Loss: (0.0111) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 220 | Batch_idx: 20 |  Loss: (0.0141) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 220 | Batch_idx: 30 |  Loss: (0.0120) | Acc: (99.60%) (3952/3968)\n",
            "Epoch: 220 | Batch_idx: 40 |  Loss: (0.0123) | Acc: (99.56%) (5225/5248)\n",
            "Epoch: 220 | Batch_idx: 50 |  Loss: (0.0129) | Acc: (99.54%) (6498/6528)\n",
            "Epoch: 220 | Batch_idx: 60 |  Loss: (0.0134) | Acc: (99.51%) (7770/7808)\n",
            "Epoch: 220 | Batch_idx: 70 |  Loss: (0.0136) | Acc: (99.50%) (9043/9088)\n",
            "Epoch: 220 | Batch_idx: 80 |  Loss: (0.0134) | Acc: (99.52%) (10318/10368)\n",
            "Epoch: 220 | Batch_idx: 90 |  Loss: (0.0140) | Acc: (99.50%) (11590/11648)\n",
            "Epoch: 220 | Batch_idx: 100 |  Loss: (0.0132) | Acc: (99.54%) (12868/12928)\n",
            "Epoch: 220 | Batch_idx: 110 |  Loss: (0.0136) | Acc: (99.52%) (14140/14208)\n",
            "Epoch: 220 | Batch_idx: 120 |  Loss: (0.0137) | Acc: (99.51%) (15412/15488)\n",
            "Epoch: 220 | Batch_idx: 130 |  Loss: (0.0137) | Acc: (99.52%) (16687/16768)\n",
            "Epoch: 220 | Batch_idx: 140 |  Loss: (0.0139) | Acc: (99.51%) (17960/18048)\n",
            "Epoch: 220 | Batch_idx: 150 |  Loss: (0.0138) | Acc: (99.53%) (19238/19328)\n",
            "Epoch: 220 | Batch_idx: 160 |  Loss: (0.0137) | Acc: (99.53%) (20512/20608)\n",
            "Epoch: 220 | Batch_idx: 170 |  Loss: (0.0138) | Acc: (99.53%) (21785/21888)\n",
            "Epoch: 220 | Batch_idx: 180 |  Loss: (0.0134) | Acc: (99.55%) (23063/23168)\n",
            "Epoch: 220 | Batch_idx: 190 |  Loss: (0.0133) | Acc: (99.55%) (24338/24448)\n",
            "Epoch: 220 | Batch_idx: 200 |  Loss: (0.0135) | Acc: (99.54%) (25610/25728)\n",
            "Epoch: 220 | Batch_idx: 210 |  Loss: (0.0132) | Acc: (99.55%) (26887/27008)\n",
            "Epoch: 220 | Batch_idx: 220 |  Loss: (0.0131) | Acc: (99.55%) (28162/28288)\n",
            "Epoch: 220 | Batch_idx: 230 |  Loss: (0.0131) | Acc: (99.56%) (29438/29568)\n",
            "Epoch: 220 | Batch_idx: 240 |  Loss: (0.0131) | Acc: (99.56%) (30712/30848)\n",
            "Epoch: 220 | Batch_idx: 250 |  Loss: (0.0131) | Acc: (99.56%) (31986/32128)\n",
            "Epoch: 220 | Batch_idx: 260 |  Loss: (0.0132) | Acc: (99.55%) (33258/33408)\n",
            "Epoch: 220 | Batch_idx: 270 |  Loss: (0.0129) | Acc: (99.56%) (34535/34688)\n",
            "Epoch: 220 | Batch_idx: 280 |  Loss: (0.0133) | Acc: (99.54%) (35804/35968)\n",
            "Epoch: 220 | Batch_idx: 290 |  Loss: (0.0134) | Acc: (99.54%) (37075/37248)\n",
            "Epoch: 220 | Batch_idx: 300 |  Loss: (0.0132) | Acc: (99.54%) (38351/38528)\n",
            "Epoch: 220 | Batch_idx: 310 |  Loss: (0.0135) | Acc: (99.53%) (39621/39808)\n",
            "Epoch: 220 | Batch_idx: 320 |  Loss: (0.0136) | Acc: (99.52%) (40892/41088)\n",
            "Epoch: 220 | Batch_idx: 330 |  Loss: (0.0135) | Acc: (99.53%) (42167/42368)\n",
            "Epoch: 220 | Batch_idx: 340 |  Loss: (0.0135) | Acc: (99.53%) (43442/43648)\n",
            "Epoch: 220 | Batch_idx: 350 |  Loss: (0.0135) | Acc: (99.53%) (44716/44928)\n",
            "Epoch: 220 | Batch_idx: 360 |  Loss: (0.0136) | Acc: (99.53%) (45991/46208)\n",
            "Epoch: 220 | Batch_idx: 370 |  Loss: (0.0136) | Acc: (99.53%) (47264/47488)\n",
            "Epoch: 220 | Batch_idx: 380 |  Loss: (0.0135) | Acc: (99.53%) (48541/48768)\n",
            "Epoch: 220 | Batch_idx: 390 |  Loss: (0.0134) | Acc: (99.54%) (49770/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3998) | Acc: (91.82%) (9182/10000)\n",
            "Epoch: 221 | Batch_idx: 0 |  Loss: (0.0075) | Acc: (100.00%) (128/128)\n",
            "Epoch: 221 | Batch_idx: 10 |  Loss: (0.0061) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 221 | Batch_idx: 20 |  Loss: (0.0075) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 221 | Batch_idx: 30 |  Loss: (0.0085) | Acc: (99.75%) (3958/3968)\n",
            "Epoch: 221 | Batch_idx: 40 |  Loss: (0.0101) | Acc: (99.66%) (5230/5248)\n",
            "Epoch: 221 | Batch_idx: 50 |  Loss: (0.0101) | Acc: (99.63%) (6504/6528)\n",
            "Epoch: 221 | Batch_idx: 60 |  Loss: (0.0116) | Acc: (99.58%) (7775/7808)\n",
            "Epoch: 221 | Batch_idx: 70 |  Loss: (0.0117) | Acc: (99.58%) (9050/9088)\n",
            "Epoch: 221 | Batch_idx: 80 |  Loss: (0.0117) | Acc: (99.58%) (10324/10368)\n",
            "Epoch: 221 | Batch_idx: 90 |  Loss: (0.0112) | Acc: (99.59%) (11600/11648)\n",
            "Epoch: 221 | Batch_idx: 100 |  Loss: (0.0115) | Acc: (99.60%) (12876/12928)\n",
            "Epoch: 221 | Batch_idx: 110 |  Loss: (0.0118) | Acc: (99.58%) (14148/14208)\n",
            "Epoch: 221 | Batch_idx: 120 |  Loss: (0.0117) | Acc: (99.57%) (15422/15488)\n",
            "Epoch: 221 | Batch_idx: 130 |  Loss: (0.0121) | Acc: (99.56%) (16694/16768)\n",
            "Epoch: 221 | Batch_idx: 140 |  Loss: (0.0120) | Acc: (99.56%) (17969/18048)\n",
            "Epoch: 221 | Batch_idx: 150 |  Loss: (0.0120) | Acc: (99.57%) (19245/19328)\n",
            "Epoch: 221 | Batch_idx: 160 |  Loss: (0.0118) | Acc: (99.58%) (20522/20608)\n",
            "Epoch: 221 | Batch_idx: 170 |  Loss: (0.0120) | Acc: (99.58%) (21795/21888)\n",
            "Epoch: 221 | Batch_idx: 180 |  Loss: (0.0123) | Acc: (99.56%) (23066/23168)\n",
            "Epoch: 221 | Batch_idx: 190 |  Loss: (0.0122) | Acc: (99.57%) (24342/24448)\n",
            "Epoch: 221 | Batch_idx: 200 |  Loss: (0.0120) | Acc: (99.58%) (25619/25728)\n",
            "Epoch: 221 | Batch_idx: 210 |  Loss: (0.0120) | Acc: (99.57%) (26893/27008)\n",
            "Epoch: 221 | Batch_idx: 220 |  Loss: (0.0119) | Acc: (99.58%) (28169/28288)\n",
            "Epoch: 221 | Batch_idx: 230 |  Loss: (0.0120) | Acc: (99.58%) (29444/29568)\n",
            "Epoch: 221 | Batch_idx: 240 |  Loss: (0.0119) | Acc: (99.59%) (30722/30848)\n",
            "Epoch: 221 | Batch_idx: 250 |  Loss: (0.0118) | Acc: (99.60%) (32000/32128)\n",
            "Epoch: 221 | Batch_idx: 260 |  Loss: (0.0118) | Acc: (99.60%) (33276/33408)\n",
            "Epoch: 221 | Batch_idx: 270 |  Loss: (0.0117) | Acc: (99.61%) (34551/34688)\n",
            "Epoch: 221 | Batch_idx: 280 |  Loss: (0.0115) | Acc: (99.62%) (35830/35968)\n",
            "Epoch: 221 | Batch_idx: 290 |  Loss: (0.0116) | Acc: (99.61%) (37103/37248)\n",
            "Epoch: 221 | Batch_idx: 300 |  Loss: (0.0116) | Acc: (99.61%) (38378/38528)\n",
            "Epoch: 221 | Batch_idx: 310 |  Loss: (0.0114) | Acc: (99.61%) (39654/39808)\n",
            "Epoch: 221 | Batch_idx: 320 |  Loss: (0.0112) | Acc: (99.62%) (40931/41088)\n",
            "Epoch: 221 | Batch_idx: 330 |  Loss: (0.0113) | Acc: (99.62%) (42205/42368)\n",
            "Epoch: 221 | Batch_idx: 340 |  Loss: (0.0114) | Acc: (99.61%) (43479/43648)\n",
            "Epoch: 221 | Batch_idx: 350 |  Loss: (0.0113) | Acc: (99.61%) (44754/44928)\n",
            "Epoch: 221 | Batch_idx: 360 |  Loss: (0.0113) | Acc: (99.61%) (46030/46208)\n",
            "Epoch: 221 | Batch_idx: 370 |  Loss: (0.0113) | Acc: (99.62%) (47306/47488)\n",
            "Epoch: 221 | Batch_idx: 380 |  Loss: (0.0113) | Acc: (99.62%) (48583/48768)\n",
            "Epoch: 221 | Batch_idx: 390 |  Loss: (0.0112) | Acc: (99.63%) (49813/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4008) | Acc: (91.74%) (9174/10000)\n",
            "Epoch: 222 | Batch_idx: 0 |  Loss: (0.0295) | Acc: (99.22%) (127/128)\n",
            "Epoch: 222 | Batch_idx: 10 |  Loss: (0.0201) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 222 | Batch_idx: 20 |  Loss: (0.0155) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 222 | Batch_idx: 30 |  Loss: (0.0156) | Acc: (99.47%) (3947/3968)\n",
            "Epoch: 222 | Batch_idx: 40 |  Loss: (0.0159) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 222 | Batch_idx: 50 |  Loss: (0.0170) | Acc: (99.40%) (6489/6528)\n",
            "Epoch: 222 | Batch_idx: 60 |  Loss: (0.0162) | Acc: (99.41%) (7762/7808)\n",
            "Epoch: 222 | Batch_idx: 70 |  Loss: (0.0154) | Acc: (99.44%) (9037/9088)\n",
            "Epoch: 222 | Batch_idx: 80 |  Loss: (0.0149) | Acc: (99.47%) (10313/10368)\n",
            "Epoch: 222 | Batch_idx: 90 |  Loss: (0.0148) | Acc: (99.47%) (11586/11648)\n",
            "Epoch: 222 | Batch_idx: 100 |  Loss: (0.0154) | Acc: (99.46%) (12858/12928)\n",
            "Epoch: 222 | Batch_idx: 110 |  Loss: (0.0157) | Acc: (99.44%) (14129/14208)\n",
            "Epoch: 222 | Batch_idx: 120 |  Loss: (0.0156) | Acc: (99.45%) (15403/15488)\n",
            "Epoch: 222 | Batch_idx: 130 |  Loss: (0.0152) | Acc: (99.46%) (16677/16768)\n",
            "Epoch: 222 | Batch_idx: 140 |  Loss: (0.0150) | Acc: (99.46%) (17951/18048)\n",
            "Epoch: 222 | Batch_idx: 150 |  Loss: (0.0146) | Acc: (99.48%) (19228/19328)\n",
            "Epoch: 222 | Batch_idx: 160 |  Loss: (0.0149) | Acc: (99.47%) (20499/20608)\n",
            "Epoch: 222 | Batch_idx: 170 |  Loss: (0.0147) | Acc: (99.47%) (21773/21888)\n",
            "Epoch: 222 | Batch_idx: 180 |  Loss: (0.0142) | Acc: (99.49%) (23051/23168)\n",
            "Epoch: 222 | Batch_idx: 190 |  Loss: (0.0140) | Acc: (99.51%) (24328/24448)\n",
            "Epoch: 222 | Batch_idx: 200 |  Loss: (0.0139) | Acc: (99.51%) (25603/25728)\n",
            "Epoch: 222 | Batch_idx: 210 |  Loss: (0.0141) | Acc: (99.52%) (26878/27008)\n",
            "Epoch: 222 | Batch_idx: 220 |  Loss: (0.0140) | Acc: (99.52%) (28152/28288)\n",
            "Epoch: 222 | Batch_idx: 230 |  Loss: (0.0140) | Acc: (99.52%) (29425/29568)\n",
            "Epoch: 222 | Batch_idx: 240 |  Loss: (0.0139) | Acc: (99.52%) (30701/30848)\n",
            "Epoch: 222 | Batch_idx: 250 |  Loss: (0.0137) | Acc: (99.53%) (31976/32128)\n",
            "Epoch: 222 | Batch_idx: 260 |  Loss: (0.0138) | Acc: (99.53%) (33251/33408)\n",
            "Epoch: 222 | Batch_idx: 270 |  Loss: (0.0138) | Acc: (99.53%) (34524/34688)\n",
            "Epoch: 222 | Batch_idx: 280 |  Loss: (0.0138) | Acc: (99.52%) (35797/35968)\n",
            "Epoch: 222 | Batch_idx: 290 |  Loss: (0.0136) | Acc: (99.53%) (37072/37248)\n",
            "Epoch: 222 | Batch_idx: 300 |  Loss: (0.0139) | Acc: (99.52%) (38344/38528)\n",
            "Epoch: 222 | Batch_idx: 310 |  Loss: (0.0138) | Acc: (99.53%) (39619/39808)\n",
            "Epoch: 222 | Batch_idx: 320 |  Loss: (0.0140) | Acc: (99.52%) (40890/41088)\n",
            "Epoch: 222 | Batch_idx: 330 |  Loss: (0.0139) | Acc: (99.52%) (42165/42368)\n",
            "Epoch: 222 | Batch_idx: 340 |  Loss: (0.0139) | Acc: (99.52%) (43440/43648)\n",
            "Epoch: 222 | Batch_idx: 350 |  Loss: (0.0138) | Acc: (99.52%) (44712/44928)\n",
            "Epoch: 222 | Batch_idx: 360 |  Loss: (0.0138) | Acc: (99.52%) (45988/46208)\n",
            "Epoch: 222 | Batch_idx: 370 |  Loss: (0.0138) | Acc: (99.52%) (47262/47488)\n",
            "Epoch: 222 | Batch_idx: 380 |  Loss: (0.0137) | Acc: (99.52%) (48535/48768)\n",
            "Epoch: 222 | Batch_idx: 390 |  Loss: (0.0137) | Acc: (99.53%) (49763/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4013) | Acc: (91.77%) (9177/10000)\n",
            "Epoch: 223 | Batch_idx: 0 |  Loss: (0.0021) | Acc: (100.00%) (128/128)\n",
            "Epoch: 223 | Batch_idx: 10 |  Loss: (0.0099) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 223 | Batch_idx: 20 |  Loss: (0.0142) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 223 | Batch_idx: 30 |  Loss: (0.0113) | Acc: (99.65%) (3954/3968)\n",
            "Epoch: 223 | Batch_idx: 40 |  Loss: (0.0112) | Acc: (99.62%) (5228/5248)\n",
            "Epoch: 223 | Batch_idx: 50 |  Loss: (0.0106) | Acc: (99.65%) (6505/6528)\n",
            "Epoch: 223 | Batch_idx: 60 |  Loss: (0.0111) | Acc: (99.62%) (7778/7808)\n",
            "Epoch: 223 | Batch_idx: 70 |  Loss: (0.0102) | Acc: (99.65%) (9056/9088)\n",
            "Epoch: 223 | Batch_idx: 80 |  Loss: (0.0109) | Acc: (99.64%) (10331/10368)\n",
            "Epoch: 223 | Batch_idx: 90 |  Loss: (0.0107) | Acc: (99.66%) (11608/11648)\n",
            "Epoch: 223 | Batch_idx: 100 |  Loss: (0.0107) | Acc: (99.68%) (12886/12928)\n",
            "Epoch: 223 | Batch_idx: 110 |  Loss: (0.0108) | Acc: (99.67%) (14161/14208)\n",
            "Epoch: 223 | Batch_idx: 120 |  Loss: (0.0111) | Acc: (99.66%) (15435/15488)\n",
            "Epoch: 223 | Batch_idx: 130 |  Loss: (0.0110) | Acc: (99.65%) (16710/16768)\n",
            "Epoch: 223 | Batch_idx: 140 |  Loss: (0.0108) | Acc: (99.67%) (17989/18048)\n",
            "Epoch: 223 | Batch_idx: 150 |  Loss: (0.0110) | Acc: (99.67%) (19264/19328)\n",
            "Epoch: 223 | Batch_idx: 160 |  Loss: (0.0112) | Acc: (99.66%) (20538/20608)\n",
            "Epoch: 223 | Batch_idx: 170 |  Loss: (0.0110) | Acc: (99.66%) (21814/21888)\n",
            "Epoch: 223 | Batch_idx: 180 |  Loss: (0.0110) | Acc: (99.65%) (23088/23168)\n",
            "Epoch: 223 | Batch_idx: 190 |  Loss: (0.0109) | Acc: (99.66%) (24364/24448)\n",
            "Epoch: 223 | Batch_idx: 200 |  Loss: (0.0112) | Acc: (99.65%) (25639/25728)\n",
            "Epoch: 223 | Batch_idx: 210 |  Loss: (0.0115) | Acc: (99.64%) (26911/27008)\n",
            "Epoch: 223 | Batch_idx: 220 |  Loss: (0.0116) | Acc: (99.63%) (28184/28288)\n",
            "Epoch: 223 | Batch_idx: 230 |  Loss: (0.0118) | Acc: (99.62%) (29455/29568)\n",
            "Epoch: 223 | Batch_idx: 240 |  Loss: (0.0119) | Acc: (99.62%) (30730/30848)\n",
            "Epoch: 223 | Batch_idx: 250 |  Loss: (0.0124) | Acc: (99.60%) (32000/32128)\n",
            "Epoch: 223 | Batch_idx: 260 |  Loss: (0.0123) | Acc: (99.60%) (33276/33408)\n",
            "Epoch: 223 | Batch_idx: 270 |  Loss: (0.0123) | Acc: (99.60%) (34550/34688)\n",
            "Epoch: 223 | Batch_idx: 280 |  Loss: (0.0125) | Acc: (99.59%) (35822/35968)\n",
            "Epoch: 223 | Batch_idx: 290 |  Loss: (0.0126) | Acc: (99.59%) (37096/37248)\n",
            "Epoch: 223 | Batch_idx: 300 |  Loss: (0.0127) | Acc: (99.59%) (38369/38528)\n",
            "Epoch: 223 | Batch_idx: 310 |  Loss: (0.0126) | Acc: (99.59%) (39643/39808)\n",
            "Epoch: 223 | Batch_idx: 320 |  Loss: (0.0127) | Acc: (99.57%) (40913/41088)\n",
            "Epoch: 223 | Batch_idx: 330 |  Loss: (0.0128) | Acc: (99.57%) (42187/42368)\n",
            "Epoch: 223 | Batch_idx: 340 |  Loss: (0.0129) | Acc: (99.57%) (43460/43648)\n",
            "Epoch: 223 | Batch_idx: 350 |  Loss: (0.0127) | Acc: (99.58%) (44738/44928)\n",
            "Epoch: 223 | Batch_idx: 360 |  Loss: (0.0127) | Acc: (99.57%) (46011/46208)\n",
            "Epoch: 223 | Batch_idx: 370 |  Loss: (0.0131) | Acc: (99.56%) (47279/47488)\n",
            "Epoch: 223 | Batch_idx: 380 |  Loss: (0.0132) | Acc: (99.55%) (48549/48768)\n",
            "Epoch: 223 | Batch_idx: 390 |  Loss: (0.0133) | Acc: (99.55%) (49775/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4030) | Acc: (91.75%) (9175/10000)\n",
            "Epoch: 224 | Batch_idx: 0 |  Loss: (0.0183) | Acc: (99.22%) (127/128)\n",
            "Epoch: 224 | Batch_idx: 10 |  Loss: (0.0142) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 224 | Batch_idx: 20 |  Loss: (0.0116) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 224 | Batch_idx: 30 |  Loss: (0.0123) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 224 | Batch_idx: 40 |  Loss: (0.0118) | Acc: (99.60%) (5227/5248)\n",
            "Epoch: 224 | Batch_idx: 50 |  Loss: (0.0111) | Acc: (99.65%) (6505/6528)\n",
            "Epoch: 224 | Batch_idx: 60 |  Loss: (0.0115) | Acc: (99.64%) (7780/7808)\n",
            "Epoch: 224 | Batch_idx: 70 |  Loss: (0.0118) | Acc: (99.60%) (9052/9088)\n",
            "Epoch: 224 | Batch_idx: 80 |  Loss: (0.0115) | Acc: (99.63%) (10330/10368)\n",
            "Epoch: 224 | Batch_idx: 90 |  Loss: (0.0111) | Acc: (99.67%) (11609/11648)\n",
            "Epoch: 224 | Batch_idx: 100 |  Loss: (0.0110) | Acc: (99.66%) (12884/12928)\n",
            "Epoch: 224 | Batch_idx: 110 |  Loss: (0.0107) | Acc: (99.67%) (14161/14208)\n",
            "Epoch: 224 | Batch_idx: 120 |  Loss: (0.0107) | Acc: (99.66%) (15436/15488)\n",
            "Epoch: 224 | Batch_idx: 130 |  Loss: (0.0110) | Acc: (99.65%) (16710/16768)\n",
            "Epoch: 224 | Batch_idx: 140 |  Loss: (0.0108) | Acc: (99.66%) (17987/18048)\n",
            "Epoch: 224 | Batch_idx: 150 |  Loss: (0.0103) | Acc: (99.68%) (19267/19328)\n",
            "Epoch: 224 | Batch_idx: 160 |  Loss: (0.0102) | Acc: (99.68%) (20543/20608)\n",
            "Epoch: 224 | Batch_idx: 170 |  Loss: (0.0105) | Acc: (99.66%) (21814/21888)\n",
            "Epoch: 224 | Batch_idx: 180 |  Loss: (0.0103) | Acc: (99.67%) (23092/23168)\n",
            "Epoch: 224 | Batch_idx: 190 |  Loss: (0.0104) | Acc: (99.67%) (24367/24448)\n",
            "Epoch: 224 | Batch_idx: 200 |  Loss: (0.0102) | Acc: (99.68%) (25645/25728)\n",
            "Epoch: 224 | Batch_idx: 210 |  Loss: (0.0102) | Acc: (99.67%) (26920/27008)\n",
            "Epoch: 224 | Batch_idx: 220 |  Loss: (0.0103) | Acc: (99.66%) (28192/28288)\n",
            "Epoch: 224 | Batch_idx: 230 |  Loss: (0.0103) | Acc: (99.66%) (29466/29568)\n",
            "Epoch: 224 | Batch_idx: 240 |  Loss: (0.0104) | Acc: (99.65%) (30740/30848)\n",
            "Epoch: 224 | Batch_idx: 250 |  Loss: (0.0104) | Acc: (99.66%) (32018/32128)\n",
            "Epoch: 224 | Batch_idx: 260 |  Loss: (0.0103) | Acc: (99.66%) (33296/33408)\n",
            "Epoch: 224 | Batch_idx: 270 |  Loss: (0.0103) | Acc: (99.66%) (34569/34688)\n",
            "Epoch: 224 | Batch_idx: 280 |  Loss: (0.0104) | Acc: (99.66%) (35845/35968)\n",
            "Epoch: 224 | Batch_idx: 290 |  Loss: (0.0105) | Acc: (99.65%) (37118/37248)\n",
            "Epoch: 224 | Batch_idx: 300 |  Loss: (0.0106) | Acc: (99.65%) (38393/38528)\n",
            "Epoch: 224 | Batch_idx: 310 |  Loss: (0.0107) | Acc: (99.64%) (39666/39808)\n",
            "Epoch: 224 | Batch_idx: 320 |  Loss: (0.0108) | Acc: (99.65%) (40943/41088)\n",
            "Epoch: 224 | Batch_idx: 330 |  Loss: (0.0108) | Acc: (99.65%) (42219/42368)\n",
            "Epoch: 224 | Batch_idx: 340 |  Loss: (0.0107) | Acc: (99.65%) (43495/43648)\n",
            "Epoch: 224 | Batch_idx: 350 |  Loss: (0.0106) | Acc: (99.66%) (44773/44928)\n",
            "Epoch: 224 | Batch_idx: 360 |  Loss: (0.0108) | Acc: (99.65%) (46046/46208)\n",
            "Epoch: 224 | Batch_idx: 370 |  Loss: (0.0108) | Acc: (99.65%) (47323/47488)\n",
            "Epoch: 224 | Batch_idx: 380 |  Loss: (0.0107) | Acc: (99.65%) (48599/48768)\n",
            "Epoch: 224 | Batch_idx: 390 |  Loss: (0.0107) | Acc: (99.65%) (49826/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4022) | Acc: (91.78%) (9178/10000)\n",
            "Epoch: 225 | Batch_idx: 0 |  Loss: (0.0048) | Acc: (100.00%) (128/128)\n",
            "Epoch: 225 | Batch_idx: 10 |  Loss: (0.0100) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 225 | Batch_idx: 20 |  Loss: (0.0114) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 225 | Batch_idx: 30 |  Loss: (0.0102) | Acc: (99.75%) (3958/3968)\n",
            "Epoch: 225 | Batch_idx: 40 |  Loss: (0.0091) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 225 | Batch_idx: 50 |  Loss: (0.0118) | Acc: (99.68%) (6507/6528)\n",
            "Epoch: 225 | Batch_idx: 60 |  Loss: (0.0117) | Acc: (99.65%) (7781/7808)\n",
            "Epoch: 225 | Batch_idx: 70 |  Loss: (0.0119) | Acc: (99.61%) (9053/9088)\n",
            "Epoch: 225 | Batch_idx: 80 |  Loss: (0.0115) | Acc: (99.61%) (10328/10368)\n",
            "Epoch: 225 | Batch_idx: 90 |  Loss: (0.0130) | Acc: (99.58%) (11599/11648)\n",
            "Epoch: 225 | Batch_idx: 100 |  Loss: (0.0128) | Acc: (99.56%) (12871/12928)\n",
            "Epoch: 225 | Batch_idx: 110 |  Loss: (0.0121) | Acc: (99.59%) (14150/14208)\n",
            "Epoch: 225 | Batch_idx: 120 |  Loss: (0.0123) | Acc: (99.57%) (15422/15488)\n",
            "Epoch: 225 | Batch_idx: 130 |  Loss: (0.0124) | Acc: (99.58%) (16697/16768)\n",
            "Epoch: 225 | Batch_idx: 140 |  Loss: (0.0125) | Acc: (99.56%) (17968/18048)\n",
            "Epoch: 225 | Batch_idx: 150 |  Loss: (0.0125) | Acc: (99.57%) (19244/19328)\n",
            "Epoch: 225 | Batch_idx: 160 |  Loss: (0.0122) | Acc: (99.58%) (20521/20608)\n",
            "Epoch: 225 | Batch_idx: 170 |  Loss: (0.0123) | Acc: (99.58%) (21795/21888)\n",
            "Epoch: 225 | Batch_idx: 180 |  Loss: (0.0124) | Acc: (99.57%) (23069/23168)\n",
            "Epoch: 225 | Batch_idx: 190 |  Loss: (0.0122) | Acc: (99.57%) (24344/24448)\n",
            "Epoch: 225 | Batch_idx: 200 |  Loss: (0.0122) | Acc: (99.57%) (25618/25728)\n",
            "Epoch: 225 | Batch_idx: 210 |  Loss: (0.0120) | Acc: (99.58%) (26894/27008)\n",
            "Epoch: 225 | Batch_idx: 220 |  Loss: (0.0119) | Acc: (99.59%) (28171/28288)\n",
            "Epoch: 225 | Batch_idx: 230 |  Loss: (0.0119) | Acc: (99.59%) (29448/29568)\n",
            "Epoch: 225 | Batch_idx: 240 |  Loss: (0.0121) | Acc: (99.59%) (30723/30848)\n",
            "Epoch: 225 | Batch_idx: 250 |  Loss: (0.0119) | Acc: (99.60%) (32000/32128)\n",
            "Epoch: 225 | Batch_idx: 260 |  Loss: (0.0118) | Acc: (99.60%) (33276/33408)\n",
            "Epoch: 225 | Batch_idx: 270 |  Loss: (0.0116) | Acc: (99.61%) (34553/34688)\n",
            "Epoch: 225 | Batch_idx: 280 |  Loss: (0.0116) | Acc: (99.62%) (35830/35968)\n",
            "Epoch: 225 | Batch_idx: 290 |  Loss: (0.0114) | Acc: (99.62%) (37107/37248)\n",
            "Epoch: 225 | Batch_idx: 300 |  Loss: (0.0114) | Acc: (99.62%) (38381/38528)\n",
            "Epoch: 225 | Batch_idx: 310 |  Loss: (0.0115) | Acc: (99.62%) (39655/39808)\n",
            "Epoch: 225 | Batch_idx: 320 |  Loss: (0.0115) | Acc: (99.62%) (40931/41088)\n",
            "Epoch: 225 | Batch_idx: 330 |  Loss: (0.0115) | Acc: (99.62%) (42206/42368)\n",
            "Epoch: 225 | Batch_idx: 340 |  Loss: (0.0114) | Acc: (99.62%) (43483/43648)\n",
            "Epoch: 225 | Batch_idx: 350 |  Loss: (0.0114) | Acc: (99.62%) (44757/44928)\n",
            "Epoch: 225 | Batch_idx: 360 |  Loss: (0.0114) | Acc: (99.62%) (46031/46208)\n",
            "Epoch: 225 | Batch_idx: 370 |  Loss: (0.0115) | Acc: (99.61%) (47305/47488)\n",
            "Epoch: 225 | Batch_idx: 380 |  Loss: (0.0118) | Acc: (99.60%) (48575/48768)\n",
            "Epoch: 225 | Batch_idx: 390 |  Loss: (0.0118) | Acc: (99.61%) (49803/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4032) | Acc: (91.92%) (9192/10000)\n",
            "Epoch: 226 | Batch_idx: 0 |  Loss: (0.0045) | Acc: (100.00%) (128/128)\n",
            "Epoch: 226 | Batch_idx: 10 |  Loss: (0.0054) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 226 | Batch_idx: 20 |  Loss: (0.0086) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 226 | Batch_idx: 30 |  Loss: (0.0117) | Acc: (99.62%) (3953/3968)\n",
            "Epoch: 226 | Batch_idx: 40 |  Loss: (0.0138) | Acc: (99.56%) (5225/5248)\n",
            "Epoch: 226 | Batch_idx: 50 |  Loss: (0.0133) | Acc: (99.56%) (6499/6528)\n",
            "Epoch: 226 | Batch_idx: 60 |  Loss: (0.0151) | Acc: (99.46%) (7766/7808)\n",
            "Epoch: 226 | Batch_idx: 70 |  Loss: (0.0150) | Acc: (99.45%) (9038/9088)\n",
            "Epoch: 226 | Batch_idx: 80 |  Loss: (0.0139) | Acc: (99.50%) (10316/10368)\n",
            "Epoch: 226 | Batch_idx: 90 |  Loss: (0.0136) | Acc: (99.53%) (11593/11648)\n",
            "Epoch: 226 | Batch_idx: 100 |  Loss: (0.0143) | Acc: (99.50%) (12863/12928)\n",
            "Epoch: 226 | Batch_idx: 110 |  Loss: (0.0141) | Acc: (99.51%) (14138/14208)\n",
            "Epoch: 226 | Batch_idx: 120 |  Loss: (0.0136) | Acc: (99.53%) (15415/15488)\n",
            "Epoch: 226 | Batch_idx: 130 |  Loss: (0.0135) | Acc: (99.53%) (16690/16768)\n",
            "Epoch: 226 | Batch_idx: 140 |  Loss: (0.0136) | Acc: (99.53%) (17964/18048)\n",
            "Epoch: 226 | Batch_idx: 150 |  Loss: (0.0136) | Acc: (99.53%) (19237/19328)\n",
            "Epoch: 226 | Batch_idx: 160 |  Loss: (0.0138) | Acc: (99.53%) (20511/20608)\n",
            "Epoch: 226 | Batch_idx: 170 |  Loss: (0.0136) | Acc: (99.53%) (21786/21888)\n",
            "Epoch: 226 | Batch_idx: 180 |  Loss: (0.0133) | Acc: (99.54%) (23061/23168)\n",
            "Epoch: 226 | Batch_idx: 190 |  Loss: (0.0140) | Acc: (99.53%) (24333/24448)\n",
            "Epoch: 226 | Batch_idx: 200 |  Loss: (0.0138) | Acc: (99.54%) (25610/25728)\n",
            "Epoch: 226 | Batch_idx: 210 |  Loss: (0.0136) | Acc: (99.54%) (26885/27008)\n",
            "Epoch: 226 | Batch_idx: 220 |  Loss: (0.0135) | Acc: (99.55%) (28161/28288)\n",
            "Epoch: 226 | Batch_idx: 230 |  Loss: (0.0135) | Acc: (99.56%) (29437/29568)\n",
            "Epoch: 226 | Batch_idx: 240 |  Loss: (0.0135) | Acc: (99.56%) (30712/30848)\n",
            "Epoch: 226 | Batch_idx: 250 |  Loss: (0.0132) | Acc: (99.57%) (31990/32128)\n",
            "Epoch: 226 | Batch_idx: 260 |  Loss: (0.0132) | Acc: (99.57%) (33266/33408)\n",
            "Epoch: 226 | Batch_idx: 270 |  Loss: (0.0130) | Acc: (99.58%) (34542/34688)\n",
            "Epoch: 226 | Batch_idx: 280 |  Loss: (0.0131) | Acc: (99.57%) (35814/35968)\n",
            "Epoch: 226 | Batch_idx: 290 |  Loss: (0.0131) | Acc: (99.57%) (37089/37248)\n",
            "Epoch: 226 | Batch_idx: 300 |  Loss: (0.0131) | Acc: (99.57%) (38362/38528)\n",
            "Epoch: 226 | Batch_idx: 310 |  Loss: (0.0130) | Acc: (99.57%) (39637/39808)\n",
            "Epoch: 226 | Batch_idx: 320 |  Loss: (0.0132) | Acc: (99.57%) (40911/41088)\n",
            "Epoch: 226 | Batch_idx: 330 |  Loss: (0.0130) | Acc: (99.57%) (42187/42368)\n",
            "Epoch: 226 | Batch_idx: 340 |  Loss: (0.0128) | Acc: (99.58%) (43464/43648)\n",
            "Epoch: 226 | Batch_idx: 350 |  Loss: (0.0127) | Acc: (99.58%) (44739/44928)\n",
            "Epoch: 226 | Batch_idx: 360 |  Loss: (0.0126) | Acc: (99.58%) (46016/46208)\n",
            "Epoch: 226 | Batch_idx: 370 |  Loss: (0.0126) | Acc: (99.59%) (47293/47488)\n",
            "Epoch: 226 | Batch_idx: 380 |  Loss: (0.0127) | Acc: (99.58%) (48564/48768)\n",
            "Epoch: 226 | Batch_idx: 390 |  Loss: (0.0125) | Acc: (99.59%) (49795/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4072) | Acc: (91.87%) (9187/10000)\n",
            "Epoch: 227 | Batch_idx: 0 |  Loss: (0.0697) | Acc: (98.44%) (126/128)\n",
            "Epoch: 227 | Batch_idx: 10 |  Loss: (0.0155) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 227 | Batch_idx: 20 |  Loss: (0.0142) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 227 | Batch_idx: 30 |  Loss: (0.0125) | Acc: (99.65%) (3954/3968)\n",
            "Epoch: 227 | Batch_idx: 40 |  Loss: (0.0114) | Acc: (99.64%) (5229/5248)\n",
            "Epoch: 227 | Batch_idx: 50 |  Loss: (0.0121) | Acc: (99.57%) (6500/6528)\n",
            "Epoch: 227 | Batch_idx: 60 |  Loss: (0.0127) | Acc: (99.53%) (7771/7808)\n",
            "Epoch: 227 | Batch_idx: 70 |  Loss: (0.0123) | Acc: (99.53%) (9045/9088)\n",
            "Epoch: 227 | Batch_idx: 80 |  Loss: (0.0129) | Acc: (99.51%) (10317/10368)\n",
            "Epoch: 227 | Batch_idx: 90 |  Loss: (0.0127) | Acc: (99.49%) (11589/11648)\n",
            "Epoch: 227 | Batch_idx: 100 |  Loss: (0.0124) | Acc: (99.51%) (12865/12928)\n",
            "Epoch: 227 | Batch_idx: 110 |  Loss: (0.0119) | Acc: (99.55%) (14144/14208)\n",
            "Epoch: 227 | Batch_idx: 120 |  Loss: (0.0118) | Acc: (99.55%) (15419/15488)\n",
            "Epoch: 227 | Batch_idx: 130 |  Loss: (0.0119) | Acc: (99.56%) (16695/16768)\n",
            "Epoch: 227 | Batch_idx: 140 |  Loss: (0.0122) | Acc: (99.54%) (17965/18048)\n",
            "Epoch: 227 | Batch_idx: 150 |  Loss: (0.0124) | Acc: (99.53%) (19238/19328)\n",
            "Epoch: 227 | Batch_idx: 160 |  Loss: (0.0122) | Acc: (99.55%) (20515/20608)\n",
            "Epoch: 227 | Batch_idx: 170 |  Loss: (0.0126) | Acc: (99.54%) (21788/21888)\n",
            "Epoch: 227 | Batch_idx: 180 |  Loss: (0.0124) | Acc: (99.56%) (23065/23168)\n",
            "Epoch: 227 | Batch_idx: 190 |  Loss: (0.0123) | Acc: (99.57%) (24342/24448)\n",
            "Epoch: 227 | Batch_idx: 200 |  Loss: (0.0124) | Acc: (99.56%) (25614/25728)\n",
            "Epoch: 227 | Batch_idx: 210 |  Loss: (0.0124) | Acc: (99.55%) (26887/27008)\n",
            "Epoch: 227 | Batch_idx: 220 |  Loss: (0.0125) | Acc: (99.55%) (28160/28288)\n",
            "Epoch: 227 | Batch_idx: 230 |  Loss: (0.0125) | Acc: (99.55%) (29435/29568)\n",
            "Epoch: 227 | Batch_idx: 240 |  Loss: (0.0125) | Acc: (99.54%) (30707/30848)\n",
            "Epoch: 227 | Batch_idx: 250 |  Loss: (0.0124) | Acc: (99.55%) (31985/32128)\n",
            "Epoch: 227 | Batch_idx: 260 |  Loss: (0.0127) | Acc: (99.55%) (33257/33408)\n",
            "Epoch: 227 | Batch_idx: 270 |  Loss: (0.0127) | Acc: (99.54%) (34530/34688)\n",
            "Epoch: 227 | Batch_idx: 280 |  Loss: (0.0125) | Acc: (99.56%) (35809/35968)\n",
            "Epoch: 227 | Batch_idx: 290 |  Loss: (0.0127) | Acc: (99.56%) (37083/37248)\n",
            "Epoch: 227 | Batch_idx: 300 |  Loss: (0.0129) | Acc: (99.55%) (38355/38528)\n",
            "Epoch: 227 | Batch_idx: 310 |  Loss: (0.0131) | Acc: (99.54%) (39626/39808)\n",
            "Epoch: 227 | Batch_idx: 320 |  Loss: (0.0133) | Acc: (99.53%) (40896/41088)\n",
            "Epoch: 227 | Batch_idx: 330 |  Loss: (0.0132) | Acc: (99.54%) (42172/42368)\n",
            "Epoch: 227 | Batch_idx: 340 |  Loss: (0.0133) | Acc: (99.53%) (43445/43648)\n",
            "Epoch: 227 | Batch_idx: 350 |  Loss: (0.0132) | Acc: (99.54%) (44720/44928)\n",
            "Epoch: 227 | Batch_idx: 360 |  Loss: (0.0134) | Acc: (99.53%) (45992/46208)\n",
            "Epoch: 227 | Batch_idx: 370 |  Loss: (0.0132) | Acc: (99.54%) (47268/47488)\n",
            "Epoch: 227 | Batch_idx: 380 |  Loss: (0.0132) | Acc: (99.54%) (48543/48768)\n",
            "Epoch: 227 | Batch_idx: 390 |  Loss: (0.0132) | Acc: (99.54%) (49768/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4065) | Acc: (91.92%) (9192/10000)\n",
            "Epoch: 228 | Batch_idx: 0 |  Loss: (0.0106) | Acc: (99.22%) (127/128)\n",
            "Epoch: 228 | Batch_idx: 10 |  Loss: (0.0082) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 228 | Batch_idx: 20 |  Loss: (0.0129) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 228 | Batch_idx: 30 |  Loss: (0.0131) | Acc: (99.55%) (3950/3968)\n",
            "Epoch: 228 | Batch_idx: 40 |  Loss: (0.0143) | Acc: (99.54%) (5224/5248)\n",
            "Epoch: 228 | Batch_idx: 50 |  Loss: (0.0147) | Acc: (99.51%) (6496/6528)\n",
            "Epoch: 228 | Batch_idx: 60 |  Loss: (0.0146) | Acc: (99.51%) (7770/7808)\n",
            "Epoch: 228 | Batch_idx: 70 |  Loss: (0.0138) | Acc: (99.54%) (9046/9088)\n",
            "Epoch: 228 | Batch_idx: 80 |  Loss: (0.0137) | Acc: (99.52%) (10318/10368)\n",
            "Epoch: 228 | Batch_idx: 90 |  Loss: (0.0134) | Acc: (99.52%) (11592/11648)\n",
            "Epoch: 228 | Batch_idx: 100 |  Loss: (0.0133) | Acc: (99.52%) (12866/12928)\n",
            "Epoch: 228 | Batch_idx: 110 |  Loss: (0.0132) | Acc: (99.54%) (14142/14208)\n",
            "Epoch: 228 | Batch_idx: 120 |  Loss: (0.0133) | Acc: (99.53%) (15415/15488)\n",
            "Epoch: 228 | Batch_idx: 130 |  Loss: (0.0129) | Acc: (99.55%) (16693/16768)\n",
            "Epoch: 228 | Batch_idx: 140 |  Loss: (0.0129) | Acc: (99.55%) (17966/18048)\n",
            "Epoch: 228 | Batch_idx: 150 |  Loss: (0.0133) | Acc: (99.53%) (19238/19328)\n",
            "Epoch: 228 | Batch_idx: 160 |  Loss: (0.0133) | Acc: (99.53%) (20512/20608)\n",
            "Epoch: 228 | Batch_idx: 170 |  Loss: (0.0131) | Acc: (99.54%) (21788/21888)\n",
            "Epoch: 228 | Batch_idx: 180 |  Loss: (0.0139) | Acc: (99.53%) (23059/23168)\n",
            "Epoch: 228 | Batch_idx: 190 |  Loss: (0.0141) | Acc: (99.51%) (24329/24448)\n",
            "Epoch: 228 | Batch_idx: 200 |  Loss: (0.0140) | Acc: (99.52%) (25605/25728)\n",
            "Epoch: 228 | Batch_idx: 210 |  Loss: (0.0143) | Acc: (99.50%) (26874/27008)\n",
            "Epoch: 228 | Batch_idx: 220 |  Loss: (0.0146) | Acc: (99.49%) (28145/28288)\n",
            "Epoch: 228 | Batch_idx: 230 |  Loss: (0.0144) | Acc: (99.51%) (29422/29568)\n",
            "Epoch: 228 | Batch_idx: 240 |  Loss: (0.0143) | Acc: (99.51%) (30698/30848)\n",
            "Epoch: 228 | Batch_idx: 250 |  Loss: (0.0142) | Acc: (99.52%) (31974/32128)\n",
            "Epoch: 228 | Batch_idx: 260 |  Loss: (0.0140) | Acc: (99.52%) (33248/33408)\n",
            "Epoch: 228 | Batch_idx: 270 |  Loss: (0.0139) | Acc: (99.52%) (34523/34688)\n",
            "Epoch: 228 | Batch_idx: 280 |  Loss: (0.0139) | Acc: (99.53%) (35799/35968)\n",
            "Epoch: 228 | Batch_idx: 290 |  Loss: (0.0137) | Acc: (99.54%) (37077/37248)\n",
            "Epoch: 228 | Batch_idx: 300 |  Loss: (0.0138) | Acc: (99.54%) (38349/38528)\n",
            "Epoch: 228 | Batch_idx: 310 |  Loss: (0.0136) | Acc: (99.54%) (39625/39808)\n",
            "Epoch: 228 | Batch_idx: 320 |  Loss: (0.0137) | Acc: (99.53%) (40896/41088)\n",
            "Epoch: 228 | Batch_idx: 330 |  Loss: (0.0137) | Acc: (99.53%) (42168/42368)\n",
            "Epoch: 228 | Batch_idx: 340 |  Loss: (0.0137) | Acc: (99.53%) (43445/43648)\n",
            "Epoch: 228 | Batch_idx: 350 |  Loss: (0.0138) | Acc: (99.53%) (44716/44928)\n",
            "Epoch: 228 | Batch_idx: 360 |  Loss: (0.0136) | Acc: (99.54%) (45995/46208)\n",
            "Epoch: 228 | Batch_idx: 370 |  Loss: (0.0136) | Acc: (99.55%) (47272/47488)\n",
            "Epoch: 228 | Batch_idx: 380 |  Loss: (0.0136) | Acc: (99.55%) (48548/48768)\n",
            "Epoch: 228 | Batch_idx: 390 |  Loss: (0.0136) | Acc: (99.55%) (49776/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4024) | Acc: (91.82%) (9182/10000)\n",
            "Epoch: 229 | Batch_idx: 0 |  Loss: (0.0155) | Acc: (99.22%) (127/128)\n",
            "Epoch: 229 | Batch_idx: 10 |  Loss: (0.0109) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 229 | Batch_idx: 20 |  Loss: (0.0126) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 229 | Batch_idx: 30 |  Loss: (0.0157) | Acc: (99.42%) (3945/3968)\n",
            "Epoch: 229 | Batch_idx: 40 |  Loss: (0.0155) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 229 | Batch_idx: 50 |  Loss: (0.0160) | Acc: (99.45%) (6492/6528)\n",
            "Epoch: 229 | Batch_idx: 60 |  Loss: (0.0142) | Acc: (99.51%) (7770/7808)\n",
            "Epoch: 229 | Batch_idx: 70 |  Loss: (0.0141) | Acc: (99.48%) (9041/9088)\n",
            "Epoch: 229 | Batch_idx: 80 |  Loss: (0.0147) | Acc: (99.48%) (10314/10368)\n",
            "Epoch: 229 | Batch_idx: 90 |  Loss: (0.0143) | Acc: (99.48%) (11588/11648)\n",
            "Epoch: 229 | Batch_idx: 100 |  Loss: (0.0156) | Acc: (99.44%) (12856/12928)\n",
            "Epoch: 229 | Batch_idx: 110 |  Loss: (0.0152) | Acc: (99.46%) (14131/14208)\n",
            "Epoch: 229 | Batch_idx: 120 |  Loss: (0.0151) | Acc: (99.46%) (15405/15488)\n",
            "Epoch: 229 | Batch_idx: 130 |  Loss: (0.0146) | Acc: (99.48%) (16681/16768)\n",
            "Epoch: 229 | Batch_idx: 140 |  Loss: (0.0143) | Acc: (99.48%) (17954/18048)\n",
            "Epoch: 229 | Batch_idx: 150 |  Loss: (0.0138) | Acc: (99.50%) (19231/19328)\n",
            "Epoch: 229 | Batch_idx: 160 |  Loss: (0.0137) | Acc: (99.51%) (20506/20608)\n",
            "Epoch: 229 | Batch_idx: 170 |  Loss: (0.0134) | Acc: (99.52%) (21782/21888)\n",
            "Epoch: 229 | Batch_idx: 180 |  Loss: (0.0138) | Acc: (99.50%) (23053/23168)\n",
            "Epoch: 229 | Batch_idx: 190 |  Loss: (0.0137) | Acc: (99.51%) (24327/24448)\n",
            "Epoch: 229 | Batch_idx: 200 |  Loss: (0.0136) | Acc: (99.51%) (25601/25728)\n",
            "Epoch: 229 | Batch_idx: 210 |  Loss: (0.0135) | Acc: (99.51%) (26876/27008)\n",
            "Epoch: 229 | Batch_idx: 220 |  Loss: (0.0135) | Acc: (99.52%) (28152/28288)\n",
            "Epoch: 229 | Batch_idx: 230 |  Loss: (0.0133) | Acc: (99.52%) (29426/29568)\n",
            "Epoch: 229 | Batch_idx: 240 |  Loss: (0.0131) | Acc: (99.52%) (30700/30848)\n",
            "Epoch: 229 | Batch_idx: 250 |  Loss: (0.0129) | Acc: (99.53%) (31978/32128)\n",
            "Epoch: 229 | Batch_idx: 260 |  Loss: (0.0127) | Acc: (99.53%) (33251/33408)\n",
            "Epoch: 229 | Batch_idx: 270 |  Loss: (0.0129) | Acc: (99.53%) (34525/34688)\n",
            "Epoch: 229 | Batch_idx: 280 |  Loss: (0.0135) | Acc: (99.52%) (35796/35968)\n",
            "Epoch: 229 | Batch_idx: 290 |  Loss: (0.0134) | Acc: (99.52%) (37069/37248)\n",
            "Epoch: 229 | Batch_idx: 300 |  Loss: (0.0136) | Acc: (99.51%) (38341/38528)\n",
            "Epoch: 229 | Batch_idx: 310 |  Loss: (0.0138) | Acc: (99.51%) (39613/39808)\n",
            "Epoch: 229 | Batch_idx: 320 |  Loss: (0.0139) | Acc: (99.51%) (40886/41088)\n",
            "Epoch: 229 | Batch_idx: 330 |  Loss: (0.0137) | Acc: (99.51%) (42161/42368)\n",
            "Epoch: 229 | Batch_idx: 340 |  Loss: (0.0138) | Acc: (99.51%) (43432/43648)\n",
            "Epoch: 229 | Batch_idx: 350 |  Loss: (0.0136) | Acc: (99.51%) (44709/44928)\n",
            "Epoch: 229 | Batch_idx: 360 |  Loss: (0.0135) | Acc: (99.52%) (45984/46208)\n",
            "Epoch: 229 | Batch_idx: 370 |  Loss: (0.0138) | Acc: (99.51%) (47253/47488)\n",
            "Epoch: 229 | Batch_idx: 380 |  Loss: (0.0136) | Acc: (99.51%) (48530/48768)\n",
            "Epoch: 229 | Batch_idx: 390 |  Loss: (0.0135) | Acc: (99.52%) (49758/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4026) | Acc: (91.80%) (9180/10000)\n",
            "Epoch: 230 | Batch_idx: 0 |  Loss: (0.0076) | Acc: (99.22%) (127/128)\n",
            "Epoch: 230 | Batch_idx: 10 |  Loss: (0.0058) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 230 | Batch_idx: 20 |  Loss: (0.0111) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 230 | Batch_idx: 30 |  Loss: (0.0145) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 230 | Batch_idx: 40 |  Loss: (0.0151) | Acc: (99.50%) (5222/5248)\n",
            "Epoch: 230 | Batch_idx: 50 |  Loss: (0.0148) | Acc: (99.49%) (6495/6528)\n",
            "Epoch: 230 | Batch_idx: 60 |  Loss: (0.0146) | Acc: (99.50%) (7769/7808)\n",
            "Epoch: 230 | Batch_idx: 70 |  Loss: (0.0133) | Acc: (99.55%) (9047/9088)\n",
            "Epoch: 230 | Batch_idx: 80 |  Loss: (0.0140) | Acc: (99.54%) (10320/10368)\n",
            "Epoch: 230 | Batch_idx: 90 |  Loss: (0.0135) | Acc: (99.54%) (11595/11648)\n",
            "Epoch: 230 | Batch_idx: 100 |  Loss: (0.0128) | Acc: (99.57%) (12873/12928)\n",
            "Epoch: 230 | Batch_idx: 110 |  Loss: (0.0126) | Acc: (99.58%) (14148/14208)\n",
            "Epoch: 230 | Batch_idx: 120 |  Loss: (0.0124) | Acc: (99.58%) (15423/15488)\n",
            "Epoch: 230 | Batch_idx: 130 |  Loss: (0.0131) | Acc: (99.56%) (16695/16768)\n",
            "Epoch: 230 | Batch_idx: 140 |  Loss: (0.0131) | Acc: (99.56%) (17969/18048)\n",
            "Epoch: 230 | Batch_idx: 150 |  Loss: (0.0129) | Acc: (99.57%) (19244/19328)\n",
            "Epoch: 230 | Batch_idx: 160 |  Loss: (0.0129) | Acc: (99.56%) (20517/20608)\n",
            "Epoch: 230 | Batch_idx: 170 |  Loss: (0.0126) | Acc: (99.58%) (21795/21888)\n",
            "Epoch: 230 | Batch_idx: 180 |  Loss: (0.0127) | Acc: (99.57%) (23068/23168)\n",
            "Epoch: 230 | Batch_idx: 190 |  Loss: (0.0126) | Acc: (99.57%) (24344/24448)\n",
            "Epoch: 230 | Batch_idx: 200 |  Loss: (0.0125) | Acc: (99.58%) (25621/25728)\n",
            "Epoch: 230 | Batch_idx: 210 |  Loss: (0.0128) | Acc: (99.58%) (26895/27008)\n",
            "Epoch: 230 | Batch_idx: 220 |  Loss: (0.0128) | Acc: (99.59%) (28171/28288)\n",
            "Epoch: 230 | Batch_idx: 230 |  Loss: (0.0127) | Acc: (99.59%) (29448/29568)\n",
            "Epoch: 230 | Batch_idx: 240 |  Loss: (0.0130) | Acc: (99.58%) (30719/30848)\n",
            "Epoch: 230 | Batch_idx: 250 |  Loss: (0.0130) | Acc: (99.58%) (31994/32128)\n",
            "Epoch: 230 | Batch_idx: 260 |  Loss: (0.0130) | Acc: (99.58%) (33268/33408)\n",
            "Epoch: 230 | Batch_idx: 270 |  Loss: (0.0128) | Acc: (99.59%) (34545/34688)\n",
            "Epoch: 230 | Batch_idx: 280 |  Loss: (0.0128) | Acc: (99.59%) (35819/35968)\n",
            "Epoch: 230 | Batch_idx: 290 |  Loss: (0.0128) | Acc: (99.58%) (37093/37248)\n",
            "Epoch: 230 | Batch_idx: 300 |  Loss: (0.0126) | Acc: (99.59%) (38369/38528)\n",
            "Epoch: 230 | Batch_idx: 310 |  Loss: (0.0127) | Acc: (99.58%) (39642/39808)\n",
            "Epoch: 230 | Batch_idx: 320 |  Loss: (0.0125) | Acc: (99.59%) (40921/41088)\n",
            "Epoch: 230 | Batch_idx: 330 |  Loss: (0.0125) | Acc: (99.59%) (42195/42368)\n",
            "Epoch: 230 | Batch_idx: 340 |  Loss: (0.0123) | Acc: (99.60%) (43473/43648)\n",
            "Epoch: 230 | Batch_idx: 350 |  Loss: (0.0125) | Acc: (99.59%) (44745/44928)\n",
            "Epoch: 230 | Batch_idx: 360 |  Loss: (0.0126) | Acc: (99.58%) (46015/46208)\n",
            "Epoch: 230 | Batch_idx: 370 |  Loss: (0.0127) | Acc: (99.58%) (47288/47488)\n",
            "Epoch: 230 | Batch_idx: 380 |  Loss: (0.0127) | Acc: (99.57%) (48560/48768)\n",
            "Epoch: 230 | Batch_idx: 390 |  Loss: (0.0127) | Acc: (99.57%) (49785/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4027) | Acc: (91.81%) (9181/10000)\n",
            "Epoch: 231 | Batch_idx: 0 |  Loss: (0.0004) | Acc: (100.00%) (128/128)\n",
            "Epoch: 231 | Batch_idx: 10 |  Loss: (0.0049) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 231 | Batch_idx: 20 |  Loss: (0.0059) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 231 | Batch_idx: 30 |  Loss: (0.0107) | Acc: (99.65%) (3954/3968)\n",
            "Epoch: 231 | Batch_idx: 40 |  Loss: (0.0096) | Acc: (99.68%) (5231/5248)\n",
            "Epoch: 231 | Batch_idx: 50 |  Loss: (0.0105) | Acc: (99.63%) (6504/6528)\n",
            "Epoch: 231 | Batch_idx: 60 |  Loss: (0.0099) | Acc: (99.68%) (7783/7808)\n",
            "Epoch: 231 | Batch_idx: 70 |  Loss: (0.0104) | Acc: (99.65%) (9056/9088)\n",
            "Epoch: 231 | Batch_idx: 80 |  Loss: (0.0103) | Acc: (99.65%) (10332/10368)\n",
            "Epoch: 231 | Batch_idx: 90 |  Loss: (0.0115) | Acc: (99.62%) (11604/11648)\n",
            "Epoch: 231 | Batch_idx: 100 |  Loss: (0.0114) | Acc: (99.63%) (12880/12928)\n",
            "Epoch: 231 | Batch_idx: 110 |  Loss: (0.0114) | Acc: (99.62%) (14154/14208)\n",
            "Epoch: 231 | Batch_idx: 120 |  Loss: (0.0116) | Acc: (99.60%) (15426/15488)\n",
            "Epoch: 231 | Batch_idx: 130 |  Loss: (0.0118) | Acc: (99.58%) (16697/16768)\n",
            "Epoch: 231 | Batch_idx: 140 |  Loss: (0.0126) | Acc: (99.55%) (17966/18048)\n",
            "Epoch: 231 | Batch_idx: 150 |  Loss: (0.0125) | Acc: (99.56%) (19242/19328)\n",
            "Epoch: 231 | Batch_idx: 160 |  Loss: (0.0123) | Acc: (99.56%) (20517/20608)\n",
            "Epoch: 231 | Batch_idx: 170 |  Loss: (0.0125) | Acc: (99.55%) (21790/21888)\n",
            "Epoch: 231 | Batch_idx: 180 |  Loss: (0.0124) | Acc: (99.56%) (23065/23168)\n",
            "Epoch: 231 | Batch_idx: 190 |  Loss: (0.0123) | Acc: (99.55%) (24339/24448)\n",
            "Epoch: 231 | Batch_idx: 200 |  Loss: (0.0121) | Acc: (99.55%) (25613/25728)\n",
            "Epoch: 231 | Batch_idx: 210 |  Loss: (0.0121) | Acc: (99.56%) (26890/27008)\n",
            "Epoch: 231 | Batch_idx: 220 |  Loss: (0.0121) | Acc: (99.56%) (28164/28288)\n",
            "Epoch: 231 | Batch_idx: 230 |  Loss: (0.0119) | Acc: (99.57%) (29440/29568)\n",
            "Epoch: 231 | Batch_idx: 240 |  Loss: (0.0117) | Acc: (99.57%) (30716/30848)\n",
            "Epoch: 231 | Batch_idx: 250 |  Loss: (0.0121) | Acc: (99.56%) (31986/32128)\n",
            "Epoch: 231 | Batch_idx: 260 |  Loss: (0.0121) | Acc: (99.56%) (33260/33408)\n",
            "Epoch: 231 | Batch_idx: 270 |  Loss: (0.0120) | Acc: (99.56%) (34537/34688)\n",
            "Epoch: 231 | Batch_idx: 280 |  Loss: (0.0119) | Acc: (99.57%) (35812/35968)\n",
            "Epoch: 231 | Batch_idx: 290 |  Loss: (0.0123) | Acc: (99.56%) (37085/37248)\n",
            "Epoch: 231 | Batch_idx: 300 |  Loss: (0.0123) | Acc: (99.56%) (38360/38528)\n",
            "Epoch: 231 | Batch_idx: 310 |  Loss: (0.0123) | Acc: (99.57%) (39636/39808)\n",
            "Epoch: 231 | Batch_idx: 320 |  Loss: (0.0124) | Acc: (99.57%) (40911/41088)\n",
            "Epoch: 231 | Batch_idx: 330 |  Loss: (0.0128) | Acc: (99.57%) (42185/42368)\n",
            "Epoch: 231 | Batch_idx: 340 |  Loss: (0.0128) | Acc: (99.57%) (43461/43648)\n",
            "Epoch: 231 | Batch_idx: 350 |  Loss: (0.0126) | Acc: (99.58%) (44738/44928)\n",
            "Epoch: 231 | Batch_idx: 360 |  Loss: (0.0125) | Acc: (99.58%) (46014/46208)\n",
            "Epoch: 231 | Batch_idx: 370 |  Loss: (0.0126) | Acc: (99.58%) (47289/47488)\n",
            "Epoch: 231 | Batch_idx: 380 |  Loss: (0.0127) | Acc: (99.58%) (48562/48768)\n",
            "Epoch: 231 | Batch_idx: 390 |  Loss: (0.0128) | Acc: (99.57%) (49786/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4041) | Acc: (91.86%) (9186/10000)\n",
            "Epoch: 232 | Batch_idx: 0 |  Loss: (0.0047) | Acc: (100.00%) (128/128)\n",
            "Epoch: 232 | Batch_idx: 10 |  Loss: (0.0256) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 232 | Batch_idx: 20 |  Loss: (0.0201) | Acc: (99.29%) (2669/2688)\n",
            "Epoch: 232 | Batch_idx: 30 |  Loss: (0.0194) | Acc: (99.27%) (3939/3968)\n",
            "Epoch: 232 | Batch_idx: 40 |  Loss: (0.0174) | Acc: (99.35%) (5214/5248)\n",
            "Epoch: 232 | Batch_idx: 50 |  Loss: (0.0157) | Acc: (99.45%) (6492/6528)\n",
            "Epoch: 232 | Batch_idx: 60 |  Loss: (0.0150) | Acc: (99.49%) (7768/7808)\n",
            "Epoch: 232 | Batch_idx: 70 |  Loss: (0.0137) | Acc: (99.53%) (9045/9088)\n",
            "Epoch: 232 | Batch_idx: 80 |  Loss: (0.0133) | Acc: (99.54%) (10320/10368)\n",
            "Epoch: 232 | Batch_idx: 90 |  Loss: (0.0128) | Acc: (99.55%) (11596/11648)\n",
            "Epoch: 232 | Batch_idx: 100 |  Loss: (0.0125) | Acc: (99.56%) (12871/12928)\n",
            "Epoch: 232 | Batch_idx: 110 |  Loss: (0.0121) | Acc: (99.57%) (14147/14208)\n",
            "Epoch: 232 | Batch_idx: 120 |  Loss: (0.0123) | Acc: (99.55%) (15419/15488)\n",
            "Epoch: 232 | Batch_idx: 130 |  Loss: (0.0122) | Acc: (99.57%) (16696/16768)\n",
            "Epoch: 232 | Batch_idx: 140 |  Loss: (0.0125) | Acc: (99.55%) (17967/18048)\n",
            "Epoch: 232 | Batch_idx: 150 |  Loss: (0.0121) | Acc: (99.57%) (19244/19328)\n",
            "Epoch: 232 | Batch_idx: 160 |  Loss: (0.0125) | Acc: (99.57%) (20519/20608)\n",
            "Epoch: 232 | Batch_idx: 170 |  Loss: (0.0128) | Acc: (99.56%) (21792/21888)\n",
            "Epoch: 232 | Batch_idx: 180 |  Loss: (0.0125) | Acc: (99.57%) (23069/23168)\n",
            "Epoch: 232 | Batch_idx: 190 |  Loss: (0.0122) | Acc: (99.59%) (24347/24448)\n",
            "Epoch: 232 | Batch_idx: 200 |  Loss: (0.0120) | Acc: (99.59%) (25622/25728)\n",
            "Epoch: 232 | Batch_idx: 210 |  Loss: (0.0119) | Acc: (99.59%) (26896/27008)\n",
            "Epoch: 232 | Batch_idx: 220 |  Loss: (0.0117) | Acc: (99.60%) (28174/28288)\n",
            "Epoch: 232 | Batch_idx: 230 |  Loss: (0.0119) | Acc: (99.59%) (29448/29568)\n",
            "Epoch: 232 | Batch_idx: 240 |  Loss: (0.0117) | Acc: (99.60%) (30725/30848)\n",
            "Epoch: 232 | Batch_idx: 250 |  Loss: (0.0115) | Acc: (99.61%) (32002/32128)\n",
            "Epoch: 232 | Batch_idx: 260 |  Loss: (0.0114) | Acc: (99.60%) (33276/33408)\n",
            "Epoch: 232 | Batch_idx: 270 |  Loss: (0.0113) | Acc: (99.61%) (34553/34688)\n",
            "Epoch: 232 | Batch_idx: 280 |  Loss: (0.0113) | Acc: (99.61%) (35827/35968)\n",
            "Epoch: 232 | Batch_idx: 290 |  Loss: (0.0112) | Acc: (99.61%) (37101/37248)\n",
            "Epoch: 232 | Batch_idx: 300 |  Loss: (0.0112) | Acc: (99.60%) (38375/38528)\n",
            "Epoch: 232 | Batch_idx: 310 |  Loss: (0.0117) | Acc: (99.59%) (39644/39808)\n",
            "Epoch: 232 | Batch_idx: 320 |  Loss: (0.0116) | Acc: (99.59%) (40921/41088)\n",
            "Epoch: 232 | Batch_idx: 330 |  Loss: (0.0115) | Acc: (99.60%) (42199/42368)\n",
            "Epoch: 232 | Batch_idx: 340 |  Loss: (0.0117) | Acc: (99.59%) (43470/43648)\n",
            "Epoch: 232 | Batch_idx: 350 |  Loss: (0.0120) | Acc: (99.58%) (44740/44928)\n",
            "Epoch: 232 | Batch_idx: 360 |  Loss: (0.0122) | Acc: (99.57%) (46011/46208)\n",
            "Epoch: 232 | Batch_idx: 370 |  Loss: (0.0120) | Acc: (99.58%) (47288/47488)\n",
            "Epoch: 232 | Batch_idx: 380 |  Loss: (0.0119) | Acc: (99.58%) (48565/48768)\n",
            "Epoch: 232 | Batch_idx: 390 |  Loss: (0.0118) | Acc: (99.59%) (49795/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4017) | Acc: (91.82%) (9182/10000)\n",
            "Epoch: 233 | Batch_idx: 0 |  Loss: (0.0015) | Acc: (100.00%) (128/128)\n",
            "Epoch: 233 | Batch_idx: 10 |  Loss: (0.0155) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 233 | Batch_idx: 20 |  Loss: (0.0168) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 233 | Batch_idx: 30 |  Loss: (0.0143) | Acc: (99.55%) (3950/3968)\n",
            "Epoch: 233 | Batch_idx: 40 |  Loss: (0.0124) | Acc: (99.58%) (5226/5248)\n",
            "Epoch: 233 | Batch_idx: 50 |  Loss: (0.0126) | Acc: (99.62%) (6503/6528)\n",
            "Epoch: 233 | Batch_idx: 60 |  Loss: (0.0128) | Acc: (99.62%) (7778/7808)\n",
            "Epoch: 233 | Batch_idx: 70 |  Loss: (0.0126) | Acc: (99.59%) (9051/9088)\n",
            "Epoch: 233 | Batch_idx: 80 |  Loss: (0.0117) | Acc: (99.61%) (10328/10368)\n",
            "Epoch: 233 | Batch_idx: 90 |  Loss: (0.0112) | Acc: (99.63%) (11605/11648)\n",
            "Epoch: 233 | Batch_idx: 100 |  Loss: (0.0111) | Acc: (99.64%) (12882/12928)\n",
            "Epoch: 233 | Batch_idx: 110 |  Loss: (0.0113) | Acc: (99.63%) (14156/14208)\n",
            "Epoch: 233 | Batch_idx: 120 |  Loss: (0.0109) | Acc: (99.65%) (15434/15488)\n",
            "Epoch: 233 | Batch_idx: 130 |  Loss: (0.0115) | Acc: (99.62%) (16704/16768)\n",
            "Epoch: 233 | Batch_idx: 140 |  Loss: (0.0125) | Acc: (99.60%) (17975/18048)\n",
            "Epoch: 233 | Batch_idx: 150 |  Loss: (0.0124) | Acc: (99.59%) (19248/19328)\n",
            "Epoch: 233 | Batch_idx: 160 |  Loss: (0.0120) | Acc: (99.60%) (20526/20608)\n",
            "Epoch: 233 | Batch_idx: 170 |  Loss: (0.0117) | Acc: (99.60%) (21801/21888)\n",
            "Epoch: 233 | Batch_idx: 180 |  Loss: (0.0117) | Acc: (99.60%) (23076/23168)\n",
            "Epoch: 233 | Batch_idx: 190 |  Loss: (0.0121) | Acc: (99.59%) (24347/24448)\n",
            "Epoch: 233 | Batch_idx: 200 |  Loss: (0.0120) | Acc: (99.59%) (25622/25728)\n",
            "Epoch: 233 | Batch_idx: 210 |  Loss: (0.0117) | Acc: (99.60%) (26900/27008)\n",
            "Epoch: 233 | Batch_idx: 220 |  Loss: (0.0117) | Acc: (99.59%) (28172/28288)\n",
            "Epoch: 233 | Batch_idx: 230 |  Loss: (0.0117) | Acc: (99.60%) (29449/29568)\n",
            "Epoch: 233 | Batch_idx: 240 |  Loss: (0.0116) | Acc: (99.59%) (30723/30848)\n",
            "Epoch: 233 | Batch_idx: 250 |  Loss: (0.0117) | Acc: (99.60%) (31998/32128)\n",
            "Epoch: 233 | Batch_idx: 260 |  Loss: (0.0120) | Acc: (99.59%) (33272/33408)\n",
            "Epoch: 233 | Batch_idx: 270 |  Loss: (0.0122) | Acc: (99.58%) (34544/34688)\n",
            "Epoch: 233 | Batch_idx: 280 |  Loss: (0.0122) | Acc: (99.58%) (35818/35968)\n",
            "Epoch: 233 | Batch_idx: 290 |  Loss: (0.0118) | Acc: (99.60%) (37098/37248)\n",
            "Epoch: 233 | Batch_idx: 300 |  Loss: (0.0118) | Acc: (99.60%) (38372/38528)\n",
            "Epoch: 233 | Batch_idx: 310 |  Loss: (0.0116) | Acc: (99.61%) (39651/39808)\n",
            "Epoch: 233 | Batch_idx: 320 |  Loss: (0.0116) | Acc: (99.61%) (40927/41088)\n",
            "Epoch: 233 | Batch_idx: 330 |  Loss: (0.0116) | Acc: (99.60%) (42199/42368)\n",
            "Epoch: 233 | Batch_idx: 340 |  Loss: (0.0120) | Acc: (99.60%) (43472/43648)\n",
            "Epoch: 233 | Batch_idx: 350 |  Loss: (0.0120) | Acc: (99.60%) (44748/44928)\n",
            "Epoch: 233 | Batch_idx: 360 |  Loss: (0.0120) | Acc: (99.60%) (46021/46208)\n",
            "Epoch: 233 | Batch_idx: 370 |  Loss: (0.0119) | Acc: (99.60%) (47296/47488)\n",
            "Epoch: 233 | Batch_idx: 380 |  Loss: (0.0117) | Acc: (99.60%) (48574/48768)\n",
            "Epoch: 233 | Batch_idx: 390 |  Loss: (0.0118) | Acc: (99.60%) (49800/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4080) | Acc: (91.76%) (9176/10000)\n",
            "Epoch: 234 | Batch_idx: 0 |  Loss: (0.0019) | Acc: (100.00%) (128/128)\n",
            "Epoch: 234 | Batch_idx: 10 |  Loss: (0.0066) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 234 | Batch_idx: 20 |  Loss: (0.0121) | Acc: (99.70%) (2680/2688)\n",
            "Epoch: 234 | Batch_idx: 30 |  Loss: (0.0098) | Acc: (99.77%) (3959/3968)\n",
            "Epoch: 234 | Batch_idx: 40 |  Loss: (0.0109) | Acc: (99.73%) (5234/5248)\n",
            "Epoch: 234 | Batch_idx: 50 |  Loss: (0.0104) | Acc: (99.72%) (6510/6528)\n",
            "Epoch: 234 | Batch_idx: 60 |  Loss: (0.0115) | Acc: (99.68%) (7783/7808)\n",
            "Epoch: 234 | Batch_idx: 70 |  Loss: (0.0106) | Acc: (99.70%) (9061/9088)\n",
            "Epoch: 234 | Batch_idx: 80 |  Loss: (0.0101) | Acc: (99.71%) (10338/10368)\n",
            "Epoch: 234 | Batch_idx: 90 |  Loss: (0.0111) | Acc: (99.67%) (11609/11648)\n",
            "Epoch: 234 | Batch_idx: 100 |  Loss: (0.0109) | Acc: (99.67%) (12885/12928)\n",
            "Epoch: 234 | Batch_idx: 110 |  Loss: (0.0107) | Acc: (99.67%) (14161/14208)\n",
            "Epoch: 234 | Batch_idx: 120 |  Loss: (0.0111) | Acc: (99.66%) (15435/15488)\n",
            "Epoch: 234 | Batch_idx: 130 |  Loss: (0.0110) | Acc: (99.65%) (16710/16768)\n",
            "Epoch: 234 | Batch_idx: 140 |  Loss: (0.0112) | Acc: (99.66%) (17986/18048)\n",
            "Epoch: 234 | Batch_idx: 150 |  Loss: (0.0109) | Acc: (99.67%) (19265/19328)\n",
            "Epoch: 234 | Batch_idx: 160 |  Loss: (0.0114) | Acc: (99.67%) (20540/20608)\n",
            "Epoch: 234 | Batch_idx: 170 |  Loss: (0.0113) | Acc: (99.67%) (21816/21888)\n",
            "Epoch: 234 | Batch_idx: 180 |  Loss: (0.0112) | Acc: (99.67%) (23091/23168)\n",
            "Epoch: 234 | Batch_idx: 190 |  Loss: (0.0109) | Acc: (99.68%) (24369/24448)\n",
            "Epoch: 234 | Batch_idx: 200 |  Loss: (0.0112) | Acc: (99.66%) (25641/25728)\n",
            "Epoch: 234 | Batch_idx: 210 |  Loss: (0.0111) | Acc: (99.66%) (26917/27008)\n",
            "Epoch: 234 | Batch_idx: 220 |  Loss: (0.0119) | Acc: (99.63%) (28183/28288)\n",
            "Epoch: 234 | Batch_idx: 230 |  Loss: (0.0121) | Acc: (99.63%) (29458/29568)\n",
            "Epoch: 234 | Batch_idx: 240 |  Loss: (0.0118) | Acc: (99.64%) (30736/30848)\n",
            "Epoch: 234 | Batch_idx: 250 |  Loss: (0.0116) | Acc: (99.64%) (32013/32128)\n",
            "Epoch: 234 | Batch_idx: 260 |  Loss: (0.0117) | Acc: (99.63%) (33284/33408)\n",
            "Epoch: 234 | Batch_idx: 270 |  Loss: (0.0117) | Acc: (99.63%) (34559/34688)\n",
            "Epoch: 234 | Batch_idx: 280 |  Loss: (0.0120) | Acc: (99.62%) (35833/35968)\n",
            "Epoch: 234 | Batch_idx: 290 |  Loss: (0.0122) | Acc: (99.62%) (37105/37248)\n",
            "Epoch: 234 | Batch_idx: 300 |  Loss: (0.0123) | Acc: (99.61%) (38377/38528)\n",
            "Epoch: 234 | Batch_idx: 310 |  Loss: (0.0126) | Acc: (99.60%) (39650/39808)\n",
            "Epoch: 234 | Batch_idx: 320 |  Loss: (0.0124) | Acc: (99.61%) (40928/41088)\n",
            "Epoch: 234 | Batch_idx: 330 |  Loss: (0.0125) | Acc: (99.60%) (42200/42368)\n",
            "Epoch: 234 | Batch_idx: 340 |  Loss: (0.0125) | Acc: (99.61%) (43476/43648)\n",
            "Epoch: 234 | Batch_idx: 350 |  Loss: (0.0125) | Acc: (99.61%) (44751/44928)\n",
            "Epoch: 234 | Batch_idx: 360 |  Loss: (0.0126) | Acc: (99.60%) (46024/46208)\n",
            "Epoch: 234 | Batch_idx: 370 |  Loss: (0.0126) | Acc: (99.60%) (47300/47488)\n",
            "Epoch: 234 | Batch_idx: 380 |  Loss: (0.0126) | Acc: (99.60%) (48574/48768)\n",
            "Epoch: 234 | Batch_idx: 390 |  Loss: (0.0127) | Acc: (99.60%) (49799/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4038) | Acc: (91.83%) (9183/10000)\n",
            "Epoch: 235 | Batch_idx: 0 |  Loss: (0.0022) | Acc: (100.00%) (128/128)\n",
            "Epoch: 235 | Batch_idx: 10 |  Loss: (0.0067) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 235 | Batch_idx: 20 |  Loss: (0.0108) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 235 | Batch_idx: 30 |  Loss: (0.0110) | Acc: (99.65%) (3954/3968)\n",
            "Epoch: 235 | Batch_idx: 40 |  Loss: (0.0103) | Acc: (99.70%) (5232/5248)\n",
            "Epoch: 235 | Batch_idx: 50 |  Loss: (0.0120) | Acc: (99.66%) (6506/6528)\n",
            "Epoch: 235 | Batch_idx: 60 |  Loss: (0.0120) | Acc: (99.68%) (7783/7808)\n",
            "Epoch: 235 | Batch_idx: 70 |  Loss: (0.0121) | Acc: (99.67%) (9058/9088)\n",
            "Epoch: 235 | Batch_idx: 80 |  Loss: (0.0123) | Acc: (99.67%) (10334/10368)\n",
            "Epoch: 235 | Batch_idx: 90 |  Loss: (0.0121) | Acc: (99.67%) (11610/11648)\n",
            "Epoch: 235 | Batch_idx: 100 |  Loss: (0.0120) | Acc: (99.65%) (12883/12928)\n",
            "Epoch: 235 | Batch_idx: 110 |  Loss: (0.0120) | Acc: (99.64%) (14157/14208)\n",
            "Epoch: 235 | Batch_idx: 120 |  Loss: (0.0116) | Acc: (99.65%) (15434/15488)\n",
            "Epoch: 235 | Batch_idx: 130 |  Loss: (0.0115) | Acc: (99.64%) (16708/16768)\n",
            "Epoch: 235 | Batch_idx: 140 |  Loss: (0.0111) | Acc: (99.65%) (17985/18048)\n",
            "Epoch: 235 | Batch_idx: 150 |  Loss: (0.0115) | Acc: (99.64%) (19259/19328)\n",
            "Epoch: 235 | Batch_idx: 160 |  Loss: (0.0113) | Acc: (99.64%) (20534/20608)\n",
            "Epoch: 235 | Batch_idx: 170 |  Loss: (0.0117) | Acc: (99.62%) (21804/21888)\n",
            "Epoch: 235 | Batch_idx: 180 |  Loss: (0.0114) | Acc: (99.63%) (23083/23168)\n",
            "Epoch: 235 | Batch_idx: 190 |  Loss: (0.0121) | Acc: (99.61%) (24353/24448)\n",
            "Epoch: 235 | Batch_idx: 200 |  Loss: (0.0123) | Acc: (99.60%) (25624/25728)\n",
            "Epoch: 235 | Batch_idx: 210 |  Loss: (0.0123) | Acc: (99.60%) (26900/27008)\n",
            "Epoch: 235 | Batch_idx: 220 |  Loss: (0.0123) | Acc: (99.60%) (28174/28288)\n",
            "Epoch: 235 | Batch_idx: 230 |  Loss: (0.0126) | Acc: (99.59%) (29448/29568)\n",
            "Epoch: 235 | Batch_idx: 240 |  Loss: (0.0123) | Acc: (99.60%) (30725/30848)\n",
            "Epoch: 235 | Batch_idx: 250 |  Loss: (0.0123) | Acc: (99.60%) (32000/32128)\n",
            "Epoch: 235 | Batch_idx: 260 |  Loss: (0.0122) | Acc: (99.60%) (33276/33408)\n",
            "Epoch: 235 | Batch_idx: 270 |  Loss: (0.0120) | Acc: (99.61%) (34552/34688)\n",
            "Epoch: 235 | Batch_idx: 280 |  Loss: (0.0121) | Acc: (99.61%) (35826/35968)\n",
            "Epoch: 235 | Batch_idx: 290 |  Loss: (0.0120) | Acc: (99.61%) (37103/37248)\n",
            "Epoch: 235 | Batch_idx: 300 |  Loss: (0.0122) | Acc: (99.61%) (38377/38528)\n",
            "Epoch: 235 | Batch_idx: 310 |  Loss: (0.0120) | Acc: (99.61%) (39654/39808)\n",
            "Epoch: 235 | Batch_idx: 320 |  Loss: (0.0118) | Acc: (99.62%) (40931/41088)\n",
            "Epoch: 235 | Batch_idx: 330 |  Loss: (0.0117) | Acc: (99.62%) (42207/42368)\n",
            "Epoch: 235 | Batch_idx: 340 |  Loss: (0.0118) | Acc: (99.62%) (43482/43648)\n",
            "Epoch: 235 | Batch_idx: 350 |  Loss: (0.0117) | Acc: (99.62%) (44757/44928)\n",
            "Epoch: 235 | Batch_idx: 360 |  Loss: (0.0119) | Acc: (99.61%) (46029/46208)\n",
            "Epoch: 235 | Batch_idx: 370 |  Loss: (0.0119) | Acc: (99.61%) (47304/47488)\n",
            "Epoch: 235 | Batch_idx: 380 |  Loss: (0.0120) | Acc: (99.61%) (48577/48768)\n",
            "Epoch: 235 | Batch_idx: 390 |  Loss: (0.0122) | Acc: (99.60%) (49802/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4071) | Acc: (91.78%) (9178/10000)\n",
            "Epoch: 236 | Batch_idx: 0 |  Loss: (0.0111) | Acc: (99.22%) (127/128)\n",
            "Epoch: 236 | Batch_idx: 10 |  Loss: (0.0120) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 236 | Batch_idx: 20 |  Loss: (0.0102) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 236 | Batch_idx: 30 |  Loss: (0.0088) | Acc: (99.67%) (3955/3968)\n",
            "Epoch: 236 | Batch_idx: 40 |  Loss: (0.0107) | Acc: (99.66%) (5230/5248)\n",
            "Epoch: 236 | Batch_idx: 50 |  Loss: (0.0113) | Acc: (99.62%) (6503/6528)\n",
            "Epoch: 236 | Batch_idx: 60 |  Loss: (0.0121) | Acc: (99.59%) (7776/7808)\n",
            "Epoch: 236 | Batch_idx: 70 |  Loss: (0.0134) | Acc: (99.52%) (9044/9088)\n",
            "Epoch: 236 | Batch_idx: 80 |  Loss: (0.0131) | Acc: (99.53%) (10319/10368)\n",
            "Epoch: 236 | Batch_idx: 90 |  Loss: (0.0129) | Acc: (99.54%) (11595/11648)\n",
            "Epoch: 236 | Batch_idx: 100 |  Loss: (0.0129) | Acc: (99.55%) (12870/12928)\n",
            "Epoch: 236 | Batch_idx: 110 |  Loss: (0.0130) | Acc: (99.56%) (14145/14208)\n",
            "Epoch: 236 | Batch_idx: 120 |  Loss: (0.0127) | Acc: (99.56%) (15420/15488)\n",
            "Epoch: 236 | Batch_idx: 130 |  Loss: (0.0125) | Acc: (99.57%) (16696/16768)\n",
            "Epoch: 236 | Batch_idx: 140 |  Loss: (0.0123) | Acc: (99.57%) (17970/18048)\n",
            "Epoch: 236 | Batch_idx: 150 |  Loss: (0.0124) | Acc: (99.56%) (19243/19328)\n",
            "Epoch: 236 | Batch_idx: 160 |  Loss: (0.0125) | Acc: (99.56%) (20518/20608)\n",
            "Epoch: 236 | Batch_idx: 170 |  Loss: (0.0126) | Acc: (99.56%) (21792/21888)\n",
            "Epoch: 236 | Batch_idx: 180 |  Loss: (0.0126) | Acc: (99.57%) (23068/23168)\n",
            "Epoch: 236 | Batch_idx: 190 |  Loss: (0.0128) | Acc: (99.57%) (24344/24448)\n",
            "Epoch: 236 | Batch_idx: 200 |  Loss: (0.0131) | Acc: (99.56%) (25614/25728)\n",
            "Epoch: 236 | Batch_idx: 210 |  Loss: (0.0136) | Acc: (99.54%) (26885/27008)\n",
            "Epoch: 236 | Batch_idx: 220 |  Loss: (0.0138) | Acc: (99.54%) (28158/28288)\n",
            "Epoch: 236 | Batch_idx: 230 |  Loss: (0.0137) | Acc: (99.54%) (29433/29568)\n",
            "Epoch: 236 | Batch_idx: 240 |  Loss: (0.0136) | Acc: (99.55%) (30709/30848)\n",
            "Epoch: 236 | Batch_idx: 250 |  Loss: (0.0133) | Acc: (99.56%) (31987/32128)\n",
            "Epoch: 236 | Batch_idx: 260 |  Loss: (0.0131) | Acc: (99.56%) (33261/33408)\n",
            "Epoch: 236 | Batch_idx: 270 |  Loss: (0.0130) | Acc: (99.56%) (34536/34688)\n",
            "Epoch: 236 | Batch_idx: 280 |  Loss: (0.0128) | Acc: (99.57%) (35813/35968)\n",
            "Epoch: 236 | Batch_idx: 290 |  Loss: (0.0129) | Acc: (99.57%) (37088/37248)\n",
            "Epoch: 236 | Batch_idx: 300 |  Loss: (0.0129) | Acc: (99.57%) (38363/38528)\n",
            "Epoch: 236 | Batch_idx: 310 |  Loss: (0.0130) | Acc: (99.56%) (39633/39808)\n",
            "Epoch: 236 | Batch_idx: 320 |  Loss: (0.0131) | Acc: (99.56%) (40907/41088)\n",
            "Epoch: 236 | Batch_idx: 330 |  Loss: (0.0130) | Acc: (99.57%) (42184/42368)\n",
            "Epoch: 236 | Batch_idx: 340 |  Loss: (0.0129) | Acc: (99.57%) (43461/43648)\n",
            "Epoch: 236 | Batch_idx: 350 |  Loss: (0.0130) | Acc: (99.57%) (44734/44928)\n",
            "Epoch: 236 | Batch_idx: 360 |  Loss: (0.0130) | Acc: (99.57%) (46009/46208)\n",
            "Epoch: 236 | Batch_idx: 370 |  Loss: (0.0129) | Acc: (99.57%) (47282/47488)\n",
            "Epoch: 236 | Batch_idx: 380 |  Loss: (0.0129) | Acc: (99.56%) (48555/48768)\n",
            "Epoch: 236 | Batch_idx: 390 |  Loss: (0.0129) | Acc: (99.56%) (49781/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4101) | Acc: (91.70%) (9170/10000)\n",
            "Epoch: 237 | Batch_idx: 0 |  Loss: (0.0016) | Acc: (100.00%) (128/128)\n",
            "Epoch: 237 | Batch_idx: 10 |  Loss: (0.0067) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 237 | Batch_idx: 20 |  Loss: (0.0090) | Acc: (99.63%) (2678/2688)\n",
            "Epoch: 237 | Batch_idx: 30 |  Loss: (0.0120) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 237 | Batch_idx: 40 |  Loss: (0.0146) | Acc: (99.43%) (5218/5248)\n",
            "Epoch: 237 | Batch_idx: 50 |  Loss: (0.0136) | Acc: (99.46%) (6493/6528)\n",
            "Epoch: 237 | Batch_idx: 60 |  Loss: (0.0131) | Acc: (99.50%) (7769/7808)\n",
            "Epoch: 237 | Batch_idx: 70 |  Loss: (0.0130) | Acc: (99.52%) (9044/9088)\n",
            "Epoch: 237 | Batch_idx: 80 |  Loss: (0.0157) | Acc: (99.43%) (10309/10368)\n",
            "Epoch: 237 | Batch_idx: 90 |  Loss: (0.0154) | Acc: (99.43%) (11582/11648)\n",
            "Epoch: 237 | Batch_idx: 100 |  Loss: (0.0153) | Acc: (99.42%) (12853/12928)\n",
            "Epoch: 237 | Batch_idx: 110 |  Loss: (0.0152) | Acc: (99.42%) (14126/14208)\n",
            "Epoch: 237 | Batch_idx: 120 |  Loss: (0.0148) | Acc: (99.43%) (15400/15488)\n",
            "Epoch: 237 | Batch_idx: 130 |  Loss: (0.0149) | Acc: (99.45%) (16675/16768)\n",
            "Epoch: 237 | Batch_idx: 140 |  Loss: (0.0142) | Acc: (99.47%) (17953/18048)\n",
            "Epoch: 237 | Batch_idx: 150 |  Loss: (0.0140) | Acc: (99.49%) (19229/19328)\n",
            "Epoch: 237 | Batch_idx: 160 |  Loss: (0.0135) | Acc: (99.51%) (20506/20608)\n",
            "Epoch: 237 | Batch_idx: 170 |  Loss: (0.0132) | Acc: (99.52%) (21784/21888)\n",
            "Epoch: 237 | Batch_idx: 180 |  Loss: (0.0133) | Acc: (99.53%) (23058/23168)\n",
            "Epoch: 237 | Batch_idx: 190 |  Loss: (0.0131) | Acc: (99.54%) (24335/24448)\n",
            "Epoch: 237 | Batch_idx: 200 |  Loss: (0.0130) | Acc: (99.54%) (25609/25728)\n",
            "Epoch: 237 | Batch_idx: 210 |  Loss: (0.0130) | Acc: (99.54%) (26883/27008)\n",
            "Epoch: 237 | Batch_idx: 220 |  Loss: (0.0129) | Acc: (99.54%) (28159/28288)\n",
            "Epoch: 237 | Batch_idx: 230 |  Loss: (0.0132) | Acc: (99.54%) (29432/29568)\n",
            "Epoch: 237 | Batch_idx: 240 |  Loss: (0.0131) | Acc: (99.55%) (30708/30848)\n",
            "Epoch: 237 | Batch_idx: 250 |  Loss: (0.0130) | Acc: (99.55%) (31982/32128)\n",
            "Epoch: 237 | Batch_idx: 260 |  Loss: (0.0127) | Acc: (99.55%) (33259/33408)\n",
            "Epoch: 237 | Batch_idx: 270 |  Loss: (0.0126) | Acc: (99.55%) (34533/34688)\n",
            "Epoch: 237 | Batch_idx: 280 |  Loss: (0.0127) | Acc: (99.55%) (35806/35968)\n",
            "Epoch: 237 | Batch_idx: 290 |  Loss: (0.0129) | Acc: (99.54%) (37078/37248)\n",
            "Epoch: 237 | Batch_idx: 300 |  Loss: (0.0127) | Acc: (99.55%) (38355/38528)\n",
            "Epoch: 237 | Batch_idx: 310 |  Loss: (0.0128) | Acc: (99.55%) (39628/39808)\n",
            "Epoch: 237 | Batch_idx: 320 |  Loss: (0.0127) | Acc: (99.55%) (40905/41088)\n",
            "Epoch: 237 | Batch_idx: 330 |  Loss: (0.0128) | Acc: (99.55%) (42178/42368)\n",
            "Epoch: 237 | Batch_idx: 340 |  Loss: (0.0127) | Acc: (99.55%) (43453/43648)\n",
            "Epoch: 237 | Batch_idx: 350 |  Loss: (0.0125) | Acc: (99.56%) (44730/44928)\n",
            "Epoch: 237 | Batch_idx: 360 |  Loss: (0.0125) | Acc: (99.56%) (46004/46208)\n",
            "Epoch: 237 | Batch_idx: 370 |  Loss: (0.0125) | Acc: (99.57%) (47282/47488)\n",
            "Epoch: 237 | Batch_idx: 380 |  Loss: (0.0125) | Acc: (99.57%) (48558/48768)\n",
            "Epoch: 237 | Batch_idx: 390 |  Loss: (0.0124) | Acc: (99.57%) (49785/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4022) | Acc: (91.94%) (9194/10000)\n",
            "Epoch: 238 | Batch_idx: 0 |  Loss: (0.0232) | Acc: (99.22%) (127/128)\n",
            "Epoch: 238 | Batch_idx: 10 |  Loss: (0.0086) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 238 | Batch_idx: 20 |  Loss: (0.0088) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 238 | Batch_idx: 30 |  Loss: (0.0114) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 238 | Batch_idx: 40 |  Loss: (0.0136) | Acc: (99.56%) (5225/5248)\n",
            "Epoch: 238 | Batch_idx: 50 |  Loss: (0.0144) | Acc: (99.53%) (6497/6528)\n",
            "Epoch: 238 | Batch_idx: 60 |  Loss: (0.0143) | Acc: (99.53%) (7771/7808)\n",
            "Epoch: 238 | Batch_idx: 70 |  Loss: (0.0155) | Acc: (99.46%) (9039/9088)\n",
            "Epoch: 238 | Batch_idx: 80 |  Loss: (0.0144) | Acc: (99.50%) (10316/10368)\n",
            "Epoch: 238 | Batch_idx: 90 |  Loss: (0.0136) | Acc: (99.53%) (11593/11648)\n",
            "Epoch: 238 | Batch_idx: 100 |  Loss: (0.0137) | Acc: (99.51%) (12865/12928)\n",
            "Epoch: 238 | Batch_idx: 110 |  Loss: (0.0138) | Acc: (99.52%) (14140/14208)\n",
            "Epoch: 238 | Batch_idx: 120 |  Loss: (0.0141) | Acc: (99.51%) (15412/15488)\n",
            "Epoch: 238 | Batch_idx: 130 |  Loss: (0.0136) | Acc: (99.54%) (16691/16768)\n",
            "Epoch: 238 | Batch_idx: 140 |  Loss: (0.0131) | Acc: (99.55%) (17967/18048)\n",
            "Epoch: 238 | Batch_idx: 150 |  Loss: (0.0132) | Acc: (99.54%) (19240/19328)\n",
            "Epoch: 238 | Batch_idx: 160 |  Loss: (0.0130) | Acc: (99.54%) (20514/20608)\n",
            "Epoch: 238 | Batch_idx: 170 |  Loss: (0.0131) | Acc: (99.55%) (21789/21888)\n",
            "Epoch: 238 | Batch_idx: 180 |  Loss: (0.0129) | Acc: (99.55%) (23063/23168)\n",
            "Epoch: 238 | Batch_idx: 190 |  Loss: (0.0129) | Acc: (99.55%) (24338/24448)\n",
            "Epoch: 238 | Batch_idx: 200 |  Loss: (0.0136) | Acc: (99.54%) (25609/25728)\n",
            "Epoch: 238 | Batch_idx: 210 |  Loss: (0.0134) | Acc: (99.54%) (26884/27008)\n",
            "Epoch: 238 | Batch_idx: 220 |  Loss: (0.0133) | Acc: (99.54%) (28158/28288)\n",
            "Epoch: 238 | Batch_idx: 230 |  Loss: (0.0135) | Acc: (99.54%) (29431/29568)\n",
            "Epoch: 238 | Batch_idx: 240 |  Loss: (0.0132) | Acc: (99.54%) (30706/30848)\n",
            "Epoch: 238 | Batch_idx: 250 |  Loss: (0.0134) | Acc: (99.54%) (31979/32128)\n",
            "Epoch: 238 | Batch_idx: 260 |  Loss: (0.0132) | Acc: (99.55%) (33258/33408)\n",
            "Epoch: 238 | Batch_idx: 270 |  Loss: (0.0129) | Acc: (99.56%) (34535/34688)\n",
            "Epoch: 238 | Batch_idx: 280 |  Loss: (0.0129) | Acc: (99.56%) (35810/35968)\n",
            "Epoch: 238 | Batch_idx: 290 |  Loss: (0.0129) | Acc: (99.57%) (37086/37248)\n",
            "Epoch: 238 | Batch_idx: 300 |  Loss: (0.0127) | Acc: (99.57%) (38364/38528)\n",
            "Epoch: 238 | Batch_idx: 310 |  Loss: (0.0125) | Acc: (99.58%) (39640/39808)\n",
            "Epoch: 238 | Batch_idx: 320 |  Loss: (0.0126) | Acc: (99.58%) (40914/41088)\n",
            "Epoch: 238 | Batch_idx: 330 |  Loss: (0.0124) | Acc: (99.58%) (42192/42368)\n",
            "Epoch: 238 | Batch_idx: 340 |  Loss: (0.0126) | Acc: (99.57%) (43460/43648)\n",
            "Epoch: 238 | Batch_idx: 350 |  Loss: (0.0128) | Acc: (99.56%) (44731/44928)\n",
            "Epoch: 238 | Batch_idx: 360 |  Loss: (0.0126) | Acc: (99.56%) (46006/46208)\n",
            "Epoch: 238 | Batch_idx: 370 |  Loss: (0.0126) | Acc: (99.57%) (47283/47488)\n",
            "Epoch: 238 | Batch_idx: 380 |  Loss: (0.0124) | Acc: (99.57%) (48560/48768)\n",
            "Epoch: 238 | Batch_idx: 390 |  Loss: (0.0126) | Acc: (99.57%) (49784/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4045) | Acc: (91.88%) (9188/10000)\n",
            "Epoch: 239 | Batch_idx: 0 |  Loss: (0.0426) | Acc: (98.44%) (126/128)\n",
            "Epoch: 239 | Batch_idx: 10 |  Loss: (0.0125) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 239 | Batch_idx: 20 |  Loss: (0.0134) | Acc: (99.52%) (2675/2688)\n",
            "Epoch: 239 | Batch_idx: 30 |  Loss: (0.0139) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 239 | Batch_idx: 40 |  Loss: (0.0127) | Acc: (99.54%) (5224/5248)\n",
            "Epoch: 239 | Batch_idx: 50 |  Loss: (0.0131) | Acc: (99.54%) (6498/6528)\n",
            "Epoch: 239 | Batch_idx: 60 |  Loss: (0.0126) | Acc: (99.56%) (7774/7808)\n",
            "Epoch: 239 | Batch_idx: 70 |  Loss: (0.0130) | Acc: (99.56%) (9048/9088)\n",
            "Epoch: 239 | Batch_idx: 80 |  Loss: (0.0140) | Acc: (99.53%) (10319/10368)\n",
            "Epoch: 239 | Batch_idx: 90 |  Loss: (0.0135) | Acc: (99.54%) (11595/11648)\n",
            "Epoch: 239 | Batch_idx: 100 |  Loss: (0.0140) | Acc: (99.54%) (12868/12928)\n",
            "Epoch: 239 | Batch_idx: 110 |  Loss: (0.0135) | Acc: (99.55%) (14144/14208)\n",
            "Epoch: 239 | Batch_idx: 120 |  Loss: (0.0132) | Acc: (99.57%) (15421/15488)\n",
            "Epoch: 239 | Batch_idx: 130 |  Loss: (0.0136) | Acc: (99.58%) (16697/16768)\n",
            "Epoch: 239 | Batch_idx: 140 |  Loss: (0.0137) | Acc: (99.56%) (17968/18048)\n",
            "Epoch: 239 | Batch_idx: 150 |  Loss: (0.0135) | Acc: (99.55%) (19241/19328)\n",
            "Epoch: 239 | Batch_idx: 160 |  Loss: (0.0136) | Acc: (99.53%) (20512/20608)\n",
            "Epoch: 239 | Batch_idx: 170 |  Loss: (0.0143) | Acc: (99.52%) (21783/21888)\n",
            "Epoch: 239 | Batch_idx: 180 |  Loss: (0.0140) | Acc: (99.53%) (23060/23168)\n",
            "Epoch: 239 | Batch_idx: 190 |  Loss: (0.0140) | Acc: (99.53%) (24332/24448)\n",
            "Epoch: 239 | Batch_idx: 200 |  Loss: (0.0144) | Acc: (99.52%) (25605/25728)\n",
            "Epoch: 239 | Batch_idx: 210 |  Loss: (0.0143) | Acc: (99.53%) (26881/27008)\n",
            "Epoch: 239 | Batch_idx: 220 |  Loss: (0.0141) | Acc: (99.53%) (28155/28288)\n",
            "Epoch: 239 | Batch_idx: 230 |  Loss: (0.0139) | Acc: (99.54%) (29431/29568)\n",
            "Epoch: 239 | Batch_idx: 240 |  Loss: (0.0137) | Acc: (99.55%) (30709/30848)\n",
            "Epoch: 239 | Batch_idx: 250 |  Loss: (0.0134) | Acc: (99.56%) (31987/32128)\n",
            "Epoch: 239 | Batch_idx: 260 |  Loss: (0.0134) | Acc: (99.55%) (33258/33408)\n",
            "Epoch: 239 | Batch_idx: 270 |  Loss: (0.0133) | Acc: (99.55%) (34532/34688)\n",
            "Epoch: 239 | Batch_idx: 280 |  Loss: (0.0135) | Acc: (99.54%) (35803/35968)\n",
            "Epoch: 239 | Batch_idx: 290 |  Loss: (0.0134) | Acc: (99.54%) (37077/37248)\n",
            "Epoch: 239 | Batch_idx: 300 |  Loss: (0.0137) | Acc: (99.53%) (38346/38528)\n",
            "Epoch: 239 | Batch_idx: 310 |  Loss: (0.0137) | Acc: (99.52%) (39618/39808)\n",
            "Epoch: 239 | Batch_idx: 320 |  Loss: (0.0134) | Acc: (99.53%) (40894/41088)\n",
            "Epoch: 239 | Batch_idx: 330 |  Loss: (0.0135) | Acc: (99.52%) (42163/42368)\n",
            "Epoch: 239 | Batch_idx: 340 |  Loss: (0.0133) | Acc: (99.52%) (43438/43648)\n",
            "Epoch: 239 | Batch_idx: 350 |  Loss: (0.0131) | Acc: (99.53%) (44716/44928)\n",
            "Epoch: 239 | Batch_idx: 360 |  Loss: (0.0132) | Acc: (99.52%) (45987/46208)\n",
            "Epoch: 239 | Batch_idx: 370 |  Loss: (0.0131) | Acc: (99.52%) (47262/47488)\n",
            "Epoch: 239 | Batch_idx: 380 |  Loss: (0.0128) | Acc: (99.53%) (48541/48768)\n",
            "Epoch: 239 | Batch_idx: 390 |  Loss: (0.0128) | Acc: (99.54%) (49769/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4057) | Acc: (91.96%) (9196/10000)\n",
            "Epoch: 240 | Batch_idx: 0 |  Loss: (0.0007) | Acc: (100.00%) (128/128)\n",
            "Epoch: 240 | Batch_idx: 10 |  Loss: (0.0162) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 240 | Batch_idx: 20 |  Loss: (0.0158) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 240 | Batch_idx: 30 |  Loss: (0.0136) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 240 | Batch_idx: 40 |  Loss: (0.0137) | Acc: (99.56%) (5225/5248)\n",
            "Epoch: 240 | Batch_idx: 50 |  Loss: (0.0129) | Acc: (99.57%) (6500/6528)\n",
            "Epoch: 240 | Batch_idx: 60 |  Loss: (0.0133) | Acc: (99.55%) (7773/7808)\n",
            "Epoch: 240 | Batch_idx: 70 |  Loss: (0.0128) | Acc: (99.55%) (9047/9088)\n",
            "Epoch: 240 | Batch_idx: 80 |  Loss: (0.0127) | Acc: (99.57%) (10323/10368)\n",
            "Epoch: 240 | Batch_idx: 90 |  Loss: (0.0124) | Acc: (99.56%) (11597/11648)\n",
            "Epoch: 240 | Batch_idx: 100 |  Loss: (0.0124) | Acc: (99.57%) (12873/12928)\n",
            "Epoch: 240 | Batch_idx: 110 |  Loss: (0.0124) | Acc: (99.56%) (14146/14208)\n",
            "Epoch: 240 | Batch_idx: 120 |  Loss: (0.0123) | Acc: (99.57%) (15421/15488)\n",
            "Epoch: 240 | Batch_idx: 130 |  Loss: (0.0127) | Acc: (99.54%) (16691/16768)\n",
            "Epoch: 240 | Batch_idx: 140 |  Loss: (0.0125) | Acc: (99.55%) (17967/18048)\n",
            "Epoch: 240 | Batch_idx: 150 |  Loss: (0.0125) | Acc: (99.55%) (19241/19328)\n",
            "Epoch: 240 | Batch_idx: 160 |  Loss: (0.0121) | Acc: (99.56%) (20518/20608)\n",
            "Epoch: 240 | Batch_idx: 170 |  Loss: (0.0120) | Acc: (99.58%) (21796/21888)\n",
            "Epoch: 240 | Batch_idx: 180 |  Loss: (0.0117) | Acc: (99.59%) (23073/23168)\n",
            "Epoch: 240 | Batch_idx: 190 |  Loss: (0.0117) | Acc: (99.59%) (24347/24448)\n",
            "Epoch: 240 | Batch_idx: 200 |  Loss: (0.0118) | Acc: (99.58%) (25619/25728)\n",
            "Epoch: 240 | Batch_idx: 210 |  Loss: (0.0114) | Acc: (99.60%) (26899/27008)\n",
            "Epoch: 240 | Batch_idx: 220 |  Loss: (0.0115) | Acc: (99.59%) (28172/28288)\n",
            "Epoch: 240 | Batch_idx: 230 |  Loss: (0.0115) | Acc: (99.59%) (29448/29568)\n",
            "Epoch: 240 | Batch_idx: 240 |  Loss: (0.0114) | Acc: (99.60%) (30726/30848)\n",
            "Epoch: 240 | Batch_idx: 250 |  Loss: (0.0112) | Acc: (99.61%) (32004/32128)\n",
            "Epoch: 240 | Batch_idx: 260 |  Loss: (0.0115) | Acc: (99.60%) (33276/33408)\n",
            "Epoch: 240 | Batch_idx: 270 |  Loss: (0.0115) | Acc: (99.61%) (34554/34688)\n",
            "Epoch: 240 | Batch_idx: 280 |  Loss: (0.0113) | Acc: (99.62%) (35831/35968)\n",
            "Epoch: 240 | Batch_idx: 290 |  Loss: (0.0115) | Acc: (99.61%) (37104/37248)\n",
            "Epoch: 240 | Batch_idx: 300 |  Loss: (0.0114) | Acc: (99.62%) (38381/38528)\n",
            "Epoch: 240 | Batch_idx: 310 |  Loss: (0.0112) | Acc: (99.62%) (39658/39808)\n",
            "Epoch: 240 | Batch_idx: 320 |  Loss: (0.0111) | Acc: (99.63%) (40934/41088)\n",
            "Epoch: 240 | Batch_idx: 330 |  Loss: (0.0110) | Acc: (99.63%) (42210/42368)\n",
            "Epoch: 240 | Batch_idx: 340 |  Loss: (0.0109) | Acc: (99.63%) (43487/43648)\n",
            "Epoch: 240 | Batch_idx: 350 |  Loss: (0.0112) | Acc: (99.63%) (44762/44928)\n",
            "Epoch: 240 | Batch_idx: 360 |  Loss: (0.0113) | Acc: (99.63%) (46037/46208)\n",
            "Epoch: 240 | Batch_idx: 370 |  Loss: (0.0114) | Acc: (99.62%) (47309/47488)\n",
            "Epoch: 240 | Batch_idx: 380 |  Loss: (0.0115) | Acc: (99.62%) (48582/48768)\n",
            "Epoch: 240 | Batch_idx: 390 |  Loss: (0.0117) | Acc: (99.61%) (49805/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4065) | Acc: (91.93%) (9193/10000)\n",
            "Epoch: 241 | Batch_idx: 0 |  Loss: (0.0033) | Acc: (100.00%) (128/128)\n",
            "Epoch: 241 | Batch_idx: 10 |  Loss: (0.0046) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 241 | Batch_idx: 20 |  Loss: (0.0092) | Acc: (99.70%) (2680/2688)\n",
            "Epoch: 241 | Batch_idx: 30 |  Loss: (0.0131) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 241 | Batch_idx: 40 |  Loss: (0.0140) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 241 | Batch_idx: 50 |  Loss: (0.0144) | Acc: (99.51%) (6496/6528)\n",
            "Epoch: 241 | Batch_idx: 60 |  Loss: (0.0152) | Acc: (99.51%) (7770/7808)\n",
            "Epoch: 241 | Batch_idx: 70 |  Loss: (0.0164) | Acc: (99.52%) (9044/9088)\n",
            "Epoch: 241 | Batch_idx: 80 |  Loss: (0.0151) | Acc: (99.55%) (10321/10368)\n",
            "Epoch: 241 | Batch_idx: 90 |  Loss: (0.0145) | Acc: (99.54%) (11595/11648)\n",
            "Epoch: 241 | Batch_idx: 100 |  Loss: (0.0148) | Acc: (99.52%) (12866/12928)\n",
            "Epoch: 241 | Batch_idx: 110 |  Loss: (0.0143) | Acc: (99.54%) (14142/14208)\n",
            "Epoch: 241 | Batch_idx: 120 |  Loss: (0.0143) | Acc: (99.54%) (15416/15488)\n",
            "Epoch: 241 | Batch_idx: 130 |  Loss: (0.0140) | Acc: (99.53%) (16690/16768)\n",
            "Epoch: 241 | Batch_idx: 140 |  Loss: (0.0143) | Acc: (99.52%) (17962/18048)\n",
            "Epoch: 241 | Batch_idx: 150 |  Loss: (0.0143) | Acc: (99.52%) (19236/19328)\n",
            "Epoch: 241 | Batch_idx: 160 |  Loss: (0.0140) | Acc: (99.53%) (20512/20608)\n",
            "Epoch: 241 | Batch_idx: 170 |  Loss: (0.0139) | Acc: (99.54%) (21787/21888)\n",
            "Epoch: 241 | Batch_idx: 180 |  Loss: (0.0145) | Acc: (99.53%) (23059/23168)\n",
            "Epoch: 241 | Batch_idx: 190 |  Loss: (0.0144) | Acc: (99.53%) (24332/24448)\n",
            "Epoch: 241 | Batch_idx: 200 |  Loss: (0.0146) | Acc: (99.52%) (25604/25728)\n",
            "Epoch: 241 | Batch_idx: 210 |  Loss: (0.0149) | Acc: (99.51%) (26877/27008)\n",
            "Epoch: 241 | Batch_idx: 220 |  Loss: (0.0151) | Acc: (99.51%) (28148/28288)\n",
            "Epoch: 241 | Batch_idx: 230 |  Loss: (0.0151) | Acc: (99.50%) (29420/29568)\n",
            "Epoch: 241 | Batch_idx: 240 |  Loss: (0.0150) | Acc: (99.51%) (30696/30848)\n",
            "Epoch: 241 | Batch_idx: 250 |  Loss: (0.0154) | Acc: (99.49%) (31964/32128)\n",
            "Epoch: 241 | Batch_idx: 260 |  Loss: (0.0152) | Acc: (99.49%) (33239/33408)\n",
            "Epoch: 241 | Batch_idx: 270 |  Loss: (0.0149) | Acc: (99.50%) (34515/34688)\n",
            "Epoch: 241 | Batch_idx: 280 |  Loss: (0.0148) | Acc: (99.51%) (35790/35968)\n",
            "Epoch: 241 | Batch_idx: 290 |  Loss: (0.0146) | Acc: (99.51%) (37067/37248)\n",
            "Epoch: 241 | Batch_idx: 300 |  Loss: (0.0146) | Acc: (99.51%) (38341/38528)\n",
            "Epoch: 241 | Batch_idx: 310 |  Loss: (0.0145) | Acc: (99.51%) (39614/39808)\n",
            "Epoch: 241 | Batch_idx: 320 |  Loss: (0.0143) | Acc: (99.52%) (40891/41088)\n",
            "Epoch: 241 | Batch_idx: 330 |  Loss: (0.0142) | Acc: (99.52%) (42166/42368)\n",
            "Epoch: 241 | Batch_idx: 340 |  Loss: (0.0143) | Acc: (99.53%) (43441/43648)\n",
            "Epoch: 241 | Batch_idx: 350 |  Loss: (0.0145) | Acc: (99.51%) (44710/44928)\n",
            "Epoch: 241 | Batch_idx: 360 |  Loss: (0.0143) | Acc: (99.52%) (45988/46208)\n",
            "Epoch: 241 | Batch_idx: 370 |  Loss: (0.0145) | Acc: (99.52%) (47258/47488)\n",
            "Epoch: 241 | Batch_idx: 380 |  Loss: (0.0145) | Acc: (99.52%) (48532/48768)\n",
            "Epoch: 241 | Batch_idx: 390 |  Loss: (0.0145) | Acc: (99.52%) (49758/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4059) | Acc: (91.84%) (9184/10000)\n",
            "Epoch: 242 | Batch_idx: 0 |  Loss: (0.0011) | Acc: (100.00%) (128/128)\n",
            "Epoch: 242 | Batch_idx: 10 |  Loss: (0.0111) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 242 | Batch_idx: 20 |  Loss: (0.0096) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 242 | Batch_idx: 30 |  Loss: (0.0083) | Acc: (99.62%) (3953/3968)\n",
            "Epoch: 242 | Batch_idx: 40 |  Loss: (0.0075) | Acc: (99.68%) (5231/5248)\n",
            "Epoch: 242 | Batch_idx: 50 |  Loss: (0.0083) | Acc: (99.69%) (6508/6528)\n",
            "Epoch: 242 | Batch_idx: 60 |  Loss: (0.0079) | Acc: (99.72%) (7786/7808)\n",
            "Epoch: 242 | Batch_idx: 70 |  Loss: (0.0084) | Acc: (99.71%) (9062/9088)\n",
            "Epoch: 242 | Batch_idx: 80 |  Loss: (0.0091) | Acc: (99.67%) (10334/10368)\n",
            "Epoch: 242 | Batch_idx: 90 |  Loss: (0.0093) | Acc: (99.69%) (11612/11648)\n",
            "Epoch: 242 | Batch_idx: 100 |  Loss: (0.0095) | Acc: (99.68%) (12887/12928)\n",
            "Epoch: 242 | Batch_idx: 110 |  Loss: (0.0094) | Acc: (99.69%) (14164/14208)\n",
            "Epoch: 242 | Batch_idx: 120 |  Loss: (0.0097) | Acc: (99.69%) (15440/15488)\n",
            "Epoch: 242 | Batch_idx: 130 |  Loss: (0.0093) | Acc: (99.71%) (16719/16768)\n",
            "Epoch: 242 | Batch_idx: 140 |  Loss: (0.0099) | Acc: (99.69%) (17992/18048)\n",
            "Epoch: 242 | Batch_idx: 150 |  Loss: (0.0096) | Acc: (99.69%) (19269/19328)\n",
            "Epoch: 242 | Batch_idx: 160 |  Loss: (0.0093) | Acc: (99.70%) (20546/20608)\n",
            "Epoch: 242 | Batch_idx: 170 |  Loss: (0.0094) | Acc: (99.69%) (21820/21888)\n",
            "Epoch: 242 | Batch_idx: 180 |  Loss: (0.0092) | Acc: (99.69%) (23097/23168)\n",
            "Epoch: 242 | Batch_idx: 190 |  Loss: (0.0089) | Acc: (99.71%) (24376/24448)\n",
            "Epoch: 242 | Batch_idx: 200 |  Loss: (0.0092) | Acc: (99.70%) (25650/25728)\n",
            "Epoch: 242 | Batch_idx: 210 |  Loss: (0.0091) | Acc: (99.70%) (26928/27008)\n",
            "Epoch: 242 | Batch_idx: 220 |  Loss: (0.0092) | Acc: (99.70%) (28202/28288)\n",
            "Epoch: 242 | Batch_idx: 230 |  Loss: (0.0093) | Acc: (99.69%) (29477/29568)\n",
            "Epoch: 242 | Batch_idx: 240 |  Loss: (0.0098) | Acc: (99.68%) (30749/30848)\n",
            "Epoch: 242 | Batch_idx: 250 |  Loss: (0.0098) | Acc: (99.69%) (32027/32128)\n",
            "Epoch: 242 | Batch_idx: 260 |  Loss: (0.0099) | Acc: (99.69%) (33304/33408)\n",
            "Epoch: 242 | Batch_idx: 270 |  Loss: (0.0101) | Acc: (99.68%) (34576/34688)\n",
            "Epoch: 242 | Batch_idx: 280 |  Loss: (0.0101) | Acc: (99.68%) (35852/35968)\n",
            "Epoch: 242 | Batch_idx: 290 |  Loss: (0.0105) | Acc: (99.66%) (37123/37248)\n",
            "Epoch: 242 | Batch_idx: 300 |  Loss: (0.0105) | Acc: (99.67%) (38401/38528)\n",
            "Epoch: 242 | Batch_idx: 310 |  Loss: (0.0103) | Acc: (99.68%) (39679/39808)\n",
            "Epoch: 242 | Batch_idx: 320 |  Loss: (0.0104) | Acc: (99.67%) (40952/41088)\n",
            "Epoch: 242 | Batch_idx: 330 |  Loss: (0.0105) | Acc: (99.66%) (42226/42368)\n",
            "Epoch: 242 | Batch_idx: 340 |  Loss: (0.0104) | Acc: (99.67%) (43502/43648)\n",
            "Epoch: 242 | Batch_idx: 350 |  Loss: (0.0106) | Acc: (99.65%) (44769/44928)\n",
            "Epoch: 242 | Batch_idx: 360 |  Loss: (0.0105) | Acc: (99.65%) (46046/46208)\n",
            "Epoch: 242 | Batch_idx: 370 |  Loss: (0.0107) | Acc: (99.65%) (47320/47488)\n",
            "Epoch: 242 | Batch_idx: 380 |  Loss: (0.0107) | Acc: (99.65%) (48595/48768)\n",
            "Epoch: 242 | Batch_idx: 390 |  Loss: (0.0108) | Acc: (99.63%) (49817/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4062) | Acc: (91.95%) (9195/10000)\n",
            "Epoch: 243 | Batch_idx: 0 |  Loss: (0.0133) | Acc: (100.00%) (128/128)\n",
            "Epoch: 243 | Batch_idx: 10 |  Loss: (0.0117) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 243 | Batch_idx: 20 |  Loss: (0.0130) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 243 | Batch_idx: 30 |  Loss: (0.0154) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 243 | Batch_idx: 40 |  Loss: (0.0183) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 243 | Batch_idx: 50 |  Loss: (0.0202) | Acc: (99.37%) (6487/6528)\n",
            "Epoch: 243 | Batch_idx: 60 |  Loss: (0.0192) | Acc: (99.37%) (7759/7808)\n",
            "Epoch: 243 | Batch_idx: 70 |  Loss: (0.0181) | Acc: (99.42%) (9035/9088)\n",
            "Epoch: 243 | Batch_idx: 80 |  Loss: (0.0180) | Acc: (99.41%) (10307/10368)\n",
            "Epoch: 243 | Batch_idx: 90 |  Loss: (0.0175) | Acc: (99.42%) (11581/11648)\n",
            "Epoch: 243 | Batch_idx: 100 |  Loss: (0.0165) | Acc: (99.46%) (12858/12928)\n",
            "Epoch: 243 | Batch_idx: 110 |  Loss: (0.0178) | Acc: (99.39%) (14122/14208)\n",
            "Epoch: 243 | Batch_idx: 120 |  Loss: (0.0175) | Acc: (99.41%) (15397/15488)\n",
            "Epoch: 243 | Batch_idx: 130 |  Loss: (0.0172) | Acc: (99.42%) (16671/16768)\n",
            "Epoch: 243 | Batch_idx: 140 |  Loss: (0.0165) | Acc: (99.45%) (17948/18048)\n",
            "Epoch: 243 | Batch_idx: 150 |  Loss: (0.0170) | Acc: (99.43%) (19217/19328)\n",
            "Epoch: 243 | Batch_idx: 160 |  Loss: (0.0168) | Acc: (99.44%) (20492/20608)\n",
            "Epoch: 243 | Batch_idx: 170 |  Loss: (0.0163) | Acc: (99.46%) (21769/21888)\n",
            "Epoch: 243 | Batch_idx: 180 |  Loss: (0.0162) | Acc: (99.47%) (23045/23168)\n",
            "Epoch: 243 | Batch_idx: 190 |  Loss: (0.0161) | Acc: (99.47%) (24319/24448)\n",
            "Epoch: 243 | Batch_idx: 200 |  Loss: (0.0160) | Acc: (99.48%) (25593/25728)\n",
            "Epoch: 243 | Batch_idx: 210 |  Loss: (0.0160) | Acc: (99.47%) (26866/27008)\n",
            "Epoch: 243 | Batch_idx: 220 |  Loss: (0.0158) | Acc: (99.48%) (28141/28288)\n",
            "Epoch: 243 | Batch_idx: 230 |  Loss: (0.0154) | Acc: (99.50%) (29420/29568)\n",
            "Epoch: 243 | Batch_idx: 240 |  Loss: (0.0154) | Acc: (99.50%) (30693/30848)\n",
            "Epoch: 243 | Batch_idx: 250 |  Loss: (0.0152) | Acc: (99.50%) (31968/32128)\n",
            "Epoch: 243 | Batch_idx: 260 |  Loss: (0.0150) | Acc: (99.51%) (33243/33408)\n",
            "Epoch: 243 | Batch_idx: 270 |  Loss: (0.0147) | Acc: (99.52%) (34520/34688)\n",
            "Epoch: 243 | Batch_idx: 280 |  Loss: (0.0145) | Acc: (99.53%) (35798/35968)\n",
            "Epoch: 243 | Batch_idx: 290 |  Loss: (0.0144) | Acc: (99.53%) (37074/37248)\n",
            "Epoch: 243 | Batch_idx: 300 |  Loss: (0.0143) | Acc: (99.53%) (38348/38528)\n",
            "Epoch: 243 | Batch_idx: 310 |  Loss: (0.0142) | Acc: (99.53%) (39620/39808)\n",
            "Epoch: 243 | Batch_idx: 320 |  Loss: (0.0141) | Acc: (99.53%) (40895/41088)\n",
            "Epoch: 243 | Batch_idx: 330 |  Loss: (0.0141) | Acc: (99.53%) (42169/42368)\n",
            "Epoch: 243 | Batch_idx: 340 |  Loss: (0.0139) | Acc: (99.54%) (43447/43648)\n",
            "Epoch: 243 | Batch_idx: 350 |  Loss: (0.0140) | Acc: (99.53%) (44717/44928)\n",
            "Epoch: 243 | Batch_idx: 360 |  Loss: (0.0139) | Acc: (99.53%) (45993/46208)\n",
            "Epoch: 243 | Batch_idx: 370 |  Loss: (0.0138) | Acc: (99.53%) (47264/47488)\n",
            "Epoch: 243 | Batch_idx: 380 |  Loss: (0.0137) | Acc: (99.53%) (48540/48768)\n",
            "Epoch: 243 | Batch_idx: 390 |  Loss: (0.0136) | Acc: (99.54%) (49770/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4042) | Acc: (91.83%) (9183/10000)\n",
            "Epoch: 244 | Batch_idx: 0 |  Loss: (0.0012) | Acc: (100.00%) (128/128)\n",
            "Epoch: 244 | Batch_idx: 10 |  Loss: (0.0088) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 244 | Batch_idx: 20 |  Loss: (0.0165) | Acc: (99.52%) (2675/2688)\n",
            "Epoch: 244 | Batch_idx: 30 |  Loss: (0.0139) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 244 | Batch_idx: 40 |  Loss: (0.0139) | Acc: (99.58%) (5226/5248)\n",
            "Epoch: 244 | Batch_idx: 50 |  Loss: (0.0149) | Acc: (99.54%) (6498/6528)\n",
            "Epoch: 244 | Batch_idx: 60 |  Loss: (0.0133) | Acc: (99.59%) (7776/7808)\n",
            "Epoch: 244 | Batch_idx: 70 |  Loss: (0.0123) | Acc: (99.61%) (9053/9088)\n",
            "Epoch: 244 | Batch_idx: 80 |  Loss: (0.0116) | Acc: (99.65%) (10332/10368)\n",
            "Epoch: 244 | Batch_idx: 90 |  Loss: (0.0113) | Acc: (99.66%) (11608/11648)\n",
            "Epoch: 244 | Batch_idx: 100 |  Loss: (0.0110) | Acc: (99.66%) (12884/12928)\n",
            "Epoch: 244 | Batch_idx: 110 |  Loss: (0.0111) | Acc: (99.66%) (14159/14208)\n",
            "Epoch: 244 | Batch_idx: 120 |  Loss: (0.0115) | Acc: (99.64%) (15432/15488)\n",
            "Epoch: 244 | Batch_idx: 130 |  Loss: (0.0115) | Acc: (99.64%) (16708/16768)\n",
            "Epoch: 244 | Batch_idx: 140 |  Loss: (0.0111) | Acc: (99.66%) (17986/18048)\n",
            "Epoch: 244 | Batch_idx: 150 |  Loss: (0.0109) | Acc: (99.66%) (19263/19328)\n",
            "Epoch: 244 | Batch_idx: 160 |  Loss: (0.0111) | Acc: (99.67%) (20540/20608)\n",
            "Epoch: 244 | Batch_idx: 170 |  Loss: (0.0109) | Acc: (99.68%) (21817/21888)\n",
            "Epoch: 244 | Batch_idx: 180 |  Loss: (0.0107) | Acc: (99.68%) (23094/23168)\n",
            "Epoch: 244 | Batch_idx: 190 |  Loss: (0.0113) | Acc: (99.66%) (24366/24448)\n",
            "Epoch: 244 | Batch_idx: 200 |  Loss: (0.0114) | Acc: (99.65%) (25639/25728)\n",
            "Epoch: 244 | Batch_idx: 210 |  Loss: (0.0114) | Acc: (99.64%) (26912/27008)\n",
            "Epoch: 244 | Batch_idx: 220 |  Loss: (0.0112) | Acc: (99.65%) (28190/28288)\n",
            "Epoch: 244 | Batch_idx: 230 |  Loss: (0.0110) | Acc: (99.66%) (29468/29568)\n",
            "Epoch: 244 | Batch_idx: 240 |  Loss: (0.0109) | Acc: (99.66%) (30744/30848)\n",
            "Epoch: 244 | Batch_idx: 250 |  Loss: (0.0107) | Acc: (99.67%) (32022/32128)\n",
            "Epoch: 244 | Batch_idx: 260 |  Loss: (0.0106) | Acc: (99.67%) (33297/33408)\n",
            "Epoch: 244 | Batch_idx: 270 |  Loss: (0.0105) | Acc: (99.67%) (34574/34688)\n",
            "Epoch: 244 | Batch_idx: 280 |  Loss: (0.0106) | Acc: (99.67%) (35849/35968)\n",
            "Epoch: 244 | Batch_idx: 290 |  Loss: (0.0106) | Acc: (99.66%) (37122/37248)\n",
            "Epoch: 244 | Batch_idx: 300 |  Loss: (0.0107) | Acc: (99.66%) (38396/38528)\n",
            "Epoch: 244 | Batch_idx: 310 |  Loss: (0.0107) | Acc: (99.66%) (39672/39808)\n",
            "Epoch: 244 | Batch_idx: 320 |  Loss: (0.0107) | Acc: (99.66%) (40947/41088)\n",
            "Epoch: 244 | Batch_idx: 330 |  Loss: (0.0110) | Acc: (99.66%) (42222/42368)\n",
            "Epoch: 244 | Batch_idx: 340 |  Loss: (0.0111) | Acc: (99.64%) (43493/43648)\n",
            "Epoch: 244 | Batch_idx: 350 |  Loss: (0.0110) | Acc: (99.65%) (44771/44928)\n",
            "Epoch: 244 | Batch_idx: 360 |  Loss: (0.0114) | Acc: (99.64%) (46041/46208)\n",
            "Epoch: 244 | Batch_idx: 370 |  Loss: (0.0112) | Acc: (99.64%) (47318/47488)\n",
            "Epoch: 244 | Batch_idx: 380 |  Loss: (0.0114) | Acc: (99.64%) (48591/48768)\n",
            "Epoch: 244 | Batch_idx: 390 |  Loss: (0.0114) | Acc: (99.64%) (49819/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4057) | Acc: (91.79%) (9179/10000)\n",
            "Epoch: 245 | Batch_idx: 0 |  Loss: (0.0005) | Acc: (100.00%) (128/128)\n",
            "Epoch: 245 | Batch_idx: 10 |  Loss: (0.0132) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 245 | Batch_idx: 20 |  Loss: (0.0140) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 245 | Batch_idx: 30 |  Loss: (0.0147) | Acc: (99.55%) (3950/3968)\n",
            "Epoch: 245 | Batch_idx: 40 |  Loss: (0.0146) | Acc: (99.49%) (5221/5248)\n",
            "Epoch: 245 | Batch_idx: 50 |  Loss: (0.0137) | Acc: (99.53%) (6497/6528)\n",
            "Epoch: 245 | Batch_idx: 60 |  Loss: (0.0129) | Acc: (99.54%) (7772/7808)\n",
            "Epoch: 245 | Batch_idx: 70 |  Loss: (0.0123) | Acc: (99.56%) (9048/9088)\n",
            "Epoch: 245 | Batch_idx: 80 |  Loss: (0.0124) | Acc: (99.58%) (10324/10368)\n",
            "Epoch: 245 | Batch_idx: 90 |  Loss: (0.0134) | Acc: (99.54%) (11594/11648)\n",
            "Epoch: 245 | Batch_idx: 100 |  Loss: (0.0130) | Acc: (99.54%) (12869/12928)\n",
            "Epoch: 245 | Batch_idx: 110 |  Loss: (0.0135) | Acc: (99.52%) (14140/14208)\n",
            "Epoch: 245 | Batch_idx: 120 |  Loss: (0.0136) | Acc: (99.52%) (15414/15488)\n",
            "Epoch: 245 | Batch_idx: 130 |  Loss: (0.0135) | Acc: (99.53%) (16689/16768)\n",
            "Epoch: 245 | Batch_idx: 140 |  Loss: (0.0131) | Acc: (99.54%) (17965/18048)\n",
            "Epoch: 245 | Batch_idx: 150 |  Loss: (0.0135) | Acc: (99.54%) (19239/19328)\n",
            "Epoch: 245 | Batch_idx: 160 |  Loss: (0.0133) | Acc: (99.55%) (20515/20608)\n",
            "Epoch: 245 | Batch_idx: 170 |  Loss: (0.0131) | Acc: (99.56%) (21791/21888)\n",
            "Epoch: 245 | Batch_idx: 180 |  Loss: (0.0131) | Acc: (99.56%) (23066/23168)\n",
            "Epoch: 245 | Batch_idx: 190 |  Loss: (0.0134) | Acc: (99.55%) (24337/24448)\n",
            "Epoch: 245 | Batch_idx: 200 |  Loss: (0.0131) | Acc: (99.55%) (25613/25728)\n",
            "Epoch: 245 | Batch_idx: 210 |  Loss: (0.0130) | Acc: (99.56%) (26890/27008)\n",
            "Epoch: 245 | Batch_idx: 220 |  Loss: (0.0128) | Acc: (99.57%) (28166/28288)\n",
            "Epoch: 245 | Batch_idx: 230 |  Loss: (0.0126) | Acc: (99.57%) (29442/29568)\n",
            "Epoch: 245 | Batch_idx: 240 |  Loss: (0.0126) | Acc: (99.57%) (30715/30848)\n",
            "Epoch: 245 | Batch_idx: 250 |  Loss: (0.0124) | Acc: (99.57%) (31990/32128)\n",
            "Epoch: 245 | Batch_idx: 260 |  Loss: (0.0125) | Acc: (99.57%) (33265/33408)\n",
            "Epoch: 245 | Batch_idx: 270 |  Loss: (0.0126) | Acc: (99.57%) (34539/34688)\n",
            "Epoch: 245 | Batch_idx: 280 |  Loss: (0.0125) | Acc: (99.57%) (35815/35968)\n",
            "Epoch: 245 | Batch_idx: 290 |  Loss: (0.0125) | Acc: (99.57%) (37089/37248)\n",
            "Epoch: 245 | Batch_idx: 300 |  Loss: (0.0124) | Acc: (99.57%) (38364/38528)\n",
            "Epoch: 245 | Batch_idx: 310 |  Loss: (0.0125) | Acc: (99.57%) (39638/39808)\n",
            "Epoch: 245 | Batch_idx: 320 |  Loss: (0.0123) | Acc: (99.58%) (40914/41088)\n",
            "Epoch: 245 | Batch_idx: 330 |  Loss: (0.0123) | Acc: (99.58%) (42189/42368)\n",
            "Epoch: 245 | Batch_idx: 340 |  Loss: (0.0123) | Acc: (99.58%) (43465/43648)\n",
            "Epoch: 245 | Batch_idx: 350 |  Loss: (0.0124) | Acc: (99.58%) (44738/44928)\n",
            "Epoch: 245 | Batch_idx: 360 |  Loss: (0.0123) | Acc: (99.58%) (46013/46208)\n",
            "Epoch: 245 | Batch_idx: 370 |  Loss: (0.0126) | Acc: (99.57%) (47286/47488)\n",
            "Epoch: 245 | Batch_idx: 380 |  Loss: (0.0126) | Acc: (99.57%) (48558/48768)\n",
            "Epoch: 245 | Batch_idx: 390 |  Loss: (0.0124) | Acc: (99.58%) (49790/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4050) | Acc: (91.81%) (9181/10000)\n",
            "Epoch: 246 | Batch_idx: 0 |  Loss: (0.0111) | Acc: (99.22%) (127/128)\n",
            "Epoch: 246 | Batch_idx: 10 |  Loss: (0.0073) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 246 | Batch_idx: 20 |  Loss: (0.0071) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 246 | Batch_idx: 30 |  Loss: (0.0070) | Acc: (99.80%) (3960/3968)\n",
            "Epoch: 246 | Batch_idx: 40 |  Loss: (0.0069) | Acc: (99.81%) (5238/5248)\n",
            "Epoch: 246 | Batch_idx: 50 |  Loss: (0.0076) | Acc: (99.79%) (6514/6528)\n",
            "Epoch: 246 | Batch_idx: 60 |  Loss: (0.0088) | Acc: (99.74%) (7788/7808)\n",
            "Epoch: 246 | Batch_idx: 70 |  Loss: (0.0095) | Acc: (99.70%) (9061/9088)\n",
            "Epoch: 246 | Batch_idx: 80 |  Loss: (0.0102) | Acc: (99.67%) (10334/10368)\n",
            "Epoch: 246 | Batch_idx: 90 |  Loss: (0.0098) | Acc: (99.68%) (11611/11648)\n",
            "Epoch: 246 | Batch_idx: 100 |  Loss: (0.0117) | Acc: (99.64%) (12882/12928)\n",
            "Epoch: 246 | Batch_idx: 110 |  Loss: (0.0113) | Acc: (99.66%) (14159/14208)\n",
            "Epoch: 246 | Batch_idx: 120 |  Loss: (0.0113) | Acc: (99.66%) (15435/15488)\n",
            "Epoch: 246 | Batch_idx: 130 |  Loss: (0.0115) | Acc: (99.65%) (16709/16768)\n",
            "Epoch: 246 | Batch_idx: 140 |  Loss: (0.0118) | Acc: (99.63%) (17982/18048)\n",
            "Epoch: 246 | Batch_idx: 150 |  Loss: (0.0120) | Acc: (99.64%) (19258/19328)\n",
            "Epoch: 246 | Batch_idx: 160 |  Loss: (0.0118) | Acc: (99.65%) (20535/20608)\n",
            "Epoch: 246 | Batch_idx: 170 |  Loss: (0.0122) | Acc: (99.63%) (21807/21888)\n",
            "Epoch: 246 | Batch_idx: 180 |  Loss: (0.0122) | Acc: (99.62%) (23081/23168)\n",
            "Epoch: 246 | Batch_idx: 190 |  Loss: (0.0120) | Acc: (99.63%) (24357/24448)\n",
            "Epoch: 246 | Batch_idx: 200 |  Loss: (0.0122) | Acc: (99.62%) (25630/25728)\n",
            "Epoch: 246 | Batch_idx: 210 |  Loss: (0.0122) | Acc: (99.62%) (26905/27008)\n",
            "Epoch: 246 | Batch_idx: 220 |  Loss: (0.0125) | Acc: (99.61%) (28178/28288)\n",
            "Epoch: 246 | Batch_idx: 230 |  Loss: (0.0122) | Acc: (99.62%) (29456/29568)\n",
            "Epoch: 246 | Batch_idx: 240 |  Loss: (0.0121) | Acc: (99.62%) (30732/30848)\n",
            "Epoch: 246 | Batch_idx: 250 |  Loss: (0.0120) | Acc: (99.62%) (32005/32128)\n",
            "Epoch: 246 | Batch_idx: 260 |  Loss: (0.0120) | Acc: (99.63%) (33283/33408)\n",
            "Epoch: 246 | Batch_idx: 270 |  Loss: (0.0121) | Acc: (99.62%) (34556/34688)\n",
            "Epoch: 246 | Batch_idx: 280 |  Loss: (0.0120) | Acc: (99.62%) (35831/35968)\n",
            "Epoch: 246 | Batch_idx: 290 |  Loss: (0.0120) | Acc: (99.62%) (37108/37248)\n",
            "Epoch: 246 | Batch_idx: 300 |  Loss: (0.0123) | Acc: (99.62%) (38382/38528)\n",
            "Epoch: 246 | Batch_idx: 310 |  Loss: (0.0122) | Acc: (99.62%) (39656/39808)\n",
            "Epoch: 246 | Batch_idx: 320 |  Loss: (0.0121) | Acc: (99.62%) (40932/41088)\n",
            "Epoch: 246 | Batch_idx: 330 |  Loss: (0.0122) | Acc: (99.62%) (42206/42368)\n",
            "Epoch: 246 | Batch_idx: 340 |  Loss: (0.0120) | Acc: (99.63%) (43485/43648)\n",
            "Epoch: 246 | Batch_idx: 350 |  Loss: (0.0119) | Acc: (99.63%) (44763/44928)\n",
            "Epoch: 246 | Batch_idx: 360 |  Loss: (0.0119) | Acc: (99.63%) (46035/46208)\n",
            "Epoch: 246 | Batch_idx: 370 |  Loss: (0.0121) | Acc: (99.62%) (47306/47488)\n",
            "Epoch: 246 | Batch_idx: 380 |  Loss: (0.0123) | Acc: (99.61%) (48577/48768)\n",
            "Epoch: 246 | Batch_idx: 390 |  Loss: (0.0124) | Acc: (99.60%) (49801/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4042) | Acc: (91.75%) (9175/10000)\n",
            "Epoch: 247 | Batch_idx: 0 |  Loss: (0.0028) | Acc: (100.00%) (128/128)\n",
            "Epoch: 247 | Batch_idx: 10 |  Loss: (0.0130) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 247 | Batch_idx: 20 |  Loss: (0.0134) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 247 | Batch_idx: 30 |  Loss: (0.0162) | Acc: (99.42%) (3945/3968)\n",
            "Epoch: 247 | Batch_idx: 40 |  Loss: (0.0147) | Acc: (99.47%) (5220/5248)\n",
            "Epoch: 247 | Batch_idx: 50 |  Loss: (0.0130) | Acc: (99.51%) (6496/6528)\n",
            "Epoch: 247 | Batch_idx: 60 |  Loss: (0.0128) | Acc: (99.55%) (7773/7808)\n",
            "Epoch: 247 | Batch_idx: 70 |  Loss: (0.0122) | Acc: (99.58%) (9050/9088)\n",
            "Epoch: 247 | Batch_idx: 80 |  Loss: (0.0111) | Acc: (99.62%) (10329/10368)\n",
            "Epoch: 247 | Batch_idx: 90 |  Loss: (0.0109) | Acc: (99.64%) (11606/11648)\n",
            "Epoch: 247 | Batch_idx: 100 |  Loss: (0.0107) | Acc: (99.65%) (12883/12928)\n",
            "Epoch: 247 | Batch_idx: 110 |  Loss: (0.0108) | Acc: (99.65%) (14158/14208)\n",
            "Epoch: 247 | Batch_idx: 120 |  Loss: (0.0106) | Acc: (99.66%) (15436/15488)\n",
            "Epoch: 247 | Batch_idx: 130 |  Loss: (0.0111) | Acc: (99.65%) (16710/16768)\n",
            "Epoch: 247 | Batch_idx: 140 |  Loss: (0.0114) | Acc: (99.66%) (17986/18048)\n",
            "Epoch: 247 | Batch_idx: 150 |  Loss: (0.0111) | Acc: (99.66%) (19263/19328)\n",
            "Epoch: 247 | Batch_idx: 160 |  Loss: (0.0114) | Acc: (99.65%) (20536/20608)\n",
            "Epoch: 247 | Batch_idx: 170 |  Loss: (0.0114) | Acc: (99.64%) (21810/21888)\n",
            "Epoch: 247 | Batch_idx: 180 |  Loss: (0.0113) | Acc: (99.64%) (23085/23168)\n",
            "Epoch: 247 | Batch_idx: 190 |  Loss: (0.0110) | Acc: (99.65%) (24363/24448)\n",
            "Epoch: 247 | Batch_idx: 200 |  Loss: (0.0109) | Acc: (99.66%) (25641/25728)\n",
            "Epoch: 247 | Batch_idx: 210 |  Loss: (0.0110) | Acc: (99.67%) (26918/27008)\n",
            "Epoch: 247 | Batch_idx: 220 |  Loss: (0.0111) | Acc: (99.66%) (28192/28288)\n",
            "Epoch: 247 | Batch_idx: 230 |  Loss: (0.0113) | Acc: (99.65%) (29465/29568)\n",
            "Epoch: 247 | Batch_idx: 240 |  Loss: (0.0114) | Acc: (99.64%) (30737/30848)\n",
            "Epoch: 247 | Batch_idx: 250 |  Loss: (0.0114) | Acc: (99.63%) (32010/32128)\n",
            "Epoch: 247 | Batch_idx: 260 |  Loss: (0.0113) | Acc: (99.64%) (33288/33408)\n",
            "Epoch: 247 | Batch_idx: 270 |  Loss: (0.0116) | Acc: (99.63%) (34561/34688)\n",
            "Epoch: 247 | Batch_idx: 280 |  Loss: (0.0115) | Acc: (99.64%) (35839/35968)\n",
            "Epoch: 247 | Batch_idx: 290 |  Loss: (0.0116) | Acc: (99.63%) (37110/37248)\n",
            "Epoch: 247 | Batch_idx: 300 |  Loss: (0.0115) | Acc: (99.63%) (38387/38528)\n",
            "Epoch: 247 | Batch_idx: 310 |  Loss: (0.0118) | Acc: (99.62%) (39658/39808)\n",
            "Epoch: 247 | Batch_idx: 320 |  Loss: (0.0118) | Acc: (99.62%) (40933/41088)\n",
            "Epoch: 247 | Batch_idx: 330 |  Loss: (0.0117) | Acc: (99.63%) (42210/42368)\n",
            "Epoch: 247 | Batch_idx: 340 |  Loss: (0.0117) | Acc: (99.62%) (43483/43648)\n",
            "Epoch: 247 | Batch_idx: 350 |  Loss: (0.0118) | Acc: (99.62%) (44759/44928)\n",
            "Epoch: 247 | Batch_idx: 360 |  Loss: (0.0119) | Acc: (99.62%) (46031/46208)\n",
            "Epoch: 247 | Batch_idx: 370 |  Loss: (0.0120) | Acc: (99.61%) (47304/47488)\n",
            "Epoch: 247 | Batch_idx: 380 |  Loss: (0.0119) | Acc: (99.62%) (48581/48768)\n",
            "Epoch: 247 | Batch_idx: 390 |  Loss: (0.0118) | Acc: (99.62%) (49809/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4066) | Acc: (91.76%) (9176/10000)\n",
            "Epoch: 248 | Batch_idx: 0 |  Loss: (0.0176) | Acc: (99.22%) (127/128)\n",
            "Epoch: 248 | Batch_idx: 10 |  Loss: (0.0100) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 248 | Batch_idx: 20 |  Loss: (0.0089) | Acc: (99.70%) (2680/2688)\n",
            "Epoch: 248 | Batch_idx: 30 |  Loss: (0.0111) | Acc: (99.62%) (3953/3968)\n",
            "Epoch: 248 | Batch_idx: 40 |  Loss: (0.0100) | Acc: (99.70%) (5232/5248)\n",
            "Epoch: 248 | Batch_idx: 50 |  Loss: (0.0097) | Acc: (99.71%) (6509/6528)\n",
            "Epoch: 248 | Batch_idx: 60 |  Loss: (0.0096) | Acc: (99.69%) (7784/7808)\n",
            "Epoch: 248 | Batch_idx: 70 |  Loss: (0.0102) | Acc: (99.68%) (9059/9088)\n",
            "Epoch: 248 | Batch_idx: 80 |  Loss: (0.0111) | Acc: (99.63%) (10330/10368)\n",
            "Epoch: 248 | Batch_idx: 90 |  Loss: (0.0111) | Acc: (99.63%) (11605/11648)\n",
            "Epoch: 248 | Batch_idx: 100 |  Loss: (0.0109) | Acc: (99.63%) (12880/12928)\n",
            "Epoch: 248 | Batch_idx: 110 |  Loss: (0.0106) | Acc: (99.65%) (14158/14208)\n",
            "Epoch: 248 | Batch_idx: 120 |  Loss: (0.0109) | Acc: (99.63%) (15431/15488)\n",
            "Epoch: 248 | Batch_idx: 130 |  Loss: (0.0111) | Acc: (99.62%) (16705/16768)\n",
            "Epoch: 248 | Batch_idx: 140 |  Loss: (0.0111) | Acc: (99.62%) (17980/18048)\n",
            "Epoch: 248 | Batch_idx: 150 |  Loss: (0.0116) | Acc: (99.60%) (19250/19328)\n",
            "Epoch: 248 | Batch_idx: 160 |  Loss: (0.0113) | Acc: (99.61%) (20527/20608)\n",
            "Epoch: 248 | Batch_idx: 170 |  Loss: (0.0114) | Acc: (99.61%) (21802/21888)\n",
            "Epoch: 248 | Batch_idx: 180 |  Loss: (0.0118) | Acc: (99.59%) (23074/23168)\n",
            "Epoch: 248 | Batch_idx: 190 |  Loss: (0.0117) | Acc: (99.60%) (24350/24448)\n",
            "Epoch: 248 | Batch_idx: 200 |  Loss: (0.0121) | Acc: (99.58%) (25621/25728)\n",
            "Epoch: 248 | Batch_idx: 210 |  Loss: (0.0119) | Acc: (99.59%) (26897/27008)\n",
            "Epoch: 248 | Batch_idx: 220 |  Loss: (0.0118) | Acc: (99.59%) (28172/28288)\n",
            "Epoch: 248 | Batch_idx: 230 |  Loss: (0.0116) | Acc: (99.60%) (29451/29568)\n",
            "Epoch: 248 | Batch_idx: 240 |  Loss: (0.0117) | Acc: (99.60%) (30725/30848)\n",
            "Epoch: 248 | Batch_idx: 250 |  Loss: (0.0117) | Acc: (99.60%) (31999/32128)\n",
            "Epoch: 248 | Batch_idx: 260 |  Loss: (0.0115) | Acc: (99.60%) (33276/33408)\n",
            "Epoch: 248 | Batch_idx: 270 |  Loss: (0.0116) | Acc: (99.60%) (34549/34688)\n",
            "Epoch: 248 | Batch_idx: 280 |  Loss: (0.0115) | Acc: (99.61%) (35826/35968)\n",
            "Epoch: 248 | Batch_idx: 290 |  Loss: (0.0114) | Acc: (99.61%) (37101/37248)\n",
            "Epoch: 248 | Batch_idx: 300 |  Loss: (0.0113) | Acc: (99.62%) (38380/38528)\n",
            "Epoch: 248 | Batch_idx: 310 |  Loss: (0.0113) | Acc: (99.61%) (39654/39808)\n",
            "Epoch: 248 | Batch_idx: 320 |  Loss: (0.0114) | Acc: (99.61%) (40928/41088)\n",
            "Epoch: 248 | Batch_idx: 330 |  Loss: (0.0115) | Acc: (99.61%) (42202/42368)\n",
            "Epoch: 248 | Batch_idx: 340 |  Loss: (0.0116) | Acc: (99.61%) (43476/43648)\n",
            "Epoch: 248 | Batch_idx: 350 |  Loss: (0.0116) | Acc: (99.61%) (44751/44928)\n",
            "Epoch: 248 | Batch_idx: 360 |  Loss: (0.0117) | Acc: (99.61%) (46026/46208)\n",
            "Epoch: 248 | Batch_idx: 370 |  Loss: (0.0120) | Acc: (99.60%) (47299/47488)\n",
            "Epoch: 248 | Batch_idx: 380 |  Loss: (0.0119) | Acc: (99.60%) (48575/48768)\n",
            "Epoch: 248 | Batch_idx: 390 |  Loss: (0.0118) | Acc: (99.61%) (49803/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4068) | Acc: (91.88%) (9188/10000)\n",
            "Epoch: 249 | Batch_idx: 0 |  Loss: (0.0028) | Acc: (100.00%) (128/128)\n",
            "Epoch: 249 | Batch_idx: 10 |  Loss: (0.0042) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 249 | Batch_idx: 20 |  Loss: (0.0057) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 249 | Batch_idx: 30 |  Loss: (0.0070) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 249 | Batch_idx: 40 |  Loss: (0.0077) | Acc: (99.81%) (5238/5248)\n",
            "Epoch: 249 | Batch_idx: 50 |  Loss: (0.0089) | Acc: (99.74%) (6511/6528)\n",
            "Epoch: 249 | Batch_idx: 60 |  Loss: (0.0088) | Acc: (99.74%) (7788/7808)\n",
            "Epoch: 249 | Batch_idx: 70 |  Loss: (0.0096) | Acc: (99.71%) (9062/9088)\n",
            "Epoch: 249 | Batch_idx: 80 |  Loss: (0.0107) | Acc: (99.68%) (10335/10368)\n",
            "Epoch: 249 | Batch_idx: 90 |  Loss: (0.0102) | Acc: (99.69%) (11612/11648)\n",
            "Epoch: 249 | Batch_idx: 100 |  Loss: (0.0101) | Acc: (99.68%) (12887/12928)\n",
            "Epoch: 249 | Batch_idx: 110 |  Loss: (0.0099) | Acc: (99.69%) (14164/14208)\n",
            "Epoch: 249 | Batch_idx: 120 |  Loss: (0.0105) | Acc: (99.66%) (15435/15488)\n",
            "Epoch: 249 | Batch_idx: 130 |  Loss: (0.0103) | Acc: (99.67%) (16712/16768)\n",
            "Epoch: 249 | Batch_idx: 140 |  Loss: (0.0102) | Acc: (99.67%) (17989/18048)\n",
            "Epoch: 249 | Batch_idx: 150 |  Loss: (0.0102) | Acc: (99.67%) (19265/19328)\n",
            "Epoch: 249 | Batch_idx: 160 |  Loss: (0.0101) | Acc: (99.68%) (20542/20608)\n",
            "Epoch: 249 | Batch_idx: 170 |  Loss: (0.0109) | Acc: (99.66%) (21814/21888)\n",
            "Epoch: 249 | Batch_idx: 180 |  Loss: (0.0110) | Acc: (99.65%) (23088/23168)\n",
            "Epoch: 249 | Batch_idx: 190 |  Loss: (0.0109) | Acc: (99.66%) (24365/24448)\n",
            "Epoch: 249 | Batch_idx: 200 |  Loss: (0.0108) | Acc: (99.67%) (25642/25728)\n",
            "Epoch: 249 | Batch_idx: 210 |  Loss: (0.0110) | Acc: (99.66%) (26916/27008)\n",
            "Epoch: 249 | Batch_idx: 220 |  Loss: (0.0112) | Acc: (99.65%) (28190/28288)\n",
            "Epoch: 249 | Batch_idx: 230 |  Loss: (0.0113) | Acc: (99.65%) (29464/29568)\n",
            "Epoch: 249 | Batch_idx: 240 |  Loss: (0.0114) | Acc: (99.64%) (30738/30848)\n",
            "Epoch: 249 | Batch_idx: 250 |  Loss: (0.0112) | Acc: (99.65%) (32015/32128)\n",
            "Epoch: 249 | Batch_idx: 260 |  Loss: (0.0113) | Acc: (99.64%) (33289/33408)\n",
            "Epoch: 249 | Batch_idx: 270 |  Loss: (0.0112) | Acc: (99.65%) (34565/34688)\n",
            "Epoch: 249 | Batch_idx: 280 |  Loss: (0.0111) | Acc: (99.64%) (35839/35968)\n",
            "Epoch: 249 | Batch_idx: 290 |  Loss: (0.0111) | Acc: (99.64%) (37115/37248)\n",
            "Epoch: 249 | Batch_idx: 300 |  Loss: (0.0111) | Acc: (99.64%) (38391/38528)\n",
            "Epoch: 249 | Batch_idx: 310 |  Loss: (0.0110) | Acc: (99.65%) (39667/39808)\n",
            "Epoch: 249 | Batch_idx: 320 |  Loss: (0.0108) | Acc: (99.66%) (40947/41088)\n",
            "Epoch: 249 | Batch_idx: 330 |  Loss: (0.0107) | Acc: (99.65%) (42220/42368)\n",
            "Epoch: 249 | Batch_idx: 340 |  Loss: (0.0108) | Acc: (99.64%) (43490/43648)\n",
            "Epoch: 249 | Batch_idx: 350 |  Loss: (0.0108) | Acc: (99.64%) (44767/44928)\n",
            "Epoch: 249 | Batch_idx: 360 |  Loss: (0.0109) | Acc: (99.64%) (46042/46208)\n",
            "Epoch: 249 | Batch_idx: 370 |  Loss: (0.0109) | Acc: (99.64%) (47318/47488)\n",
            "Epoch: 249 | Batch_idx: 380 |  Loss: (0.0108) | Acc: (99.64%) (48594/48768)\n",
            "Epoch: 249 | Batch_idx: 390 |  Loss: (0.0109) | Acc: (99.64%) (49820/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4083) | Acc: (91.83%) (9183/10000)\n",
            "1 hours 26 mins 35 secs for training\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import os\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'                # GPU Number \n",
        "start_time = time.time()\n",
        "batch_size = 128\n",
        "learning_rate = 0.1 #Changed the initial Learning rate\n",
        "root_dir = 'drive/app/cifar10/'\n",
        "default_directory = 'drive/app/torch/save_models'\n",
        "\n",
        "# Data Augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),               # Random Position Crop\n",
        "    transforms.RandomHorizontalFlip(),                  # right and left flip\n",
        "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
        "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
        "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
        "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
        "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
        "])\n",
        "\n",
        "# automatically download\n",
        "train_dataset = datasets.CIFAR10(root=root_dir,\n",
        "                                 train=True,\n",
        "                                 transform=transform_train,\n",
        "                                 download=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root=root_dir,\n",
        "                                train=False,\n",
        "                                transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,            # at Training Procedure, Data Shuffle = True\n",
        "                                           num_workers=4)           # CPU loader number\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,            # at Test Procedure, Data Shuffle = False\n",
        "                                          num_workers=4)            # CPU loader number\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.3),                                       ################### Added\n",
        "\t    \n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.3),                                       ################### Added\n",
        "\t    \n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.3), #################### Dropout value set to 0.3\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.3), #################### Dropout value set to 0.3\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "model = VGG()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), learning_rate,\n",
        "                                momentum=0.9,\n",
        "                                weight_decay=1e-4,\n",
        "                                nesterov=True)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "if torch.cuda.device_count() > 0:\n",
        "    print(\"USE\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model).cuda()\n",
        "    cudnn.benchmark = True\n",
        "else:\n",
        "    print(\"USE ONLY CPU!\")\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0 \n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
        "        else:\n",
        "            data, target = Variable(data), Variable(target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.data).cpu().sum()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Epoch: {} | Batch_idx: {} |  Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
        "                  .format(epoch, batch_idx, train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
        "        else:\n",
        "            data, target = Variable(data), Variable(target)\n",
        "\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, target)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.data).cpu().sum()\n",
        "    print('# TEST : Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
        "          .format(test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "\n",
        "\n",
        "def save_checkpoint(directory, state, filename='latest.tar.gz'):\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    model_filename = os.path.join(directory, filename)\n",
        "    torch.save(state, model_filename)\n",
        "    print(\"=> saving checkpoint\")\n",
        "\n",
        "def load_checkpoint(directory, filename='latest.tar.gz'):\n",
        "\n",
        "    model_filename = os.path.join(directory, filename)\n",
        "    if os.path.exists(model_filename):\n",
        "        print(\"=> loading checkpoint\")\n",
        "        state = torch.load(model_filename)\n",
        "        return state\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "start_epoch = 0\n",
        "\n",
        "for epoch in range(start_epoch, 250):#################### Changing epoch\n",
        "\n",
        "    if epoch < 80:\n",
        "        lr = learning_rate\n",
        "    elif epoch < 120:\n",
        "        lr = learning_rate * 0.1\n",
        "    else:\n",
        "        lr = learning_rate * 0.01\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    train(epoch)\n",
        "    save_checkpoint(default_directory, {\n",
        "        'epoch': epoch,\n",
        "        'model': model,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "    })\n",
        "    test()  \n",
        "\n",
        "now = time.gmtime(time.time() - start_time)\n",
        "print('{} hours {} mins {} secs for training'.format(now.tm_hour, now.tm_min, now.tm_sec))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "z3679FisFAmj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}