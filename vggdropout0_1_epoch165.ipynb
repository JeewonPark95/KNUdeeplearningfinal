{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vggdropout0.1_epoch165.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMpPZJdOFlg6tzSfkaMpuH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5c0c4e7b0fdb44d6801f1a63aa3dbcde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e6b4010ff9243dbbc99967f08e225ee",
              "IPY_MODEL_523775d278db4738a95e2b91ddca0f11",
              "IPY_MODEL_4dad6d92c84b446d9ae5a4734ea656a7"
            ],
            "layout": "IPY_MODEL_fa335e7f82bb4eb0b1f0f512b7a7273d"
          }
        },
        "0e6b4010ff9243dbbc99967f08e225ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66868dd400d84cdd93b2707155034ddc",
            "placeholder": "​",
            "style": "IPY_MODEL_91ec1a83cc4a48dda834944cc82198b4",
            "value": ""
          }
        },
        "523775d278db4738a95e2b91ddca0f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93047efabaed49da93b3561db78462d5",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_901f544638d2410995a8db141f6fc212",
            "value": 170498071
          }
        },
        "4dad6d92c84b446d9ae5a4734ea656a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c681fa695a8543eeb4b8add58f23fa23",
            "placeholder": "​",
            "style": "IPY_MODEL_d76aee066cea4d2d91617c491d640b08",
            "value": " 170499072/? [00:13&lt;00:00, 14517848.54it/s]"
          }
        },
        "fa335e7f82bb4eb0b1f0f512b7a7273d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66868dd400d84cdd93b2707155034ddc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91ec1a83cc4a48dda834944cc82198b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93047efabaed49da93b3561db78462d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "901f544638d2410995a8db141f6fc212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c681fa695a8543eeb4b8add58f23fa23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d76aee066cea4d2d91617c491d640b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeewonPark95/KNUdeeplearningfinal/blob/main/vggdropout0_1_epoch165.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5c0c4e7b0fdb44d6801f1a63aa3dbcde",
            "0e6b4010ff9243dbbc99967f08e225ee",
            "523775d278db4738a95e2b91ddca0f11",
            "4dad6d92c84b446d9ae5a4734ea656a7",
            "fa335e7f82bb4eb0b1f0f512b7a7273d",
            "66868dd400d84cdd93b2707155034ddc",
            "91ec1a83cc4a48dda834944cc82198b4",
            "93047efabaed49da93b3561db78462d5",
            "901f544638d2410995a8db141f6fc212",
            "c681fa695a8543eeb4b8add58f23fa23",
            "d76aee066cea4d2d91617c491d640b08"
          ]
        },
        "id": "yLAxLnRsEvAb",
        "outputId": "a99a9771-3652-4f7e-cd0a-62111ce1282a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to drive/app/cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c0c4e7b0fdb44d6801f1a63aa3dbcde"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting drive/app/cifar10/cifar-10-python.tar.gz to drive/app/cifar10/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "# TEST : Loss: (0.4366) | Acc: (86.65%) (8665/10000)\n",
            "Epoch: 46 | Batch_idx: 0 |  Loss: (0.1725) | Acc: (96.09%) (123/128)\n",
            "Epoch: 46 | Batch_idx: 10 |  Loss: (0.2072) | Acc: (93.25%) (1313/1408)\n",
            "Epoch: 46 | Batch_idx: 20 |  Loss: (0.2110) | Acc: (93.08%) (2502/2688)\n",
            "Epoch: 46 | Batch_idx: 30 |  Loss: (0.1997) | Acc: (93.27%) (3701/3968)\n",
            "Epoch: 46 | Batch_idx: 40 |  Loss: (0.2096) | Acc: (92.85%) (4873/5248)\n",
            "Epoch: 46 | Batch_idx: 50 |  Loss: (0.2155) | Acc: (92.72%) (6053/6528)\n",
            "Epoch: 46 | Batch_idx: 60 |  Loss: (0.2194) | Acc: (92.58%) (7229/7808)\n",
            "Epoch: 46 | Batch_idx: 70 |  Loss: (0.2222) | Acc: (92.37%) (8395/9088)\n",
            "Epoch: 46 | Batch_idx: 80 |  Loss: (0.2237) | Acc: (92.40%) (9580/10368)\n",
            "Epoch: 46 | Batch_idx: 90 |  Loss: (0.2244) | Acc: (92.42%) (10765/11648)\n",
            "Epoch: 46 | Batch_idx: 100 |  Loss: (0.2251) | Acc: (92.35%) (11939/12928)\n",
            "Epoch: 46 | Batch_idx: 110 |  Loss: (0.2233) | Acc: (92.36%) (13122/14208)\n",
            "Epoch: 46 | Batch_idx: 120 |  Loss: (0.2225) | Acc: (92.37%) (14306/15488)\n",
            "Epoch: 46 | Batch_idx: 130 |  Loss: (0.2197) | Acc: (92.43%) (15498/16768)\n",
            "Epoch: 46 | Batch_idx: 140 |  Loss: (0.2180) | Acc: (92.45%) (16685/18048)\n",
            "Epoch: 46 | Batch_idx: 150 |  Loss: (0.2171) | Acc: (92.47%) (17872/19328)\n",
            "Epoch: 46 | Batch_idx: 160 |  Loss: (0.2169) | Acc: (92.46%) (19055/20608)\n",
            "Epoch: 46 | Batch_idx: 170 |  Loss: (0.2193) | Acc: (92.40%) (20224/21888)\n",
            "Epoch: 46 | Batch_idx: 180 |  Loss: (0.2194) | Acc: (92.43%) (21414/23168)\n",
            "Epoch: 46 | Batch_idx: 190 |  Loss: (0.2204) | Acc: (92.42%) (22595/24448)\n",
            "Epoch: 46 | Batch_idx: 200 |  Loss: (0.2197) | Acc: (92.46%) (23787/25728)\n",
            "Epoch: 46 | Batch_idx: 210 |  Loss: (0.2193) | Acc: (92.46%) (24972/27008)\n",
            "Epoch: 46 | Batch_idx: 220 |  Loss: (0.2214) | Acc: (92.41%) (26141/28288)\n",
            "Epoch: 46 | Batch_idx: 230 |  Loss: (0.2206) | Acc: (92.42%) (27327/29568)\n",
            "Epoch: 46 | Batch_idx: 240 |  Loss: (0.2214) | Acc: (92.39%) (28502/30848)\n",
            "Epoch: 46 | Batch_idx: 250 |  Loss: (0.2204) | Acc: (92.46%) (29705/32128)\n",
            "Epoch: 46 | Batch_idx: 260 |  Loss: (0.2201) | Acc: (92.46%) (30890/33408)\n",
            "Epoch: 46 | Batch_idx: 270 |  Loss: (0.2219) | Acc: (92.42%) (32057/34688)\n",
            "Epoch: 46 | Batch_idx: 280 |  Loss: (0.2216) | Acc: (92.42%) (33240/35968)\n",
            "Epoch: 46 | Batch_idx: 290 |  Loss: (0.2238) | Acc: (92.35%) (34398/37248)\n",
            "Epoch: 46 | Batch_idx: 300 |  Loss: (0.2250) | Acc: (92.31%) (35564/38528)\n",
            "Epoch: 46 | Batch_idx: 310 |  Loss: (0.2249) | Acc: (92.30%) (36742/39808)\n",
            "Epoch: 46 | Batch_idx: 320 |  Loss: (0.2256) | Acc: (92.26%) (37908/41088)\n",
            "Epoch: 46 | Batch_idx: 330 |  Loss: (0.2253) | Acc: (92.30%) (39107/42368)\n",
            "Epoch: 46 | Batch_idx: 340 |  Loss: (0.2249) | Acc: (92.30%) (40286/43648)\n",
            "Epoch: 46 | Batch_idx: 350 |  Loss: (0.2242) | Acc: (92.33%) (41484/44928)\n",
            "Epoch: 46 | Batch_idx: 360 |  Loss: (0.2243) | Acc: (92.34%) (42667/46208)\n",
            "Epoch: 46 | Batch_idx: 370 |  Loss: (0.2244) | Acc: (92.33%) (43844/47488)\n",
            "Epoch: 46 | Batch_idx: 380 |  Loss: (0.2243) | Acc: (92.34%) (45030/48768)\n",
            "Epoch: 46 | Batch_idx: 390 |  Loss: (0.2237) | Acc: (92.36%) (46181/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4194) | Acc: (87.37%) (8737/10000)\n",
            "Epoch: 47 | Batch_idx: 0 |  Loss: (0.0889) | Acc: (96.88%) (124/128)\n",
            "Epoch: 47 | Batch_idx: 10 |  Loss: (0.1902) | Acc: (93.25%) (1313/1408)\n",
            "Epoch: 47 | Batch_idx: 20 |  Loss: (0.1870) | Acc: (93.60%) (2516/2688)\n",
            "Epoch: 47 | Batch_idx: 30 |  Loss: (0.1861) | Acc: (93.67%) (3717/3968)\n",
            "Epoch: 47 | Batch_idx: 40 |  Loss: (0.2037) | Acc: (93.22%) (4892/5248)\n",
            "Epoch: 47 | Batch_idx: 50 |  Loss: (0.2071) | Acc: (93.05%) (6074/6528)\n",
            "Epoch: 47 | Batch_idx: 60 |  Loss: (0.2071) | Acc: (93.06%) (7266/7808)\n",
            "Epoch: 47 | Batch_idx: 70 |  Loss: (0.2075) | Acc: (93.09%) (8460/9088)\n",
            "Epoch: 47 | Batch_idx: 80 |  Loss: (0.2076) | Acc: (93.07%) (9649/10368)\n",
            "Epoch: 47 | Batch_idx: 90 |  Loss: (0.2063) | Acc: (93.17%) (10852/11648)\n",
            "Epoch: 47 | Batch_idx: 100 |  Loss: (0.2069) | Acc: (93.08%) (12033/12928)\n",
            "Epoch: 47 | Batch_idx: 110 |  Loss: (0.2078) | Acc: (93.00%) (13214/14208)\n",
            "Epoch: 47 | Batch_idx: 120 |  Loss: (0.2078) | Acc: (93.04%) (14410/15488)\n",
            "Epoch: 47 | Batch_idx: 130 |  Loss: (0.2085) | Acc: (93.03%) (15599/16768)\n",
            "Epoch: 47 | Batch_idx: 140 |  Loss: (0.2067) | Acc: (93.06%) (16795/18048)\n",
            "Epoch: 47 | Batch_idx: 150 |  Loss: (0.2043) | Acc: (93.12%) (17999/19328)\n",
            "Epoch: 47 | Batch_idx: 160 |  Loss: (0.2038) | Acc: (93.13%) (19193/20608)\n",
            "Epoch: 47 | Batch_idx: 170 |  Loss: (0.2041) | Acc: (93.07%) (20371/21888)\n",
            "Epoch: 47 | Batch_idx: 180 |  Loss: (0.2030) | Acc: (93.12%) (21575/23168)\n",
            "Epoch: 47 | Batch_idx: 190 |  Loss: (0.2033) | Acc: (93.09%) (22758/24448)\n",
            "Epoch: 47 | Batch_idx: 200 |  Loss: (0.2041) | Acc: (93.07%) (23944/25728)\n",
            "Epoch: 47 | Batch_idx: 210 |  Loss: (0.2052) | Acc: (93.05%) (25130/27008)\n",
            "Epoch: 47 | Batch_idx: 220 |  Loss: (0.2058) | Acc: (93.03%) (26317/28288)\n",
            "Epoch: 47 | Batch_idx: 230 |  Loss: (0.2063) | Acc: (93.02%) (27503/29568)\n",
            "Epoch: 47 | Batch_idx: 240 |  Loss: (0.2070) | Acc: (92.98%) (28684/30848)\n",
            "Epoch: 47 | Batch_idx: 250 |  Loss: (0.2068) | Acc: (93.00%) (29879/32128)\n",
            "Epoch: 47 | Batch_idx: 260 |  Loss: (0.2069) | Acc: (93.00%) (31069/33408)\n",
            "Epoch: 47 | Batch_idx: 270 |  Loss: (0.2082) | Acc: (92.96%) (32245/34688)\n",
            "Epoch: 47 | Batch_idx: 280 |  Loss: (0.2077) | Acc: (92.98%) (33442/35968)\n",
            "Epoch: 47 | Batch_idx: 290 |  Loss: (0.2078) | Acc: (92.99%) (34638/37248)\n",
            "Epoch: 47 | Batch_idx: 300 |  Loss: (0.2075) | Acc: (93.01%) (35834/38528)\n",
            "Epoch: 47 | Batch_idx: 310 |  Loss: (0.2077) | Acc: (93.01%) (37026/39808)\n",
            "Epoch: 47 | Batch_idx: 320 |  Loss: (0.2083) | Acc: (92.98%) (38203/41088)\n",
            "Epoch: 47 | Batch_idx: 330 |  Loss: (0.2087) | Acc: (92.97%) (39390/42368)\n",
            "Epoch: 47 | Batch_idx: 340 |  Loss: (0.2092) | Acc: (92.96%) (40577/43648)\n",
            "Epoch: 47 | Batch_idx: 350 |  Loss: (0.2091) | Acc: (92.94%) (41757/44928)\n",
            "Epoch: 47 | Batch_idx: 360 |  Loss: (0.2091) | Acc: (92.93%) (42943/46208)\n",
            "Epoch: 47 | Batch_idx: 370 |  Loss: (0.2087) | Acc: (92.93%) (44131/47488)\n",
            "Epoch: 47 | Batch_idx: 380 |  Loss: (0.2097) | Acc: (92.91%) (45308/48768)\n",
            "Epoch: 47 | Batch_idx: 390 |  Loss: (0.2107) | Acc: (92.87%) (46436/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4259) | Acc: (86.85%) (8685/10000)\n",
            "Epoch: 48 | Batch_idx: 0 |  Loss: (0.2383) | Acc: (93.75%) (120/128)\n",
            "Epoch: 48 | Batch_idx: 10 |  Loss: (0.2141) | Acc: (92.40%) (1301/1408)\n",
            "Epoch: 48 | Batch_idx: 20 |  Loss: (0.2026) | Acc: (93.01%) (2500/2688)\n",
            "Epoch: 48 | Batch_idx: 30 |  Loss: (0.2006) | Acc: (92.82%) (3683/3968)\n",
            "Epoch: 48 | Batch_idx: 40 |  Loss: (0.2012) | Acc: (92.91%) (4876/5248)\n",
            "Epoch: 48 | Batch_idx: 50 |  Loss: (0.2000) | Acc: (93.01%) (6072/6528)\n",
            "Epoch: 48 | Batch_idx: 60 |  Loss: (0.2024) | Acc: (92.84%) (7249/7808)\n",
            "Epoch: 48 | Batch_idx: 70 |  Loss: (0.2054) | Acc: (92.78%) (8432/9088)\n",
            "Epoch: 48 | Batch_idx: 80 |  Loss: (0.2067) | Acc: (92.69%) (9610/10368)\n",
            "Epoch: 48 | Batch_idx: 90 |  Loss: (0.2087) | Acc: (92.69%) (10797/11648)\n",
            "Epoch: 48 | Batch_idx: 100 |  Loss: (0.2093) | Acc: (92.60%) (11971/12928)\n",
            "Epoch: 48 | Batch_idx: 110 |  Loss: (0.2091) | Acc: (92.67%) (13167/14208)\n",
            "Epoch: 48 | Batch_idx: 120 |  Loss: (0.2084) | Acc: (92.66%) (14351/15488)\n",
            "Epoch: 48 | Batch_idx: 130 |  Loss: (0.2072) | Acc: (92.69%) (15542/16768)\n",
            "Epoch: 48 | Batch_idx: 140 |  Loss: (0.2058) | Acc: (92.76%) (16742/18048)\n",
            "Epoch: 48 | Batch_idx: 150 |  Loss: (0.2067) | Acc: (92.70%) (17918/19328)\n",
            "Epoch: 48 | Batch_idx: 160 |  Loss: (0.2069) | Acc: (92.71%) (19106/20608)\n",
            "Epoch: 48 | Batch_idx: 170 |  Loss: (0.2062) | Acc: (92.75%) (20301/21888)\n",
            "Epoch: 48 | Batch_idx: 180 |  Loss: (0.2069) | Acc: (92.74%) (21487/23168)\n",
            "Epoch: 48 | Batch_idx: 190 |  Loss: (0.2071) | Acc: (92.74%) (22674/24448)\n",
            "Epoch: 48 | Batch_idx: 200 |  Loss: (0.2069) | Acc: (92.77%) (23869/25728)\n",
            "Epoch: 48 | Batch_idx: 210 |  Loss: (0.2066) | Acc: (92.79%) (25062/27008)\n",
            "Epoch: 48 | Batch_idx: 220 |  Loss: (0.2052) | Acc: (92.89%) (26276/28288)\n",
            "Epoch: 48 | Batch_idx: 230 |  Loss: (0.2068) | Acc: (92.86%) (27458/29568)\n",
            "Epoch: 48 | Batch_idx: 240 |  Loss: (0.2074) | Acc: (92.87%) (28647/30848)\n",
            "Epoch: 48 | Batch_idx: 250 |  Loss: (0.2077) | Acc: (92.84%) (29829/32128)\n",
            "Epoch: 48 | Batch_idx: 260 |  Loss: (0.2096) | Acc: (92.79%) (30998/33408)\n",
            "Epoch: 48 | Batch_idx: 270 |  Loss: (0.2106) | Acc: (92.75%) (32173/34688)\n",
            "Epoch: 48 | Batch_idx: 280 |  Loss: (0.2103) | Acc: (92.73%) (33354/35968)\n",
            "Epoch: 48 | Batch_idx: 290 |  Loss: (0.2099) | Acc: (92.73%) (34541/37248)\n",
            "Epoch: 48 | Batch_idx: 300 |  Loss: (0.2106) | Acc: (92.72%) (35725/38528)\n",
            "Epoch: 48 | Batch_idx: 310 |  Loss: (0.2115) | Acc: (92.70%) (36904/39808)\n",
            "Epoch: 48 | Batch_idx: 320 |  Loss: (0.2119) | Acc: (92.69%) (38085/41088)\n",
            "Epoch: 48 | Batch_idx: 330 |  Loss: (0.2118) | Acc: (92.71%) (39280/42368)\n",
            "Epoch: 48 | Batch_idx: 340 |  Loss: (0.2114) | Acc: (92.71%) (40468/43648)\n",
            "Epoch: 48 | Batch_idx: 350 |  Loss: (0.2114) | Acc: (92.70%) (41650/44928)\n",
            "Epoch: 48 | Batch_idx: 360 |  Loss: (0.2122) | Acc: (92.70%) (42835/46208)\n",
            "Epoch: 48 | Batch_idx: 370 |  Loss: (0.2131) | Acc: (92.69%) (44016/47488)\n",
            "Epoch: 48 | Batch_idx: 380 |  Loss: (0.2143) | Acc: (92.64%) (45181/48768)\n",
            "Epoch: 48 | Batch_idx: 390 |  Loss: (0.2157) | Acc: (92.59%) (46297/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3935) | Acc: (87.31%) (8731/10000)\n",
            "Epoch: 49 | Batch_idx: 0 |  Loss: (0.1728) | Acc: (93.75%) (120/128)\n",
            "Epoch: 49 | Batch_idx: 10 |  Loss: (0.1700) | Acc: (94.25%) (1327/1408)\n",
            "Epoch: 49 | Batch_idx: 20 |  Loss: (0.1750) | Acc: (94.31%) (2535/2688)\n",
            "Epoch: 49 | Batch_idx: 30 |  Loss: (0.1825) | Acc: (94.03%) (3731/3968)\n",
            "Epoch: 49 | Batch_idx: 40 |  Loss: (0.1853) | Acc: (93.88%) (4927/5248)\n",
            "Epoch: 49 | Batch_idx: 50 |  Loss: (0.1873) | Acc: (93.92%) (6131/6528)\n",
            "Epoch: 49 | Batch_idx: 60 |  Loss: (0.1905) | Acc: (93.76%) (7321/7808)\n",
            "Epoch: 49 | Batch_idx: 70 |  Loss: (0.1908) | Acc: (93.79%) (8524/9088)\n",
            "Epoch: 49 | Batch_idx: 80 |  Loss: (0.1920) | Acc: (93.62%) (9707/10368)\n",
            "Epoch: 49 | Batch_idx: 90 |  Loss: (0.1938) | Acc: (93.56%) (10898/11648)\n",
            "Epoch: 49 | Batch_idx: 100 |  Loss: (0.1961) | Acc: (93.48%) (12085/12928)\n",
            "Epoch: 49 | Batch_idx: 110 |  Loss: (0.1962) | Acc: (93.47%) (13280/14208)\n",
            "Epoch: 49 | Batch_idx: 120 |  Loss: (0.1979) | Acc: (93.38%) (14462/15488)\n",
            "Epoch: 49 | Batch_idx: 130 |  Loss: (0.1982) | Acc: (93.34%) (15652/16768)\n",
            "Epoch: 49 | Batch_idx: 140 |  Loss: (0.1966) | Acc: (93.36%) (16849/18048)\n",
            "Epoch: 49 | Batch_idx: 150 |  Loss: (0.1978) | Acc: (93.35%) (18043/19328)\n",
            "Epoch: 49 | Batch_idx: 160 |  Loss: (0.1985) | Acc: (93.37%) (19241/20608)\n",
            "Epoch: 49 | Batch_idx: 170 |  Loss: (0.2004) | Acc: (93.27%) (20416/21888)\n",
            "Epoch: 49 | Batch_idx: 180 |  Loss: (0.2019) | Acc: (93.24%) (21601/23168)\n",
            "Epoch: 49 | Batch_idx: 190 |  Loss: (0.2012) | Acc: (93.26%) (22799/24448)\n",
            "Epoch: 49 | Batch_idx: 200 |  Loss: (0.2015) | Acc: (93.25%) (23991/25728)\n",
            "Epoch: 49 | Batch_idx: 210 |  Loss: (0.2023) | Acc: (93.19%) (25169/27008)\n",
            "Epoch: 49 | Batch_idx: 220 |  Loss: (0.2020) | Acc: (93.18%) (26360/28288)\n",
            "Epoch: 49 | Batch_idx: 230 |  Loss: (0.2042) | Acc: (93.15%) (27542/29568)\n",
            "Epoch: 49 | Batch_idx: 240 |  Loss: (0.2044) | Acc: (93.13%) (28729/30848)\n",
            "Epoch: 49 | Batch_idx: 250 |  Loss: (0.2041) | Acc: (93.16%) (29930/32128)\n",
            "Epoch: 49 | Batch_idx: 260 |  Loss: (0.2047) | Acc: (93.15%) (31119/33408)\n",
            "Epoch: 49 | Batch_idx: 270 |  Loss: (0.2059) | Acc: (93.13%) (32304/34688)\n",
            "Epoch: 49 | Batch_idx: 280 |  Loss: (0.2062) | Acc: (93.12%) (33495/35968)\n",
            "Epoch: 49 | Batch_idx: 290 |  Loss: (0.2065) | Acc: (93.09%) (34675/37248)\n",
            "Epoch: 49 | Batch_idx: 300 |  Loss: (0.2065) | Acc: (93.08%) (35860/38528)\n",
            "Epoch: 49 | Batch_idx: 310 |  Loss: (0.2086) | Acc: (93.03%) (37034/39808)\n",
            "Epoch: 49 | Batch_idx: 320 |  Loss: (0.2102) | Acc: (92.94%) (38188/41088)\n",
            "Epoch: 49 | Batch_idx: 330 |  Loss: (0.2107) | Acc: (92.93%) (39374/42368)\n",
            "Epoch: 49 | Batch_idx: 340 |  Loss: (0.2107) | Acc: (92.92%) (40559/43648)\n",
            "Epoch: 49 | Batch_idx: 350 |  Loss: (0.2105) | Acc: (92.93%) (41750/44928)\n",
            "Epoch: 49 | Batch_idx: 360 |  Loss: (0.2113) | Acc: (92.87%) (42915/46208)\n",
            "Epoch: 49 | Batch_idx: 370 |  Loss: (0.2115) | Acc: (92.87%) (44103/47488)\n",
            "Epoch: 49 | Batch_idx: 380 |  Loss: (0.2119) | Acc: (92.86%) (45285/48768)\n",
            "Epoch: 49 | Batch_idx: 390 |  Loss: (0.2117) | Acc: (92.87%) (46436/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4190) | Acc: (86.85%) (8685/10000)\n",
            "Epoch: 50 | Batch_idx: 0 |  Loss: (0.2294) | Acc: (91.41%) (117/128)\n",
            "Epoch: 50 | Batch_idx: 10 |  Loss: (0.2054) | Acc: (92.83%) (1307/1408)\n",
            "Epoch: 50 | Batch_idx: 20 |  Loss: (0.2016) | Acc: (93.38%) (2510/2688)\n",
            "Epoch: 50 | Batch_idx: 30 |  Loss: (0.1982) | Acc: (93.32%) (3703/3968)\n",
            "Epoch: 50 | Batch_idx: 40 |  Loss: (0.1965) | Acc: (93.37%) (4900/5248)\n",
            "Epoch: 50 | Batch_idx: 50 |  Loss: (0.1962) | Acc: (93.31%) (6091/6528)\n",
            "Epoch: 50 | Batch_idx: 60 |  Loss: (0.1978) | Acc: (93.16%) (7274/7808)\n",
            "Epoch: 50 | Batch_idx: 70 |  Loss: (0.2019) | Acc: (92.99%) (8451/9088)\n",
            "Epoch: 50 | Batch_idx: 80 |  Loss: (0.2021) | Acc: (93.04%) (9646/10368)\n",
            "Epoch: 50 | Batch_idx: 90 |  Loss: (0.2027) | Acc: (92.99%) (10832/11648)\n",
            "Epoch: 50 | Batch_idx: 100 |  Loss: (0.2058) | Acc: (92.89%) (12009/12928)\n",
            "Epoch: 50 | Batch_idx: 110 |  Loss: (0.2089) | Acc: (92.79%) (13184/14208)\n",
            "Epoch: 50 | Batch_idx: 120 |  Loss: (0.2112) | Acc: (92.73%) (14362/15488)\n",
            "Epoch: 50 | Batch_idx: 130 |  Loss: (0.2110) | Acc: (92.73%) (15549/16768)\n",
            "Epoch: 50 | Batch_idx: 140 |  Loss: (0.2143) | Acc: (92.65%) (16722/18048)\n",
            "Epoch: 50 | Batch_idx: 150 |  Loss: (0.2110) | Acc: (92.83%) (17943/19328)\n",
            "Epoch: 50 | Batch_idx: 160 |  Loss: (0.2117) | Acc: (92.81%) (19126/20608)\n",
            "Epoch: 50 | Batch_idx: 170 |  Loss: (0.2136) | Acc: (92.80%) (20312/21888)\n",
            "Epoch: 50 | Batch_idx: 180 |  Loss: (0.2129) | Acc: (92.81%) (21502/23168)\n",
            "Epoch: 50 | Batch_idx: 190 |  Loss: (0.2108) | Acc: (92.88%) (22707/24448)\n",
            "Epoch: 50 | Batch_idx: 200 |  Loss: (0.2114) | Acc: (92.91%) (23903/25728)\n",
            "Epoch: 50 | Batch_idx: 210 |  Loss: (0.2126) | Acc: (92.87%) (25081/27008)\n",
            "Epoch: 50 | Batch_idx: 220 |  Loss: (0.2130) | Acc: (92.86%) (26267/28288)\n",
            "Epoch: 50 | Batch_idx: 230 |  Loss: (0.2152) | Acc: (92.80%) (27440/29568)\n",
            "Epoch: 50 | Batch_idx: 240 |  Loss: (0.2153) | Acc: (92.77%) (28617/30848)\n",
            "Epoch: 50 | Batch_idx: 250 |  Loss: (0.2151) | Acc: (92.79%) (29810/32128)\n",
            "Epoch: 50 | Batch_idx: 260 |  Loss: (0.2143) | Acc: (92.80%) (31001/33408)\n",
            "Epoch: 50 | Batch_idx: 270 |  Loss: (0.2154) | Acc: (92.74%) (32169/34688)\n",
            "Epoch: 50 | Batch_idx: 280 |  Loss: (0.2161) | Acc: (92.74%) (33357/35968)\n",
            "Epoch: 50 | Batch_idx: 290 |  Loss: (0.2163) | Acc: (92.75%) (34546/37248)\n",
            "Epoch: 50 | Batch_idx: 300 |  Loss: (0.2166) | Acc: (92.74%) (35729/38528)\n",
            "Epoch: 50 | Batch_idx: 310 |  Loss: (0.2172) | Acc: (92.69%) (36897/39808)\n",
            "Epoch: 50 | Batch_idx: 320 |  Loss: (0.2178) | Acc: (92.69%) (38086/41088)\n",
            "Epoch: 50 | Batch_idx: 330 |  Loss: (0.2188) | Acc: (92.66%) (39260/42368)\n",
            "Epoch: 50 | Batch_idx: 340 |  Loss: (0.2191) | Acc: (92.67%) (40448/43648)\n",
            "Epoch: 50 | Batch_idx: 350 |  Loss: (0.2196) | Acc: (92.65%) (41624/44928)\n",
            "Epoch: 50 | Batch_idx: 360 |  Loss: (0.2199) | Acc: (92.64%) (42805/46208)\n",
            "Epoch: 50 | Batch_idx: 370 |  Loss: (0.2202) | Acc: (92.64%) (43993/47488)\n",
            "Epoch: 50 | Batch_idx: 380 |  Loss: (0.2192) | Acc: (92.68%) (45196/48768)\n",
            "Epoch: 50 | Batch_idx: 390 |  Loss: (0.2194) | Acc: (92.67%) (46337/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4248) | Acc: (87.17%) (8717/10000)\n",
            "Epoch: 51 | Batch_idx: 0 |  Loss: (0.2578) | Acc: (92.19%) (118/128)\n",
            "Epoch: 51 | Batch_idx: 10 |  Loss: (0.2148) | Acc: (93.25%) (1313/1408)\n",
            "Epoch: 51 | Batch_idx: 20 |  Loss: (0.2122) | Acc: (92.97%) (2499/2688)\n",
            "Epoch: 51 | Batch_idx: 30 |  Loss: (0.2004) | Acc: (93.30%) (3702/3968)\n",
            "Epoch: 51 | Batch_idx: 40 |  Loss: (0.2020) | Acc: (93.20%) (4891/5248)\n",
            "Epoch: 51 | Batch_idx: 50 |  Loss: (0.2017) | Acc: (93.12%) (6079/6528)\n",
            "Epoch: 51 | Batch_idx: 60 |  Loss: (0.2074) | Acc: (93.01%) (7262/7808)\n",
            "Epoch: 51 | Batch_idx: 70 |  Loss: (0.2101) | Acc: (92.83%) (8436/9088)\n",
            "Epoch: 51 | Batch_idx: 80 |  Loss: (0.2124) | Acc: (92.84%) (9626/10368)\n",
            "Epoch: 51 | Batch_idx: 90 |  Loss: (0.2134) | Acc: (92.81%) (10810/11648)\n",
            "Epoch: 51 | Batch_idx: 100 |  Loss: (0.2147) | Acc: (92.78%) (11994/12928)\n",
            "Epoch: 51 | Batch_idx: 110 |  Loss: (0.2146) | Acc: (92.72%) (13174/14208)\n",
            "Epoch: 51 | Batch_idx: 120 |  Loss: (0.2143) | Acc: (92.73%) (14362/15488)\n",
            "Epoch: 51 | Batch_idx: 130 |  Loss: (0.2119) | Acc: (92.84%) (15567/16768)\n",
            "Epoch: 51 | Batch_idx: 140 |  Loss: (0.2119) | Acc: (92.84%) (16755/18048)\n",
            "Epoch: 51 | Batch_idx: 150 |  Loss: (0.2121) | Acc: (92.84%) (17945/19328)\n",
            "Epoch: 51 | Batch_idx: 160 |  Loss: (0.2122) | Acc: (92.83%) (19130/20608)\n",
            "Epoch: 51 | Batch_idx: 170 |  Loss: (0.2107) | Acc: (92.85%) (20323/21888)\n",
            "Epoch: 51 | Batch_idx: 180 |  Loss: (0.2106) | Acc: (92.85%) (21512/23168)\n",
            "Epoch: 51 | Batch_idx: 190 |  Loss: (0.2107) | Acc: (92.87%) (22705/24448)\n",
            "Epoch: 51 | Batch_idx: 200 |  Loss: (0.2120) | Acc: (92.86%) (23891/25728)\n",
            "Epoch: 51 | Batch_idx: 210 |  Loss: (0.2127) | Acc: (92.85%) (25078/27008)\n",
            "Epoch: 51 | Batch_idx: 220 |  Loss: (0.2121) | Acc: (92.88%) (26274/28288)\n",
            "Epoch: 51 | Batch_idx: 230 |  Loss: (0.2137) | Acc: (92.84%) (27450/29568)\n",
            "Epoch: 51 | Batch_idx: 240 |  Loss: (0.2146) | Acc: (92.82%) (28634/30848)\n",
            "Epoch: 51 | Batch_idx: 250 |  Loss: (0.2139) | Acc: (92.85%) (29830/32128)\n",
            "Epoch: 51 | Batch_idx: 260 |  Loss: (0.2139) | Acc: (92.85%) (31018/33408)\n",
            "Epoch: 51 | Batch_idx: 270 |  Loss: (0.2130) | Acc: (92.88%) (32219/34688)\n",
            "Epoch: 51 | Batch_idx: 280 |  Loss: (0.2135) | Acc: (92.82%) (33385/35968)\n",
            "Epoch: 51 | Batch_idx: 290 |  Loss: (0.2125) | Acc: (92.86%) (34589/37248)\n",
            "Epoch: 51 | Batch_idx: 300 |  Loss: (0.2140) | Acc: (92.83%) (35766/38528)\n",
            "Epoch: 51 | Batch_idx: 310 |  Loss: (0.2146) | Acc: (92.80%) (36941/39808)\n",
            "Epoch: 51 | Batch_idx: 320 |  Loss: (0.2149) | Acc: (92.81%) (38132/41088)\n",
            "Epoch: 51 | Batch_idx: 330 |  Loss: (0.2144) | Acc: (92.83%) (39330/42368)\n",
            "Epoch: 51 | Batch_idx: 340 |  Loss: (0.2146) | Acc: (92.84%) (40521/43648)\n",
            "Epoch: 51 | Batch_idx: 350 |  Loss: (0.2149) | Acc: (92.81%) (41698/44928)\n",
            "Epoch: 51 | Batch_idx: 360 |  Loss: (0.2150) | Acc: (92.80%) (42880/46208)\n",
            "Epoch: 51 | Batch_idx: 370 |  Loss: (0.2157) | Acc: (92.75%) (44043/47488)\n",
            "Epoch: 51 | Batch_idx: 380 |  Loss: (0.2163) | Acc: (92.72%) (45218/48768)\n",
            "Epoch: 51 | Batch_idx: 390 |  Loss: (0.2160) | Acc: (92.73%) (46367/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4062) | Acc: (87.29%) (8729/10000)\n",
            "Epoch: 52 | Batch_idx: 0 |  Loss: (0.1488) | Acc: (93.75%) (120/128)\n",
            "Epoch: 52 | Batch_idx: 10 |  Loss: (0.2137) | Acc: (92.76%) (1306/1408)\n",
            "Epoch: 52 | Batch_idx: 20 |  Loss: (0.2077) | Acc: (93.08%) (2502/2688)\n",
            "Epoch: 52 | Batch_idx: 30 |  Loss: (0.1915) | Acc: (93.45%) (3708/3968)\n",
            "Epoch: 52 | Batch_idx: 40 |  Loss: (0.1879) | Acc: (93.54%) (4909/5248)\n",
            "Epoch: 52 | Batch_idx: 50 |  Loss: (0.1918) | Acc: (93.55%) (6107/6528)\n",
            "Epoch: 52 | Batch_idx: 60 |  Loss: (0.1929) | Acc: (93.48%) (7299/7808)\n",
            "Epoch: 52 | Batch_idx: 70 |  Loss: (0.1931) | Acc: (93.46%) (8494/9088)\n",
            "Epoch: 52 | Batch_idx: 80 |  Loss: (0.1959) | Acc: (93.37%) (9681/10368)\n",
            "Epoch: 52 | Batch_idx: 90 |  Loss: (0.1937) | Acc: (93.51%) (10892/11648)\n",
            "Epoch: 52 | Batch_idx: 100 |  Loss: (0.1955) | Acc: (93.48%) (12085/12928)\n",
            "Epoch: 52 | Batch_idx: 110 |  Loss: (0.1950) | Acc: (93.44%) (13276/14208)\n",
            "Epoch: 52 | Batch_idx: 120 |  Loss: (0.1919) | Acc: (93.53%) (14486/15488)\n",
            "Epoch: 52 | Batch_idx: 130 |  Loss: (0.1931) | Acc: (93.55%) (15687/16768)\n",
            "Epoch: 52 | Batch_idx: 140 |  Loss: (0.1931) | Acc: (93.58%) (16889/18048)\n",
            "Epoch: 52 | Batch_idx: 150 |  Loss: (0.1943) | Acc: (93.48%) (18068/19328)\n",
            "Epoch: 52 | Batch_idx: 160 |  Loss: (0.1965) | Acc: (93.35%) (19237/20608)\n",
            "Epoch: 52 | Batch_idx: 170 |  Loss: (0.1973) | Acc: (93.34%) (20430/21888)\n",
            "Epoch: 52 | Batch_idx: 180 |  Loss: (0.2006) | Acc: (93.29%) (21614/23168)\n",
            "Epoch: 52 | Batch_idx: 190 |  Loss: (0.2023) | Acc: (93.19%) (22783/24448)\n",
            "Epoch: 52 | Batch_idx: 200 |  Loss: (0.2020) | Acc: (93.18%) (23973/25728)\n",
            "Epoch: 52 | Batch_idx: 210 |  Loss: (0.2019) | Acc: (93.17%) (25164/27008)\n",
            "Epoch: 52 | Batch_idx: 220 |  Loss: (0.2028) | Acc: (93.12%) (26342/28288)\n",
            "Epoch: 52 | Batch_idx: 230 |  Loss: (0.2036) | Acc: (93.08%) (27521/29568)\n",
            "Epoch: 52 | Batch_idx: 240 |  Loss: (0.2044) | Acc: (93.06%) (28706/30848)\n",
            "Epoch: 52 | Batch_idx: 250 |  Loss: (0.2059) | Acc: (93.00%) (29880/32128)\n",
            "Epoch: 52 | Batch_idx: 260 |  Loss: (0.2056) | Acc: (93.00%) (31069/33408)\n",
            "Epoch: 52 | Batch_idx: 270 |  Loss: (0.2062) | Acc: (92.98%) (32252/34688)\n",
            "Epoch: 52 | Batch_idx: 280 |  Loss: (0.2045) | Acc: (93.02%) (33459/35968)\n",
            "Epoch: 52 | Batch_idx: 290 |  Loss: (0.2054) | Acc: (93.00%) (34641/37248)\n",
            "Epoch: 52 | Batch_idx: 300 |  Loss: (0.2049) | Acc: (93.01%) (35835/38528)\n",
            "Epoch: 52 | Batch_idx: 310 |  Loss: (0.2058) | Acc: (93.01%) (37024/39808)\n",
            "Epoch: 52 | Batch_idx: 320 |  Loss: (0.2063) | Acc: (93.00%) (38211/41088)\n",
            "Epoch: 52 | Batch_idx: 330 |  Loss: (0.2068) | Acc: (92.96%) (39385/42368)\n",
            "Epoch: 52 | Batch_idx: 340 |  Loss: (0.2063) | Acc: (92.96%) (40577/43648)\n",
            "Epoch: 52 | Batch_idx: 350 |  Loss: (0.2068) | Acc: (92.94%) (41756/44928)\n",
            "Epoch: 52 | Batch_idx: 360 |  Loss: (0.2071) | Acc: (92.92%) (42938/46208)\n",
            "Epoch: 52 | Batch_idx: 370 |  Loss: (0.2079) | Acc: (92.90%) (44116/47488)\n",
            "Epoch: 52 | Batch_idx: 380 |  Loss: (0.2072) | Acc: (92.93%) (45318/48768)\n",
            "Epoch: 52 | Batch_idx: 390 |  Loss: (0.2085) | Acc: (92.87%) (46435/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4094) | Acc: (87.46%) (8746/10000)\n",
            "Epoch: 53 | Batch_idx: 0 |  Loss: (0.1133) | Acc: (96.88%) (124/128)\n",
            "Epoch: 53 | Batch_idx: 10 |  Loss: (0.2003) | Acc: (92.83%) (1307/1408)\n",
            "Epoch: 53 | Batch_idx: 20 |  Loss: (0.1867) | Acc: (93.34%) (2509/2688)\n",
            "Epoch: 53 | Batch_idx: 30 |  Loss: (0.1862) | Acc: (93.47%) (3709/3968)\n",
            "Epoch: 53 | Batch_idx: 40 |  Loss: (0.1865) | Acc: (93.56%) (4910/5248)\n",
            "Epoch: 53 | Batch_idx: 50 |  Loss: (0.1856) | Acc: (93.50%) (6104/6528)\n",
            "Epoch: 53 | Batch_idx: 60 |  Loss: (0.1882) | Acc: (93.30%) (7285/7808)\n",
            "Epoch: 53 | Batch_idx: 70 |  Loss: (0.1925) | Acc: (93.14%) (8465/9088)\n",
            "Epoch: 53 | Batch_idx: 80 |  Loss: (0.1946) | Acc: (93.14%) (9657/10368)\n",
            "Epoch: 53 | Batch_idx: 90 |  Loss: (0.1950) | Acc: (93.13%) (10848/11648)\n",
            "Epoch: 53 | Batch_idx: 100 |  Loss: (0.1940) | Acc: (93.19%) (12047/12928)\n",
            "Epoch: 53 | Batch_idx: 110 |  Loss: (0.1927) | Acc: (93.24%) (13247/14208)\n",
            "Epoch: 53 | Batch_idx: 120 |  Loss: (0.1938) | Acc: (93.22%) (14438/15488)\n",
            "Epoch: 53 | Batch_idx: 130 |  Loss: (0.1947) | Acc: (93.23%) (15633/16768)\n",
            "Epoch: 53 | Batch_idx: 140 |  Loss: (0.1959) | Acc: (93.18%) (16817/18048)\n",
            "Epoch: 53 | Batch_idx: 150 |  Loss: (0.1956) | Acc: (93.19%) (18011/19328)\n",
            "Epoch: 53 | Batch_idx: 160 |  Loss: (0.1950) | Acc: (93.20%) (19207/20608)\n",
            "Epoch: 53 | Batch_idx: 170 |  Loss: (0.1945) | Acc: (93.23%) (20407/21888)\n",
            "Epoch: 53 | Batch_idx: 180 |  Loss: (0.1955) | Acc: (93.20%) (21593/23168)\n",
            "Epoch: 53 | Batch_idx: 190 |  Loss: (0.1951) | Acc: (93.26%) (22800/24448)\n",
            "Epoch: 53 | Batch_idx: 200 |  Loss: (0.1963) | Acc: (93.24%) (23988/25728)\n",
            "Epoch: 53 | Batch_idx: 210 |  Loss: (0.1959) | Acc: (93.25%) (25184/27008)\n",
            "Epoch: 53 | Batch_idx: 220 |  Loss: (0.1957) | Acc: (93.24%) (26376/28288)\n",
            "Epoch: 53 | Batch_idx: 230 |  Loss: (0.1952) | Acc: (93.30%) (27586/29568)\n",
            "Epoch: 53 | Batch_idx: 240 |  Loss: (0.1963) | Acc: (93.26%) (28770/30848)\n",
            "Epoch: 53 | Batch_idx: 250 |  Loss: (0.1964) | Acc: (93.27%) (29967/32128)\n",
            "Epoch: 53 | Batch_idx: 260 |  Loss: (0.1959) | Acc: (93.31%) (31173/33408)\n",
            "Epoch: 53 | Batch_idx: 270 |  Loss: (0.1957) | Acc: (93.32%) (32370/34688)\n",
            "Epoch: 53 | Batch_idx: 280 |  Loss: (0.1962) | Acc: (93.29%) (33553/35968)\n",
            "Epoch: 53 | Batch_idx: 290 |  Loss: (0.1968) | Acc: (93.27%) (34742/37248)\n",
            "Epoch: 53 | Batch_idx: 300 |  Loss: (0.1988) | Acc: (93.19%) (35906/38528)\n",
            "Epoch: 53 | Batch_idx: 310 |  Loss: (0.1993) | Acc: (93.19%) (37096/39808)\n",
            "Epoch: 53 | Batch_idx: 320 |  Loss: (0.2001) | Acc: (93.14%) (38270/41088)\n",
            "Epoch: 53 | Batch_idx: 330 |  Loss: (0.2004) | Acc: (93.14%) (39463/42368)\n",
            "Epoch: 53 | Batch_idx: 340 |  Loss: (0.1999) | Acc: (93.15%) (40658/43648)\n",
            "Epoch: 53 | Batch_idx: 350 |  Loss: (0.2003) | Acc: (93.14%) (41845/44928)\n",
            "Epoch: 53 | Batch_idx: 360 |  Loss: (0.2003) | Acc: (93.14%) (43040/46208)\n",
            "Epoch: 53 | Batch_idx: 370 |  Loss: (0.2009) | Acc: (93.13%) (44224/47488)\n",
            "Epoch: 53 | Batch_idx: 380 |  Loss: (0.2008) | Acc: (93.12%) (45413/48768)\n",
            "Epoch: 53 | Batch_idx: 390 |  Loss: (0.2007) | Acc: (93.12%) (46558/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4411) | Acc: (86.32%) (8632/10000)\n",
            "Epoch: 54 | Batch_idx: 0 |  Loss: (0.1778) | Acc: (94.53%) (121/128)\n",
            "Epoch: 54 | Batch_idx: 10 |  Loss: (0.1803) | Acc: (93.47%) (1316/1408)\n",
            "Epoch: 54 | Batch_idx: 20 |  Loss: (0.2020) | Acc: (93.38%) (2510/2688)\n",
            "Epoch: 54 | Batch_idx: 30 |  Loss: (0.2005) | Acc: (93.40%) (3706/3968)\n",
            "Epoch: 54 | Batch_idx: 40 |  Loss: (0.1961) | Acc: (93.35%) (4899/5248)\n",
            "Epoch: 54 | Batch_idx: 50 |  Loss: (0.1986) | Acc: (93.18%) (6083/6528)\n",
            "Epoch: 54 | Batch_idx: 60 |  Loss: (0.1968) | Acc: (93.35%) (7289/7808)\n",
            "Epoch: 54 | Batch_idx: 70 |  Loss: (0.1985) | Acc: (93.25%) (8475/9088)\n",
            "Epoch: 54 | Batch_idx: 80 |  Loss: (0.1987) | Acc: (93.19%) (9662/10368)\n",
            "Epoch: 54 | Batch_idx: 90 |  Loss: (0.1981) | Acc: (93.22%) (10858/11648)\n",
            "Epoch: 54 | Batch_idx: 100 |  Loss: (0.1992) | Acc: (93.20%) (12049/12928)\n",
            "Epoch: 54 | Batch_idx: 110 |  Loss: (0.2002) | Acc: (93.17%) (13237/14208)\n",
            "Epoch: 54 | Batch_idx: 120 |  Loss: (0.2003) | Acc: (93.20%) (14435/15488)\n",
            "Epoch: 54 | Batch_idx: 130 |  Loss: (0.2004) | Acc: (93.19%) (15626/16768)\n",
            "Epoch: 54 | Batch_idx: 140 |  Loss: (0.2009) | Acc: (93.16%) (16813/18048)\n",
            "Epoch: 54 | Batch_idx: 150 |  Loss: (0.2029) | Acc: (93.08%) (17991/19328)\n",
            "Epoch: 54 | Batch_idx: 160 |  Loss: (0.2034) | Acc: (93.13%) (19192/20608)\n",
            "Epoch: 54 | Batch_idx: 170 |  Loss: (0.2027) | Acc: (93.14%) (20387/21888)\n",
            "Epoch: 54 | Batch_idx: 180 |  Loss: (0.2041) | Acc: (93.09%) (21568/23168)\n",
            "Epoch: 54 | Batch_idx: 190 |  Loss: (0.2040) | Acc: (93.12%) (22765/24448)\n",
            "Epoch: 54 | Batch_idx: 200 |  Loss: (0.2035) | Acc: (93.14%) (23962/25728)\n",
            "Epoch: 54 | Batch_idx: 210 |  Loss: (0.2043) | Acc: (93.12%) (25151/27008)\n",
            "Epoch: 54 | Batch_idx: 220 |  Loss: (0.2043) | Acc: (93.12%) (26341/28288)\n",
            "Epoch: 54 | Batch_idx: 230 |  Loss: (0.2049) | Acc: (93.11%) (27532/29568)\n",
            "Epoch: 54 | Batch_idx: 240 |  Loss: (0.2041) | Acc: (93.16%) (28739/30848)\n",
            "Epoch: 54 | Batch_idx: 250 |  Loss: (0.2042) | Acc: (93.18%) (29936/32128)\n",
            "Epoch: 54 | Batch_idx: 260 |  Loss: (0.2046) | Acc: (93.16%) (31123/33408)\n",
            "Epoch: 54 | Batch_idx: 270 |  Loss: (0.2053) | Acc: (93.13%) (32306/34688)\n",
            "Epoch: 54 | Batch_idx: 280 |  Loss: (0.2061) | Acc: (93.14%) (33502/35968)\n",
            "Epoch: 54 | Batch_idx: 290 |  Loss: (0.2064) | Acc: (93.12%) (34687/37248)\n",
            "Epoch: 54 | Batch_idx: 300 |  Loss: (0.2070) | Acc: (93.08%) (35863/38528)\n",
            "Epoch: 54 | Batch_idx: 310 |  Loss: (0.2060) | Acc: (93.13%) (37072/39808)\n",
            "Epoch: 54 | Batch_idx: 320 |  Loss: (0.2055) | Acc: (93.16%) (38277/41088)\n",
            "Epoch: 54 | Batch_idx: 330 |  Loss: (0.2058) | Acc: (93.14%) (39461/42368)\n",
            "Epoch: 54 | Batch_idx: 340 |  Loss: (0.2060) | Acc: (93.12%) (40645/43648)\n",
            "Epoch: 54 | Batch_idx: 350 |  Loss: (0.2063) | Acc: (93.12%) (41838/44928)\n",
            "Epoch: 54 | Batch_idx: 360 |  Loss: (0.2064) | Acc: (93.10%) (43021/46208)\n",
            "Epoch: 54 | Batch_idx: 370 |  Loss: (0.2066) | Acc: (93.10%) (44209/47488)\n",
            "Epoch: 54 | Batch_idx: 380 |  Loss: (0.2064) | Acc: (93.10%) (45403/48768)\n",
            "Epoch: 54 | Batch_idx: 390 |  Loss: (0.2057) | Acc: (93.13%) (46565/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3991) | Acc: (87.65%) (8765/10000)\n",
            "Epoch: 55 | Batch_idx: 0 |  Loss: (0.1946) | Acc: (92.97%) (119/128)\n",
            "Epoch: 55 | Batch_idx: 10 |  Loss: (0.1499) | Acc: (94.74%) (1334/1408)\n",
            "Epoch: 55 | Batch_idx: 20 |  Loss: (0.1480) | Acc: (94.98%) (2553/2688)\n",
            "Epoch: 55 | Batch_idx: 30 |  Loss: (0.1729) | Acc: (94.08%) (3733/3968)\n",
            "Epoch: 55 | Batch_idx: 40 |  Loss: (0.1788) | Acc: (94.05%) (4936/5248)\n",
            "Epoch: 55 | Batch_idx: 50 |  Loss: (0.1798) | Acc: (93.92%) (6131/6528)\n",
            "Epoch: 55 | Batch_idx: 60 |  Loss: (0.1836) | Acc: (93.74%) (7319/7808)\n",
            "Epoch: 55 | Batch_idx: 70 |  Loss: (0.1872) | Acc: (93.57%) (8504/9088)\n",
            "Epoch: 55 | Batch_idx: 80 |  Loss: (0.1862) | Acc: (93.54%) (9698/10368)\n",
            "Epoch: 55 | Batch_idx: 90 |  Loss: (0.1855) | Acc: (93.56%) (10898/11648)\n",
            "Epoch: 55 | Batch_idx: 100 |  Loss: (0.1874) | Acc: (93.46%) (12083/12928)\n",
            "Epoch: 55 | Batch_idx: 110 |  Loss: (0.1902) | Acc: (93.41%) (13272/14208)\n",
            "Epoch: 55 | Batch_idx: 120 |  Loss: (0.1913) | Acc: (93.42%) (14469/15488)\n",
            "Epoch: 55 | Batch_idx: 130 |  Loss: (0.1935) | Acc: (93.41%) (15663/16768)\n",
            "Epoch: 55 | Batch_idx: 140 |  Loss: (0.1938) | Acc: (93.42%) (16860/18048)\n",
            "Epoch: 55 | Batch_idx: 150 |  Loss: (0.1939) | Acc: (93.36%) (18045/19328)\n",
            "Epoch: 55 | Batch_idx: 160 |  Loss: (0.1945) | Acc: (93.33%) (19234/20608)\n",
            "Epoch: 55 | Batch_idx: 170 |  Loss: (0.1951) | Acc: (93.30%) (20422/21888)\n",
            "Epoch: 55 | Batch_idx: 180 |  Loss: (0.1967) | Acc: (93.26%) (21607/23168)\n",
            "Epoch: 55 | Batch_idx: 190 |  Loss: (0.1979) | Acc: (93.25%) (22798/24448)\n",
            "Epoch: 55 | Batch_idx: 200 |  Loss: (0.1984) | Acc: (93.24%) (23990/25728)\n",
            "Epoch: 55 | Batch_idx: 210 |  Loss: (0.1981) | Acc: (93.26%) (25188/27008)\n",
            "Epoch: 55 | Batch_idx: 220 |  Loss: (0.1999) | Acc: (93.17%) (26355/28288)\n",
            "Epoch: 55 | Batch_idx: 230 |  Loss: (0.2000) | Acc: (93.15%) (27543/29568)\n",
            "Epoch: 55 | Batch_idx: 240 |  Loss: (0.2015) | Acc: (93.13%) (28729/30848)\n",
            "Epoch: 55 | Batch_idx: 250 |  Loss: (0.2029) | Acc: (93.08%) (29906/32128)\n",
            "Epoch: 55 | Batch_idx: 260 |  Loss: (0.2028) | Acc: (93.08%) (31095/33408)\n",
            "Epoch: 55 | Batch_idx: 270 |  Loss: (0.2028) | Acc: (93.09%) (32292/34688)\n",
            "Epoch: 55 | Batch_idx: 280 |  Loss: (0.2034) | Acc: (93.05%) (33470/35968)\n",
            "Epoch: 55 | Batch_idx: 290 |  Loss: (0.2047) | Acc: (93.01%) (34645/37248)\n",
            "Epoch: 55 | Batch_idx: 300 |  Loss: (0.2045) | Acc: (93.03%) (35842/38528)\n",
            "Epoch: 55 | Batch_idx: 310 |  Loss: (0.2051) | Acc: (93.02%) (37028/39808)\n",
            "Epoch: 55 | Batch_idx: 320 |  Loss: (0.2065) | Acc: (92.97%) (38199/41088)\n",
            "Epoch: 55 | Batch_idx: 330 |  Loss: (0.2065) | Acc: (92.97%) (39390/42368)\n",
            "Epoch: 55 | Batch_idx: 340 |  Loss: (0.2066) | Acc: (92.95%) (40572/43648)\n",
            "Epoch: 55 | Batch_idx: 350 |  Loss: (0.2063) | Acc: (92.97%) (41770/44928)\n",
            "Epoch: 55 | Batch_idx: 360 |  Loss: (0.2065) | Acc: (92.97%) (42961/46208)\n",
            "Epoch: 55 | Batch_idx: 370 |  Loss: (0.2074) | Acc: (92.93%) (44131/47488)\n",
            "Epoch: 55 | Batch_idx: 380 |  Loss: (0.2069) | Acc: (92.94%) (45323/48768)\n",
            "Epoch: 55 | Batch_idx: 390 |  Loss: (0.2069) | Acc: (92.92%) (46460/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4353) | Acc: (86.60%) (8660/10000)\n",
            "Epoch: 56 | Batch_idx: 0 |  Loss: (0.1223) | Acc: (94.53%) (121/128)\n",
            "Epoch: 56 | Batch_idx: 10 |  Loss: (0.1976) | Acc: (92.83%) (1307/1408)\n",
            "Epoch: 56 | Batch_idx: 20 |  Loss: (0.1781) | Acc: (93.60%) (2516/2688)\n",
            "Epoch: 56 | Batch_idx: 30 |  Loss: (0.1751) | Acc: (93.93%) (3727/3968)\n",
            "Epoch: 56 | Batch_idx: 40 |  Loss: (0.1801) | Acc: (93.69%) (4917/5248)\n",
            "Epoch: 56 | Batch_idx: 50 |  Loss: (0.1794) | Acc: (93.72%) (6118/6528)\n",
            "Epoch: 56 | Batch_idx: 60 |  Loss: (0.1828) | Acc: (93.62%) (7310/7808)\n",
            "Epoch: 56 | Batch_idx: 70 |  Loss: (0.1832) | Acc: (93.55%) (8502/9088)\n",
            "Epoch: 56 | Batch_idx: 80 |  Loss: (0.1828) | Acc: (93.59%) (9703/10368)\n",
            "Epoch: 56 | Batch_idx: 90 |  Loss: (0.1808) | Acc: (93.69%) (10913/11648)\n",
            "Epoch: 56 | Batch_idx: 100 |  Loss: (0.1821) | Acc: (93.67%) (12110/12928)\n",
            "Epoch: 56 | Batch_idx: 110 |  Loss: (0.1849) | Acc: (93.63%) (13303/14208)\n",
            "Epoch: 56 | Batch_idx: 120 |  Loss: (0.1874) | Acc: (93.47%) (14477/15488)\n",
            "Epoch: 56 | Batch_idx: 130 |  Loss: (0.1865) | Acc: (93.57%) (15690/16768)\n",
            "Epoch: 56 | Batch_idx: 140 |  Loss: (0.1874) | Acc: (93.53%) (16881/18048)\n",
            "Epoch: 56 | Batch_idx: 150 |  Loss: (0.1898) | Acc: (93.42%) (18056/19328)\n",
            "Epoch: 56 | Batch_idx: 160 |  Loss: (0.1905) | Acc: (93.41%) (19250/20608)\n",
            "Epoch: 56 | Batch_idx: 170 |  Loss: (0.1901) | Acc: (93.45%) (20455/21888)\n",
            "Epoch: 56 | Batch_idx: 180 |  Loss: (0.1896) | Acc: (93.50%) (21661/23168)\n",
            "Epoch: 56 | Batch_idx: 190 |  Loss: (0.1898) | Acc: (93.53%) (22867/24448)\n",
            "Epoch: 56 | Batch_idx: 200 |  Loss: (0.1925) | Acc: (93.45%) (24043/25728)\n",
            "Epoch: 56 | Batch_idx: 210 |  Loss: (0.1926) | Acc: (93.45%) (25240/27008)\n",
            "Epoch: 56 | Batch_idx: 220 |  Loss: (0.1920) | Acc: (93.47%) (26441/28288)\n",
            "Epoch: 56 | Batch_idx: 230 |  Loss: (0.1923) | Acc: (93.45%) (27632/29568)\n",
            "Epoch: 56 | Batch_idx: 240 |  Loss: (0.1925) | Acc: (93.41%) (28815/30848)\n",
            "Epoch: 56 | Batch_idx: 250 |  Loss: (0.1925) | Acc: (93.41%) (30011/32128)\n",
            "Epoch: 56 | Batch_idx: 260 |  Loss: (0.1928) | Acc: (93.39%) (31201/33408)\n",
            "Epoch: 56 | Batch_idx: 270 |  Loss: (0.1934) | Acc: (93.37%) (32389/34688)\n",
            "Epoch: 56 | Batch_idx: 280 |  Loss: (0.1947) | Acc: (93.32%) (33566/35968)\n",
            "Epoch: 56 | Batch_idx: 290 |  Loss: (0.1954) | Acc: (93.31%) (34755/37248)\n",
            "Epoch: 56 | Batch_idx: 300 |  Loss: (0.1958) | Acc: (93.30%) (35946/38528)\n",
            "Epoch: 56 | Batch_idx: 310 |  Loss: (0.1960) | Acc: (93.31%) (37144/39808)\n",
            "Epoch: 56 | Batch_idx: 320 |  Loss: (0.1971) | Acc: (93.27%) (38323/41088)\n",
            "Epoch: 56 | Batch_idx: 330 |  Loss: (0.1982) | Acc: (93.26%) (39511/42368)\n",
            "Epoch: 56 | Batch_idx: 340 |  Loss: (0.1987) | Acc: (93.22%) (40690/43648)\n",
            "Epoch: 56 | Batch_idx: 350 |  Loss: (0.1996) | Acc: (93.20%) (41873/44928)\n",
            "Epoch: 56 | Batch_idx: 360 |  Loss: (0.1994) | Acc: (93.19%) (43061/46208)\n",
            "Epoch: 56 | Batch_idx: 370 |  Loss: (0.1992) | Acc: (93.19%) (44252/47488)\n",
            "Epoch: 56 | Batch_idx: 380 |  Loss: (0.1989) | Acc: (93.19%) (45449/48768)\n",
            "Epoch: 56 | Batch_idx: 390 |  Loss: (0.1996) | Acc: (93.18%) (46588/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4431) | Acc: (86.71%) (8671/10000)\n",
            "Epoch: 57 | Batch_idx: 0 |  Loss: (0.1526) | Acc: (96.09%) (123/128)\n",
            "Epoch: 57 | Batch_idx: 10 |  Loss: (0.1908) | Acc: (93.75%) (1320/1408)\n",
            "Epoch: 57 | Batch_idx: 20 |  Loss: (0.1807) | Acc: (94.08%) (2529/2688)\n",
            "Epoch: 57 | Batch_idx: 30 |  Loss: (0.1817) | Acc: (93.98%) (3729/3968)\n",
            "Epoch: 57 | Batch_idx: 40 |  Loss: (0.1819) | Acc: (93.83%) (4924/5248)\n",
            "Epoch: 57 | Batch_idx: 50 |  Loss: (0.1807) | Acc: (93.87%) (6128/6528)\n",
            "Epoch: 57 | Batch_idx: 60 |  Loss: (0.1823) | Acc: (93.80%) (7324/7808)\n",
            "Epoch: 57 | Batch_idx: 70 |  Loss: (0.1802) | Acc: (93.78%) (8523/9088)\n",
            "Epoch: 57 | Batch_idx: 80 |  Loss: (0.1801) | Acc: (93.78%) (9723/10368)\n",
            "Epoch: 57 | Batch_idx: 90 |  Loss: (0.1819) | Acc: (93.72%) (10916/11648)\n",
            "Epoch: 57 | Batch_idx: 100 |  Loss: (0.1803) | Acc: (93.68%) (12111/12928)\n",
            "Epoch: 57 | Batch_idx: 110 |  Loss: (0.1831) | Acc: (93.64%) (13304/14208)\n",
            "Epoch: 57 | Batch_idx: 120 |  Loss: (0.1852) | Acc: (93.60%) (14497/15488)\n",
            "Epoch: 57 | Batch_idx: 130 |  Loss: (0.1837) | Acc: (93.65%) (15703/16768)\n",
            "Epoch: 57 | Batch_idx: 140 |  Loss: (0.1844) | Acc: (93.62%) (16897/18048)\n",
            "Epoch: 57 | Batch_idx: 150 |  Loss: (0.1843) | Acc: (93.64%) (18098/19328)\n",
            "Epoch: 57 | Batch_idx: 160 |  Loss: (0.1850) | Acc: (93.59%) (19286/20608)\n",
            "Epoch: 57 | Batch_idx: 170 |  Loss: (0.1855) | Acc: (93.63%) (20493/21888)\n",
            "Epoch: 57 | Batch_idx: 180 |  Loss: (0.1862) | Acc: (93.58%) (21681/23168)\n",
            "Epoch: 57 | Batch_idx: 190 |  Loss: (0.1864) | Acc: (93.58%) (22879/24448)\n",
            "Epoch: 57 | Batch_idx: 200 |  Loss: (0.1866) | Acc: (93.56%) (24072/25728)\n",
            "Epoch: 57 | Batch_idx: 210 |  Loss: (0.1885) | Acc: (93.50%) (25253/27008)\n",
            "Epoch: 57 | Batch_idx: 220 |  Loss: (0.1899) | Acc: (93.46%) (26438/28288)\n",
            "Epoch: 57 | Batch_idx: 230 |  Loss: (0.1923) | Acc: (93.40%) (27617/29568)\n",
            "Epoch: 57 | Batch_idx: 240 |  Loss: (0.1925) | Acc: (93.40%) (28812/30848)\n",
            "Epoch: 57 | Batch_idx: 250 |  Loss: (0.1941) | Acc: (93.32%) (29983/32128)\n",
            "Epoch: 57 | Batch_idx: 260 |  Loss: (0.1950) | Acc: (93.31%) (31172/33408)\n",
            "Epoch: 57 | Batch_idx: 270 |  Loss: (0.1948) | Acc: (93.33%) (32374/34688)\n",
            "Epoch: 57 | Batch_idx: 280 |  Loss: (0.1946) | Acc: (93.35%) (33577/35968)\n",
            "Epoch: 57 | Batch_idx: 290 |  Loss: (0.1939) | Acc: (93.39%) (34785/37248)\n",
            "Epoch: 57 | Batch_idx: 300 |  Loss: (0.1938) | Acc: (93.43%) (35997/38528)\n",
            "Epoch: 57 | Batch_idx: 310 |  Loss: (0.1958) | Acc: (93.36%) (37164/39808)\n",
            "Epoch: 57 | Batch_idx: 320 |  Loss: (0.1961) | Acc: (93.36%) (38358/41088)\n",
            "Epoch: 57 | Batch_idx: 330 |  Loss: (0.1973) | Acc: (93.30%) (39531/42368)\n",
            "Epoch: 57 | Batch_idx: 340 |  Loss: (0.1984) | Acc: (93.26%) (40704/43648)\n",
            "Epoch: 57 | Batch_idx: 350 |  Loss: (0.1984) | Acc: (93.26%) (41902/44928)\n",
            "Epoch: 57 | Batch_idx: 360 |  Loss: (0.1988) | Acc: (93.25%) (43090/46208)\n",
            "Epoch: 57 | Batch_idx: 370 |  Loss: (0.1993) | Acc: (93.22%) (44266/47488)\n",
            "Epoch: 57 | Batch_idx: 380 |  Loss: (0.1994) | Acc: (93.22%) (45462/48768)\n",
            "Epoch: 57 | Batch_idx: 390 |  Loss: (0.2009) | Acc: (93.16%) (46582/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4317) | Acc: (86.38%) (8638/10000)\n",
            "Epoch: 58 | Batch_idx: 0 |  Loss: (0.1116) | Acc: (96.88%) (124/128)\n",
            "Epoch: 58 | Batch_idx: 10 |  Loss: (0.1518) | Acc: (94.82%) (1335/1408)\n",
            "Epoch: 58 | Batch_idx: 20 |  Loss: (0.1626) | Acc: (94.42%) (2538/2688)\n",
            "Epoch: 58 | Batch_idx: 30 |  Loss: (0.1737) | Acc: (94.43%) (3747/3968)\n",
            "Epoch: 58 | Batch_idx: 40 |  Loss: (0.1748) | Acc: (94.40%) (4954/5248)\n",
            "Epoch: 58 | Batch_idx: 50 |  Loss: (0.1696) | Acc: (94.47%) (6167/6528)\n",
            "Epoch: 58 | Batch_idx: 60 |  Loss: (0.1708) | Acc: (94.33%) (7365/7808)\n",
            "Epoch: 58 | Batch_idx: 70 |  Loss: (0.1776) | Acc: (94.18%) (8559/9088)\n",
            "Epoch: 58 | Batch_idx: 80 |  Loss: (0.1841) | Acc: (93.95%) (9741/10368)\n",
            "Epoch: 58 | Batch_idx: 90 |  Loss: (0.1857) | Acc: (93.93%) (10941/11648)\n",
            "Epoch: 58 | Batch_idx: 100 |  Loss: (0.1896) | Acc: (93.80%) (12127/12928)\n",
            "Epoch: 58 | Batch_idx: 110 |  Loss: (0.1925) | Acc: (93.65%) (13306/14208)\n",
            "Epoch: 58 | Batch_idx: 120 |  Loss: (0.1923) | Acc: (93.66%) (14506/15488)\n",
            "Epoch: 58 | Batch_idx: 130 |  Loss: (0.1941) | Acc: (93.52%) (15682/16768)\n",
            "Epoch: 58 | Batch_idx: 140 |  Loss: (0.1931) | Acc: (93.50%) (16875/18048)\n",
            "Epoch: 58 | Batch_idx: 150 |  Loss: (0.1928) | Acc: (93.54%) (18080/19328)\n",
            "Epoch: 58 | Batch_idx: 160 |  Loss: (0.1925) | Acc: (93.53%) (19274/20608)\n",
            "Epoch: 58 | Batch_idx: 170 |  Loss: (0.1963) | Acc: (93.40%) (20444/21888)\n",
            "Epoch: 58 | Batch_idx: 180 |  Loss: (0.1981) | Acc: (93.32%) (21620/23168)\n",
            "Epoch: 58 | Batch_idx: 190 |  Loss: (0.1987) | Acc: (93.28%) (22806/24448)\n",
            "Epoch: 58 | Batch_idx: 200 |  Loss: (0.1992) | Acc: (93.29%) (24001/25728)\n",
            "Epoch: 58 | Batch_idx: 210 |  Loss: (0.1978) | Acc: (93.33%) (25206/27008)\n",
            "Epoch: 58 | Batch_idx: 220 |  Loss: (0.1971) | Acc: (93.30%) (26393/28288)\n",
            "Epoch: 58 | Batch_idx: 230 |  Loss: (0.1970) | Acc: (93.28%) (27580/29568)\n",
            "Epoch: 58 | Batch_idx: 240 |  Loss: (0.1994) | Acc: (93.22%) (28755/30848)\n",
            "Epoch: 58 | Batch_idx: 250 |  Loss: (0.1998) | Acc: (93.22%) (29951/32128)\n",
            "Epoch: 58 | Batch_idx: 260 |  Loss: (0.2000) | Acc: (93.24%) (31150/33408)\n",
            "Epoch: 58 | Batch_idx: 270 |  Loss: (0.2001) | Acc: (93.22%) (32336/34688)\n",
            "Epoch: 58 | Batch_idx: 280 |  Loss: (0.1998) | Acc: (93.21%) (33527/35968)\n",
            "Epoch: 58 | Batch_idx: 290 |  Loss: (0.2002) | Acc: (93.19%) (34712/37248)\n",
            "Epoch: 58 | Batch_idx: 300 |  Loss: (0.2014) | Acc: (93.17%) (35897/38528)\n",
            "Epoch: 58 | Batch_idx: 310 |  Loss: (0.2014) | Acc: (93.14%) (37078/39808)\n",
            "Epoch: 58 | Batch_idx: 320 |  Loss: (0.2019) | Acc: (93.14%) (38268/41088)\n",
            "Epoch: 58 | Batch_idx: 330 |  Loss: (0.2011) | Acc: (93.16%) (39470/42368)\n",
            "Epoch: 58 | Batch_idx: 340 |  Loss: (0.2021) | Acc: (93.12%) (40647/43648)\n",
            "Epoch: 58 | Batch_idx: 350 |  Loss: (0.2027) | Acc: (93.10%) (41826/44928)\n",
            "Epoch: 58 | Batch_idx: 360 |  Loss: (0.2033) | Acc: (93.06%) (43002/46208)\n",
            "Epoch: 58 | Batch_idx: 370 |  Loss: (0.2037) | Acc: (93.06%) (44190/47488)\n",
            "Epoch: 58 | Batch_idx: 380 |  Loss: (0.2034) | Acc: (93.07%) (45386/48768)\n",
            "Epoch: 58 | Batch_idx: 390 |  Loss: (0.2026) | Acc: (93.09%) (46543/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4045) | Acc: (87.51%) (8751/10000)\n",
            "Epoch: 59 | Batch_idx: 0 |  Loss: (0.1928) | Acc: (92.19%) (118/128)\n",
            "Epoch: 59 | Batch_idx: 10 |  Loss: (0.1800) | Acc: (93.89%) (1322/1408)\n",
            "Epoch: 59 | Batch_idx: 20 |  Loss: (0.1755) | Acc: (93.64%) (2517/2688)\n",
            "Epoch: 59 | Batch_idx: 30 |  Loss: (0.1815) | Acc: (93.35%) (3704/3968)\n",
            "Epoch: 59 | Batch_idx: 40 |  Loss: (0.1875) | Acc: (93.31%) (4897/5248)\n",
            "Epoch: 59 | Batch_idx: 50 |  Loss: (0.1903) | Acc: (93.32%) (6092/6528)\n",
            "Epoch: 59 | Batch_idx: 60 |  Loss: (0.1895) | Acc: (93.48%) (7299/7808)\n",
            "Epoch: 59 | Batch_idx: 70 |  Loss: (0.1890) | Acc: (93.55%) (8502/9088)\n",
            "Epoch: 59 | Batch_idx: 80 |  Loss: (0.1873) | Acc: (93.74%) (9719/10368)\n",
            "Epoch: 59 | Batch_idx: 90 |  Loss: (0.1867) | Acc: (93.78%) (10924/11648)\n",
            "Epoch: 59 | Batch_idx: 100 |  Loss: (0.1879) | Acc: (93.71%) (12115/12928)\n",
            "Epoch: 59 | Batch_idx: 110 |  Loss: (0.1887) | Acc: (93.64%) (13304/14208)\n",
            "Epoch: 59 | Batch_idx: 120 |  Loss: (0.1874) | Acc: (93.68%) (14509/15488)\n",
            "Epoch: 59 | Batch_idx: 130 |  Loss: (0.1878) | Acc: (93.71%) (15714/16768)\n",
            "Epoch: 59 | Batch_idx: 140 |  Loss: (0.1878) | Acc: (93.74%) (16918/18048)\n",
            "Epoch: 59 | Batch_idx: 150 |  Loss: (0.1887) | Acc: (93.72%) (18115/19328)\n",
            "Epoch: 59 | Batch_idx: 160 |  Loss: (0.1899) | Acc: (93.69%) (19308/20608)\n",
            "Epoch: 59 | Batch_idx: 170 |  Loss: (0.1930) | Acc: (93.61%) (20490/21888)\n",
            "Epoch: 59 | Batch_idx: 180 |  Loss: (0.1946) | Acc: (93.60%) (21685/23168)\n",
            "Epoch: 59 | Batch_idx: 190 |  Loss: (0.1943) | Acc: (93.59%) (22880/24448)\n",
            "Epoch: 59 | Batch_idx: 200 |  Loss: (0.1936) | Acc: (93.58%) (24075/25728)\n",
            "Epoch: 59 | Batch_idx: 210 |  Loss: (0.1923) | Acc: (93.63%) (25288/27008)\n",
            "Epoch: 59 | Batch_idx: 220 |  Loss: (0.1943) | Acc: (93.54%) (26462/28288)\n",
            "Epoch: 59 | Batch_idx: 230 |  Loss: (0.1947) | Acc: (93.52%) (27653/29568)\n",
            "Epoch: 59 | Batch_idx: 240 |  Loss: (0.1954) | Acc: (93.49%) (28841/30848)\n",
            "Epoch: 59 | Batch_idx: 250 |  Loss: (0.1953) | Acc: (93.47%) (30029/32128)\n",
            "Epoch: 59 | Batch_idx: 260 |  Loss: (0.1967) | Acc: (93.42%) (31211/33408)\n",
            "Epoch: 59 | Batch_idx: 270 |  Loss: (0.1972) | Acc: (93.42%) (32406/34688)\n",
            "Epoch: 59 | Batch_idx: 280 |  Loss: (0.1977) | Acc: (93.40%) (33593/35968)\n",
            "Epoch: 59 | Batch_idx: 290 |  Loss: (0.1969) | Acc: (93.42%) (34796/37248)\n",
            "Epoch: 59 | Batch_idx: 300 |  Loss: (0.1971) | Acc: (93.41%) (35990/38528)\n",
            "Epoch: 59 | Batch_idx: 310 |  Loss: (0.1976) | Acc: (93.42%) (37187/39808)\n",
            "Epoch: 59 | Batch_idx: 320 |  Loss: (0.1983) | Acc: (93.39%) (38373/41088)\n",
            "Epoch: 59 | Batch_idx: 330 |  Loss: (0.1989) | Acc: (93.35%) (39552/42368)\n",
            "Epoch: 59 | Batch_idx: 340 |  Loss: (0.1993) | Acc: (93.31%) (40730/43648)\n",
            "Epoch: 59 | Batch_idx: 350 |  Loss: (0.1996) | Acc: (93.32%) (41928/44928)\n",
            "Epoch: 59 | Batch_idx: 360 |  Loss: (0.1999) | Acc: (93.32%) (43121/46208)\n",
            "Epoch: 59 | Batch_idx: 370 |  Loss: (0.2006) | Acc: (93.29%) (44303/47488)\n",
            "Epoch: 59 | Batch_idx: 380 |  Loss: (0.2012) | Acc: (93.25%) (45474/48768)\n",
            "Epoch: 59 | Batch_idx: 390 |  Loss: (0.2013) | Acc: (93.23%) (46615/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4042) | Acc: (87.62%) (8762/10000)\n",
            "Epoch: 60 | Batch_idx: 0 |  Loss: (0.1670) | Acc: (92.97%) (119/128)\n",
            "Epoch: 60 | Batch_idx: 10 |  Loss: (0.1809) | Acc: (93.54%) (1317/1408)\n",
            "Epoch: 60 | Batch_idx: 20 |  Loss: (0.1894) | Acc: (93.71%) (2519/2688)\n",
            "Epoch: 60 | Batch_idx: 30 |  Loss: (0.1889) | Acc: (93.50%) (3710/3968)\n",
            "Epoch: 60 | Batch_idx: 40 |  Loss: (0.1845) | Acc: (93.73%) (4919/5248)\n",
            "Epoch: 60 | Batch_idx: 50 |  Loss: (0.1861) | Acc: (93.58%) (6109/6528)\n",
            "Epoch: 60 | Batch_idx: 60 |  Loss: (0.1881) | Acc: (93.53%) (7303/7808)\n",
            "Epoch: 60 | Batch_idx: 70 |  Loss: (0.1921) | Acc: (93.41%) (8489/9088)\n",
            "Epoch: 60 | Batch_idx: 80 |  Loss: (0.1910) | Acc: (93.43%) (9687/10368)\n",
            "Epoch: 60 | Batch_idx: 90 |  Loss: (0.1902) | Acc: (93.44%) (10884/11648)\n",
            "Epoch: 60 | Batch_idx: 100 |  Loss: (0.1893) | Acc: (93.51%) (12089/12928)\n",
            "Epoch: 60 | Batch_idx: 110 |  Loss: (0.1875) | Acc: (93.57%) (13294/14208)\n",
            "Epoch: 60 | Batch_idx: 120 |  Loss: (0.1869) | Acc: (93.59%) (14495/15488)\n",
            "Epoch: 60 | Batch_idx: 130 |  Loss: (0.1873) | Acc: (93.59%) (15694/16768)\n",
            "Epoch: 60 | Batch_idx: 140 |  Loss: (0.1890) | Acc: (93.52%) (16878/18048)\n",
            "Epoch: 60 | Batch_idx: 150 |  Loss: (0.1865) | Acc: (93.64%) (18099/19328)\n",
            "Epoch: 60 | Batch_idx: 160 |  Loss: (0.1875) | Acc: (93.59%) (19287/20608)\n",
            "Epoch: 60 | Batch_idx: 170 |  Loss: (0.1891) | Acc: (93.55%) (20476/21888)\n",
            "Epoch: 60 | Batch_idx: 180 |  Loss: (0.1918) | Acc: (93.43%) (21646/23168)\n",
            "Epoch: 60 | Batch_idx: 190 |  Loss: (0.1917) | Acc: (93.46%) (22849/24448)\n",
            "Epoch: 60 | Batch_idx: 200 |  Loss: (0.1931) | Acc: (93.40%) (24029/25728)\n",
            "Epoch: 60 | Batch_idx: 210 |  Loss: (0.1948) | Acc: (93.37%) (25217/27008)\n",
            "Epoch: 60 | Batch_idx: 220 |  Loss: (0.1947) | Acc: (93.32%) (26399/28288)\n",
            "Epoch: 60 | Batch_idx: 230 |  Loss: (0.1944) | Acc: (93.35%) (27602/29568)\n",
            "Epoch: 60 | Batch_idx: 240 |  Loss: (0.1953) | Acc: (93.31%) (28785/30848)\n",
            "Epoch: 60 | Batch_idx: 250 |  Loss: (0.1938) | Acc: (93.36%) (29995/32128)\n",
            "Epoch: 60 | Batch_idx: 260 |  Loss: (0.1942) | Acc: (93.34%) (31183/33408)\n",
            "Epoch: 60 | Batch_idx: 270 |  Loss: (0.1942) | Acc: (93.32%) (32370/34688)\n",
            "Epoch: 60 | Batch_idx: 280 |  Loss: (0.1945) | Acc: (93.28%) (33552/35968)\n",
            "Epoch: 60 | Batch_idx: 290 |  Loss: (0.1949) | Acc: (93.27%) (34742/37248)\n",
            "Epoch: 60 | Batch_idx: 300 |  Loss: (0.1953) | Acc: (93.26%) (35931/38528)\n",
            "Epoch: 60 | Batch_idx: 310 |  Loss: (0.1960) | Acc: (93.25%) (37122/39808)\n",
            "Epoch: 60 | Batch_idx: 320 |  Loss: (0.1956) | Acc: (93.26%) (38318/41088)\n",
            "Epoch: 60 | Batch_idx: 330 |  Loss: (0.1940) | Acc: (93.30%) (39529/42368)\n",
            "Epoch: 60 | Batch_idx: 340 |  Loss: (0.1951) | Acc: (93.28%) (40715/43648)\n",
            "Epoch: 60 | Batch_idx: 350 |  Loss: (0.1968) | Acc: (93.24%) (41890/44928)\n",
            "Epoch: 60 | Batch_idx: 360 |  Loss: (0.1981) | Acc: (93.21%) (43070/46208)\n",
            "Epoch: 60 | Batch_idx: 370 |  Loss: (0.1982) | Acc: (93.22%) (44269/47488)\n",
            "Epoch: 60 | Batch_idx: 380 |  Loss: (0.1987) | Acc: (93.21%) (45457/48768)\n",
            "Epoch: 60 | Batch_idx: 390 |  Loss: (0.1980) | Acc: (93.24%) (46620/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4297) | Acc: (87.30%) (8730/10000)\n",
            "Epoch: 61 | Batch_idx: 0 |  Loss: (0.1486) | Acc: (94.53%) (121/128)\n",
            "Epoch: 61 | Batch_idx: 10 |  Loss: (0.1809) | Acc: (93.82%) (1321/1408)\n",
            "Epoch: 61 | Batch_idx: 20 |  Loss: (0.1938) | Acc: (93.27%) (2507/2688)\n",
            "Epoch: 61 | Batch_idx: 30 |  Loss: (0.1987) | Acc: (92.99%) (3690/3968)\n",
            "Epoch: 61 | Batch_idx: 40 |  Loss: (0.1914) | Acc: (93.18%) (4890/5248)\n",
            "Epoch: 61 | Batch_idx: 50 |  Loss: (0.1892) | Acc: (93.41%) (6098/6528)\n",
            "Epoch: 61 | Batch_idx: 60 |  Loss: (0.1900) | Acc: (93.37%) (7290/7808)\n",
            "Epoch: 61 | Batch_idx: 70 |  Loss: (0.1899) | Acc: (93.39%) (8487/9088)\n",
            "Epoch: 61 | Batch_idx: 80 |  Loss: (0.1889) | Acc: (93.38%) (9682/10368)\n",
            "Epoch: 61 | Batch_idx: 90 |  Loss: (0.1911) | Acc: (93.35%) (10873/11648)\n",
            "Epoch: 61 | Batch_idx: 100 |  Loss: (0.1917) | Acc: (93.45%) (12081/12928)\n",
            "Epoch: 61 | Batch_idx: 110 |  Loss: (0.1916) | Acc: (93.46%) (13279/14208)\n",
            "Epoch: 61 | Batch_idx: 120 |  Loss: (0.1896) | Acc: (93.58%) (14494/15488)\n",
            "Epoch: 61 | Batch_idx: 130 |  Loss: (0.1868) | Acc: (93.64%) (15702/16768)\n",
            "Epoch: 61 | Batch_idx: 140 |  Loss: (0.1878) | Acc: (93.61%) (16894/18048)\n",
            "Epoch: 61 | Batch_idx: 150 |  Loss: (0.1887) | Acc: (93.55%) (18081/19328)\n",
            "Epoch: 61 | Batch_idx: 160 |  Loss: (0.1886) | Acc: (93.56%) (19281/20608)\n",
            "Epoch: 61 | Batch_idx: 170 |  Loss: (0.1888) | Acc: (93.54%) (20475/21888)\n",
            "Epoch: 61 | Batch_idx: 180 |  Loss: (0.1897) | Acc: (93.53%) (21668/23168)\n",
            "Epoch: 61 | Batch_idx: 190 |  Loss: (0.1913) | Acc: (93.48%) (22853/24448)\n",
            "Epoch: 61 | Batch_idx: 200 |  Loss: (0.1933) | Acc: (93.39%) (24028/25728)\n",
            "Epoch: 61 | Batch_idx: 210 |  Loss: (0.1944) | Acc: (93.38%) (25219/27008)\n",
            "Epoch: 61 | Batch_idx: 220 |  Loss: (0.1946) | Acc: (93.38%) (26414/28288)\n",
            "Epoch: 61 | Batch_idx: 230 |  Loss: (0.1942) | Acc: (93.38%) (27611/29568)\n",
            "Epoch: 61 | Batch_idx: 240 |  Loss: (0.1942) | Acc: (93.39%) (28810/30848)\n",
            "Epoch: 61 | Batch_idx: 250 |  Loss: (0.1939) | Acc: (93.40%) (30007/32128)\n",
            "Epoch: 61 | Batch_idx: 260 |  Loss: (0.1943) | Acc: (93.39%) (31201/33408)\n",
            "Epoch: 61 | Batch_idx: 270 |  Loss: (0.1931) | Acc: (93.42%) (32404/34688)\n",
            "Epoch: 61 | Batch_idx: 280 |  Loss: (0.1935) | Acc: (93.40%) (33594/35968)\n",
            "Epoch: 61 | Batch_idx: 290 |  Loss: (0.1935) | Acc: (93.41%) (34793/37248)\n",
            "Epoch: 61 | Batch_idx: 300 |  Loss: (0.1934) | Acc: (93.43%) (35996/38528)\n",
            "Epoch: 61 | Batch_idx: 310 |  Loss: (0.1941) | Acc: (93.41%) (37183/39808)\n",
            "Epoch: 61 | Batch_idx: 320 |  Loss: (0.1944) | Acc: (93.38%) (38369/41088)\n",
            "Epoch: 61 | Batch_idx: 330 |  Loss: (0.1952) | Acc: (93.37%) (39561/42368)\n",
            "Epoch: 61 | Batch_idx: 340 |  Loss: (0.1956) | Acc: (93.37%) (40752/43648)\n",
            "Epoch: 61 | Batch_idx: 350 |  Loss: (0.1954) | Acc: (93.37%) (41949/44928)\n",
            "Epoch: 61 | Batch_idx: 360 |  Loss: (0.1954) | Acc: (93.36%) (43138/46208)\n",
            "Epoch: 61 | Batch_idx: 370 |  Loss: (0.1952) | Acc: (93.37%) (44339/47488)\n",
            "Epoch: 61 | Batch_idx: 380 |  Loss: (0.1951) | Acc: (93.37%) (45534/48768)\n",
            "Epoch: 61 | Batch_idx: 390 |  Loss: (0.1947) | Acc: (93.38%) (46688/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4174) | Acc: (87.77%) (8777/10000)\n",
            "Epoch: 62 | Batch_idx: 0 |  Loss: (0.1182) | Acc: (95.31%) (122/128)\n",
            "Epoch: 62 | Batch_idx: 10 |  Loss: (0.1460) | Acc: (94.82%) (1335/1408)\n",
            "Epoch: 62 | Batch_idx: 20 |  Loss: (0.1441) | Acc: (94.79%) (2548/2688)\n",
            "Epoch: 62 | Batch_idx: 30 |  Loss: (0.1539) | Acc: (94.53%) (3751/3968)\n",
            "Epoch: 62 | Batch_idx: 40 |  Loss: (0.1604) | Acc: (94.36%) (4952/5248)\n",
            "Epoch: 62 | Batch_idx: 50 |  Loss: (0.1678) | Acc: (94.21%) (6150/6528)\n",
            "Epoch: 62 | Batch_idx: 60 |  Loss: (0.1689) | Acc: (94.19%) (7354/7808)\n",
            "Epoch: 62 | Batch_idx: 70 |  Loss: (0.1739) | Acc: (94.09%) (8551/9088)\n",
            "Epoch: 62 | Batch_idx: 80 |  Loss: (0.1783) | Acc: (94.01%) (9747/10368)\n",
            "Epoch: 62 | Batch_idx: 90 |  Loss: (0.1784) | Acc: (93.99%) (10948/11648)\n",
            "Epoch: 62 | Batch_idx: 100 |  Loss: (0.1798) | Acc: (93.95%) (12146/12928)\n",
            "Epoch: 62 | Batch_idx: 110 |  Loss: (0.1823) | Acc: (93.89%) (13340/14208)\n",
            "Epoch: 62 | Batch_idx: 120 |  Loss: (0.1839) | Acc: (93.81%) (14529/15488)\n",
            "Epoch: 62 | Batch_idx: 130 |  Loss: (0.1852) | Acc: (93.79%) (15726/16768)\n",
            "Epoch: 62 | Batch_idx: 140 |  Loss: (0.1859) | Acc: (93.74%) (16918/18048)\n",
            "Epoch: 62 | Batch_idx: 150 |  Loss: (0.1849) | Acc: (93.74%) (18119/19328)\n",
            "Epoch: 62 | Batch_idx: 160 |  Loss: (0.1847) | Acc: (93.75%) (19320/20608)\n",
            "Epoch: 62 | Batch_idx: 170 |  Loss: (0.1842) | Acc: (93.74%) (20518/21888)\n",
            "Epoch: 62 | Batch_idx: 180 |  Loss: (0.1854) | Acc: (93.70%) (21708/23168)\n",
            "Epoch: 62 | Batch_idx: 190 |  Loss: (0.1862) | Acc: (93.68%) (22903/24448)\n",
            "Epoch: 62 | Batch_idx: 200 |  Loss: (0.1861) | Acc: (93.66%) (24096/25728)\n",
            "Epoch: 62 | Batch_idx: 210 |  Loss: (0.1859) | Acc: (93.68%) (25300/27008)\n",
            "Epoch: 62 | Batch_idx: 220 |  Loss: (0.1858) | Acc: (93.67%) (26497/28288)\n",
            "Epoch: 62 | Batch_idx: 230 |  Loss: (0.1861) | Acc: (93.65%) (27689/29568)\n",
            "Epoch: 62 | Batch_idx: 240 |  Loss: (0.1863) | Acc: (93.59%) (28872/30848)\n",
            "Epoch: 62 | Batch_idx: 250 |  Loss: (0.1883) | Acc: (93.53%) (30048/32128)\n",
            "Epoch: 62 | Batch_idx: 260 |  Loss: (0.1894) | Acc: (93.50%) (31235/33408)\n",
            "Epoch: 62 | Batch_idx: 270 |  Loss: (0.1900) | Acc: (93.47%) (32424/34688)\n",
            "Epoch: 62 | Batch_idx: 280 |  Loss: (0.1904) | Acc: (93.48%) (33623/35968)\n",
            "Epoch: 62 | Batch_idx: 290 |  Loss: (0.1896) | Acc: (93.51%) (34832/37248)\n",
            "Epoch: 62 | Batch_idx: 300 |  Loss: (0.1900) | Acc: (93.54%) (36038/38528)\n",
            "Epoch: 62 | Batch_idx: 310 |  Loss: (0.1892) | Acc: (93.56%) (37244/39808)\n",
            "Epoch: 62 | Batch_idx: 320 |  Loss: (0.1914) | Acc: (93.50%) (38417/41088)\n",
            "Epoch: 62 | Batch_idx: 330 |  Loss: (0.1926) | Acc: (93.47%) (39603/42368)\n",
            "Epoch: 62 | Batch_idx: 340 |  Loss: (0.1933) | Acc: (93.47%) (40796/43648)\n",
            "Epoch: 62 | Batch_idx: 350 |  Loss: (0.1927) | Acc: (93.47%) (41993/44928)\n",
            "Epoch: 62 | Batch_idx: 360 |  Loss: (0.1935) | Acc: (93.44%) (43177/46208)\n",
            "Epoch: 62 | Batch_idx: 370 |  Loss: (0.1934) | Acc: (93.44%) (44372/47488)\n",
            "Epoch: 62 | Batch_idx: 380 |  Loss: (0.1936) | Acc: (93.42%) (45559/48768)\n",
            "Epoch: 62 | Batch_idx: 390 |  Loss: (0.1942) | Acc: (93.41%) (46704/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.5200) | Acc: (84.40%) (8440/10000)\n",
            "Epoch: 63 | Batch_idx: 0 |  Loss: (0.2231) | Acc: (90.62%) (116/128)\n",
            "Epoch: 63 | Batch_idx: 10 |  Loss: (0.2048) | Acc: (92.54%) (1303/1408)\n",
            "Epoch: 63 | Batch_idx: 20 |  Loss: (0.2020) | Acc: (93.19%) (2505/2688)\n",
            "Epoch: 63 | Batch_idx: 30 |  Loss: (0.1906) | Acc: (93.72%) (3719/3968)\n",
            "Epoch: 63 | Batch_idx: 40 |  Loss: (0.1851) | Acc: (93.75%) (4920/5248)\n",
            "Epoch: 63 | Batch_idx: 50 |  Loss: (0.1865) | Acc: (93.70%) (6117/6528)\n",
            "Epoch: 63 | Batch_idx: 60 |  Loss: (0.1855) | Acc: (93.67%) (7314/7808)\n",
            "Epoch: 63 | Batch_idx: 70 |  Loss: (0.1905) | Acc: (93.54%) (8501/9088)\n",
            "Epoch: 63 | Batch_idx: 80 |  Loss: (0.1882) | Acc: (93.54%) (9698/10368)\n",
            "Epoch: 63 | Batch_idx: 90 |  Loss: (0.1839) | Acc: (93.66%) (10910/11648)\n",
            "Epoch: 63 | Batch_idx: 100 |  Loss: (0.1818) | Acc: (93.67%) (12110/12928)\n",
            "Epoch: 63 | Batch_idx: 110 |  Loss: (0.1804) | Acc: (93.76%) (13322/14208)\n",
            "Epoch: 63 | Batch_idx: 120 |  Loss: (0.1828) | Acc: (93.64%) (14503/15488)\n",
            "Epoch: 63 | Batch_idx: 130 |  Loss: (0.1827) | Acc: (93.64%) (15702/16768)\n",
            "Epoch: 63 | Batch_idx: 140 |  Loss: (0.1839) | Acc: (93.62%) (16897/18048)\n",
            "Epoch: 63 | Batch_idx: 150 |  Loss: (0.1840) | Acc: (93.65%) (18101/19328)\n",
            "Epoch: 63 | Batch_idx: 160 |  Loss: (0.1842) | Acc: (93.63%) (19295/20608)\n",
            "Epoch: 63 | Batch_idx: 170 |  Loss: (0.1854) | Acc: (93.57%) (20480/21888)\n",
            "Epoch: 63 | Batch_idx: 180 |  Loss: (0.1857) | Acc: (93.53%) (21669/23168)\n",
            "Epoch: 63 | Batch_idx: 190 |  Loss: (0.1858) | Acc: (93.52%) (22863/24448)\n",
            "Epoch: 63 | Batch_idx: 200 |  Loss: (0.1861) | Acc: (93.56%) (24072/25728)\n",
            "Epoch: 63 | Batch_idx: 210 |  Loss: (0.1864) | Acc: (93.52%) (25257/27008)\n",
            "Epoch: 63 | Batch_idx: 220 |  Loss: (0.1874) | Acc: (93.53%) (26458/28288)\n",
            "Epoch: 63 | Batch_idx: 230 |  Loss: (0.1886) | Acc: (93.50%) (27647/29568)\n",
            "Epoch: 63 | Batch_idx: 240 |  Loss: (0.1915) | Acc: (93.37%) (28803/30848)\n",
            "Epoch: 63 | Batch_idx: 250 |  Loss: (0.1932) | Acc: (93.30%) (29975/32128)\n",
            "Epoch: 63 | Batch_idx: 260 |  Loss: (0.1934) | Acc: (93.29%) (31166/33408)\n",
            "Epoch: 63 | Batch_idx: 270 |  Loss: (0.1939) | Acc: (93.27%) (32354/34688)\n",
            "Epoch: 63 | Batch_idx: 280 |  Loss: (0.1952) | Acc: (93.23%) (33533/35968)\n",
            "Epoch: 63 | Batch_idx: 290 |  Loss: (0.1958) | Acc: (93.23%) (34727/37248)\n",
            "Epoch: 63 | Batch_idx: 300 |  Loss: (0.1960) | Acc: (93.23%) (35919/38528)\n",
            "Epoch: 63 | Batch_idx: 310 |  Loss: (0.1953) | Acc: (93.24%) (37118/39808)\n",
            "Epoch: 63 | Batch_idx: 320 |  Loss: (0.1958) | Acc: (93.21%) (38300/41088)\n",
            "Epoch: 63 | Batch_idx: 330 |  Loss: (0.1971) | Acc: (93.20%) (39485/42368)\n",
            "Epoch: 63 | Batch_idx: 340 |  Loss: (0.1985) | Acc: (93.14%) (40652/43648)\n",
            "Epoch: 63 | Batch_idx: 350 |  Loss: (0.1986) | Acc: (93.14%) (41846/44928)\n",
            "Epoch: 63 | Batch_idx: 360 |  Loss: (0.1990) | Acc: (93.11%) (43026/46208)\n",
            "Epoch: 63 | Batch_idx: 370 |  Loss: (0.1998) | Acc: (93.10%) (44211/47488)\n",
            "Epoch: 63 | Batch_idx: 380 |  Loss: (0.2004) | Acc: (93.09%) (45399/48768)\n",
            "Epoch: 63 | Batch_idx: 390 |  Loss: (0.2008) | Acc: (93.08%) (46542/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4980) | Acc: (85.25%) (8525/10000)\n",
            "Epoch: 64 | Batch_idx: 0 |  Loss: (0.2210) | Acc: (92.19%) (118/128)\n",
            "Epoch: 64 | Batch_idx: 10 |  Loss: (0.1629) | Acc: (93.89%) (1322/1408)\n",
            "Epoch: 64 | Batch_idx: 20 |  Loss: (0.1810) | Acc: (93.60%) (2516/2688)\n",
            "Epoch: 64 | Batch_idx: 30 |  Loss: (0.1845) | Acc: (93.52%) (3711/3968)\n",
            "Epoch: 64 | Batch_idx: 40 |  Loss: (0.1841) | Acc: (93.64%) (4914/5248)\n",
            "Epoch: 64 | Batch_idx: 50 |  Loss: (0.1934) | Acc: (93.43%) (6099/6528)\n",
            "Epoch: 64 | Batch_idx: 60 |  Loss: (0.1924) | Acc: (93.40%) (7293/7808)\n",
            "Epoch: 64 | Batch_idx: 70 |  Loss: (0.1915) | Acc: (93.47%) (8495/9088)\n",
            "Epoch: 64 | Batch_idx: 80 |  Loss: (0.1930) | Acc: (93.54%) (9698/10368)\n",
            "Epoch: 64 | Batch_idx: 90 |  Loss: (0.1972) | Acc: (93.47%) (10887/11648)\n",
            "Epoch: 64 | Batch_idx: 100 |  Loss: (0.1954) | Acc: (93.51%) (12089/12928)\n",
            "Epoch: 64 | Batch_idx: 110 |  Loss: (0.1941) | Acc: (93.52%) (13288/14208)\n",
            "Epoch: 64 | Batch_idx: 120 |  Loss: (0.1923) | Acc: (93.57%) (14492/15488)\n",
            "Epoch: 64 | Batch_idx: 130 |  Loss: (0.1918) | Acc: (93.54%) (15684/16768)\n",
            "Epoch: 64 | Batch_idx: 140 |  Loss: (0.1925) | Acc: (93.47%) (16870/18048)\n",
            "Epoch: 64 | Batch_idx: 150 |  Loss: (0.1927) | Acc: (93.50%) (18072/19328)\n",
            "Epoch: 64 | Batch_idx: 160 |  Loss: (0.1933) | Acc: (93.49%) (19266/20608)\n",
            "Epoch: 64 | Batch_idx: 170 |  Loss: (0.1947) | Acc: (93.38%) (20438/21888)\n",
            "Epoch: 64 | Batch_idx: 180 |  Loss: (0.1954) | Acc: (93.34%) (21625/23168)\n",
            "Epoch: 64 | Batch_idx: 190 |  Loss: (0.1954) | Acc: (93.34%) (22820/24448)\n",
            "Epoch: 64 | Batch_idx: 200 |  Loss: (0.1961) | Acc: (93.30%) (24005/25728)\n",
            "Epoch: 64 | Batch_idx: 210 |  Loss: (0.1961) | Acc: (93.30%) (25199/27008)\n",
            "Epoch: 64 | Batch_idx: 220 |  Loss: (0.1978) | Acc: (93.23%) (26372/28288)\n",
            "Epoch: 64 | Batch_idx: 230 |  Loss: (0.1986) | Acc: (93.17%) (27548/29568)\n",
            "Epoch: 64 | Batch_idx: 240 |  Loss: (0.1981) | Acc: (93.20%) (28750/30848)\n",
            "Epoch: 64 | Batch_idx: 250 |  Loss: (0.1991) | Acc: (93.19%) (29939/32128)\n",
            "Epoch: 64 | Batch_idx: 260 |  Loss: (0.1990) | Acc: (93.21%) (31138/33408)\n",
            "Epoch: 64 | Batch_idx: 270 |  Loss: (0.1976) | Acc: (93.24%) (32342/34688)\n",
            "Epoch: 64 | Batch_idx: 280 |  Loss: (0.1982) | Acc: (93.22%) (33531/35968)\n",
            "Epoch: 64 | Batch_idx: 290 |  Loss: (0.1978) | Acc: (93.23%) (34728/37248)\n",
            "Epoch: 64 | Batch_idx: 300 |  Loss: (0.1983) | Acc: (93.24%) (35922/38528)\n",
            "Epoch: 64 | Batch_idx: 310 |  Loss: (0.1995) | Acc: (93.21%) (37106/39808)\n",
            "Epoch: 64 | Batch_idx: 320 |  Loss: (0.1995) | Acc: (93.21%) (38300/41088)\n",
            "Epoch: 64 | Batch_idx: 330 |  Loss: (0.2001) | Acc: (93.20%) (39485/42368)\n",
            "Epoch: 64 | Batch_idx: 340 |  Loss: (0.1995) | Acc: (93.21%) (40686/43648)\n",
            "Epoch: 64 | Batch_idx: 350 |  Loss: (0.1994) | Acc: (93.22%) (41882/44928)\n",
            "Epoch: 64 | Batch_idx: 360 |  Loss: (0.2000) | Acc: (93.21%) (43069/46208)\n",
            "Epoch: 64 | Batch_idx: 370 |  Loss: (0.2002) | Acc: (93.19%) (44254/47488)\n",
            "Epoch: 64 | Batch_idx: 380 |  Loss: (0.2003) | Acc: (93.19%) (45446/48768)\n",
            "Epoch: 64 | Batch_idx: 390 |  Loss: (0.2002) | Acc: (93.19%) (46595/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4256) | Acc: (87.27%) (8727/10000)\n",
            "Epoch: 65 | Batch_idx: 0 |  Loss: (0.2145) | Acc: (92.97%) (119/128)\n",
            "Epoch: 65 | Batch_idx: 10 |  Loss: (0.1811) | Acc: (94.11%) (1325/1408)\n",
            "Epoch: 65 | Batch_idx: 20 |  Loss: (0.1797) | Acc: (93.64%) (2517/2688)\n",
            "Epoch: 65 | Batch_idx: 30 |  Loss: (0.1808) | Acc: (93.67%) (3717/3968)\n",
            "Epoch: 65 | Batch_idx: 40 |  Loss: (0.1795) | Acc: (93.79%) (4922/5248)\n",
            "Epoch: 65 | Batch_idx: 50 |  Loss: (0.1798) | Acc: (93.84%) (6126/6528)\n",
            "Epoch: 65 | Batch_idx: 60 |  Loss: (0.1831) | Acc: (93.71%) (7317/7808)\n",
            "Epoch: 65 | Batch_idx: 70 |  Loss: (0.1773) | Acc: (93.83%) (8527/9088)\n",
            "Epoch: 65 | Batch_idx: 80 |  Loss: (0.1776) | Acc: (93.77%) (9722/10368)\n",
            "Epoch: 65 | Batch_idx: 90 |  Loss: (0.1772) | Acc: (93.78%) (10924/11648)\n",
            "Epoch: 65 | Batch_idx: 100 |  Loss: (0.1786) | Acc: (93.77%) (12122/12928)\n",
            "Epoch: 65 | Batch_idx: 110 |  Loss: (0.1784) | Acc: (93.74%) (13318/14208)\n",
            "Epoch: 65 | Batch_idx: 120 |  Loss: (0.1805) | Acc: (93.69%) (14510/15488)\n",
            "Epoch: 65 | Batch_idx: 130 |  Loss: (0.1811) | Acc: (93.61%) (15697/16768)\n",
            "Epoch: 65 | Batch_idx: 140 |  Loss: (0.1829) | Acc: (93.57%) (16888/18048)\n",
            "Epoch: 65 | Batch_idx: 150 |  Loss: (0.1829) | Acc: (93.64%) (18098/19328)\n",
            "Epoch: 65 | Batch_idx: 160 |  Loss: (0.1846) | Acc: (93.58%) (19284/20608)\n",
            "Epoch: 65 | Batch_idx: 170 |  Loss: (0.1856) | Acc: (93.58%) (20483/21888)\n",
            "Epoch: 65 | Batch_idx: 180 |  Loss: (0.1857) | Acc: (93.56%) (21677/23168)\n",
            "Epoch: 65 | Batch_idx: 190 |  Loss: (0.1859) | Acc: (93.56%) (22873/24448)\n",
            "Epoch: 65 | Batch_idx: 200 |  Loss: (0.1874) | Acc: (93.49%) (24052/25728)\n",
            "Epoch: 65 | Batch_idx: 210 |  Loss: (0.1880) | Acc: (93.47%) (25244/27008)\n",
            "Epoch: 65 | Batch_idx: 220 |  Loss: (0.1892) | Acc: (93.45%) (26434/28288)\n",
            "Epoch: 65 | Batch_idx: 230 |  Loss: (0.1898) | Acc: (93.43%) (27624/29568)\n",
            "Epoch: 65 | Batch_idx: 240 |  Loss: (0.1899) | Acc: (93.42%) (28818/30848)\n",
            "Epoch: 65 | Batch_idx: 250 |  Loss: (0.1901) | Acc: (93.42%) (30013/32128)\n",
            "Epoch: 65 | Batch_idx: 260 |  Loss: (0.1892) | Acc: (93.45%) (31220/33408)\n",
            "Epoch: 65 | Batch_idx: 270 |  Loss: (0.1890) | Acc: (93.48%) (32428/34688)\n",
            "Epoch: 65 | Batch_idx: 280 |  Loss: (0.1893) | Acc: (93.52%) (33637/35968)\n",
            "Epoch: 65 | Batch_idx: 290 |  Loss: (0.1886) | Acc: (93.53%) (34839/37248)\n",
            "Epoch: 65 | Batch_idx: 300 |  Loss: (0.1876) | Acc: (93.56%) (36047/38528)\n",
            "Epoch: 65 | Batch_idx: 310 |  Loss: (0.1885) | Acc: (93.52%) (37229/39808)\n",
            "Epoch: 65 | Batch_idx: 320 |  Loss: (0.1883) | Acc: (93.54%) (38435/41088)\n",
            "Epoch: 65 | Batch_idx: 330 |  Loss: (0.1888) | Acc: (93.51%) (39618/42368)\n",
            "Epoch: 65 | Batch_idx: 340 |  Loss: (0.1899) | Acc: (93.46%) (40792/43648)\n",
            "Epoch: 65 | Batch_idx: 350 |  Loss: (0.1910) | Acc: (93.42%) (41972/44928)\n",
            "Epoch: 65 | Batch_idx: 360 |  Loss: (0.1914) | Acc: (93.41%) (43161/46208)\n",
            "Epoch: 65 | Batch_idx: 370 |  Loss: (0.1921) | Acc: (93.40%) (44352/47488)\n",
            "Epoch: 65 | Batch_idx: 380 |  Loss: (0.1936) | Acc: (93.35%) (45526/48768)\n",
            "Epoch: 65 | Batch_idx: 390 |  Loss: (0.1925) | Acc: (93.39%) (46694/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4100) | Acc: (88.04%) (8804/10000)\n",
            "Epoch: 66 | Batch_idx: 0 |  Loss: (0.1282) | Acc: (93.75%) (120/128)\n",
            "Epoch: 66 | Batch_idx: 10 |  Loss: (0.2098) | Acc: (92.97%) (1309/1408)\n",
            "Epoch: 66 | Batch_idx: 20 |  Loss: (0.1981) | Acc: (93.27%) (2507/2688)\n",
            "Epoch: 66 | Batch_idx: 30 |  Loss: (0.1897) | Acc: (93.70%) (3718/3968)\n",
            "Epoch: 66 | Batch_idx: 40 |  Loss: (0.1902) | Acc: (93.71%) (4918/5248)\n",
            "Epoch: 66 | Batch_idx: 50 |  Loss: (0.1921) | Acc: (93.55%) (6107/6528)\n",
            "Epoch: 66 | Batch_idx: 60 |  Loss: (0.1924) | Acc: (93.51%) (7301/7808)\n",
            "Epoch: 66 | Batch_idx: 70 |  Loss: (0.1899) | Acc: (93.50%) (8497/9088)\n",
            "Epoch: 66 | Batch_idx: 80 |  Loss: (0.1874) | Acc: (93.66%) (9711/10368)\n",
            "Epoch: 66 | Batch_idx: 90 |  Loss: (0.1866) | Acc: (93.65%) (10908/11648)\n",
            "Epoch: 66 | Batch_idx: 100 |  Loss: (0.1847) | Acc: (93.74%) (12119/12928)\n",
            "Epoch: 66 | Batch_idx: 110 |  Loss: (0.1835) | Acc: (93.79%) (13326/14208)\n",
            "Epoch: 66 | Batch_idx: 120 |  Loss: (0.1864) | Acc: (93.68%) (14509/15488)\n",
            "Epoch: 66 | Batch_idx: 130 |  Loss: (0.1891) | Acc: (93.58%) (15692/16768)\n",
            "Epoch: 66 | Batch_idx: 140 |  Loss: (0.1910) | Acc: (93.46%) (16867/18048)\n",
            "Epoch: 66 | Batch_idx: 150 |  Loss: (0.1932) | Acc: (93.41%) (18054/19328)\n",
            "Epoch: 66 | Batch_idx: 160 |  Loss: (0.1945) | Acc: (93.42%) (19251/20608)\n",
            "Epoch: 66 | Batch_idx: 170 |  Loss: (0.1940) | Acc: (93.42%) (20448/21888)\n",
            "Epoch: 66 | Batch_idx: 180 |  Loss: (0.1930) | Acc: (93.47%) (21655/23168)\n",
            "Epoch: 66 | Batch_idx: 190 |  Loss: (0.1936) | Acc: (93.44%) (22845/24448)\n",
            "Epoch: 66 | Batch_idx: 200 |  Loss: (0.1941) | Acc: (93.43%) (24038/25728)\n",
            "Epoch: 66 | Batch_idx: 210 |  Loss: (0.1947) | Acc: (93.42%) (25231/27008)\n",
            "Epoch: 66 | Batch_idx: 220 |  Loss: (0.1947) | Acc: (93.42%) (26428/28288)\n",
            "Epoch: 66 | Batch_idx: 230 |  Loss: (0.1933) | Acc: (93.46%) (27634/29568)\n",
            "Epoch: 66 | Batch_idx: 240 |  Loss: (0.1941) | Acc: (93.42%) (28817/30848)\n",
            "Epoch: 66 | Batch_idx: 250 |  Loss: (0.1938) | Acc: (93.44%) (30020/32128)\n",
            "Epoch: 66 | Batch_idx: 260 |  Loss: (0.1940) | Acc: (93.44%) (31217/33408)\n",
            "Epoch: 66 | Batch_idx: 270 |  Loss: (0.1939) | Acc: (93.44%) (32411/34688)\n",
            "Epoch: 66 | Batch_idx: 280 |  Loss: (0.1934) | Acc: (93.45%) (33613/35968)\n",
            "Epoch: 66 | Batch_idx: 290 |  Loss: (0.1936) | Acc: (93.47%) (34814/37248)\n",
            "Epoch: 66 | Batch_idx: 300 |  Loss: (0.1952) | Acc: (93.43%) (35996/38528)\n",
            "Epoch: 66 | Batch_idx: 310 |  Loss: (0.1953) | Acc: (93.42%) (37188/39808)\n",
            "Epoch: 66 | Batch_idx: 320 |  Loss: (0.1952) | Acc: (93.40%) (38378/41088)\n",
            "Epoch: 66 | Batch_idx: 330 |  Loss: (0.1942) | Acc: (93.45%) (39595/42368)\n",
            "Epoch: 66 | Batch_idx: 340 |  Loss: (0.1935) | Acc: (93.47%) (40798/43648)\n",
            "Epoch: 66 | Batch_idx: 350 |  Loss: (0.1941) | Acc: (93.44%) (41982/44928)\n",
            "Epoch: 66 | Batch_idx: 360 |  Loss: (0.1942) | Acc: (93.44%) (43176/46208)\n",
            "Epoch: 66 | Batch_idx: 370 |  Loss: (0.1946) | Acc: (93.41%) (44359/47488)\n",
            "Epoch: 66 | Batch_idx: 380 |  Loss: (0.1950) | Acc: (93.40%) (45549/48768)\n",
            "Epoch: 66 | Batch_idx: 390 |  Loss: (0.1962) | Acc: (93.35%) (46675/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4830) | Acc: (85.80%) (8580/10000)\n",
            "Epoch: 67 | Batch_idx: 0 |  Loss: (0.1502) | Acc: (95.31%) (122/128)\n",
            "Epoch: 67 | Batch_idx: 10 |  Loss: (0.1825) | Acc: (93.68%) (1319/1408)\n",
            "Epoch: 67 | Batch_idx: 20 |  Loss: (0.1899) | Acc: (93.75%) (2520/2688)\n",
            "Epoch: 67 | Batch_idx: 30 |  Loss: (0.1973) | Acc: (93.42%) (3707/3968)\n",
            "Epoch: 67 | Batch_idx: 40 |  Loss: (0.1920) | Acc: (93.58%) (4911/5248)\n",
            "Epoch: 67 | Batch_idx: 50 |  Loss: (0.1878) | Acc: (93.67%) (6115/6528)\n",
            "Epoch: 67 | Batch_idx: 60 |  Loss: (0.1825) | Acc: (93.89%) (7331/7808)\n",
            "Epoch: 67 | Batch_idx: 70 |  Loss: (0.1822) | Acc: (93.88%) (8532/9088)\n",
            "Epoch: 67 | Batch_idx: 80 |  Loss: (0.1795) | Acc: (94.00%) (9746/10368)\n",
            "Epoch: 67 | Batch_idx: 90 |  Loss: (0.1806) | Acc: (93.96%) (10945/11648)\n",
            "Epoch: 67 | Batch_idx: 100 |  Loss: (0.1803) | Acc: (93.94%) (12144/12928)\n",
            "Epoch: 67 | Batch_idx: 110 |  Loss: (0.1784) | Acc: (93.96%) (13350/14208)\n",
            "Epoch: 67 | Batch_idx: 120 |  Loss: (0.1789) | Acc: (93.98%) (14555/15488)\n",
            "Epoch: 67 | Batch_idx: 130 |  Loss: (0.1824) | Acc: (93.86%) (15739/16768)\n",
            "Epoch: 67 | Batch_idx: 140 |  Loss: (0.1810) | Acc: (93.93%) (16952/18048)\n",
            "Epoch: 67 | Batch_idx: 150 |  Loss: (0.1800) | Acc: (93.94%) (18157/19328)\n",
            "Epoch: 67 | Batch_idx: 160 |  Loss: (0.1829) | Acc: (93.84%) (19338/20608)\n",
            "Epoch: 67 | Batch_idx: 170 |  Loss: (0.1870) | Acc: (93.70%) (20510/21888)\n",
            "Epoch: 67 | Batch_idx: 180 |  Loss: (0.1882) | Acc: (93.64%) (21695/23168)\n",
            "Epoch: 67 | Batch_idx: 190 |  Loss: (0.1881) | Acc: (93.67%) (22900/24448)\n",
            "Epoch: 67 | Batch_idx: 200 |  Loss: (0.1878) | Acc: (93.68%) (24103/25728)\n",
            "Epoch: 67 | Batch_idx: 210 |  Loss: (0.1885) | Acc: (93.63%) (25287/27008)\n",
            "Epoch: 67 | Batch_idx: 220 |  Loss: (0.1894) | Acc: (93.60%) (26478/28288)\n",
            "Epoch: 67 | Batch_idx: 230 |  Loss: (0.1886) | Acc: (93.67%) (27695/29568)\n",
            "Epoch: 67 | Batch_idx: 240 |  Loss: (0.1894) | Acc: (93.67%) (28895/30848)\n",
            "Epoch: 67 | Batch_idx: 250 |  Loss: (0.1895) | Acc: (93.63%) (30083/32128)\n",
            "Epoch: 67 | Batch_idx: 260 |  Loss: (0.1891) | Acc: (93.67%) (31292/33408)\n",
            "Epoch: 67 | Batch_idx: 270 |  Loss: (0.1892) | Acc: (93.67%) (32491/34688)\n",
            "Epoch: 67 | Batch_idx: 280 |  Loss: (0.1889) | Acc: (93.66%) (33688/35968)\n",
            "Epoch: 67 | Batch_idx: 290 |  Loss: (0.1896) | Acc: (93.62%) (34871/37248)\n",
            "Epoch: 67 | Batch_idx: 300 |  Loss: (0.1895) | Acc: (93.60%) (36064/38528)\n",
            "Epoch: 67 | Batch_idx: 310 |  Loss: (0.1886) | Acc: (93.64%) (37275/39808)\n",
            "Epoch: 67 | Batch_idx: 320 |  Loss: (0.1883) | Acc: (93.64%) (38476/41088)\n",
            "Epoch: 67 | Batch_idx: 330 |  Loss: (0.1887) | Acc: (93.64%) (39672/42368)\n",
            "Epoch: 67 | Batch_idx: 340 |  Loss: (0.1880) | Acc: (93.66%) (40881/43648)\n",
            "Epoch: 67 | Batch_idx: 350 |  Loss: (0.1882) | Acc: (93.68%) (42087/44928)\n",
            "Epoch: 67 | Batch_idx: 360 |  Loss: (0.1887) | Acc: (93.64%) (43267/46208)\n",
            "Epoch: 67 | Batch_idx: 370 |  Loss: (0.1896) | Acc: (93.60%) (44447/47488)\n",
            "Epoch: 67 | Batch_idx: 380 |  Loss: (0.1897) | Acc: (93.59%) (45641/48768)\n",
            "Epoch: 67 | Batch_idx: 390 |  Loss: (0.1898) | Acc: (93.55%) (46777/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4347) | Acc: (87.43%) (8743/10000)\n",
            "Epoch: 68 | Batch_idx: 0 |  Loss: (0.1673) | Acc: (92.97%) (119/128)\n",
            "Epoch: 68 | Batch_idx: 10 |  Loss: (0.1721) | Acc: (93.89%) (1322/1408)\n",
            "Epoch: 68 | Batch_idx: 20 |  Loss: (0.1990) | Acc: (93.68%) (2518/2688)\n",
            "Epoch: 68 | Batch_idx: 30 |  Loss: (0.1899) | Acc: (93.72%) (3719/3968)\n",
            "Epoch: 68 | Batch_idx: 40 |  Loss: (0.1871) | Acc: (93.85%) (4925/5248)\n",
            "Epoch: 68 | Batch_idx: 50 |  Loss: (0.1916) | Acc: (93.83%) (6125/6528)\n",
            "Epoch: 68 | Batch_idx: 60 |  Loss: (0.1906) | Acc: (93.72%) (7318/7808)\n",
            "Epoch: 68 | Batch_idx: 70 |  Loss: (0.1874) | Acc: (93.86%) (8530/9088)\n",
            "Epoch: 68 | Batch_idx: 80 |  Loss: (0.1866) | Acc: (93.86%) (9731/10368)\n",
            "Epoch: 68 | Batch_idx: 90 |  Loss: (0.1870) | Acc: (93.85%) (10932/11648)\n",
            "Epoch: 68 | Batch_idx: 100 |  Loss: (0.1862) | Acc: (93.87%) (12136/12928)\n",
            "Epoch: 68 | Batch_idx: 110 |  Loss: (0.1862) | Acc: (93.85%) (13334/14208)\n",
            "Epoch: 68 | Batch_idx: 120 |  Loss: (0.1851) | Acc: (93.85%) (14535/15488)\n",
            "Epoch: 68 | Batch_idx: 130 |  Loss: (0.1855) | Acc: (93.80%) (15729/16768)\n",
            "Epoch: 68 | Batch_idx: 140 |  Loss: (0.1861) | Acc: (93.73%) (16916/18048)\n",
            "Epoch: 68 | Batch_idx: 150 |  Loss: (0.1856) | Acc: (93.68%) (18107/19328)\n",
            "Epoch: 68 | Batch_idx: 160 |  Loss: (0.1840) | Acc: (93.69%) (19308/20608)\n",
            "Epoch: 68 | Batch_idx: 170 |  Loss: (0.1865) | Acc: (93.61%) (20490/21888)\n",
            "Epoch: 68 | Batch_idx: 180 |  Loss: (0.1874) | Acc: (93.60%) (21685/23168)\n",
            "Epoch: 68 | Batch_idx: 190 |  Loss: (0.1867) | Acc: (93.59%) (22881/24448)\n",
            "Epoch: 68 | Batch_idx: 200 |  Loss: (0.1876) | Acc: (93.54%) (24067/25728)\n",
            "Epoch: 68 | Batch_idx: 210 |  Loss: (0.1874) | Acc: (93.54%) (25262/27008)\n",
            "Epoch: 68 | Batch_idx: 220 |  Loss: (0.1863) | Acc: (93.60%) (26478/28288)\n",
            "Epoch: 68 | Batch_idx: 230 |  Loss: (0.1872) | Acc: (93.56%) (27664/29568)\n",
            "Epoch: 68 | Batch_idx: 240 |  Loss: (0.1856) | Acc: (93.61%) (28878/30848)\n",
            "Epoch: 68 | Batch_idx: 250 |  Loss: (0.1863) | Acc: (93.59%) (30067/32128)\n",
            "Epoch: 68 | Batch_idx: 260 |  Loss: (0.1865) | Acc: (93.57%) (31261/33408)\n",
            "Epoch: 68 | Batch_idx: 270 |  Loss: (0.1862) | Acc: (93.56%) (32455/34688)\n",
            "Epoch: 68 | Batch_idx: 280 |  Loss: (0.1865) | Acc: (93.56%) (33651/35968)\n",
            "Epoch: 68 | Batch_idx: 290 |  Loss: (0.1859) | Acc: (93.58%) (34857/37248)\n",
            "Epoch: 68 | Batch_idx: 300 |  Loss: (0.1860) | Acc: (93.59%) (36060/38528)\n",
            "Epoch: 68 | Batch_idx: 310 |  Loss: (0.1862) | Acc: (93.58%) (37253/39808)\n",
            "Epoch: 68 | Batch_idx: 320 |  Loss: (0.1873) | Acc: (93.56%) (38443/41088)\n",
            "Epoch: 68 | Batch_idx: 330 |  Loss: (0.1865) | Acc: (93.59%) (39653/42368)\n",
            "Epoch: 68 | Batch_idx: 340 |  Loss: (0.1862) | Acc: (93.60%) (40856/43648)\n",
            "Epoch: 68 | Batch_idx: 350 |  Loss: (0.1865) | Acc: (93.59%) (42046/44928)\n",
            "Epoch: 68 | Batch_idx: 360 |  Loss: (0.1874) | Acc: (93.57%) (43236/46208)\n",
            "Epoch: 68 | Batch_idx: 370 |  Loss: (0.1877) | Acc: (93.55%) (44425/47488)\n",
            "Epoch: 68 | Batch_idx: 380 |  Loss: (0.1881) | Acc: (93.53%) (45614/48768)\n",
            "Epoch: 68 | Batch_idx: 390 |  Loss: (0.1888) | Acc: (93.50%) (46752/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4257) | Acc: (86.84%) (8684/10000)\n",
            "Epoch: 69 | Batch_idx: 0 |  Loss: (0.2047) | Acc: (91.41%) (117/128)\n",
            "Epoch: 69 | Batch_idx: 10 |  Loss: (0.1641) | Acc: (94.60%) (1332/1408)\n",
            "Epoch: 69 | Batch_idx: 20 |  Loss: (0.1518) | Acc: (94.87%) (2550/2688)\n",
            "Epoch: 69 | Batch_idx: 30 |  Loss: (0.1567) | Acc: (94.61%) (3754/3968)\n",
            "Epoch: 69 | Batch_idx: 40 |  Loss: (0.1657) | Acc: (94.23%) (4945/5248)\n",
            "Epoch: 69 | Batch_idx: 50 |  Loss: (0.1692) | Acc: (94.16%) (6147/6528)\n",
            "Epoch: 69 | Batch_idx: 60 |  Loss: (0.1707) | Acc: (94.06%) (7344/7808)\n",
            "Epoch: 69 | Batch_idx: 70 |  Loss: (0.1672) | Acc: (94.07%) (8549/9088)\n",
            "Epoch: 69 | Batch_idx: 80 |  Loss: (0.1694) | Acc: (94.08%) (9754/10368)\n",
            "Epoch: 69 | Batch_idx: 90 |  Loss: (0.1737) | Acc: (94.02%) (10952/11648)\n",
            "Epoch: 69 | Batch_idx: 100 |  Loss: (0.1743) | Acc: (93.90%) (12139/12928)\n",
            "Epoch: 69 | Batch_idx: 110 |  Loss: (0.1742) | Acc: (94.00%) (13355/14208)\n",
            "Epoch: 69 | Batch_idx: 120 |  Loss: (0.1745) | Acc: (94.02%) (14562/15488)\n",
            "Epoch: 69 | Batch_idx: 130 |  Loss: (0.1754) | Acc: (94.03%) (15767/16768)\n",
            "Epoch: 69 | Batch_idx: 140 |  Loss: (0.1782) | Acc: (93.97%) (16960/18048)\n",
            "Epoch: 69 | Batch_idx: 150 |  Loss: (0.1826) | Acc: (93.84%) (18138/19328)\n",
            "Epoch: 69 | Batch_idx: 160 |  Loss: (0.1846) | Acc: (93.75%) (19321/20608)\n",
            "Epoch: 69 | Batch_idx: 170 |  Loss: (0.1863) | Acc: (93.69%) (20507/21888)\n",
            "Epoch: 69 | Batch_idx: 180 |  Loss: (0.1853) | Acc: (93.70%) (21709/23168)\n",
            "Epoch: 69 | Batch_idx: 190 |  Loss: (0.1839) | Acc: (93.75%) (22920/24448)\n",
            "Epoch: 69 | Batch_idx: 200 |  Loss: (0.1863) | Acc: (93.65%) (24093/25728)\n",
            "Epoch: 69 | Batch_idx: 210 |  Loss: (0.1865) | Acc: (93.62%) (25285/27008)\n",
            "Epoch: 69 | Batch_idx: 220 |  Loss: (0.1867) | Acc: (93.61%) (26479/28288)\n",
            "Epoch: 69 | Batch_idx: 230 |  Loss: (0.1876) | Acc: (93.60%) (27675/29568)\n",
            "Epoch: 69 | Batch_idx: 240 |  Loss: (0.1884) | Acc: (93.57%) (28863/30848)\n",
            "Epoch: 69 | Batch_idx: 250 |  Loss: (0.1891) | Acc: (93.52%) (30045/32128)\n",
            "Epoch: 69 | Batch_idx: 260 |  Loss: (0.1892) | Acc: (93.50%) (31235/33408)\n",
            "Epoch: 69 | Batch_idx: 270 |  Loss: (0.1888) | Acc: (93.48%) (32426/34688)\n",
            "Epoch: 69 | Batch_idx: 280 |  Loss: (0.1884) | Acc: (93.49%) (33628/35968)\n",
            "Epoch: 69 | Batch_idx: 290 |  Loss: (0.1896) | Acc: (93.46%) (34812/37248)\n",
            "Epoch: 69 | Batch_idx: 300 |  Loss: (0.1899) | Acc: (93.44%) (36001/38528)\n",
            "Epoch: 69 | Batch_idx: 310 |  Loss: (0.1907) | Acc: (93.38%) (37174/39808)\n",
            "Epoch: 69 | Batch_idx: 320 |  Loss: (0.1903) | Acc: (93.40%) (38375/41088)\n",
            "Epoch: 69 | Batch_idx: 330 |  Loss: (0.1908) | Acc: (93.38%) (39564/42368)\n",
            "Epoch: 69 | Batch_idx: 340 |  Loss: (0.1911) | Acc: (93.36%) (40750/43648)\n",
            "Epoch: 69 | Batch_idx: 350 |  Loss: (0.1927) | Acc: (93.30%) (41919/44928)\n",
            "Epoch: 69 | Batch_idx: 360 |  Loss: (0.1924) | Acc: (93.31%) (43117/46208)\n",
            "Epoch: 69 | Batch_idx: 370 |  Loss: (0.1919) | Acc: (93.32%) (44317/47488)\n",
            "Epoch: 69 | Batch_idx: 380 |  Loss: (0.1914) | Acc: (93.35%) (45526/48768)\n",
            "Epoch: 69 | Batch_idx: 390 |  Loss: (0.1917) | Acc: (93.35%) (46674/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4036) | Acc: (87.82%) (8782/10000)\n",
            "Epoch: 70 | Batch_idx: 0 |  Loss: (0.2154) | Acc: (94.53%) (121/128)\n",
            "Epoch: 70 | Batch_idx: 10 |  Loss: (0.1852) | Acc: (94.18%) (1326/1408)\n",
            "Epoch: 70 | Batch_idx: 20 |  Loss: (0.1776) | Acc: (93.97%) (2526/2688)\n",
            "Epoch: 70 | Batch_idx: 30 |  Loss: (0.1759) | Acc: (94.10%) (3734/3968)\n",
            "Epoch: 70 | Batch_idx: 40 |  Loss: (0.1807) | Acc: (94.00%) (4933/5248)\n",
            "Epoch: 70 | Batch_idx: 50 |  Loss: (0.1729) | Acc: (94.33%) (6158/6528)\n",
            "Epoch: 70 | Batch_idx: 60 |  Loss: (0.1732) | Acc: (94.33%) (7365/7808)\n",
            "Epoch: 70 | Batch_idx: 70 |  Loss: (0.1751) | Acc: (94.37%) (8576/9088)\n",
            "Epoch: 70 | Batch_idx: 80 |  Loss: (0.1745) | Acc: (94.32%) (9779/10368)\n",
            "Epoch: 70 | Batch_idx: 90 |  Loss: (0.1739) | Acc: (94.27%) (10981/11648)\n",
            "Epoch: 70 | Batch_idx: 100 |  Loss: (0.1735) | Acc: (94.28%) (12188/12928)\n",
            "Epoch: 70 | Batch_idx: 110 |  Loss: (0.1722) | Acc: (94.33%) (13402/14208)\n",
            "Epoch: 70 | Batch_idx: 120 |  Loss: (0.1750) | Acc: (94.21%) (14592/15488)\n",
            "Epoch: 70 | Batch_idx: 130 |  Loss: (0.1796) | Acc: (94.08%) (15775/16768)\n",
            "Epoch: 70 | Batch_idx: 140 |  Loss: (0.1832) | Acc: (93.96%) (16957/18048)\n",
            "Epoch: 70 | Batch_idx: 150 |  Loss: (0.1824) | Acc: (93.95%) (18159/19328)\n",
            "Epoch: 70 | Batch_idx: 160 |  Loss: (0.1839) | Acc: (93.90%) (19350/20608)\n",
            "Epoch: 70 | Batch_idx: 170 |  Loss: (0.1847) | Acc: (93.86%) (20545/21888)\n",
            "Epoch: 70 | Batch_idx: 180 |  Loss: (0.1859) | Acc: (93.83%) (21738/23168)\n",
            "Epoch: 70 | Batch_idx: 190 |  Loss: (0.1860) | Acc: (93.81%) (22935/24448)\n",
            "Epoch: 70 | Batch_idx: 200 |  Loss: (0.1865) | Acc: (93.76%) (24123/25728)\n",
            "Epoch: 70 | Batch_idx: 210 |  Loss: (0.1862) | Acc: (93.76%) (25323/27008)\n",
            "Epoch: 70 | Batch_idx: 220 |  Loss: (0.1861) | Acc: (93.75%) (26521/28288)\n",
            "Epoch: 70 | Batch_idx: 230 |  Loss: (0.1850) | Acc: (93.77%) (27725/29568)\n",
            "Epoch: 70 | Batch_idx: 240 |  Loss: (0.1847) | Acc: (93.80%) (28936/30848)\n",
            "Epoch: 70 | Batch_idx: 250 |  Loss: (0.1854) | Acc: (93.76%) (30122/32128)\n",
            "Epoch: 70 | Batch_idx: 260 |  Loss: (0.1864) | Acc: (93.76%) (31322/33408)\n",
            "Epoch: 70 | Batch_idx: 270 |  Loss: (0.1871) | Acc: (93.73%) (32512/34688)\n",
            "Epoch: 70 | Batch_idx: 280 |  Loss: (0.1877) | Acc: (93.69%) (33698/35968)\n",
            "Epoch: 70 | Batch_idx: 290 |  Loss: (0.1877) | Acc: (93.71%) (34905/37248)\n",
            "Epoch: 70 | Batch_idx: 300 |  Loss: (0.1869) | Acc: (93.74%) (36118/38528)\n",
            "Epoch: 70 | Batch_idx: 310 |  Loss: (0.1873) | Acc: (93.72%) (37308/39808)\n",
            "Epoch: 70 | Batch_idx: 320 |  Loss: (0.1876) | Acc: (93.68%) (38493/41088)\n",
            "Epoch: 70 | Batch_idx: 330 |  Loss: (0.1878) | Acc: (93.67%) (39684/42368)\n",
            "Epoch: 70 | Batch_idx: 340 |  Loss: (0.1877) | Acc: (93.67%) (40885/43648)\n",
            "Epoch: 70 | Batch_idx: 350 |  Loss: (0.1876) | Acc: (93.67%) (42082/44928)\n",
            "Epoch: 70 | Batch_idx: 360 |  Loss: (0.1883) | Acc: (93.64%) (43271/46208)\n",
            "Epoch: 70 | Batch_idx: 370 |  Loss: (0.1883) | Acc: (93.63%) (44465/47488)\n",
            "Epoch: 70 | Batch_idx: 380 |  Loss: (0.1884) | Acc: (93.63%) (45662/48768)\n",
            "Epoch: 70 | Batch_idx: 390 |  Loss: (0.1894) | Acc: (93.58%) (46792/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3989) | Acc: (87.66%) (8766/10000)\n",
            "Epoch: 71 | Batch_idx: 0 |  Loss: (0.1438) | Acc: (93.75%) (120/128)\n",
            "Epoch: 71 | Batch_idx: 10 |  Loss: (0.2046) | Acc: (93.04%) (1310/1408)\n",
            "Epoch: 71 | Batch_idx: 20 |  Loss: (0.1869) | Acc: (93.60%) (2516/2688)\n",
            "Epoch: 71 | Batch_idx: 30 |  Loss: (0.1826) | Acc: (93.90%) (3726/3968)\n",
            "Epoch: 71 | Batch_idx: 40 |  Loss: (0.1840) | Acc: (93.98%) (4932/5248)\n",
            "Epoch: 71 | Batch_idx: 50 |  Loss: (0.1858) | Acc: (93.86%) (6127/6528)\n",
            "Epoch: 71 | Batch_idx: 60 |  Loss: (0.1819) | Acc: (93.98%) (7338/7808)\n",
            "Epoch: 71 | Batch_idx: 70 |  Loss: (0.1809) | Acc: (93.98%) (8541/9088)\n",
            "Epoch: 71 | Batch_idx: 80 |  Loss: (0.1810) | Acc: (93.93%) (9739/10368)\n",
            "Epoch: 71 | Batch_idx: 90 |  Loss: (0.1805) | Acc: (93.94%) (10942/11648)\n",
            "Epoch: 71 | Batch_idx: 100 |  Loss: (0.1791) | Acc: (93.95%) (12146/12928)\n",
            "Epoch: 71 | Batch_idx: 110 |  Loss: (0.1778) | Acc: (93.99%) (13354/14208)\n",
            "Epoch: 71 | Batch_idx: 120 |  Loss: (0.1752) | Acc: (94.04%) (14565/15488)\n",
            "Epoch: 71 | Batch_idx: 130 |  Loss: (0.1767) | Acc: (93.99%) (15760/16768)\n",
            "Epoch: 71 | Batch_idx: 140 |  Loss: (0.1761) | Acc: (93.96%) (16958/18048)\n",
            "Epoch: 71 | Batch_idx: 150 |  Loss: (0.1772) | Acc: (93.94%) (18157/19328)\n",
            "Epoch: 71 | Batch_idx: 160 |  Loss: (0.1764) | Acc: (93.98%) (19368/20608)\n",
            "Epoch: 71 | Batch_idx: 170 |  Loss: (0.1766) | Acc: (93.95%) (20564/21888)\n",
            "Epoch: 71 | Batch_idx: 180 |  Loss: (0.1782) | Acc: (93.92%) (21759/23168)\n",
            "Epoch: 71 | Batch_idx: 190 |  Loss: (0.1788) | Acc: (93.87%) (22949/24448)\n",
            "Epoch: 71 | Batch_idx: 200 |  Loss: (0.1785) | Acc: (93.87%) (24151/25728)\n",
            "Epoch: 71 | Batch_idx: 210 |  Loss: (0.1792) | Acc: (93.82%) (25338/27008)\n",
            "Epoch: 71 | Batch_idx: 220 |  Loss: (0.1801) | Acc: (93.76%) (26523/28288)\n",
            "Epoch: 71 | Batch_idx: 230 |  Loss: (0.1802) | Acc: (93.79%) (27731/29568)\n",
            "Epoch: 71 | Batch_idx: 240 |  Loss: (0.1809) | Acc: (93.78%) (28930/30848)\n",
            "Epoch: 71 | Batch_idx: 250 |  Loss: (0.1826) | Acc: (93.70%) (30105/32128)\n",
            "Epoch: 71 | Batch_idx: 260 |  Loss: (0.1824) | Acc: (93.71%) (31308/33408)\n",
            "Epoch: 71 | Batch_idx: 270 |  Loss: (0.1829) | Acc: (93.70%) (32504/34688)\n",
            "Epoch: 71 | Batch_idx: 280 |  Loss: (0.1835) | Acc: (93.67%) (33693/35968)\n",
            "Epoch: 71 | Batch_idx: 290 |  Loss: (0.1826) | Acc: (93.71%) (34905/37248)\n",
            "Epoch: 71 | Batch_idx: 300 |  Loss: (0.1825) | Acc: (93.73%) (36112/38528)\n",
            "Epoch: 71 | Batch_idx: 310 |  Loss: (0.1815) | Acc: (93.75%) (37320/39808)\n",
            "Epoch: 71 | Batch_idx: 320 |  Loss: (0.1816) | Acc: (93.76%) (38523/41088)\n",
            "Epoch: 71 | Batch_idx: 330 |  Loss: (0.1808) | Acc: (93.81%) (39744/42368)\n",
            "Epoch: 71 | Batch_idx: 340 |  Loss: (0.1811) | Acc: (93.81%) (40945/43648)\n",
            "Epoch: 71 | Batch_idx: 350 |  Loss: (0.1818) | Acc: (93.78%) (42135/44928)\n",
            "Epoch: 71 | Batch_idx: 360 |  Loss: (0.1825) | Acc: (93.76%) (43325/46208)\n",
            "Epoch: 71 | Batch_idx: 370 |  Loss: (0.1840) | Acc: (93.71%) (44499/47488)\n",
            "Epoch: 71 | Batch_idx: 380 |  Loss: (0.1844) | Acc: (93.68%) (45685/48768)\n",
            "Epoch: 71 | Batch_idx: 390 |  Loss: (0.1850) | Acc: (93.66%) (46832/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4176) | Acc: (87.40%) (8740/10000)\n",
            "Epoch: 72 | Batch_idx: 0 |  Loss: (0.1817) | Acc: (94.53%) (121/128)\n",
            "Epoch: 72 | Batch_idx: 10 |  Loss: (0.1671) | Acc: (94.18%) (1326/1408)\n",
            "Epoch: 72 | Batch_idx: 20 |  Loss: (0.1647) | Acc: (94.27%) (2534/2688)\n",
            "Epoch: 72 | Batch_idx: 30 |  Loss: (0.1614) | Acc: (94.48%) (3749/3968)\n",
            "Epoch: 72 | Batch_idx: 40 |  Loss: (0.1656) | Acc: (94.36%) (4952/5248)\n",
            "Epoch: 72 | Batch_idx: 50 |  Loss: (0.1658) | Acc: (94.30%) (6156/6528)\n",
            "Epoch: 72 | Batch_idx: 60 |  Loss: (0.1695) | Acc: (94.25%) (7359/7808)\n",
            "Epoch: 72 | Batch_idx: 70 |  Loss: (0.1675) | Acc: (94.23%) (8564/9088)\n",
            "Epoch: 72 | Batch_idx: 80 |  Loss: (0.1695) | Acc: (94.14%) (9760/10368)\n",
            "Epoch: 72 | Batch_idx: 90 |  Loss: (0.1757) | Acc: (93.93%) (10941/11648)\n",
            "Epoch: 72 | Batch_idx: 100 |  Loss: (0.1797) | Acc: (93.84%) (12131/12928)\n",
            "Epoch: 72 | Batch_idx: 110 |  Loss: (0.1769) | Acc: (93.93%) (13346/14208)\n",
            "Epoch: 72 | Batch_idx: 120 |  Loss: (0.1766) | Acc: (93.92%) (14546/15488)\n",
            "Epoch: 72 | Batch_idx: 130 |  Loss: (0.1756) | Acc: (93.96%) (15756/16768)\n",
            "Epoch: 72 | Batch_idx: 140 |  Loss: (0.1747) | Acc: (93.96%) (16957/18048)\n",
            "Epoch: 72 | Batch_idx: 150 |  Loss: (0.1752) | Acc: (93.96%) (18161/19328)\n",
            "Epoch: 72 | Batch_idx: 160 |  Loss: (0.1758) | Acc: (93.93%) (19358/20608)\n",
            "Epoch: 72 | Batch_idx: 170 |  Loss: (0.1762) | Acc: (93.94%) (20562/21888)\n",
            "Epoch: 72 | Batch_idx: 180 |  Loss: (0.1779) | Acc: (93.88%) (21751/23168)\n",
            "Epoch: 72 | Batch_idx: 190 |  Loss: (0.1778) | Acc: (93.88%) (22953/24448)\n",
            "Epoch: 72 | Batch_idx: 200 |  Loss: (0.1773) | Acc: (93.89%) (24157/25728)\n",
            "Epoch: 72 | Batch_idx: 210 |  Loss: (0.1782) | Acc: (93.84%) (25345/27008)\n",
            "Epoch: 72 | Batch_idx: 220 |  Loss: (0.1791) | Acc: (93.82%) (26539/28288)\n",
            "Epoch: 72 | Batch_idx: 230 |  Loss: (0.1788) | Acc: (93.80%) (27736/29568)\n",
            "Epoch: 72 | Batch_idx: 240 |  Loss: (0.1799) | Acc: (93.78%) (28930/30848)\n",
            "Epoch: 72 | Batch_idx: 250 |  Loss: (0.1806) | Acc: (93.79%) (30132/32128)\n",
            "Epoch: 72 | Batch_idx: 260 |  Loss: (0.1808) | Acc: (93.77%) (31327/33408)\n",
            "Epoch: 72 | Batch_idx: 270 |  Loss: (0.1818) | Acc: (93.73%) (32514/34688)\n",
            "Epoch: 72 | Batch_idx: 280 |  Loss: (0.1819) | Acc: (93.75%) (33719/35968)\n",
            "Epoch: 72 | Batch_idx: 290 |  Loss: (0.1814) | Acc: (93.76%) (34925/37248)\n",
            "Epoch: 72 | Batch_idx: 300 |  Loss: (0.1811) | Acc: (93.76%) (36123/38528)\n",
            "Epoch: 72 | Batch_idx: 310 |  Loss: (0.1825) | Acc: (93.73%) (37313/39808)\n",
            "Epoch: 72 | Batch_idx: 320 |  Loss: (0.1829) | Acc: (93.72%) (38506/41088)\n",
            "Epoch: 72 | Batch_idx: 330 |  Loss: (0.1837) | Acc: (93.70%) (39698/42368)\n",
            "Epoch: 72 | Batch_idx: 340 |  Loss: (0.1840) | Acc: (93.66%) (40881/43648)\n",
            "Epoch: 72 | Batch_idx: 350 |  Loss: (0.1843) | Acc: (93.63%) (42065/44928)\n",
            "Epoch: 72 | Batch_idx: 360 |  Loss: (0.1853) | Acc: (93.59%) (43247/46208)\n",
            "Epoch: 72 | Batch_idx: 370 |  Loss: (0.1853) | Acc: (93.58%) (44441/47488)\n",
            "Epoch: 72 | Batch_idx: 380 |  Loss: (0.1861) | Acc: (93.55%) (45622/48768)\n",
            "Epoch: 72 | Batch_idx: 390 |  Loss: (0.1875) | Acc: (93.51%) (46757/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3961) | Acc: (87.66%) (8766/10000)\n",
            "Epoch: 73 | Batch_idx: 0 |  Loss: (0.1807) | Acc: (94.53%) (121/128)\n",
            "Epoch: 73 | Batch_idx: 10 |  Loss: (0.1490) | Acc: (94.74%) (1334/1408)\n",
            "Epoch: 73 | Batch_idx: 20 |  Loss: (0.1624) | Acc: (94.46%) (2539/2688)\n",
            "Epoch: 73 | Batch_idx: 30 |  Loss: (0.1622) | Acc: (94.28%) (3741/3968)\n",
            "Epoch: 73 | Batch_idx: 40 |  Loss: (0.1650) | Acc: (94.15%) (4941/5248)\n",
            "Epoch: 73 | Batch_idx: 50 |  Loss: (0.1663) | Acc: (94.09%) (6142/6528)\n",
            "Epoch: 73 | Batch_idx: 60 |  Loss: (0.1693) | Acc: (94.06%) (7344/7808)\n",
            "Epoch: 73 | Batch_idx: 70 |  Loss: (0.1705) | Acc: (94.07%) (8549/9088)\n",
            "Epoch: 73 | Batch_idx: 80 |  Loss: (0.1701) | Acc: (94.11%) (9757/10368)\n",
            "Epoch: 73 | Batch_idx: 90 |  Loss: (0.1701) | Acc: (94.09%) (10960/11648)\n",
            "Epoch: 73 | Batch_idx: 100 |  Loss: (0.1709) | Acc: (94.11%) (12166/12928)\n",
            "Epoch: 73 | Batch_idx: 110 |  Loss: (0.1726) | Acc: (94.08%) (13367/14208)\n",
            "Epoch: 73 | Batch_idx: 120 |  Loss: (0.1740) | Acc: (94.04%) (14565/15488)\n",
            "Epoch: 73 | Batch_idx: 130 |  Loss: (0.1746) | Acc: (94.04%) (15768/16768)\n",
            "Epoch: 73 | Batch_idx: 140 |  Loss: (0.1737) | Acc: (94.01%) (16967/18048)\n",
            "Epoch: 73 | Batch_idx: 150 |  Loss: (0.1740) | Acc: (94.01%) (18171/19328)\n",
            "Epoch: 73 | Batch_idx: 160 |  Loss: (0.1776) | Acc: (93.88%) (19346/20608)\n",
            "Epoch: 73 | Batch_idx: 170 |  Loss: (0.1807) | Acc: (93.79%) (20528/21888)\n",
            "Epoch: 73 | Batch_idx: 180 |  Loss: (0.1803) | Acc: (93.81%) (21735/23168)\n",
            "Epoch: 73 | Batch_idx: 190 |  Loss: (0.1799) | Acc: (93.85%) (22945/24448)\n",
            "Epoch: 73 | Batch_idx: 200 |  Loss: (0.1799) | Acc: (93.84%) (24142/25728)\n",
            "Epoch: 73 | Batch_idx: 210 |  Loss: (0.1818) | Acc: (93.72%) (25311/27008)\n",
            "Epoch: 73 | Batch_idx: 220 |  Loss: (0.1819) | Acc: (93.67%) (26496/28288)\n",
            "Epoch: 73 | Batch_idx: 230 |  Loss: (0.1823) | Acc: (93.65%) (27691/29568)\n",
            "Epoch: 73 | Batch_idx: 240 |  Loss: (0.1828) | Acc: (93.63%) (28883/30848)\n",
            "Epoch: 73 | Batch_idx: 250 |  Loss: (0.1840) | Acc: (93.62%) (30077/32128)\n",
            "Epoch: 73 | Batch_idx: 260 |  Loss: (0.1849) | Acc: (93.59%) (31267/33408)\n",
            "Epoch: 73 | Batch_idx: 270 |  Loss: (0.1853) | Acc: (93.60%) (32468/34688)\n",
            "Epoch: 73 | Batch_idx: 280 |  Loss: (0.1867) | Acc: (93.55%) (33649/35968)\n",
            "Epoch: 73 | Batch_idx: 290 |  Loss: (0.1860) | Acc: (93.56%) (34850/37248)\n",
            "Epoch: 73 | Batch_idx: 300 |  Loss: (0.1861) | Acc: (93.56%) (36046/38528)\n",
            "Epoch: 73 | Batch_idx: 310 |  Loss: (0.1860) | Acc: (93.57%) (37247/39808)\n",
            "Epoch: 73 | Batch_idx: 320 |  Loss: (0.1858) | Acc: (93.57%) (38445/41088)\n",
            "Epoch: 73 | Batch_idx: 330 |  Loss: (0.1869) | Acc: (93.53%) (39628/42368)\n",
            "Epoch: 73 | Batch_idx: 340 |  Loss: (0.1874) | Acc: (93.54%) (40827/43648)\n",
            "Epoch: 73 | Batch_idx: 350 |  Loss: (0.1871) | Acc: (93.54%) (42025/44928)\n",
            "Epoch: 73 | Batch_idx: 360 |  Loss: (0.1880) | Acc: (93.54%) (43222/46208)\n",
            "Epoch: 73 | Batch_idx: 370 |  Loss: (0.1873) | Acc: (93.56%) (44428/47488)\n",
            "Epoch: 73 | Batch_idx: 380 |  Loss: (0.1859) | Acc: (93.61%) (45653/48768)\n",
            "Epoch: 73 | Batch_idx: 390 |  Loss: (0.1859) | Acc: (93.60%) (46800/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4337) | Acc: (87.85%) (8785/10000)\n",
            "Epoch: 74 | Batch_idx: 0 |  Loss: (0.2141) | Acc: (93.75%) (120/128)\n",
            "Epoch: 74 | Batch_idx: 10 |  Loss: (0.1689) | Acc: (94.39%) (1329/1408)\n",
            "Epoch: 74 | Batch_idx: 20 |  Loss: (0.1813) | Acc: (93.82%) (2522/2688)\n",
            "Epoch: 74 | Batch_idx: 30 |  Loss: (0.1872) | Acc: (93.78%) (3721/3968)\n",
            "Epoch: 74 | Batch_idx: 40 |  Loss: (0.1907) | Acc: (93.79%) (4922/5248)\n",
            "Epoch: 74 | Batch_idx: 50 |  Loss: (0.1878) | Acc: (93.78%) (6122/6528)\n",
            "Epoch: 74 | Batch_idx: 60 |  Loss: (0.1809) | Acc: (93.93%) (7334/7808)\n",
            "Epoch: 74 | Batch_idx: 70 |  Loss: (0.1821) | Acc: (93.82%) (8526/9088)\n",
            "Epoch: 74 | Batch_idx: 80 |  Loss: (0.1784) | Acc: (94.01%) (9747/10368)\n",
            "Epoch: 74 | Batch_idx: 90 |  Loss: (0.1800) | Acc: (93.89%) (10936/11648)\n",
            "Epoch: 74 | Batch_idx: 100 |  Loss: (0.1808) | Acc: (93.90%) (12140/12928)\n",
            "Epoch: 74 | Batch_idx: 110 |  Loss: (0.1788) | Acc: (94.01%) (13357/14208)\n",
            "Epoch: 74 | Batch_idx: 120 |  Loss: (0.1807) | Acc: (93.94%) (14549/15488)\n",
            "Epoch: 74 | Batch_idx: 130 |  Loss: (0.1785) | Acc: (93.97%) (15757/16768)\n",
            "Epoch: 74 | Batch_idx: 140 |  Loss: (0.1798) | Acc: (93.96%) (16957/18048)\n",
            "Epoch: 74 | Batch_idx: 150 |  Loss: (0.1779) | Acc: (94.03%) (18175/19328)\n",
            "Epoch: 74 | Batch_idx: 160 |  Loss: (0.1796) | Acc: (93.97%) (19365/20608)\n",
            "Epoch: 74 | Batch_idx: 170 |  Loss: (0.1803) | Acc: (93.98%) (20570/21888)\n",
            "Epoch: 74 | Batch_idx: 180 |  Loss: (0.1815) | Acc: (93.94%) (21763/23168)\n",
            "Epoch: 74 | Batch_idx: 190 |  Loss: (0.1818) | Acc: (93.92%) (22962/24448)\n",
            "Epoch: 74 | Batch_idx: 200 |  Loss: (0.1819) | Acc: (93.91%) (24160/25728)\n",
            "Epoch: 74 | Batch_idx: 210 |  Loss: (0.1810) | Acc: (93.92%) (25366/27008)\n",
            "Epoch: 74 | Batch_idx: 220 |  Loss: (0.1799) | Acc: (93.93%) (26570/28288)\n",
            "Epoch: 74 | Batch_idx: 230 |  Loss: (0.1808) | Acc: (93.91%) (27766/29568)\n",
            "Epoch: 74 | Batch_idx: 240 |  Loss: (0.1803) | Acc: (93.91%) (28970/30848)\n",
            "Epoch: 74 | Batch_idx: 250 |  Loss: (0.1792) | Acc: (93.95%) (30183/32128)\n",
            "Epoch: 74 | Batch_idx: 260 |  Loss: (0.1795) | Acc: (93.97%) (31393/33408)\n",
            "Epoch: 74 | Batch_idx: 270 |  Loss: (0.1798) | Acc: (93.95%) (32591/34688)\n",
            "Epoch: 74 | Batch_idx: 280 |  Loss: (0.1808) | Acc: (93.90%) (33773/35968)\n",
            "Epoch: 74 | Batch_idx: 290 |  Loss: (0.1813) | Acc: (93.87%) (34965/37248)\n",
            "Epoch: 74 | Batch_idx: 300 |  Loss: (0.1812) | Acc: (93.87%) (36167/38528)\n",
            "Epoch: 74 | Batch_idx: 310 |  Loss: (0.1822) | Acc: (93.85%) (37358/39808)\n",
            "Epoch: 74 | Batch_idx: 320 |  Loss: (0.1838) | Acc: (93.80%) (38540/41088)\n",
            "Epoch: 74 | Batch_idx: 330 |  Loss: (0.1835) | Acc: (93.81%) (39746/42368)\n",
            "Epoch: 74 | Batch_idx: 340 |  Loss: (0.1833) | Acc: (93.80%) (40941/43648)\n",
            "Epoch: 74 | Batch_idx: 350 |  Loss: (0.1837) | Acc: (93.79%) (42136/44928)\n",
            "Epoch: 74 | Batch_idx: 360 |  Loss: (0.1842) | Acc: (93.78%) (43335/46208)\n",
            "Epoch: 74 | Batch_idx: 370 |  Loss: (0.1840) | Acc: (93.80%) (44545/47488)\n",
            "Epoch: 74 | Batch_idx: 380 |  Loss: (0.1841) | Acc: (93.80%) (45745/48768)\n",
            "Epoch: 74 | Batch_idx: 390 |  Loss: (0.1841) | Acc: (93.79%) (46896/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4389) | Acc: (87.62%) (8762/10000)\n",
            "Epoch: 75 | Batch_idx: 0 |  Loss: (0.3450) | Acc: (91.41%) (117/128)\n",
            "Epoch: 75 | Batch_idx: 10 |  Loss: (0.1933) | Acc: (93.18%) (1312/1408)\n",
            "Epoch: 75 | Batch_idx: 20 |  Loss: (0.1730) | Acc: (94.01%) (2527/2688)\n",
            "Epoch: 75 | Batch_idx: 30 |  Loss: (0.1677) | Acc: (94.30%) (3742/3968)\n",
            "Epoch: 75 | Batch_idx: 40 |  Loss: (0.1658) | Acc: (94.38%) (4953/5248)\n",
            "Epoch: 75 | Batch_idx: 50 |  Loss: (0.1746) | Acc: (93.93%) (6132/6528)\n",
            "Epoch: 75 | Batch_idx: 60 |  Loss: (0.1771) | Acc: (93.94%) (7335/7808)\n",
            "Epoch: 75 | Batch_idx: 70 |  Loss: (0.1787) | Acc: (93.89%) (8533/9088)\n",
            "Epoch: 75 | Batch_idx: 80 |  Loss: (0.1791) | Acc: (93.88%) (9733/10368)\n",
            "Epoch: 75 | Batch_idx: 90 |  Loss: (0.1797) | Acc: (93.84%) (10931/11648)\n",
            "Epoch: 75 | Batch_idx: 100 |  Loss: (0.1812) | Acc: (93.80%) (12126/12928)\n",
            "Epoch: 75 | Batch_idx: 110 |  Loss: (0.1809) | Acc: (93.82%) (13330/14208)\n",
            "Epoch: 75 | Batch_idx: 120 |  Loss: (0.1809) | Acc: (93.81%) (14529/15488)\n",
            "Epoch: 75 | Batch_idx: 130 |  Loss: (0.1827) | Acc: (93.73%) (15716/16768)\n",
            "Epoch: 75 | Batch_idx: 140 |  Loss: (0.1850) | Acc: (93.66%) (16903/18048)\n",
            "Epoch: 75 | Batch_idx: 150 |  Loss: (0.1859) | Acc: (93.62%) (18094/19328)\n",
            "Epoch: 75 | Batch_idx: 160 |  Loss: (0.1867) | Acc: (93.62%) (19293/20608)\n",
            "Epoch: 75 | Batch_idx: 170 |  Loss: (0.1854) | Acc: (93.66%) (20500/21888)\n",
            "Epoch: 75 | Batch_idx: 180 |  Loss: (0.1844) | Acc: (93.69%) (21705/23168)\n",
            "Epoch: 75 | Batch_idx: 190 |  Loss: (0.1835) | Acc: (93.72%) (22913/24448)\n",
            "Epoch: 75 | Batch_idx: 200 |  Loss: (0.1845) | Acc: (93.70%) (24108/25728)\n",
            "Epoch: 75 | Batch_idx: 210 |  Loss: (0.1840) | Acc: (93.73%) (25314/27008)\n",
            "Epoch: 75 | Batch_idx: 220 |  Loss: (0.1843) | Acc: (93.76%) (26523/28288)\n",
            "Epoch: 75 | Batch_idx: 230 |  Loss: (0.1847) | Acc: (93.76%) (27722/29568)\n",
            "Epoch: 75 | Batch_idx: 240 |  Loss: (0.1851) | Acc: (93.73%) (28915/30848)\n",
            "Epoch: 75 | Batch_idx: 250 |  Loss: (0.1863) | Acc: (93.68%) (30099/32128)\n",
            "Epoch: 75 | Batch_idx: 260 |  Loss: (0.1858) | Acc: (93.70%) (31304/33408)\n",
            "Epoch: 75 | Batch_idx: 270 |  Loss: (0.1868) | Acc: (93.63%) (32479/34688)\n",
            "Epoch: 75 | Batch_idx: 280 |  Loss: (0.1861) | Acc: (93.69%) (33697/35968)\n",
            "Epoch: 75 | Batch_idx: 290 |  Loss: (0.1859) | Acc: (93.67%) (34891/37248)\n",
            "Epoch: 75 | Batch_idx: 300 |  Loss: (0.1864) | Acc: (93.66%) (36086/38528)\n",
            "Epoch: 75 | Batch_idx: 310 |  Loss: (0.1859) | Acc: (93.67%) (37289/39808)\n",
            "Epoch: 75 | Batch_idx: 320 |  Loss: (0.1864) | Acc: (93.67%) (38488/41088)\n",
            "Epoch: 75 | Batch_idx: 330 |  Loss: (0.1861) | Acc: (93.68%) (39690/42368)\n",
            "Epoch: 75 | Batch_idx: 340 |  Loss: (0.1861) | Acc: (93.68%) (40889/43648)\n",
            "Epoch: 75 | Batch_idx: 350 |  Loss: (0.1869) | Acc: (93.66%) (42080/44928)\n",
            "Epoch: 75 | Batch_idx: 360 |  Loss: (0.1875) | Acc: (93.67%) (43281/46208)\n",
            "Epoch: 75 | Batch_idx: 370 |  Loss: (0.1879) | Acc: (93.65%) (44472/47488)\n",
            "Epoch: 75 | Batch_idx: 380 |  Loss: (0.1877) | Acc: (93.64%) (45668/48768)\n",
            "Epoch: 75 | Batch_idx: 390 |  Loss: (0.1885) | Acc: (93.61%) (46805/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4875) | Acc: (85.66%) (8566/10000)\n",
            "Epoch: 76 | Batch_idx: 0 |  Loss: (0.1231) | Acc: (96.09%) (123/128)\n",
            "Epoch: 76 | Batch_idx: 10 |  Loss: (0.1726) | Acc: (94.39%) (1329/1408)\n",
            "Epoch: 76 | Batch_idx: 20 |  Loss: (0.1674) | Acc: (94.16%) (2531/2688)\n",
            "Epoch: 76 | Batch_idx: 30 |  Loss: (0.1590) | Acc: (94.43%) (3747/3968)\n",
            "Epoch: 76 | Batch_idx: 40 |  Loss: (0.1555) | Acc: (94.70%) (4970/5248)\n",
            "Epoch: 76 | Batch_idx: 50 |  Loss: (0.1658) | Acc: (94.39%) (6162/6528)\n",
            "Epoch: 76 | Batch_idx: 60 |  Loss: (0.1654) | Acc: (94.35%) (7367/7808)\n",
            "Epoch: 76 | Batch_idx: 70 |  Loss: (0.1659) | Acc: (94.36%) (8575/9088)\n",
            "Epoch: 76 | Batch_idx: 80 |  Loss: (0.1650) | Acc: (94.35%) (9782/10368)\n",
            "Epoch: 76 | Batch_idx: 90 |  Loss: (0.1678) | Acc: (94.33%) (10988/11648)\n",
            "Epoch: 76 | Batch_idx: 100 |  Loss: (0.1691) | Acc: (94.28%) (12189/12928)\n",
            "Epoch: 76 | Batch_idx: 110 |  Loss: (0.1738) | Acc: (94.16%) (13378/14208)\n",
            "Epoch: 76 | Batch_idx: 120 |  Loss: (0.1758) | Acc: (94.09%) (14572/15488)\n",
            "Epoch: 76 | Batch_idx: 130 |  Loss: (0.1734) | Acc: (94.20%) (15795/16768)\n",
            "Epoch: 76 | Batch_idx: 140 |  Loss: (0.1753) | Acc: (94.12%) (16986/18048)\n",
            "Epoch: 76 | Batch_idx: 150 |  Loss: (0.1775) | Acc: (94.00%) (18168/19328)\n",
            "Epoch: 76 | Batch_idx: 160 |  Loss: (0.1789) | Acc: (93.91%) (19354/20608)\n",
            "Epoch: 76 | Batch_idx: 170 |  Loss: (0.1769) | Acc: (93.97%) (20569/21888)\n",
            "Epoch: 76 | Batch_idx: 180 |  Loss: (0.1761) | Acc: (94.01%) (21780/23168)\n",
            "Epoch: 76 | Batch_idx: 190 |  Loss: (0.1786) | Acc: (93.94%) (22967/24448)\n",
            "Epoch: 76 | Batch_idx: 200 |  Loss: (0.1791) | Acc: (93.94%) (24169/25728)\n",
            "Epoch: 76 | Batch_idx: 210 |  Loss: (0.1788) | Acc: (93.93%) (25368/27008)\n",
            "Epoch: 76 | Batch_idx: 220 |  Loss: (0.1781) | Acc: (93.96%) (26578/28288)\n",
            "Epoch: 76 | Batch_idx: 230 |  Loss: (0.1792) | Acc: (93.94%) (27775/29568)\n",
            "Epoch: 76 | Batch_idx: 240 |  Loss: (0.1798) | Acc: (93.93%) (28974/30848)\n",
            "Epoch: 76 | Batch_idx: 250 |  Loss: (0.1797) | Acc: (93.91%) (30171/32128)\n",
            "Epoch: 76 | Batch_idx: 260 |  Loss: (0.1810) | Acc: (93.85%) (31354/33408)\n",
            "Epoch: 76 | Batch_idx: 270 |  Loss: (0.1819) | Acc: (93.84%) (32552/34688)\n",
            "Epoch: 76 | Batch_idx: 280 |  Loss: (0.1818) | Acc: (93.83%) (33748/35968)\n",
            "Epoch: 76 | Batch_idx: 290 |  Loss: (0.1817) | Acc: (93.84%) (34955/37248)\n",
            "Epoch: 76 | Batch_idx: 300 |  Loss: (0.1817) | Acc: (93.84%) (36155/38528)\n",
            "Epoch: 76 | Batch_idx: 310 |  Loss: (0.1822) | Acc: (93.82%) (37346/39808)\n",
            "Epoch: 76 | Batch_idx: 320 |  Loss: (0.1830) | Acc: (93.76%) (38526/41088)\n",
            "Epoch: 76 | Batch_idx: 330 |  Loss: (0.1829) | Acc: (93.75%) (39718/42368)\n",
            "Epoch: 76 | Batch_idx: 340 |  Loss: (0.1822) | Acc: (93.76%) (40923/43648)\n",
            "Epoch: 76 | Batch_idx: 350 |  Loss: (0.1824) | Acc: (93.77%) (42130/44928)\n",
            "Epoch: 76 | Batch_idx: 360 |  Loss: (0.1827) | Acc: (93.76%) (43326/46208)\n",
            "Epoch: 76 | Batch_idx: 370 |  Loss: (0.1835) | Acc: (93.74%) (44516/47488)\n",
            "Epoch: 76 | Batch_idx: 380 |  Loss: (0.1839) | Acc: (93.73%) (45712/48768)\n",
            "Epoch: 76 | Batch_idx: 390 |  Loss: (0.1842) | Acc: (93.74%) (46871/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4805) | Acc: (86.10%) (8610/10000)\n",
            "Epoch: 77 | Batch_idx: 0 |  Loss: (0.2476) | Acc: (90.62%) (116/128)\n",
            "Epoch: 77 | Batch_idx: 10 |  Loss: (0.2122) | Acc: (93.11%) (1311/1408)\n",
            "Epoch: 77 | Batch_idx: 20 |  Loss: (0.1981) | Acc: (93.45%) (2512/2688)\n",
            "Epoch: 77 | Batch_idx: 30 |  Loss: (0.1888) | Acc: (93.62%) (3715/3968)\n",
            "Epoch: 77 | Batch_idx: 40 |  Loss: (0.1851) | Acc: (93.62%) (4913/5248)\n",
            "Epoch: 77 | Batch_idx: 50 |  Loss: (0.1825) | Acc: (93.86%) (6127/6528)\n",
            "Epoch: 77 | Batch_idx: 60 |  Loss: (0.1811) | Acc: (93.98%) (7338/7808)\n",
            "Epoch: 77 | Batch_idx: 70 |  Loss: (0.1775) | Acc: (94.00%) (8543/9088)\n",
            "Epoch: 77 | Batch_idx: 80 |  Loss: (0.1809) | Acc: (93.94%) (9740/10368)\n",
            "Epoch: 77 | Batch_idx: 90 |  Loss: (0.1812) | Acc: (93.99%) (10948/11648)\n",
            "Epoch: 77 | Batch_idx: 100 |  Loss: (0.1814) | Acc: (93.97%) (12149/12928)\n",
            "Epoch: 77 | Batch_idx: 110 |  Loss: (0.1815) | Acc: (93.92%) (13344/14208)\n",
            "Epoch: 77 | Batch_idx: 120 |  Loss: (0.1796) | Acc: (93.97%) (14554/15488)\n",
            "Epoch: 77 | Batch_idx: 130 |  Loss: (0.1789) | Acc: (93.98%) (15758/16768)\n",
            "Epoch: 77 | Batch_idx: 140 |  Loss: (0.1825) | Acc: (93.87%) (16941/18048)\n",
            "Epoch: 77 | Batch_idx: 150 |  Loss: (0.1814) | Acc: (93.89%) (18147/19328)\n",
            "Epoch: 77 | Batch_idx: 160 |  Loss: (0.1797) | Acc: (93.94%) (19359/20608)\n",
            "Epoch: 77 | Batch_idx: 170 |  Loss: (0.1782) | Acc: (93.95%) (20564/21888)\n",
            "Epoch: 77 | Batch_idx: 180 |  Loss: (0.1796) | Acc: (93.94%) (21764/23168)\n",
            "Epoch: 77 | Batch_idx: 190 |  Loss: (0.1803) | Acc: (93.91%) (22960/24448)\n",
            "Epoch: 77 | Batch_idx: 200 |  Loss: (0.1818) | Acc: (93.84%) (24143/25728)\n",
            "Epoch: 77 | Batch_idx: 210 |  Loss: (0.1838) | Acc: (93.80%) (25334/27008)\n",
            "Epoch: 77 | Batch_idx: 220 |  Loss: (0.1862) | Acc: (93.74%) (26517/28288)\n",
            "Epoch: 77 | Batch_idx: 230 |  Loss: (0.1870) | Acc: (93.69%) (27701/29568)\n",
            "Epoch: 77 | Batch_idx: 240 |  Loss: (0.1857) | Acc: (93.72%) (28910/30848)\n",
            "Epoch: 77 | Batch_idx: 250 |  Loss: (0.1852) | Acc: (93.73%) (30113/32128)\n",
            "Epoch: 77 | Batch_idx: 260 |  Loss: (0.1863) | Acc: (93.71%) (31307/33408)\n",
            "Epoch: 77 | Batch_idx: 270 |  Loss: (0.1857) | Acc: (93.72%) (32509/34688)\n",
            "Epoch: 77 | Batch_idx: 280 |  Loss: (0.1860) | Acc: (93.69%) (33698/35968)\n",
            "Epoch: 77 | Batch_idx: 290 |  Loss: (0.1863) | Acc: (93.69%) (34898/37248)\n",
            "Epoch: 77 | Batch_idx: 300 |  Loss: (0.1858) | Acc: (93.70%) (36101/38528)\n",
            "Epoch: 77 | Batch_idx: 310 |  Loss: (0.1861) | Acc: (93.70%) (37299/39808)\n",
            "Epoch: 77 | Batch_idx: 320 |  Loss: (0.1869) | Acc: (93.68%) (38493/41088)\n",
            "Epoch: 77 | Batch_idx: 330 |  Loss: (0.1881) | Acc: (93.62%) (39667/42368)\n",
            "Epoch: 77 | Batch_idx: 340 |  Loss: (0.1887) | Acc: (93.61%) (40861/43648)\n",
            "Epoch: 77 | Batch_idx: 350 |  Loss: (0.1878) | Acc: (93.64%) (42070/44928)\n",
            "Epoch: 77 | Batch_idx: 360 |  Loss: (0.1879) | Acc: (93.66%) (43277/46208)\n",
            "Epoch: 77 | Batch_idx: 370 |  Loss: (0.1874) | Acc: (93.67%) (44481/47488)\n",
            "Epoch: 77 | Batch_idx: 380 |  Loss: (0.1873) | Acc: (93.67%) (45679/48768)\n",
            "Epoch: 77 | Batch_idx: 390 |  Loss: (0.1882) | Acc: (93.63%) (46817/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4340) | Acc: (87.08%) (8708/10000)\n",
            "Epoch: 78 | Batch_idx: 0 |  Loss: (0.1554) | Acc: (96.09%) (123/128)\n",
            "Epoch: 78 | Batch_idx: 10 |  Loss: (0.1643) | Acc: (94.11%) (1325/1408)\n",
            "Epoch: 78 | Batch_idx: 20 |  Loss: (0.1606) | Acc: (94.31%) (2535/2688)\n",
            "Epoch: 78 | Batch_idx: 30 |  Loss: (0.1576) | Acc: (94.41%) (3746/3968)\n",
            "Epoch: 78 | Batch_idx: 40 |  Loss: (0.1629) | Acc: (94.42%) (4955/5248)\n",
            "Epoch: 78 | Batch_idx: 50 |  Loss: (0.1599) | Acc: (94.49%) (6168/6528)\n",
            "Epoch: 78 | Batch_idx: 60 |  Loss: (0.1606) | Acc: (94.54%) (7382/7808)\n",
            "Epoch: 78 | Batch_idx: 70 |  Loss: (0.1625) | Acc: (94.48%) (8586/9088)\n",
            "Epoch: 78 | Batch_idx: 80 |  Loss: (0.1614) | Acc: (94.46%) (9794/10368)\n",
            "Epoch: 78 | Batch_idx: 90 |  Loss: (0.1644) | Acc: (94.34%) (10989/11648)\n",
            "Epoch: 78 | Batch_idx: 100 |  Loss: (0.1634) | Acc: (94.39%) (12203/12928)\n",
            "Epoch: 78 | Batch_idx: 110 |  Loss: (0.1635) | Acc: (94.38%) (13409/14208)\n",
            "Epoch: 78 | Batch_idx: 120 |  Loss: (0.1665) | Acc: (94.25%) (14597/15488)\n",
            "Epoch: 78 | Batch_idx: 130 |  Loss: (0.1667) | Acc: (94.23%) (15800/16768)\n",
            "Epoch: 78 | Batch_idx: 140 |  Loss: (0.1663) | Acc: (94.25%) (17010/18048)\n",
            "Epoch: 78 | Batch_idx: 150 |  Loss: (0.1673) | Acc: (94.23%) (18212/19328)\n",
            "Epoch: 78 | Batch_idx: 160 |  Loss: (0.1692) | Acc: (94.18%) (19409/20608)\n",
            "Epoch: 78 | Batch_idx: 170 |  Loss: (0.1706) | Acc: (94.14%) (20606/21888)\n",
            "Epoch: 78 | Batch_idx: 180 |  Loss: (0.1705) | Acc: (94.15%) (21813/23168)\n",
            "Epoch: 78 | Batch_idx: 190 |  Loss: (0.1710) | Acc: (94.12%) (23010/24448)\n",
            "Epoch: 78 | Batch_idx: 200 |  Loss: (0.1716) | Acc: (94.09%) (24207/25728)\n",
            "Epoch: 78 | Batch_idx: 210 |  Loss: (0.1710) | Acc: (94.11%) (25418/27008)\n",
            "Epoch: 78 | Batch_idx: 220 |  Loss: (0.1720) | Acc: (94.05%) (26606/28288)\n",
            "Epoch: 78 | Batch_idx: 230 |  Loss: (0.1729) | Acc: (94.05%) (27809/29568)\n",
            "Epoch: 78 | Batch_idx: 240 |  Loss: (0.1731) | Acc: (94.05%) (29013/30848)\n",
            "Epoch: 78 | Batch_idx: 250 |  Loss: (0.1728) | Acc: (94.08%) (30225/32128)\n",
            "Epoch: 78 | Batch_idx: 260 |  Loss: (0.1731) | Acc: (94.07%) (31427/33408)\n",
            "Epoch: 78 | Batch_idx: 270 |  Loss: (0.1726) | Acc: (94.10%) (32640/34688)\n",
            "Epoch: 78 | Batch_idx: 280 |  Loss: (0.1732) | Acc: (94.08%) (33840/35968)\n",
            "Epoch: 78 | Batch_idx: 290 |  Loss: (0.1742) | Acc: (94.06%) (35034/37248)\n",
            "Epoch: 78 | Batch_idx: 300 |  Loss: (0.1748) | Acc: (94.02%) (36225/38528)\n",
            "Epoch: 78 | Batch_idx: 310 |  Loss: (0.1747) | Acc: (94.02%) (37427/39808)\n",
            "Epoch: 78 | Batch_idx: 320 |  Loss: (0.1759) | Acc: (94.00%) (38622/41088)\n",
            "Epoch: 78 | Batch_idx: 330 |  Loss: (0.1772) | Acc: (93.95%) (39806/42368)\n",
            "Epoch: 78 | Batch_idx: 340 |  Loss: (0.1781) | Acc: (93.93%) (41000/43648)\n",
            "Epoch: 78 | Batch_idx: 350 |  Loss: (0.1789) | Acc: (93.90%) (42186/44928)\n",
            "Epoch: 78 | Batch_idx: 360 |  Loss: (0.1795) | Acc: (93.87%) (43376/46208)\n",
            "Epoch: 78 | Batch_idx: 370 |  Loss: (0.1806) | Acc: (93.82%) (44551/47488)\n",
            "Epoch: 78 | Batch_idx: 380 |  Loss: (0.1812) | Acc: (93.79%) (45741/48768)\n",
            "Epoch: 78 | Batch_idx: 390 |  Loss: (0.1811) | Acc: (93.79%) (46895/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4443) | Acc: (87.07%) (8707/10000)\n",
            "Epoch: 79 | Batch_idx: 0 |  Loss: (0.1741) | Acc: (93.75%) (120/128)\n",
            "Epoch: 79 | Batch_idx: 10 |  Loss: (0.1549) | Acc: (94.67%) (1333/1408)\n",
            "Epoch: 79 | Batch_idx: 20 |  Loss: (0.1630) | Acc: (94.31%) (2535/2688)\n",
            "Epoch: 79 | Batch_idx: 30 |  Loss: (0.1720) | Acc: (93.95%) (3728/3968)\n",
            "Epoch: 79 | Batch_idx: 40 |  Loss: (0.1679) | Acc: (94.07%) (4937/5248)\n",
            "Epoch: 79 | Batch_idx: 50 |  Loss: (0.1650) | Acc: (94.18%) (6148/6528)\n",
            "Epoch: 79 | Batch_idx: 60 |  Loss: (0.1594) | Acc: (94.38%) (7369/7808)\n",
            "Epoch: 79 | Batch_idx: 70 |  Loss: (0.1630) | Acc: (94.30%) (8570/9088)\n",
            "Epoch: 79 | Batch_idx: 80 |  Loss: (0.1669) | Acc: (94.12%) (9758/10368)\n",
            "Epoch: 79 | Batch_idx: 90 |  Loss: (0.1689) | Acc: (94.01%) (10950/11648)\n",
            "Epoch: 79 | Batch_idx: 100 |  Loss: (0.1689) | Acc: (94.05%) (12159/12928)\n",
            "Epoch: 79 | Batch_idx: 110 |  Loss: (0.1691) | Acc: (94.02%) (13358/14208)\n",
            "Epoch: 79 | Batch_idx: 120 |  Loss: (0.1697) | Acc: (93.98%) (14556/15488)\n",
            "Epoch: 79 | Batch_idx: 130 |  Loss: (0.1705) | Acc: (93.91%) (15746/16768)\n",
            "Epoch: 79 | Batch_idx: 140 |  Loss: (0.1726) | Acc: (93.88%) (16944/18048)\n",
            "Epoch: 79 | Batch_idx: 150 |  Loss: (0.1732) | Acc: (93.94%) (18157/19328)\n",
            "Epoch: 79 | Batch_idx: 160 |  Loss: (0.1720) | Acc: (94.01%) (19374/20608)\n",
            "Epoch: 79 | Batch_idx: 170 |  Loss: (0.1742) | Acc: (93.99%) (20573/21888)\n",
            "Epoch: 79 | Batch_idx: 180 |  Loss: (0.1761) | Acc: (93.94%) (21764/23168)\n",
            "Epoch: 79 | Batch_idx: 190 |  Loss: (0.1757) | Acc: (93.95%) (22969/24448)\n",
            "Epoch: 79 | Batch_idx: 200 |  Loss: (0.1762) | Acc: (93.94%) (24169/25728)\n",
            "Epoch: 79 | Batch_idx: 210 |  Loss: (0.1785) | Acc: (93.89%) (25358/27008)\n",
            "Epoch: 79 | Batch_idx: 220 |  Loss: (0.1791) | Acc: (93.89%) (26560/28288)\n",
            "Epoch: 79 | Batch_idx: 230 |  Loss: (0.1776) | Acc: (93.97%) (27784/29568)\n",
            "Epoch: 79 | Batch_idx: 240 |  Loss: (0.1781) | Acc: (93.97%) (28989/30848)\n",
            "Epoch: 79 | Batch_idx: 250 |  Loss: (0.1781) | Acc: (93.96%) (30189/32128)\n",
            "Epoch: 79 | Batch_idx: 260 |  Loss: (0.1794) | Acc: (93.89%) (31367/33408)\n",
            "Epoch: 79 | Batch_idx: 270 |  Loss: (0.1807) | Acc: (93.86%) (32558/34688)\n",
            "Epoch: 79 | Batch_idx: 280 |  Loss: (0.1812) | Acc: (93.86%) (33761/35968)\n",
            "Epoch: 79 | Batch_idx: 290 |  Loss: (0.1813) | Acc: (93.86%) (34961/37248)\n",
            "Epoch: 79 | Batch_idx: 300 |  Loss: (0.1822) | Acc: (93.85%) (36159/38528)\n",
            "Epoch: 79 | Batch_idx: 310 |  Loss: (0.1813) | Acc: (93.87%) (37369/39808)\n",
            "Epoch: 79 | Batch_idx: 320 |  Loss: (0.1822) | Acc: (93.82%) (38548/41088)\n",
            "Epoch: 79 | Batch_idx: 330 |  Loss: (0.1823) | Acc: (93.81%) (39747/42368)\n",
            "Epoch: 79 | Batch_idx: 340 |  Loss: (0.1829) | Acc: (93.80%) (40942/43648)\n",
            "Epoch: 79 | Batch_idx: 350 |  Loss: (0.1836) | Acc: (93.78%) (42135/44928)\n",
            "Epoch: 79 | Batch_idx: 360 |  Loss: (0.1828) | Acc: (93.80%) (43345/46208)\n",
            "Epoch: 79 | Batch_idx: 370 |  Loss: (0.1831) | Acc: (93.80%) (44545/47488)\n",
            "Epoch: 79 | Batch_idx: 380 |  Loss: (0.1839) | Acc: (93.79%) (45738/48768)\n",
            "Epoch: 79 | Batch_idx: 390 |  Loss: (0.1843) | Acc: (93.75%) (46876/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3977) | Acc: (87.80%) (8780/10000)\n",
            "Epoch: 80 | Batch_idx: 0 |  Loss: (0.0991) | Acc: (96.09%) (123/128)\n",
            "Epoch: 80 | Batch_idx: 10 |  Loss: (0.1342) | Acc: (95.38%) (1343/1408)\n",
            "Epoch: 80 | Batch_idx: 20 |  Loss: (0.1365) | Acc: (95.31%) (2562/2688)\n",
            "Epoch: 80 | Batch_idx: 30 |  Loss: (0.1292) | Acc: (95.59%) (3793/3968)\n",
            "Epoch: 80 | Batch_idx: 40 |  Loss: (0.1288) | Acc: (95.60%) (5017/5248)\n",
            "Epoch: 80 | Batch_idx: 50 |  Loss: (0.1252) | Acc: (95.70%) (6247/6528)\n",
            "Epoch: 80 | Batch_idx: 60 |  Loss: (0.1270) | Acc: (95.66%) (7469/7808)\n",
            "Epoch: 80 | Batch_idx: 70 |  Loss: (0.1244) | Acc: (95.72%) (8699/9088)\n",
            "Epoch: 80 | Batch_idx: 80 |  Loss: (0.1237) | Acc: (95.75%) (9927/10368)\n",
            "Epoch: 80 | Batch_idx: 90 |  Loss: (0.1213) | Acc: (95.91%) (11172/11648)\n",
            "Epoch: 80 | Batch_idx: 100 |  Loss: (0.1195) | Acc: (96.02%) (12413/12928)\n",
            "Epoch: 80 | Batch_idx: 110 |  Loss: (0.1195) | Acc: (96.00%) (13639/14208)\n",
            "Epoch: 80 | Batch_idx: 120 |  Loss: (0.1171) | Acc: (96.09%) (14883/15488)\n",
            "Epoch: 80 | Batch_idx: 130 |  Loss: (0.1144) | Acc: (96.19%) (16129/16768)\n",
            "Epoch: 80 | Batch_idx: 140 |  Loss: (0.1123) | Acc: (96.24%) (17370/18048)\n",
            "Epoch: 80 | Batch_idx: 150 |  Loss: (0.1112) | Acc: (96.26%) (18605/19328)\n",
            "Epoch: 80 | Batch_idx: 160 |  Loss: (0.1113) | Acc: (96.26%) (19838/20608)\n",
            "Epoch: 80 | Batch_idx: 170 |  Loss: (0.1092) | Acc: (96.33%) (21084/21888)\n",
            "Epoch: 80 | Batch_idx: 180 |  Loss: (0.1080) | Acc: (96.37%) (22328/23168)\n",
            "Epoch: 80 | Batch_idx: 190 |  Loss: (0.1060) | Acc: (96.43%) (23576/24448)\n",
            "Epoch: 80 | Batch_idx: 200 |  Loss: (0.1059) | Acc: (96.44%) (24813/25728)\n",
            "Epoch: 80 | Batch_idx: 210 |  Loss: (0.1047) | Acc: (96.50%) (26062/27008)\n",
            "Epoch: 80 | Batch_idx: 220 |  Loss: (0.1037) | Acc: (96.51%) (27302/28288)\n",
            "Epoch: 80 | Batch_idx: 230 |  Loss: (0.1031) | Acc: (96.53%) (28542/29568)\n",
            "Epoch: 80 | Batch_idx: 240 |  Loss: (0.1023) | Acc: (96.54%) (29780/30848)\n",
            "Epoch: 80 | Batch_idx: 250 |  Loss: (0.1010) | Acc: (96.59%) (31032/32128)\n",
            "Epoch: 80 | Batch_idx: 260 |  Loss: (0.1004) | Acc: (96.62%) (32279/33408)\n",
            "Epoch: 80 | Batch_idx: 270 |  Loss: (0.0996) | Acc: (96.66%) (33531/34688)\n",
            "Epoch: 80 | Batch_idx: 280 |  Loss: (0.0995) | Acc: (96.66%) (34768/35968)\n",
            "Epoch: 80 | Batch_idx: 290 |  Loss: (0.0987) | Acc: (96.69%) (36016/37248)\n",
            "Epoch: 80 | Batch_idx: 300 |  Loss: (0.0980) | Acc: (96.71%) (37261/38528)\n",
            "Epoch: 80 | Batch_idx: 310 |  Loss: (0.0974) | Acc: (96.73%) (38505/39808)\n",
            "Epoch: 80 | Batch_idx: 320 |  Loss: (0.0967) | Acc: (96.76%) (39757/41088)\n",
            "Epoch: 80 | Batch_idx: 330 |  Loss: (0.0961) | Acc: (96.76%) (40997/42368)\n",
            "Epoch: 80 | Batch_idx: 340 |  Loss: (0.0959) | Acc: (96.76%) (42234/43648)\n",
            "Epoch: 80 | Batch_idx: 350 |  Loss: (0.0953) | Acc: (96.79%) (43484/44928)\n",
            "Epoch: 80 | Batch_idx: 360 |  Loss: (0.0943) | Acc: (96.83%) (44741/46208)\n",
            "Epoch: 80 | Batch_idx: 370 |  Loss: (0.0942) | Acc: (96.83%) (45984/47488)\n",
            "Epoch: 80 | Batch_idx: 380 |  Loss: (0.0934) | Acc: (96.85%) (47232/48768)\n",
            "Epoch: 80 | Batch_idx: 390 |  Loss: (0.0931) | Acc: (96.84%) (48422/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3252) | Acc: (90.90%) (9090/10000)\n",
            "Epoch: 81 | Batch_idx: 0 |  Loss: (0.0300) | Acc: (100.00%) (128/128)\n",
            "Epoch: 81 | Batch_idx: 10 |  Loss: (0.0575) | Acc: (98.51%) (1387/1408)\n",
            "Epoch: 81 | Batch_idx: 20 |  Loss: (0.0577) | Acc: (98.03%) (2635/2688)\n",
            "Epoch: 81 | Batch_idx: 30 |  Loss: (0.0633) | Acc: (97.91%) (3885/3968)\n",
            "Epoch: 81 | Batch_idx: 40 |  Loss: (0.0634) | Acc: (97.92%) (5139/5248)\n",
            "Epoch: 81 | Batch_idx: 50 |  Loss: (0.0669) | Acc: (97.78%) (6383/6528)\n",
            "Epoch: 81 | Batch_idx: 60 |  Loss: (0.0681) | Acc: (97.75%) (7632/7808)\n",
            "Epoch: 81 | Batch_idx: 70 |  Loss: (0.0680) | Acc: (97.69%) (8878/9088)\n",
            "Epoch: 81 | Batch_idx: 80 |  Loss: (0.0701) | Acc: (97.60%) (10119/10368)\n",
            "Epoch: 81 | Batch_idx: 90 |  Loss: (0.0711) | Acc: (97.59%) (11367/11648)\n",
            "Epoch: 81 | Batch_idx: 100 |  Loss: (0.0696) | Acc: (97.60%) (12618/12928)\n",
            "Epoch: 81 | Batch_idx: 110 |  Loss: (0.0690) | Acc: (97.65%) (13874/14208)\n",
            "Epoch: 81 | Batch_idx: 120 |  Loss: (0.0699) | Acc: (97.62%) (15119/15488)\n",
            "Epoch: 81 | Batch_idx: 130 |  Loss: (0.0687) | Acc: (97.67%) (16377/16768)\n",
            "Epoch: 81 | Batch_idx: 140 |  Loss: (0.0687) | Acc: (97.69%) (17631/18048)\n",
            "Epoch: 81 | Batch_idx: 150 |  Loss: (0.0695) | Acc: (97.69%) (18881/19328)\n",
            "Epoch: 81 | Batch_idx: 160 |  Loss: (0.0685) | Acc: (97.70%) (20133/20608)\n",
            "Epoch: 81 | Batch_idx: 170 |  Loss: (0.0688) | Acc: (97.69%) (21382/21888)\n",
            "Epoch: 81 | Batch_idx: 180 |  Loss: (0.0681) | Acc: (97.72%) (22639/23168)\n",
            "Epoch: 81 | Batch_idx: 190 |  Loss: (0.0691) | Acc: (97.69%) (23884/24448)\n",
            "Epoch: 81 | Batch_idx: 200 |  Loss: (0.0686) | Acc: (97.69%) (25133/25728)\n",
            "Epoch: 81 | Batch_idx: 210 |  Loss: (0.0688) | Acc: (97.66%) (26376/27008)\n",
            "Epoch: 81 | Batch_idx: 220 |  Loss: (0.0683) | Acc: (97.68%) (27631/28288)\n",
            "Epoch: 81 | Batch_idx: 230 |  Loss: (0.0686) | Acc: (97.66%) (28876/29568)\n",
            "Epoch: 81 | Batch_idx: 240 |  Loss: (0.0687) | Acc: (97.66%) (30126/30848)\n",
            "Epoch: 81 | Batch_idx: 250 |  Loss: (0.0680) | Acc: (97.69%) (31386/32128)\n",
            "Epoch: 81 | Batch_idx: 260 |  Loss: (0.0671) | Acc: (97.70%) (32641/33408)\n",
            "Epoch: 81 | Batch_idx: 270 |  Loss: (0.0671) | Acc: (97.70%) (33889/34688)\n",
            "Epoch: 81 | Batch_idx: 280 |  Loss: (0.0669) | Acc: (97.70%) (35142/35968)\n",
            "Epoch: 81 | Batch_idx: 290 |  Loss: (0.0667) | Acc: (97.72%) (36398/37248)\n",
            "Epoch: 81 | Batch_idx: 300 |  Loss: (0.0662) | Acc: (97.75%) (37663/38528)\n",
            "Epoch: 81 | Batch_idx: 310 |  Loss: (0.0661) | Acc: (97.74%) (38908/39808)\n",
            "Epoch: 81 | Batch_idx: 320 |  Loss: (0.0659) | Acc: (97.76%) (40166/41088)\n",
            "Epoch: 81 | Batch_idx: 330 |  Loss: (0.0658) | Acc: (97.76%) (41418/42368)\n",
            "Epoch: 81 | Batch_idx: 340 |  Loss: (0.0657) | Acc: (97.76%) (42670/43648)\n",
            "Epoch: 81 | Batch_idx: 350 |  Loss: (0.0653) | Acc: (97.77%) (43926/44928)\n",
            "Epoch: 81 | Batch_idx: 360 |  Loss: (0.0649) | Acc: (97.78%) (45184/46208)\n",
            "Epoch: 81 | Batch_idx: 370 |  Loss: (0.0647) | Acc: (97.79%) (46438/47488)\n",
            "Epoch: 81 | Batch_idx: 380 |  Loss: (0.0643) | Acc: (97.80%) (47694/48768)\n",
            "Epoch: 81 | Batch_idx: 390 |  Loss: (0.0644) | Acc: (97.80%) (48901/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3386) | Acc: (90.92%) (9092/10000)\n",
            "Epoch: 82 | Batch_idx: 0 |  Loss: (0.0324) | Acc: (98.44%) (126/128)\n",
            "Epoch: 82 | Batch_idx: 10 |  Loss: (0.0343) | Acc: (98.58%) (1388/1408)\n",
            "Epoch: 82 | Batch_idx: 20 |  Loss: (0.0447) | Acc: (98.51%) (2648/2688)\n",
            "Epoch: 82 | Batch_idx: 30 |  Loss: (0.0476) | Acc: (98.44%) (3906/3968)\n",
            "Epoch: 82 | Batch_idx: 40 |  Loss: (0.0479) | Acc: (98.42%) (5165/5248)\n",
            "Epoch: 82 | Batch_idx: 50 |  Loss: (0.0490) | Acc: (98.41%) (6424/6528)\n",
            "Epoch: 82 | Batch_idx: 60 |  Loss: (0.0473) | Acc: (98.46%) (7688/7808)\n",
            "Epoch: 82 | Batch_idx: 70 |  Loss: (0.0497) | Acc: (98.40%) (8943/9088)\n",
            "Epoch: 82 | Batch_idx: 80 |  Loss: (0.0484) | Acc: (98.40%) (10202/10368)\n",
            "Epoch: 82 | Batch_idx: 90 |  Loss: (0.0495) | Acc: (98.39%) (11460/11648)\n",
            "Epoch: 82 | Batch_idx: 100 |  Loss: (0.0504) | Acc: (98.36%) (12716/12928)\n",
            "Epoch: 82 | Batch_idx: 110 |  Loss: (0.0504) | Acc: (98.37%) (13977/14208)\n",
            "Epoch: 82 | Batch_idx: 120 |  Loss: (0.0500) | Acc: (98.35%) (15233/15488)\n",
            "Epoch: 82 | Batch_idx: 130 |  Loss: (0.0497) | Acc: (98.35%) (16492/16768)\n",
            "Epoch: 82 | Batch_idx: 140 |  Loss: (0.0499) | Acc: (98.30%) (17742/18048)\n",
            "Epoch: 82 | Batch_idx: 150 |  Loss: (0.0498) | Acc: (98.30%) (18999/19328)\n",
            "Epoch: 82 | Batch_idx: 160 |  Loss: (0.0495) | Acc: (98.32%) (20262/20608)\n",
            "Epoch: 82 | Batch_idx: 170 |  Loss: (0.0499) | Acc: (98.33%) (21522/21888)\n",
            "Epoch: 82 | Batch_idx: 180 |  Loss: (0.0498) | Acc: (98.33%) (22782/23168)\n",
            "Epoch: 82 | Batch_idx: 190 |  Loss: (0.0503) | Acc: (98.30%) (24033/24448)\n",
            "Epoch: 82 | Batch_idx: 200 |  Loss: (0.0507) | Acc: (98.30%) (25290/25728)\n",
            "Epoch: 82 | Batch_idx: 210 |  Loss: (0.0510) | Acc: (98.28%) (26543/27008)\n",
            "Epoch: 82 | Batch_idx: 220 |  Loss: (0.0519) | Acc: (98.26%) (27795/28288)\n",
            "Epoch: 82 | Batch_idx: 230 |  Loss: (0.0520) | Acc: (98.26%) (29054/29568)\n",
            "Epoch: 82 | Batch_idx: 240 |  Loss: (0.0530) | Acc: (98.24%) (30305/30848)\n",
            "Epoch: 82 | Batch_idx: 250 |  Loss: (0.0536) | Acc: (98.22%) (31555/32128)\n",
            "Epoch: 82 | Batch_idx: 260 |  Loss: (0.0536) | Acc: (98.22%) (32813/33408)\n",
            "Epoch: 82 | Batch_idx: 270 |  Loss: (0.0536) | Acc: (98.22%) (34069/34688)\n",
            "Epoch: 82 | Batch_idx: 280 |  Loss: (0.0528) | Acc: (98.24%) (35335/35968)\n",
            "Epoch: 82 | Batch_idx: 290 |  Loss: (0.0530) | Acc: (98.24%) (36593/37248)\n",
            "Epoch: 82 | Batch_idx: 300 |  Loss: (0.0531) | Acc: (98.22%) (37844/38528)\n",
            "Epoch: 82 | Batch_idx: 310 |  Loss: (0.0531) | Acc: (98.23%) (39105/39808)\n",
            "Epoch: 82 | Batch_idx: 320 |  Loss: (0.0531) | Acc: (98.24%) (40364/41088)\n",
            "Epoch: 82 | Batch_idx: 330 |  Loss: (0.0532) | Acc: (98.24%) (41621/42368)\n",
            "Epoch: 82 | Batch_idx: 340 |  Loss: (0.0531) | Acc: (98.24%) (42880/43648)\n",
            "Epoch: 82 | Batch_idx: 350 |  Loss: (0.0531) | Acc: (98.24%) (44137/44928)\n",
            "Epoch: 82 | Batch_idx: 360 |  Loss: (0.0534) | Acc: (98.21%) (45382/46208)\n",
            "Epoch: 82 | Batch_idx: 370 |  Loss: (0.0531) | Acc: (98.22%) (46643/47488)\n",
            "Epoch: 82 | Batch_idx: 380 |  Loss: (0.0530) | Acc: (98.22%) (47901/48768)\n",
            "Epoch: 82 | Batch_idx: 390 |  Loss: (0.0533) | Acc: (98.20%) (49102/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3354) | Acc: (91.22%) (9122/10000)\n",
            "Epoch: 83 | Batch_idx: 0 |  Loss: (0.0296) | Acc: (99.22%) (127/128)\n",
            "Epoch: 83 | Batch_idx: 10 |  Loss: (0.0558) | Acc: (97.80%) (1377/1408)\n",
            "Epoch: 83 | Batch_idx: 20 |  Loss: (0.0504) | Acc: (98.33%) (2643/2688)\n",
            "Epoch: 83 | Batch_idx: 30 |  Loss: (0.0473) | Acc: (98.49%) (3908/3968)\n",
            "Epoch: 83 | Batch_idx: 40 |  Loss: (0.0473) | Acc: (98.48%) (5168/5248)\n",
            "Epoch: 83 | Batch_idx: 50 |  Loss: (0.0458) | Acc: (98.47%) (6428/6528)\n",
            "Epoch: 83 | Batch_idx: 60 |  Loss: (0.0465) | Acc: (98.48%) (7689/7808)\n",
            "Epoch: 83 | Batch_idx: 70 |  Loss: (0.0459) | Acc: (98.48%) (8950/9088)\n",
            "Epoch: 83 | Batch_idx: 80 |  Loss: (0.0470) | Acc: (98.43%) (10205/10368)\n",
            "Epoch: 83 | Batch_idx: 90 |  Loss: (0.0478) | Acc: (98.40%) (11462/11648)\n",
            "Epoch: 83 | Batch_idx: 100 |  Loss: (0.0481) | Acc: (98.40%) (12721/12928)\n",
            "Epoch: 83 | Batch_idx: 110 |  Loss: (0.0468) | Acc: (98.44%) (13986/14208)\n",
            "Epoch: 83 | Batch_idx: 120 |  Loss: (0.0463) | Acc: (98.46%) (15250/15488)\n",
            "Epoch: 83 | Batch_idx: 130 |  Loss: (0.0466) | Acc: (98.46%) (16509/16768)\n",
            "Epoch: 83 | Batch_idx: 140 |  Loss: (0.0460) | Acc: (98.47%) (17772/18048)\n",
            "Epoch: 83 | Batch_idx: 150 |  Loss: (0.0464) | Acc: (98.46%) (19031/19328)\n",
            "Epoch: 83 | Batch_idx: 160 |  Loss: (0.0456) | Acc: (98.50%) (20298/20608)\n",
            "Epoch: 83 | Batch_idx: 170 |  Loss: (0.0459) | Acc: (98.49%) (21557/21888)\n",
            "Epoch: 83 | Batch_idx: 180 |  Loss: (0.0456) | Acc: (98.50%) (22821/23168)\n",
            "Epoch: 83 | Batch_idx: 190 |  Loss: (0.0454) | Acc: (98.50%) (24082/24448)\n",
            "Epoch: 83 | Batch_idx: 200 |  Loss: (0.0452) | Acc: (98.52%) (25346/25728)\n",
            "Epoch: 83 | Batch_idx: 210 |  Loss: (0.0446) | Acc: (98.53%) (26612/27008)\n",
            "Epoch: 83 | Batch_idx: 220 |  Loss: (0.0444) | Acc: (98.55%) (27878/28288)\n",
            "Epoch: 83 | Batch_idx: 230 |  Loss: (0.0447) | Acc: (98.52%) (29131/29568)\n",
            "Epoch: 83 | Batch_idx: 240 |  Loss: (0.0449) | Acc: (98.51%) (30389/30848)\n",
            "Epoch: 83 | Batch_idx: 250 |  Loss: (0.0450) | Acc: (98.51%) (31648/32128)\n",
            "Epoch: 83 | Batch_idx: 260 |  Loss: (0.0447) | Acc: (98.51%) (32910/33408)\n",
            "Epoch: 83 | Batch_idx: 270 |  Loss: (0.0450) | Acc: (98.50%) (34169/34688)\n",
            "Epoch: 83 | Batch_idx: 280 |  Loss: (0.0453) | Acc: (98.49%) (35426/35968)\n",
            "Epoch: 83 | Batch_idx: 290 |  Loss: (0.0456) | Acc: (98.47%) (36679/37248)\n",
            "Epoch: 83 | Batch_idx: 300 |  Loss: (0.0454) | Acc: (98.47%) (37937/38528)\n",
            "Epoch: 83 | Batch_idx: 310 |  Loss: (0.0454) | Acc: (98.47%) (39199/39808)\n",
            "Epoch: 83 | Batch_idx: 320 |  Loss: (0.0455) | Acc: (98.46%) (40457/41088)\n",
            "Epoch: 83 | Batch_idx: 330 |  Loss: (0.0455) | Acc: (98.46%) (41716/42368)\n",
            "Epoch: 83 | Batch_idx: 340 |  Loss: (0.0458) | Acc: (98.45%) (42970/43648)\n",
            "Epoch: 83 | Batch_idx: 350 |  Loss: (0.0458) | Acc: (98.44%) (44228/44928)\n",
            "Epoch: 83 | Batch_idx: 360 |  Loss: (0.0457) | Acc: (98.45%) (45491/46208)\n",
            "Epoch: 83 | Batch_idx: 370 |  Loss: (0.0456) | Acc: (98.45%) (46750/47488)\n",
            "Epoch: 83 | Batch_idx: 380 |  Loss: (0.0456) | Acc: (98.44%) (48007/48768)\n",
            "Epoch: 83 | Batch_idx: 390 |  Loss: (0.0459) | Acc: (98.44%) (49218/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3478) | Acc: (91.08%) (9108/10000)\n",
            "Epoch: 84 | Batch_idx: 0 |  Loss: (0.1110) | Acc: (96.09%) (123/128)\n",
            "Epoch: 84 | Batch_idx: 10 |  Loss: (0.0615) | Acc: (98.15%) (1382/1408)\n",
            "Epoch: 84 | Batch_idx: 20 |  Loss: (0.0539) | Acc: (98.29%) (2642/2688)\n",
            "Epoch: 84 | Batch_idx: 30 |  Loss: (0.0476) | Acc: (98.49%) (3908/3968)\n",
            "Epoch: 84 | Batch_idx: 40 |  Loss: (0.0449) | Acc: (98.59%) (5174/5248)\n",
            "Epoch: 84 | Batch_idx: 50 |  Loss: (0.0464) | Acc: (98.51%) (6431/6528)\n",
            "Epoch: 84 | Batch_idx: 60 |  Loss: (0.0449) | Acc: (98.48%) (7689/7808)\n",
            "Epoch: 84 | Batch_idx: 70 |  Loss: (0.0425) | Acc: (98.61%) (8962/9088)\n",
            "Epoch: 84 | Batch_idx: 80 |  Loss: (0.0419) | Acc: (98.59%) (10222/10368)\n",
            "Epoch: 84 | Batch_idx: 90 |  Loss: (0.0421) | Acc: (98.57%) (11482/11648)\n",
            "Epoch: 84 | Batch_idx: 100 |  Loss: (0.0409) | Acc: (98.62%) (12750/12928)\n",
            "Epoch: 84 | Batch_idx: 110 |  Loss: (0.0404) | Acc: (98.64%) (14015/14208)\n",
            "Epoch: 84 | Batch_idx: 120 |  Loss: (0.0399) | Acc: (98.65%) (15279/15488)\n",
            "Epoch: 84 | Batch_idx: 130 |  Loss: (0.0410) | Acc: (98.62%) (16536/16768)\n",
            "Epoch: 84 | Batch_idx: 140 |  Loss: (0.0406) | Acc: (98.63%) (17800/18048)\n",
            "Epoch: 84 | Batch_idx: 150 |  Loss: (0.0406) | Acc: (98.64%) (19065/19328)\n",
            "Epoch: 84 | Batch_idx: 160 |  Loss: (0.0410) | Acc: (98.64%) (20328/20608)\n",
            "Epoch: 84 | Batch_idx: 170 |  Loss: (0.0408) | Acc: (98.64%) (21590/21888)\n",
            "Epoch: 84 | Batch_idx: 180 |  Loss: (0.0408) | Acc: (98.64%) (22852/23168)\n",
            "Epoch: 84 | Batch_idx: 190 |  Loss: (0.0405) | Acc: (98.65%) (24117/24448)\n",
            "Epoch: 84 | Batch_idx: 200 |  Loss: (0.0406) | Acc: (98.61%) (25371/25728)\n",
            "Epoch: 84 | Batch_idx: 210 |  Loss: (0.0404) | Acc: (98.60%) (26629/27008)\n",
            "Epoch: 84 | Batch_idx: 220 |  Loss: (0.0402) | Acc: (98.60%) (27891/28288)\n",
            "Epoch: 84 | Batch_idx: 230 |  Loss: (0.0401) | Acc: (98.60%) (29155/29568)\n",
            "Epoch: 84 | Batch_idx: 240 |  Loss: (0.0405) | Acc: (98.58%) (30410/30848)\n",
            "Epoch: 84 | Batch_idx: 250 |  Loss: (0.0416) | Acc: (98.54%) (31660/32128)\n",
            "Epoch: 84 | Batch_idx: 260 |  Loss: (0.0417) | Acc: (98.55%) (32922/33408)\n",
            "Epoch: 84 | Batch_idx: 270 |  Loss: (0.0424) | Acc: (98.51%) (34171/34688)\n",
            "Epoch: 84 | Batch_idx: 280 |  Loss: (0.0430) | Acc: (98.50%) (35428/35968)\n",
            "Epoch: 84 | Batch_idx: 290 |  Loss: (0.0431) | Acc: (98.50%) (36689/37248)\n",
            "Epoch: 84 | Batch_idx: 300 |  Loss: (0.0429) | Acc: (98.50%) (37952/38528)\n",
            "Epoch: 84 | Batch_idx: 310 |  Loss: (0.0429) | Acc: (98.52%) (39218/39808)\n",
            "Epoch: 84 | Batch_idx: 320 |  Loss: (0.0424) | Acc: (98.54%) (40489/41088)\n",
            "Epoch: 84 | Batch_idx: 330 |  Loss: (0.0424) | Acc: (98.54%) (41748/42368)\n",
            "Epoch: 84 | Batch_idx: 340 |  Loss: (0.0426) | Acc: (98.54%) (43009/43648)\n",
            "Epoch: 84 | Batch_idx: 350 |  Loss: (0.0423) | Acc: (98.55%) (44275/44928)\n",
            "Epoch: 84 | Batch_idx: 360 |  Loss: (0.0421) | Acc: (98.55%) (45539/46208)\n",
            "Epoch: 84 | Batch_idx: 370 |  Loss: (0.0419) | Acc: (98.57%) (46807/47488)\n",
            "Epoch: 84 | Batch_idx: 380 |  Loss: (0.0416) | Acc: (98.57%) (48072/48768)\n",
            "Epoch: 84 | Batch_idx: 390 |  Loss: (0.0421) | Acc: (98.56%) (49278/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3559) | Acc: (91.05%) (9105/10000)\n",
            "Epoch: 85 | Batch_idx: 0 |  Loss: (0.0205) | Acc: (99.22%) (127/128)\n",
            "Epoch: 85 | Batch_idx: 10 |  Loss: (0.0386) | Acc: (98.22%) (1383/1408)\n",
            "Epoch: 85 | Batch_idx: 20 |  Loss: (0.0328) | Acc: (98.59%) (2650/2688)\n",
            "Epoch: 85 | Batch_idx: 30 |  Loss: (0.0353) | Acc: (98.64%) (3914/3968)\n",
            "Epoch: 85 | Batch_idx: 40 |  Loss: (0.0347) | Acc: (98.69%) (5179/5248)\n",
            "Epoch: 85 | Batch_idx: 50 |  Loss: (0.0345) | Acc: (98.70%) (6443/6528)\n",
            "Epoch: 85 | Batch_idx: 60 |  Loss: (0.0347) | Acc: (98.72%) (7708/7808)\n",
            "Epoch: 85 | Batch_idx: 70 |  Loss: (0.0360) | Acc: (98.70%) (8970/9088)\n",
            "Epoch: 85 | Batch_idx: 80 |  Loss: (0.0363) | Acc: (98.70%) (10233/10368)\n",
            "Epoch: 85 | Batch_idx: 90 |  Loss: (0.0359) | Acc: (98.68%) (11494/11648)\n",
            "Epoch: 85 | Batch_idx: 100 |  Loss: (0.0375) | Acc: (98.65%) (12753/12928)\n",
            "Epoch: 85 | Batch_idx: 110 |  Loss: (0.0379) | Acc: (98.61%) (14011/14208)\n",
            "Epoch: 85 | Batch_idx: 120 |  Loss: (0.0373) | Acc: (98.64%) (15278/15488)\n",
            "Epoch: 85 | Batch_idx: 130 |  Loss: (0.0375) | Acc: (98.65%) (16541/16768)\n",
            "Epoch: 85 | Batch_idx: 140 |  Loss: (0.0377) | Acc: (98.64%) (17802/18048)\n",
            "Epoch: 85 | Batch_idx: 150 |  Loss: (0.0386) | Acc: (98.62%) (19061/19328)\n",
            "Epoch: 85 | Batch_idx: 160 |  Loss: (0.0390) | Acc: (98.61%) (20322/20608)\n",
            "Epoch: 85 | Batch_idx: 170 |  Loss: (0.0387) | Acc: (98.64%) (21590/21888)\n",
            "Epoch: 85 | Batch_idx: 180 |  Loss: (0.0395) | Acc: (98.62%) (22848/23168)\n",
            "Epoch: 85 | Batch_idx: 190 |  Loss: (0.0395) | Acc: (98.62%) (24110/24448)\n",
            "Epoch: 85 | Batch_idx: 200 |  Loss: (0.0398) | Acc: (98.61%) (25370/25728)\n",
            "Epoch: 85 | Batch_idx: 210 |  Loss: (0.0396) | Acc: (98.60%) (26629/27008)\n",
            "Epoch: 85 | Batch_idx: 220 |  Loss: (0.0395) | Acc: (98.61%) (27896/28288)\n",
            "Epoch: 85 | Batch_idx: 230 |  Loss: (0.0395) | Acc: (98.62%) (29159/29568)\n",
            "Epoch: 85 | Batch_idx: 240 |  Loss: (0.0397) | Acc: (98.60%) (30417/30848)\n",
            "Epoch: 85 | Batch_idx: 250 |  Loss: (0.0395) | Acc: (98.61%) (31682/32128)\n",
            "Epoch: 85 | Batch_idx: 260 |  Loss: (0.0394) | Acc: (98.62%) (32947/33408)\n",
            "Epoch: 85 | Batch_idx: 270 |  Loss: (0.0395) | Acc: (98.61%) (34207/34688)\n",
            "Epoch: 85 | Batch_idx: 280 |  Loss: (0.0390) | Acc: (98.63%) (35475/35968)\n",
            "Epoch: 85 | Batch_idx: 290 |  Loss: (0.0391) | Acc: (98.62%) (36735/37248)\n",
            "Epoch: 85 | Batch_idx: 300 |  Loss: (0.0389) | Acc: (98.62%) (37998/38528)\n",
            "Epoch: 85 | Batch_idx: 310 |  Loss: (0.0387) | Acc: (98.62%) (39260/39808)\n",
            "Epoch: 85 | Batch_idx: 320 |  Loss: (0.0385) | Acc: (98.62%) (40523/41088)\n",
            "Epoch: 85 | Batch_idx: 330 |  Loss: (0.0384) | Acc: (98.63%) (41787/42368)\n",
            "Epoch: 85 | Batch_idx: 340 |  Loss: (0.0382) | Acc: (98.63%) (43050/43648)\n",
            "Epoch: 85 | Batch_idx: 350 |  Loss: (0.0383) | Acc: (98.62%) (44309/44928)\n",
            "Epoch: 85 | Batch_idx: 360 |  Loss: (0.0383) | Acc: (98.63%) (45573/46208)\n",
            "Epoch: 85 | Batch_idx: 370 |  Loss: (0.0385) | Acc: (98.63%) (46837/47488)\n",
            "Epoch: 85 | Batch_idx: 380 |  Loss: (0.0387) | Acc: (98.63%) (48102/48768)\n",
            "Epoch: 85 | Batch_idx: 390 |  Loss: (0.0386) | Acc: (98.64%) (49320/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3527) | Acc: (91.11%) (9111/10000)\n",
            "Epoch: 86 | Batch_idx: 0 |  Loss: (0.0134) | Acc: (100.00%) (128/128)\n",
            "Epoch: 86 | Batch_idx: 10 |  Loss: (0.0217) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 86 | Batch_idx: 20 |  Loss: (0.0258) | Acc: (99.26%) (2668/2688)\n",
            "Epoch: 86 | Batch_idx: 30 |  Loss: (0.0278) | Acc: (99.14%) (3934/3968)\n",
            "Epoch: 86 | Batch_idx: 40 |  Loss: (0.0296) | Acc: (99.01%) (5196/5248)\n",
            "Epoch: 86 | Batch_idx: 50 |  Loss: (0.0324) | Acc: (98.94%) (6459/6528)\n",
            "Epoch: 86 | Batch_idx: 60 |  Loss: (0.0318) | Acc: (98.91%) (7723/7808)\n",
            "Epoch: 86 | Batch_idx: 70 |  Loss: (0.0314) | Acc: (98.90%) (8988/9088)\n",
            "Epoch: 86 | Batch_idx: 80 |  Loss: (0.0326) | Acc: (98.84%) (10248/10368)\n",
            "Epoch: 86 | Batch_idx: 90 |  Loss: (0.0310) | Acc: (98.88%) (11517/11648)\n",
            "Epoch: 86 | Batch_idx: 100 |  Loss: (0.0312) | Acc: (98.89%) (12784/12928)\n",
            "Epoch: 86 | Batch_idx: 110 |  Loss: (0.0311) | Acc: (98.88%) (14049/14208)\n",
            "Epoch: 86 | Batch_idx: 120 |  Loss: (0.0308) | Acc: (98.89%) (15316/15488)\n",
            "Epoch: 86 | Batch_idx: 130 |  Loss: (0.0313) | Acc: (98.87%) (16579/16768)\n",
            "Epoch: 86 | Batch_idx: 140 |  Loss: (0.0324) | Acc: (98.81%) (17834/18048)\n",
            "Epoch: 86 | Batch_idx: 150 |  Loss: (0.0315) | Acc: (98.85%) (19106/19328)\n",
            "Epoch: 86 | Batch_idx: 160 |  Loss: (0.0317) | Acc: (98.85%) (20370/20608)\n",
            "Epoch: 86 | Batch_idx: 170 |  Loss: (0.0324) | Acc: (98.83%) (21631/21888)\n",
            "Epoch: 86 | Batch_idx: 180 |  Loss: (0.0325) | Acc: (98.83%) (22897/23168)\n",
            "Epoch: 86 | Batch_idx: 190 |  Loss: (0.0331) | Acc: (98.83%) (24162/24448)\n",
            "Epoch: 86 | Batch_idx: 200 |  Loss: (0.0329) | Acc: (98.83%) (25427/25728)\n",
            "Epoch: 86 | Batch_idx: 210 |  Loss: (0.0332) | Acc: (98.83%) (26693/27008)\n",
            "Epoch: 86 | Batch_idx: 220 |  Loss: (0.0337) | Acc: (98.81%) (27951/28288)\n",
            "Epoch: 86 | Batch_idx: 230 |  Loss: (0.0333) | Acc: (98.83%) (29221/29568)\n",
            "Epoch: 86 | Batch_idx: 240 |  Loss: (0.0338) | Acc: (98.81%) (30481/30848)\n",
            "Epoch: 86 | Batch_idx: 250 |  Loss: (0.0334) | Acc: (98.82%) (31750/32128)\n",
            "Epoch: 86 | Batch_idx: 260 |  Loss: (0.0340) | Acc: (98.81%) (33010/33408)\n",
            "Epoch: 86 | Batch_idx: 270 |  Loss: (0.0345) | Acc: (98.78%) (34265/34688)\n",
            "Epoch: 86 | Batch_idx: 280 |  Loss: (0.0347) | Acc: (98.78%) (35530/35968)\n",
            "Epoch: 86 | Batch_idx: 290 |  Loss: (0.0347) | Acc: (98.79%) (36797/37248)\n",
            "Epoch: 86 | Batch_idx: 300 |  Loss: (0.0346) | Acc: (98.79%) (38063/38528)\n",
            "Epoch: 86 | Batch_idx: 310 |  Loss: (0.0345) | Acc: (98.79%) (39328/39808)\n",
            "Epoch: 86 | Batch_idx: 320 |  Loss: (0.0348) | Acc: (98.79%) (40592/41088)\n",
            "Epoch: 86 | Batch_idx: 330 |  Loss: (0.0347) | Acc: (98.79%) (41855/42368)\n",
            "Epoch: 86 | Batch_idx: 340 |  Loss: (0.0346) | Acc: (98.79%) (43121/43648)\n",
            "Epoch: 86 | Batch_idx: 350 |  Loss: (0.0348) | Acc: (98.79%) (44386/44928)\n",
            "Epoch: 86 | Batch_idx: 360 |  Loss: (0.0350) | Acc: (98.79%) (45649/46208)\n",
            "Epoch: 86 | Batch_idx: 370 |  Loss: (0.0351) | Acc: (98.77%) (46906/47488)\n",
            "Epoch: 86 | Batch_idx: 380 |  Loss: (0.0353) | Acc: (98.77%) (48167/48768)\n",
            "Epoch: 86 | Batch_idx: 390 |  Loss: (0.0351) | Acc: (98.76%) (49380/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3604) | Acc: (91.36%) (9136/10000)\n",
            "Epoch: 87 | Batch_idx: 0 |  Loss: (0.0041) | Acc: (100.00%) (128/128)\n",
            "Epoch: 87 | Batch_idx: 10 |  Loss: (0.0231) | Acc: (99.22%) (1397/1408)\n",
            "Epoch: 87 | Batch_idx: 20 |  Loss: (0.0231) | Acc: (99.22%) (2667/2688)\n",
            "Epoch: 87 | Batch_idx: 30 |  Loss: (0.0236) | Acc: (99.19%) (3936/3968)\n",
            "Epoch: 87 | Batch_idx: 40 |  Loss: (0.0237) | Acc: (99.16%) (5204/5248)\n",
            "Epoch: 87 | Batch_idx: 50 |  Loss: (0.0229) | Acc: (99.19%) (6475/6528)\n",
            "Epoch: 87 | Batch_idx: 60 |  Loss: (0.0238) | Acc: (99.15%) (7742/7808)\n",
            "Epoch: 87 | Batch_idx: 70 |  Loss: (0.0237) | Acc: (99.15%) (9011/9088)\n",
            "Epoch: 87 | Batch_idx: 80 |  Loss: (0.0229) | Acc: (99.21%) (10286/10368)\n",
            "Epoch: 87 | Batch_idx: 90 |  Loss: (0.0242) | Acc: (99.18%) (11552/11648)\n",
            "Epoch: 87 | Batch_idx: 100 |  Loss: (0.0263) | Acc: (99.08%) (12809/12928)\n",
            "Epoch: 87 | Batch_idx: 110 |  Loss: (0.0261) | Acc: (99.09%) (14078/14208)\n",
            "Epoch: 87 | Batch_idx: 120 |  Loss: (0.0262) | Acc: (99.08%) (15346/15488)\n",
            "Epoch: 87 | Batch_idx: 130 |  Loss: (0.0260) | Acc: (99.08%) (16614/16768)\n",
            "Epoch: 87 | Batch_idx: 140 |  Loss: (0.0278) | Acc: (99.02%) (17871/18048)\n",
            "Epoch: 87 | Batch_idx: 150 |  Loss: (0.0276) | Acc: (99.02%) (19139/19328)\n",
            "Epoch: 87 | Batch_idx: 160 |  Loss: (0.0276) | Acc: (99.02%) (20407/20608)\n",
            "Epoch: 87 | Batch_idx: 170 |  Loss: (0.0277) | Acc: (99.04%) (21678/21888)\n",
            "Epoch: 87 | Batch_idx: 180 |  Loss: (0.0277) | Acc: (99.04%) (22946/23168)\n",
            "Epoch: 87 | Batch_idx: 190 |  Loss: (0.0283) | Acc: (99.03%) (24212/24448)\n",
            "Epoch: 87 | Batch_idx: 200 |  Loss: (0.0284) | Acc: (99.03%) (25479/25728)\n",
            "Epoch: 87 | Batch_idx: 210 |  Loss: (0.0290) | Acc: (99.02%) (26742/27008)\n",
            "Epoch: 87 | Batch_idx: 220 |  Loss: (0.0289) | Acc: (99.01%) (28009/28288)\n",
            "Epoch: 87 | Batch_idx: 230 |  Loss: (0.0287) | Acc: (99.02%) (29278/29568)\n",
            "Epoch: 87 | Batch_idx: 240 |  Loss: (0.0285) | Acc: (99.02%) (30546/30848)\n",
            "Epoch: 87 | Batch_idx: 250 |  Loss: (0.0283) | Acc: (99.03%) (31816/32128)\n",
            "Epoch: 87 | Batch_idx: 260 |  Loss: (0.0286) | Acc: (99.02%) (33080/33408)\n",
            "Epoch: 87 | Batch_idx: 270 |  Loss: (0.0289) | Acc: (99.01%) (34343/34688)\n",
            "Epoch: 87 | Batch_idx: 280 |  Loss: (0.0292) | Acc: (98.99%) (35604/35968)\n",
            "Epoch: 87 | Batch_idx: 290 |  Loss: (0.0292) | Acc: (98.99%) (36871/37248)\n",
            "Epoch: 87 | Batch_idx: 300 |  Loss: (0.0297) | Acc: (98.98%) (38134/38528)\n",
            "Epoch: 87 | Batch_idx: 310 |  Loss: (0.0300) | Acc: (98.97%) (39398/39808)\n",
            "Epoch: 87 | Batch_idx: 320 |  Loss: (0.0307) | Acc: (98.94%) (40653/41088)\n",
            "Epoch: 87 | Batch_idx: 330 |  Loss: (0.0308) | Acc: (98.94%) (41917/42368)\n",
            "Epoch: 87 | Batch_idx: 340 |  Loss: (0.0311) | Acc: (98.93%) (43179/43648)\n",
            "Epoch: 87 | Batch_idx: 350 |  Loss: (0.0315) | Acc: (98.91%) (44440/44928)\n",
            "Epoch: 87 | Batch_idx: 360 |  Loss: (0.0320) | Acc: (98.90%) (45698/46208)\n",
            "Epoch: 87 | Batch_idx: 370 |  Loss: (0.0323) | Acc: (98.89%) (46962/47488)\n",
            "Epoch: 87 | Batch_idx: 380 |  Loss: (0.0325) | Acc: (98.88%) (48223/48768)\n",
            "Epoch: 87 | Batch_idx: 390 |  Loss: (0.0323) | Acc: (98.89%) (49445/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3727) | Acc: (91.13%) (9113/10000)\n",
            "Epoch: 88 | Batch_idx: 0 |  Loss: (0.0549) | Acc: (97.66%) (125/128)\n",
            "Epoch: 88 | Batch_idx: 10 |  Loss: (0.0304) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 88 | Batch_idx: 20 |  Loss: (0.0291) | Acc: (99.14%) (2665/2688)\n",
            "Epoch: 88 | Batch_idx: 30 |  Loss: (0.0331) | Acc: (98.94%) (3926/3968)\n",
            "Epoch: 88 | Batch_idx: 40 |  Loss: (0.0344) | Acc: (98.89%) (5190/5248)\n",
            "Epoch: 88 | Batch_idx: 50 |  Loss: (0.0348) | Acc: (98.91%) (6457/6528)\n",
            "Epoch: 88 | Batch_idx: 60 |  Loss: (0.0346) | Acc: (98.91%) (7723/7808)\n",
            "Epoch: 88 | Batch_idx: 70 |  Loss: (0.0333) | Acc: (98.98%) (8995/9088)\n",
            "Epoch: 88 | Batch_idx: 80 |  Loss: (0.0331) | Acc: (98.97%) (10261/10368)\n",
            "Epoch: 88 | Batch_idx: 90 |  Loss: (0.0325) | Acc: (98.99%) (11530/11648)\n",
            "Epoch: 88 | Batch_idx: 100 |  Loss: (0.0315) | Acc: (99.01%) (12800/12928)\n",
            "Epoch: 88 | Batch_idx: 110 |  Loss: (0.0309) | Acc: (99.01%) (14067/14208)\n",
            "Epoch: 88 | Batch_idx: 120 |  Loss: (0.0302) | Acc: (99.03%) (15338/15488)\n",
            "Epoch: 88 | Batch_idx: 130 |  Loss: (0.0305) | Acc: (99.00%) (16601/16768)\n",
            "Epoch: 88 | Batch_idx: 140 |  Loss: (0.0303) | Acc: (99.00%) (17867/18048)\n",
            "Epoch: 88 | Batch_idx: 150 |  Loss: (0.0311) | Acc: (98.94%) (19124/19328)\n",
            "Epoch: 88 | Batch_idx: 160 |  Loss: (0.0310) | Acc: (98.93%) (20387/20608)\n",
            "Epoch: 88 | Batch_idx: 170 |  Loss: (0.0317) | Acc: (98.90%) (21647/21888)\n",
            "Epoch: 88 | Batch_idx: 180 |  Loss: (0.0313) | Acc: (98.91%) (22915/23168)\n",
            "Epoch: 88 | Batch_idx: 190 |  Loss: (0.0310) | Acc: (98.90%) (24180/24448)\n",
            "Epoch: 88 | Batch_idx: 200 |  Loss: (0.0311) | Acc: (98.91%) (25447/25728)\n",
            "Epoch: 88 | Batch_idx: 210 |  Loss: (0.0311) | Acc: (98.91%) (26713/27008)\n",
            "Epoch: 88 | Batch_idx: 220 |  Loss: (0.0311) | Acc: (98.91%) (27981/28288)\n",
            "Epoch: 88 | Batch_idx: 230 |  Loss: (0.0308) | Acc: (98.92%) (29250/29568)\n",
            "Epoch: 88 | Batch_idx: 240 |  Loss: (0.0310) | Acc: (98.92%) (30514/30848)\n",
            "Epoch: 88 | Batch_idx: 250 |  Loss: (0.0311) | Acc: (98.92%) (31780/32128)\n",
            "Epoch: 88 | Batch_idx: 260 |  Loss: (0.0313) | Acc: (98.90%) (33042/33408)\n",
            "Epoch: 88 | Batch_idx: 270 |  Loss: (0.0311) | Acc: (98.90%) (34308/34688)\n",
            "Epoch: 88 | Batch_idx: 280 |  Loss: (0.0316) | Acc: (98.89%) (35567/35968)\n",
            "Epoch: 88 | Batch_idx: 290 |  Loss: (0.0317) | Acc: (98.87%) (36827/37248)\n",
            "Epoch: 88 | Batch_idx: 300 |  Loss: (0.0322) | Acc: (98.87%) (38091/38528)\n",
            "Epoch: 88 | Batch_idx: 310 |  Loss: (0.0320) | Acc: (98.87%) (39360/39808)\n",
            "Epoch: 88 | Batch_idx: 320 |  Loss: (0.0319) | Acc: (98.90%) (40634/41088)\n",
            "Epoch: 88 | Batch_idx: 330 |  Loss: (0.0317) | Acc: (98.89%) (41899/42368)\n",
            "Epoch: 88 | Batch_idx: 340 |  Loss: (0.0318) | Acc: (98.90%) (43166/43648)\n",
            "Epoch: 88 | Batch_idx: 350 |  Loss: (0.0318) | Acc: (98.90%) (44434/44928)\n",
            "Epoch: 88 | Batch_idx: 360 |  Loss: (0.0321) | Acc: (98.89%) (45695/46208)\n",
            "Epoch: 88 | Batch_idx: 370 |  Loss: (0.0322) | Acc: (98.89%) (46962/47488)\n",
            "Epoch: 88 | Batch_idx: 380 |  Loss: (0.0319) | Acc: (98.90%) (48231/48768)\n",
            "Epoch: 88 | Batch_idx: 390 |  Loss: (0.0319) | Acc: (98.90%) (49449/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3753) | Acc: (91.27%) (9127/10000)\n",
            "Epoch: 89 | Batch_idx: 0 |  Loss: (0.0485) | Acc: (98.44%) (126/128)\n",
            "Epoch: 89 | Batch_idx: 10 |  Loss: (0.0320) | Acc: (98.93%) (1393/1408)\n",
            "Epoch: 89 | Batch_idx: 20 |  Loss: (0.0294) | Acc: (99.07%) (2663/2688)\n",
            "Epoch: 89 | Batch_idx: 30 |  Loss: (0.0285) | Acc: (99.09%) (3932/3968)\n",
            "Epoch: 89 | Batch_idx: 40 |  Loss: (0.0275) | Acc: (99.14%) (5203/5248)\n",
            "Epoch: 89 | Batch_idx: 50 |  Loss: (0.0266) | Acc: (99.13%) (6471/6528)\n",
            "Epoch: 89 | Batch_idx: 60 |  Loss: (0.0262) | Acc: (99.13%) (7740/7808)\n",
            "Epoch: 89 | Batch_idx: 70 |  Loss: (0.0259) | Acc: (99.13%) (9009/9088)\n",
            "Epoch: 89 | Batch_idx: 80 |  Loss: (0.0251) | Acc: (99.17%) (10282/10368)\n",
            "Epoch: 89 | Batch_idx: 90 |  Loss: (0.0249) | Acc: (99.19%) (11554/11648)\n",
            "Epoch: 89 | Batch_idx: 100 |  Loss: (0.0259) | Acc: (99.15%) (12818/12928)\n",
            "Epoch: 89 | Batch_idx: 110 |  Loss: (0.0260) | Acc: (99.13%) (14085/14208)\n",
            "Epoch: 89 | Batch_idx: 120 |  Loss: (0.0256) | Acc: (99.15%) (15356/15488)\n",
            "Epoch: 89 | Batch_idx: 130 |  Loss: (0.0260) | Acc: (99.12%) (16621/16768)\n",
            "Epoch: 89 | Batch_idx: 140 |  Loss: (0.0258) | Acc: (99.12%) (17890/18048)\n",
            "Epoch: 89 | Batch_idx: 150 |  Loss: (0.0259) | Acc: (99.13%) (19159/19328)\n",
            "Epoch: 89 | Batch_idx: 160 |  Loss: (0.0259) | Acc: (99.12%) (20426/20608)\n",
            "Epoch: 89 | Batch_idx: 170 |  Loss: (0.0257) | Acc: (99.12%) (21696/21888)\n",
            "Epoch: 89 | Batch_idx: 180 |  Loss: (0.0261) | Acc: (99.11%) (22962/23168)\n",
            "Epoch: 89 | Batch_idx: 190 |  Loss: (0.0270) | Acc: (99.08%) (24224/24448)\n",
            "Epoch: 89 | Batch_idx: 200 |  Loss: (0.0279) | Acc: (99.04%) (25482/25728)\n",
            "Epoch: 89 | Batch_idx: 210 |  Loss: (0.0276) | Acc: (99.05%) (26752/27008)\n",
            "Epoch: 89 | Batch_idx: 220 |  Loss: (0.0279) | Acc: (99.03%) (28013/28288)\n",
            "Epoch: 89 | Batch_idx: 230 |  Loss: (0.0275) | Acc: (99.04%) (29285/29568)\n",
            "Epoch: 89 | Batch_idx: 240 |  Loss: (0.0275) | Acc: (99.04%) (30553/30848)\n",
            "Epoch: 89 | Batch_idx: 250 |  Loss: (0.0279) | Acc: (99.03%) (31816/32128)\n",
            "Epoch: 89 | Batch_idx: 260 |  Loss: (0.0278) | Acc: (99.03%) (33084/33408)\n",
            "Epoch: 89 | Batch_idx: 270 |  Loss: (0.0279) | Acc: (99.02%) (34349/34688)\n",
            "Epoch: 89 | Batch_idx: 280 |  Loss: (0.0276) | Acc: (99.03%) (35619/35968)\n",
            "Epoch: 89 | Batch_idx: 290 |  Loss: (0.0275) | Acc: (99.04%) (36891/37248)\n",
            "Epoch: 89 | Batch_idx: 300 |  Loss: (0.0271) | Acc: (99.05%) (38163/38528)\n",
            "Epoch: 89 | Batch_idx: 310 |  Loss: (0.0273) | Acc: (99.05%) (39431/39808)\n",
            "Epoch: 89 | Batch_idx: 320 |  Loss: (0.0275) | Acc: (99.05%) (40697/41088)\n",
            "Epoch: 89 | Batch_idx: 330 |  Loss: (0.0273) | Acc: (99.05%) (41965/42368)\n",
            "Epoch: 89 | Batch_idx: 340 |  Loss: (0.0270) | Acc: (99.06%) (43237/43648)\n",
            "Epoch: 89 | Batch_idx: 350 |  Loss: (0.0268) | Acc: (99.07%) (44509/44928)\n",
            "Epoch: 89 | Batch_idx: 360 |  Loss: (0.0268) | Acc: (99.07%) (45777/46208)\n",
            "Epoch: 89 | Batch_idx: 370 |  Loss: (0.0272) | Acc: (99.05%) (47039/47488)\n",
            "Epoch: 89 | Batch_idx: 380 |  Loss: (0.0271) | Acc: (99.06%) (48311/48768)\n",
            "Epoch: 89 | Batch_idx: 390 |  Loss: (0.0270) | Acc: (99.07%) (49535/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3791) | Acc: (91.37%) (9137/10000)\n",
            "Epoch: 90 | Batch_idx: 0 |  Loss: (0.0494) | Acc: (98.44%) (126/128)\n",
            "Epoch: 90 | Batch_idx: 10 |  Loss: (0.0310) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 90 | Batch_idx: 20 |  Loss: (0.0328) | Acc: (98.96%) (2660/2688)\n",
            "Epoch: 90 | Batch_idx: 30 |  Loss: (0.0322) | Acc: (98.82%) (3921/3968)\n",
            "Epoch: 90 | Batch_idx: 40 |  Loss: (0.0299) | Acc: (98.88%) (5189/5248)\n",
            "Epoch: 90 | Batch_idx: 50 |  Loss: (0.0290) | Acc: (98.97%) (6461/6528)\n",
            "Epoch: 90 | Batch_idx: 60 |  Loss: (0.0276) | Acc: (99.05%) (7734/7808)\n",
            "Epoch: 90 | Batch_idx: 70 |  Loss: (0.0280) | Acc: (99.06%) (9003/9088)\n",
            "Epoch: 90 | Batch_idx: 80 |  Loss: (0.0289) | Acc: (99.02%) (10266/10368)\n",
            "Epoch: 90 | Batch_idx: 90 |  Loss: (0.0288) | Acc: (99.04%) (11536/11648)\n",
            "Epoch: 90 | Batch_idx: 100 |  Loss: (0.0281) | Acc: (99.06%) (12806/12928)\n",
            "Epoch: 90 | Batch_idx: 110 |  Loss: (0.0272) | Acc: (99.08%) (14077/14208)\n",
            "Epoch: 90 | Batch_idx: 120 |  Loss: (0.0269) | Acc: (99.09%) (15347/15488)\n",
            "Epoch: 90 | Batch_idx: 130 |  Loss: (0.0269) | Acc: (99.08%) (16613/16768)\n",
            "Epoch: 90 | Batch_idx: 140 |  Loss: (0.0274) | Acc: (99.06%) (17878/18048)\n",
            "Epoch: 90 | Batch_idx: 150 |  Loss: (0.0277) | Acc: (99.06%) (19146/19328)\n",
            "Epoch: 90 | Batch_idx: 160 |  Loss: (0.0282) | Acc: (99.04%) (20411/20608)\n",
            "Epoch: 90 | Batch_idx: 170 |  Loss: (0.0281) | Acc: (99.06%) (21682/21888)\n",
            "Epoch: 90 | Batch_idx: 180 |  Loss: (0.0275) | Acc: (99.07%) (22953/23168)\n",
            "Epoch: 90 | Batch_idx: 190 |  Loss: (0.0275) | Acc: (99.07%) (24220/24448)\n",
            "Epoch: 90 | Batch_idx: 200 |  Loss: (0.0274) | Acc: (99.06%) (25486/25728)\n",
            "Epoch: 90 | Batch_idx: 210 |  Loss: (0.0273) | Acc: (99.06%) (26753/27008)\n",
            "Epoch: 90 | Batch_idx: 220 |  Loss: (0.0273) | Acc: (99.06%) (28021/28288)\n",
            "Epoch: 90 | Batch_idx: 230 |  Loss: (0.0275) | Acc: (99.06%) (29291/29568)\n",
            "Epoch: 90 | Batch_idx: 240 |  Loss: (0.0276) | Acc: (99.05%) (30555/30848)\n",
            "Epoch: 90 | Batch_idx: 250 |  Loss: (0.0275) | Acc: (99.05%) (31822/32128)\n",
            "Epoch: 90 | Batch_idx: 260 |  Loss: (0.0277) | Acc: (99.05%) (33089/33408)\n",
            "Epoch: 90 | Batch_idx: 270 |  Loss: (0.0278) | Acc: (99.04%) (34356/34688)\n",
            "Epoch: 90 | Batch_idx: 280 |  Loss: (0.0275) | Acc: (99.05%) (35627/35968)\n",
            "Epoch: 90 | Batch_idx: 290 |  Loss: (0.0278) | Acc: (99.05%) (36894/37248)\n",
            "Epoch: 90 | Batch_idx: 300 |  Loss: (0.0281) | Acc: (99.04%) (38159/38528)\n",
            "Epoch: 90 | Batch_idx: 310 |  Loss: (0.0282) | Acc: (99.04%) (39426/39808)\n",
            "Epoch: 90 | Batch_idx: 320 |  Loss: (0.0282) | Acc: (99.04%) (40695/41088)\n",
            "Epoch: 90 | Batch_idx: 330 |  Loss: (0.0282) | Acc: (99.03%) (41958/42368)\n",
            "Epoch: 90 | Batch_idx: 340 |  Loss: (0.0286) | Acc: (99.03%) (43224/43648)\n",
            "Epoch: 90 | Batch_idx: 350 |  Loss: (0.0283) | Acc: (99.03%) (44494/44928)\n",
            "Epoch: 90 | Batch_idx: 360 |  Loss: (0.0284) | Acc: (99.03%) (45759/46208)\n",
            "Epoch: 90 | Batch_idx: 370 |  Loss: (0.0283) | Acc: (99.04%) (47032/47488)\n",
            "Epoch: 90 | Batch_idx: 380 |  Loss: (0.0287) | Acc: (99.03%) (48296/48768)\n",
            "Epoch: 90 | Batch_idx: 390 |  Loss: (0.0287) | Acc: (99.03%) (49516/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3776) | Acc: (91.26%) (9126/10000)\n",
            "Epoch: 91 | Batch_idx: 0 |  Loss: (0.0677) | Acc: (96.88%) (124/128)\n",
            "Epoch: 91 | Batch_idx: 10 |  Loss: (0.0296) | Acc: (98.93%) (1393/1408)\n",
            "Epoch: 91 | Batch_idx: 20 |  Loss: (0.0353) | Acc: (98.74%) (2654/2688)\n",
            "Epoch: 91 | Batch_idx: 30 |  Loss: (0.0340) | Acc: (98.84%) (3922/3968)\n",
            "Epoch: 91 | Batch_idx: 40 |  Loss: (0.0302) | Acc: (98.97%) (5194/5248)\n",
            "Epoch: 91 | Batch_idx: 50 |  Loss: (0.0287) | Acc: (99.00%) (6463/6528)\n",
            "Epoch: 91 | Batch_idx: 60 |  Loss: (0.0293) | Acc: (99.03%) (7732/7808)\n",
            "Epoch: 91 | Batch_idx: 70 |  Loss: (0.0289) | Acc: (99.03%) (9000/9088)\n",
            "Epoch: 91 | Batch_idx: 80 |  Loss: (0.0286) | Acc: (99.07%) (10272/10368)\n",
            "Epoch: 91 | Batch_idx: 90 |  Loss: (0.0298) | Acc: (99.02%) (11534/11648)\n",
            "Epoch: 91 | Batch_idx: 100 |  Loss: (0.0284) | Acc: (99.06%) (12807/12928)\n",
            "Epoch: 91 | Batch_idx: 110 |  Loss: (0.0292) | Acc: (99.04%) (14072/14208)\n",
            "Epoch: 91 | Batch_idx: 120 |  Loss: (0.0287) | Acc: (99.04%) (15340/15488)\n",
            "Epoch: 91 | Batch_idx: 130 |  Loss: (0.0288) | Acc: (99.02%) (16604/16768)\n",
            "Epoch: 91 | Batch_idx: 140 |  Loss: (0.0287) | Acc: (99.01%) (17870/18048)\n",
            "Epoch: 91 | Batch_idx: 150 |  Loss: (0.0295) | Acc: (98.97%) (19129/19328)\n",
            "Epoch: 91 | Batch_idx: 160 |  Loss: (0.0294) | Acc: (98.99%) (20399/20608)\n",
            "Epoch: 91 | Batch_idx: 170 |  Loss: (0.0289) | Acc: (99.00%) (21669/21888)\n",
            "Epoch: 91 | Batch_idx: 180 |  Loss: (0.0291) | Acc: (99.01%) (22938/23168)\n",
            "Epoch: 91 | Batch_idx: 190 |  Loss: (0.0283) | Acc: (99.03%) (24212/24448)\n",
            "Epoch: 91 | Batch_idx: 200 |  Loss: (0.0281) | Acc: (99.03%) (25479/25728)\n",
            "Epoch: 91 | Batch_idx: 210 |  Loss: (0.0283) | Acc: (99.03%) (26745/27008)\n",
            "Epoch: 91 | Batch_idx: 220 |  Loss: (0.0279) | Acc: (99.04%) (28017/28288)\n",
            "Epoch: 91 | Batch_idx: 230 |  Loss: (0.0280) | Acc: (99.04%) (29283/29568)\n",
            "Epoch: 91 | Batch_idx: 240 |  Loss: (0.0280) | Acc: (99.03%) (30550/30848)\n",
            "Epoch: 91 | Batch_idx: 250 |  Loss: (0.0274) | Acc: (99.07%) (31828/32128)\n",
            "Epoch: 91 | Batch_idx: 260 |  Loss: (0.0279) | Acc: (99.05%) (33091/33408)\n",
            "Epoch: 91 | Batch_idx: 270 |  Loss: (0.0277) | Acc: (99.05%) (34360/34688)\n",
            "Epoch: 91 | Batch_idx: 280 |  Loss: (0.0278) | Acc: (99.04%) (35623/35968)\n",
            "Epoch: 91 | Batch_idx: 290 |  Loss: (0.0280) | Acc: (99.04%) (36890/37248)\n",
            "Epoch: 91 | Batch_idx: 300 |  Loss: (0.0277) | Acc: (99.05%) (38161/38528)\n",
            "Epoch: 91 | Batch_idx: 310 |  Loss: (0.0275) | Acc: (99.06%) (39432/39808)\n",
            "Epoch: 91 | Batch_idx: 320 |  Loss: (0.0272) | Acc: (99.07%) (40704/41088)\n",
            "Epoch: 91 | Batch_idx: 330 |  Loss: (0.0271) | Acc: (99.07%) (41975/42368)\n",
            "Epoch: 91 | Batch_idx: 340 |  Loss: (0.0276) | Acc: (99.07%) (43240/43648)\n",
            "Epoch: 91 | Batch_idx: 350 |  Loss: (0.0274) | Acc: (99.07%) (44511/44928)\n",
            "Epoch: 91 | Batch_idx: 360 |  Loss: (0.0272) | Acc: (99.07%) (45779/46208)\n",
            "Epoch: 91 | Batch_idx: 370 |  Loss: (0.0274) | Acc: (99.08%) (47049/47488)\n",
            "Epoch: 91 | Batch_idx: 380 |  Loss: (0.0275) | Acc: (99.06%) (48312/48768)\n",
            "Epoch: 91 | Batch_idx: 390 |  Loss: (0.0274) | Acc: (99.07%) (49534/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3776) | Acc: (91.40%) (9140/10000)\n",
            "Epoch: 92 | Batch_idx: 0 |  Loss: (0.0099) | Acc: (100.00%) (128/128)\n",
            "Epoch: 92 | Batch_idx: 10 |  Loss: (0.0193) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 92 | Batch_idx: 20 |  Loss: (0.0190) | Acc: (99.33%) (2670/2688)\n",
            "Epoch: 92 | Batch_idx: 30 |  Loss: (0.0205) | Acc: (99.27%) (3939/3968)\n",
            "Epoch: 92 | Batch_idx: 40 |  Loss: (0.0212) | Acc: (99.26%) (5209/5248)\n",
            "Epoch: 92 | Batch_idx: 50 |  Loss: (0.0230) | Acc: (99.19%) (6475/6528)\n",
            "Epoch: 92 | Batch_idx: 60 |  Loss: (0.0234) | Acc: (99.19%) (7745/7808)\n",
            "Epoch: 92 | Batch_idx: 70 |  Loss: (0.0228) | Acc: (99.24%) (9019/9088)\n",
            "Epoch: 92 | Batch_idx: 80 |  Loss: (0.0233) | Acc: (99.23%) (10288/10368)\n",
            "Epoch: 92 | Batch_idx: 90 |  Loss: (0.0232) | Acc: (99.18%) (11553/11648)\n",
            "Epoch: 92 | Batch_idx: 100 |  Loss: (0.0238) | Acc: (99.18%) (12822/12928)\n",
            "Epoch: 92 | Batch_idx: 110 |  Loss: (0.0251) | Acc: (99.16%) (14088/14208)\n",
            "Epoch: 92 | Batch_idx: 120 |  Loss: (0.0254) | Acc: (99.15%) (15356/15488)\n",
            "Epoch: 92 | Batch_idx: 130 |  Loss: (0.0252) | Acc: (99.15%) (16626/16768)\n",
            "Epoch: 92 | Batch_idx: 140 |  Loss: (0.0245) | Acc: (99.19%) (17901/18048)\n",
            "Epoch: 92 | Batch_idx: 150 |  Loss: (0.0248) | Acc: (99.19%) (19171/19328)\n",
            "Epoch: 92 | Batch_idx: 160 |  Loss: (0.0245) | Acc: (99.21%) (20445/20608)\n",
            "Epoch: 92 | Batch_idx: 170 |  Loss: (0.0251) | Acc: (99.20%) (21713/21888)\n",
            "Epoch: 92 | Batch_idx: 180 |  Loss: (0.0255) | Acc: (99.19%) (22981/23168)\n",
            "Epoch: 92 | Batch_idx: 190 |  Loss: (0.0259) | Acc: (99.19%) (24250/24448)\n",
            "Epoch: 92 | Batch_idx: 200 |  Loss: (0.0258) | Acc: (99.20%) (25522/25728)\n",
            "Epoch: 92 | Batch_idx: 210 |  Loss: (0.0254) | Acc: (99.21%) (26794/27008)\n",
            "Epoch: 92 | Batch_idx: 220 |  Loss: (0.0258) | Acc: (99.20%) (28062/28288)\n",
            "Epoch: 92 | Batch_idx: 230 |  Loss: (0.0257) | Acc: (99.20%) (29331/29568)\n",
            "Epoch: 92 | Batch_idx: 240 |  Loss: (0.0256) | Acc: (99.19%) (30599/30848)\n",
            "Epoch: 92 | Batch_idx: 250 |  Loss: (0.0257) | Acc: (99.19%) (31868/32128)\n",
            "Epoch: 92 | Batch_idx: 260 |  Loss: (0.0255) | Acc: (99.18%) (33135/33408)\n",
            "Epoch: 92 | Batch_idx: 270 |  Loss: (0.0250) | Acc: (99.20%) (34409/34688)\n",
            "Epoch: 92 | Batch_idx: 280 |  Loss: (0.0245) | Acc: (99.21%) (35683/35968)\n",
            "Epoch: 92 | Batch_idx: 290 |  Loss: (0.0244) | Acc: (99.21%) (36955/37248)\n",
            "Epoch: 92 | Batch_idx: 300 |  Loss: (0.0242) | Acc: (99.21%) (38224/38528)\n",
            "Epoch: 92 | Batch_idx: 310 |  Loss: (0.0239) | Acc: (99.21%) (39495/39808)\n",
            "Epoch: 92 | Batch_idx: 320 |  Loss: (0.0241) | Acc: (99.21%) (40764/41088)\n",
            "Epoch: 92 | Batch_idx: 330 |  Loss: (0.0241) | Acc: (99.21%) (42033/42368)\n",
            "Epoch: 92 | Batch_idx: 340 |  Loss: (0.0241) | Acc: (99.20%) (43300/43648)\n",
            "Epoch: 92 | Batch_idx: 350 |  Loss: (0.0241) | Acc: (99.21%) (44572/44928)\n",
            "Epoch: 92 | Batch_idx: 360 |  Loss: (0.0241) | Acc: (99.21%) (45845/46208)\n",
            "Epoch: 92 | Batch_idx: 370 |  Loss: (0.0240) | Acc: (99.21%) (47115/47488)\n",
            "Epoch: 92 | Batch_idx: 380 |  Loss: (0.0240) | Acc: (99.21%) (48384/48768)\n",
            "Epoch: 92 | Batch_idx: 390 |  Loss: (0.0240) | Acc: (99.21%) (49606/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3967) | Acc: (91.14%) (9114/10000)\n",
            "Epoch: 93 | Batch_idx: 0 |  Loss: (0.0030) | Acc: (100.00%) (128/128)\n",
            "Epoch: 93 | Batch_idx: 10 |  Loss: (0.0192) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 93 | Batch_idx: 20 |  Loss: (0.0211) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 93 | Batch_idx: 30 |  Loss: (0.0198) | Acc: (99.47%) (3947/3968)\n",
            "Epoch: 93 | Batch_idx: 40 |  Loss: (0.0208) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 93 | Batch_idx: 50 |  Loss: (0.0204) | Acc: (99.39%) (6488/6528)\n",
            "Epoch: 93 | Batch_idx: 60 |  Loss: (0.0195) | Acc: (99.39%) (7760/7808)\n",
            "Epoch: 93 | Batch_idx: 70 |  Loss: (0.0189) | Acc: (99.39%) (9033/9088)\n",
            "Epoch: 93 | Batch_idx: 80 |  Loss: (0.0190) | Acc: (99.39%) (10305/10368)\n",
            "Epoch: 93 | Batch_idx: 90 |  Loss: (0.0191) | Acc: (99.38%) (11576/11648)\n",
            "Epoch: 93 | Batch_idx: 100 |  Loss: (0.0196) | Acc: (99.37%) (12846/12928)\n",
            "Epoch: 93 | Batch_idx: 110 |  Loss: (0.0204) | Acc: (99.32%) (14112/14208)\n",
            "Epoch: 93 | Batch_idx: 120 |  Loss: (0.0206) | Acc: (99.30%) (15380/15488)\n",
            "Epoch: 93 | Batch_idx: 130 |  Loss: (0.0222) | Acc: (99.27%) (16645/16768)\n",
            "Epoch: 93 | Batch_idx: 140 |  Loss: (0.0221) | Acc: (99.25%) (17912/18048)\n",
            "Epoch: 93 | Batch_idx: 150 |  Loss: (0.0218) | Acc: (99.25%) (19184/19328)\n",
            "Epoch: 93 | Batch_idx: 160 |  Loss: (0.0228) | Acc: (99.23%) (20449/20608)\n",
            "Epoch: 93 | Batch_idx: 170 |  Loss: (0.0228) | Acc: (99.24%) (21721/21888)\n",
            "Epoch: 93 | Batch_idx: 180 |  Loss: (0.0230) | Acc: (99.24%) (22992/23168)\n",
            "Epoch: 93 | Batch_idx: 190 |  Loss: (0.0235) | Acc: (99.21%) (24255/24448)\n",
            "Epoch: 93 | Batch_idx: 200 |  Loss: (0.0236) | Acc: (99.20%) (25521/25728)\n",
            "Epoch: 93 | Batch_idx: 210 |  Loss: (0.0238) | Acc: (99.19%) (26789/27008)\n",
            "Epoch: 93 | Batch_idx: 220 |  Loss: (0.0240) | Acc: (99.19%) (28059/28288)\n",
            "Epoch: 93 | Batch_idx: 230 |  Loss: (0.0242) | Acc: (99.19%) (29329/29568)\n",
            "Epoch: 93 | Batch_idx: 240 |  Loss: (0.0245) | Acc: (99.17%) (30593/30848)\n",
            "Epoch: 93 | Batch_idx: 250 |  Loss: (0.0245) | Acc: (99.17%) (31861/32128)\n",
            "Epoch: 93 | Batch_idx: 260 |  Loss: (0.0246) | Acc: (99.17%) (33130/33408)\n",
            "Epoch: 93 | Batch_idx: 270 |  Loss: (0.0247) | Acc: (99.17%) (34400/34688)\n",
            "Epoch: 93 | Batch_idx: 280 |  Loss: (0.0250) | Acc: (99.15%) (35662/35968)\n",
            "Epoch: 93 | Batch_idx: 290 |  Loss: (0.0254) | Acc: (99.13%) (36924/37248)\n",
            "Epoch: 93 | Batch_idx: 300 |  Loss: (0.0251) | Acc: (99.14%) (38195/38528)\n",
            "Epoch: 93 | Batch_idx: 310 |  Loss: (0.0253) | Acc: (99.12%) (39459/39808)\n",
            "Epoch: 93 | Batch_idx: 320 |  Loss: (0.0255) | Acc: (99.13%) (40730/41088)\n",
            "Epoch: 93 | Batch_idx: 330 |  Loss: (0.0251) | Acc: (99.14%) (42004/42368)\n",
            "Epoch: 93 | Batch_idx: 340 |  Loss: (0.0252) | Acc: (99.14%) (43274/43648)\n",
            "Epoch: 93 | Batch_idx: 350 |  Loss: (0.0251) | Acc: (99.15%) (44546/44928)\n",
            "Epoch: 93 | Batch_idx: 360 |  Loss: (0.0250) | Acc: (99.16%) (45819/46208)\n",
            "Epoch: 93 | Batch_idx: 370 |  Loss: (0.0252) | Acc: (99.16%) (47087/47488)\n",
            "Epoch: 93 | Batch_idx: 380 |  Loss: (0.0252) | Acc: (99.15%) (48352/48768)\n",
            "Epoch: 93 | Batch_idx: 390 |  Loss: (0.0254) | Acc: (99.14%) (49571/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3815) | Acc: (91.26%) (9126/10000)\n",
            "Epoch: 94 | Batch_idx: 0 |  Loss: (0.0108) | Acc: (100.00%) (128/128)\n",
            "Epoch: 94 | Batch_idx: 10 |  Loss: (0.0263) | Acc: (98.93%) (1393/1408)\n",
            "Epoch: 94 | Batch_idx: 20 |  Loss: (0.0247) | Acc: (99.00%) (2661/2688)\n",
            "Epoch: 94 | Batch_idx: 30 |  Loss: (0.0231) | Acc: (99.17%) (3935/3968)\n",
            "Epoch: 94 | Batch_idx: 40 |  Loss: (0.0230) | Acc: (99.14%) (5203/5248)\n",
            "Epoch: 94 | Batch_idx: 50 |  Loss: (0.0249) | Acc: (99.10%) (6469/6528)\n",
            "Epoch: 94 | Batch_idx: 60 |  Loss: (0.0258) | Acc: (99.07%) (7735/7808)\n",
            "Epoch: 94 | Batch_idx: 70 |  Loss: (0.0249) | Acc: (99.10%) (9006/9088)\n",
            "Epoch: 94 | Batch_idx: 80 |  Loss: (0.0240) | Acc: (99.13%) (10278/10368)\n",
            "Epoch: 94 | Batch_idx: 90 |  Loss: (0.0246) | Acc: (99.12%) (11546/11648)\n",
            "Epoch: 94 | Batch_idx: 100 |  Loss: (0.0244) | Acc: (99.13%) (12816/12928)\n",
            "Epoch: 94 | Batch_idx: 110 |  Loss: (0.0238) | Acc: (99.17%) (14090/14208)\n",
            "Epoch: 94 | Batch_idx: 120 |  Loss: (0.0229) | Acc: (99.21%) (15365/15488)\n",
            "Epoch: 94 | Batch_idx: 130 |  Loss: (0.0225) | Acc: (99.21%) (16635/16768)\n",
            "Epoch: 94 | Batch_idx: 140 |  Loss: (0.0225) | Acc: (99.21%) (17906/18048)\n",
            "Epoch: 94 | Batch_idx: 150 |  Loss: (0.0225) | Acc: (99.23%) (19180/19328)\n",
            "Epoch: 94 | Batch_idx: 160 |  Loss: (0.0234) | Acc: (99.23%) (20450/20608)\n",
            "Epoch: 94 | Batch_idx: 170 |  Loss: (0.0226) | Acc: (99.26%) (21727/21888)\n",
            "Epoch: 94 | Batch_idx: 180 |  Loss: (0.0224) | Acc: (99.27%) (22999/23168)\n",
            "Epoch: 94 | Batch_idx: 190 |  Loss: (0.0222) | Acc: (99.27%) (24269/24448)\n",
            "Epoch: 94 | Batch_idx: 200 |  Loss: (0.0220) | Acc: (99.28%) (25544/25728)\n",
            "Epoch: 94 | Batch_idx: 210 |  Loss: (0.0215) | Acc: (99.30%) (26820/27008)\n",
            "Epoch: 94 | Batch_idx: 220 |  Loss: (0.0217) | Acc: (99.29%) (28088/28288)\n",
            "Epoch: 94 | Batch_idx: 230 |  Loss: (0.0217) | Acc: (99.27%) (29353/29568)\n",
            "Epoch: 94 | Batch_idx: 240 |  Loss: (0.0214) | Acc: (99.29%) (30628/30848)\n",
            "Epoch: 94 | Batch_idx: 250 |  Loss: (0.0212) | Acc: (99.30%) (31903/32128)\n",
            "Epoch: 94 | Batch_idx: 260 |  Loss: (0.0213) | Acc: (99.29%) (33171/33408)\n",
            "Epoch: 94 | Batch_idx: 270 |  Loss: (0.0211) | Acc: (99.29%) (34443/34688)\n",
            "Epoch: 94 | Batch_idx: 280 |  Loss: (0.0214) | Acc: (99.28%) (35709/35968)\n",
            "Epoch: 94 | Batch_idx: 290 |  Loss: (0.0212) | Acc: (99.28%) (36981/37248)\n",
            "Epoch: 94 | Batch_idx: 300 |  Loss: (0.0211) | Acc: (99.28%) (38249/38528)\n",
            "Epoch: 94 | Batch_idx: 310 |  Loss: (0.0209) | Acc: (99.29%) (39525/39808)\n",
            "Epoch: 94 | Batch_idx: 320 |  Loss: (0.0212) | Acc: (99.27%) (40787/41088)\n",
            "Epoch: 94 | Batch_idx: 330 |  Loss: (0.0212) | Acc: (99.27%) (42060/42368)\n",
            "Epoch: 94 | Batch_idx: 340 |  Loss: (0.0213) | Acc: (99.27%) (43330/43648)\n",
            "Epoch: 94 | Batch_idx: 350 |  Loss: (0.0214) | Acc: (99.27%) (44598/44928)\n",
            "Epoch: 94 | Batch_idx: 360 |  Loss: (0.0219) | Acc: (99.25%) (45863/46208)\n",
            "Epoch: 94 | Batch_idx: 370 |  Loss: (0.0220) | Acc: (99.25%) (47132/47488)\n",
            "Epoch: 94 | Batch_idx: 380 |  Loss: (0.0218) | Acc: (99.25%) (48404/48768)\n",
            "Epoch: 94 | Batch_idx: 390 |  Loss: (0.0217) | Acc: (99.26%) (49631/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3949) | Acc: (91.34%) (9134/10000)\n",
            "Epoch: 95 | Batch_idx: 0 |  Loss: (0.0202) | Acc: (99.22%) (127/128)\n",
            "Epoch: 95 | Batch_idx: 10 |  Loss: (0.0134) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 95 | Batch_idx: 20 |  Loss: (0.0157) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 95 | Batch_idx: 30 |  Loss: (0.0185) | Acc: (99.42%) (3945/3968)\n",
            "Epoch: 95 | Batch_idx: 40 |  Loss: (0.0184) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 95 | Batch_idx: 50 |  Loss: (0.0175) | Acc: (99.42%) (6490/6528)\n",
            "Epoch: 95 | Batch_idx: 60 |  Loss: (0.0189) | Acc: (99.37%) (7759/7808)\n",
            "Epoch: 95 | Batch_idx: 70 |  Loss: (0.0184) | Acc: (99.39%) (9033/9088)\n",
            "Epoch: 95 | Batch_idx: 80 |  Loss: (0.0183) | Acc: (99.38%) (10304/10368)\n",
            "Epoch: 95 | Batch_idx: 90 |  Loss: (0.0188) | Acc: (99.38%) (11576/11648)\n",
            "Epoch: 95 | Batch_idx: 100 |  Loss: (0.0184) | Acc: (99.40%) (12850/12928)\n",
            "Epoch: 95 | Batch_idx: 110 |  Loss: (0.0188) | Acc: (99.38%) (14120/14208)\n",
            "Epoch: 95 | Batch_idx: 120 |  Loss: (0.0192) | Acc: (99.36%) (15389/15488)\n",
            "Epoch: 95 | Batch_idx: 130 |  Loss: (0.0196) | Acc: (99.33%) (16656/16768)\n",
            "Epoch: 95 | Batch_idx: 140 |  Loss: (0.0207) | Acc: (99.31%) (17923/18048)\n",
            "Epoch: 95 | Batch_idx: 150 |  Loss: (0.0204) | Acc: (99.31%) (19195/19328)\n",
            "Epoch: 95 | Batch_idx: 160 |  Loss: (0.0206) | Acc: (99.31%) (20466/20608)\n",
            "Epoch: 95 | Batch_idx: 170 |  Loss: (0.0211) | Acc: (99.30%) (21735/21888)\n",
            "Epoch: 95 | Batch_idx: 180 |  Loss: (0.0209) | Acc: (99.31%) (23009/23168)\n",
            "Epoch: 95 | Batch_idx: 190 |  Loss: (0.0205) | Acc: (99.33%) (24283/24448)\n",
            "Epoch: 95 | Batch_idx: 200 |  Loss: (0.0207) | Acc: (99.31%) (25551/25728)\n",
            "Epoch: 95 | Batch_idx: 210 |  Loss: (0.0207) | Acc: (99.31%) (26822/27008)\n",
            "Epoch: 95 | Batch_idx: 220 |  Loss: (0.0210) | Acc: (99.29%) (28086/28288)\n",
            "Epoch: 95 | Batch_idx: 230 |  Loss: (0.0209) | Acc: (99.29%) (29359/29568)\n",
            "Epoch: 95 | Batch_idx: 240 |  Loss: (0.0208) | Acc: (99.30%) (30632/30848)\n",
            "Epoch: 95 | Batch_idx: 250 |  Loss: (0.0210) | Acc: (99.30%) (31902/32128)\n",
            "Epoch: 95 | Batch_idx: 260 |  Loss: (0.0209) | Acc: (99.29%) (33170/33408)\n",
            "Epoch: 95 | Batch_idx: 270 |  Loss: (0.0211) | Acc: (99.28%) (34438/34688)\n",
            "Epoch: 95 | Batch_idx: 280 |  Loss: (0.0210) | Acc: (99.29%) (35711/35968)\n",
            "Epoch: 95 | Batch_idx: 290 |  Loss: (0.0213) | Acc: (99.27%) (36975/37248)\n",
            "Epoch: 95 | Batch_idx: 300 |  Loss: (0.0211) | Acc: (99.28%) (38249/38528)\n",
            "Epoch: 95 | Batch_idx: 310 |  Loss: (0.0213) | Acc: (99.27%) (39517/39808)\n",
            "Epoch: 95 | Batch_idx: 320 |  Loss: (0.0212) | Acc: (99.27%) (40788/41088)\n",
            "Epoch: 95 | Batch_idx: 330 |  Loss: (0.0213) | Acc: (99.27%) (42057/42368)\n",
            "Epoch: 95 | Batch_idx: 340 |  Loss: (0.0211) | Acc: (99.27%) (43330/43648)\n",
            "Epoch: 95 | Batch_idx: 350 |  Loss: (0.0213) | Acc: (99.27%) (44602/44928)\n",
            "Epoch: 95 | Batch_idx: 360 |  Loss: (0.0213) | Acc: (99.27%) (45870/46208)\n",
            "Epoch: 95 | Batch_idx: 370 |  Loss: (0.0213) | Acc: (99.27%) (47141/47488)\n",
            "Epoch: 95 | Batch_idx: 380 |  Loss: (0.0214) | Acc: (99.27%) (48410/48768)\n",
            "Epoch: 95 | Batch_idx: 390 |  Loss: (0.0214) | Acc: (99.26%) (49631/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3947) | Acc: (91.29%) (9129/10000)\n",
            "Epoch: 96 | Batch_idx: 0 |  Loss: (0.0151) | Acc: (99.22%) (127/128)\n",
            "Epoch: 96 | Batch_idx: 10 |  Loss: (0.0113) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 96 | Batch_idx: 20 |  Loss: (0.0159) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 96 | Batch_idx: 30 |  Loss: (0.0168) | Acc: (99.42%) (3945/3968)\n",
            "Epoch: 96 | Batch_idx: 40 |  Loss: (0.0161) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 96 | Batch_idx: 50 |  Loss: (0.0154) | Acc: (99.43%) (6491/6528)\n",
            "Epoch: 96 | Batch_idx: 60 |  Loss: (0.0150) | Acc: (99.47%) (7767/7808)\n",
            "Epoch: 96 | Batch_idx: 70 |  Loss: (0.0174) | Acc: (99.39%) (9033/9088)\n",
            "Epoch: 96 | Batch_idx: 80 |  Loss: (0.0183) | Acc: (99.37%) (10303/10368)\n",
            "Epoch: 96 | Batch_idx: 90 |  Loss: (0.0190) | Acc: (99.35%) (11572/11648)\n",
            "Epoch: 96 | Batch_idx: 100 |  Loss: (0.0186) | Acc: (99.35%) (12844/12928)\n",
            "Epoch: 96 | Batch_idx: 110 |  Loss: (0.0187) | Acc: (99.37%) (14119/14208)\n",
            "Epoch: 96 | Batch_idx: 120 |  Loss: (0.0185) | Acc: (99.39%) (15394/15488)\n",
            "Epoch: 96 | Batch_idx: 130 |  Loss: (0.0195) | Acc: (99.37%) (16663/16768)\n",
            "Epoch: 96 | Batch_idx: 140 |  Loss: (0.0192) | Acc: (99.37%) (17934/18048)\n",
            "Epoch: 96 | Batch_idx: 150 |  Loss: (0.0196) | Acc: (99.36%) (19204/19328)\n",
            "Epoch: 96 | Batch_idx: 160 |  Loss: (0.0199) | Acc: (99.35%) (20475/20608)\n",
            "Epoch: 96 | Batch_idx: 170 |  Loss: (0.0202) | Acc: (99.33%) (21742/21888)\n",
            "Epoch: 96 | Batch_idx: 180 |  Loss: (0.0203) | Acc: (99.33%) (23012/23168)\n",
            "Epoch: 96 | Batch_idx: 190 |  Loss: (0.0204) | Acc: (99.33%) (24283/24448)\n",
            "Epoch: 96 | Batch_idx: 200 |  Loss: (0.0203) | Acc: (99.32%) (25554/25728)\n",
            "Epoch: 96 | Batch_idx: 210 |  Loss: (0.0207) | Acc: (99.31%) (26821/27008)\n",
            "Epoch: 96 | Batch_idx: 220 |  Loss: (0.0210) | Acc: (99.29%) (28087/28288)\n",
            "Epoch: 96 | Batch_idx: 230 |  Loss: (0.0213) | Acc: (99.28%) (29355/29568)\n",
            "Epoch: 96 | Batch_idx: 240 |  Loss: (0.0208) | Acc: (99.30%) (30632/30848)\n",
            "Epoch: 96 | Batch_idx: 250 |  Loss: (0.0209) | Acc: (99.29%) (31901/32128)\n",
            "Epoch: 96 | Batch_idx: 260 |  Loss: (0.0206) | Acc: (99.30%) (33174/33408)\n",
            "Epoch: 96 | Batch_idx: 270 |  Loss: (0.0208) | Acc: (99.30%) (34445/34688)\n",
            "Epoch: 96 | Batch_idx: 280 |  Loss: (0.0211) | Acc: (99.29%) (35713/35968)\n",
            "Epoch: 96 | Batch_idx: 290 |  Loss: (0.0209) | Acc: (99.29%) (36984/37248)\n",
            "Epoch: 96 | Batch_idx: 300 |  Loss: (0.0212) | Acc: (99.29%) (38254/38528)\n",
            "Epoch: 96 | Batch_idx: 310 |  Loss: (0.0214) | Acc: (99.28%) (39520/39808)\n",
            "Epoch: 96 | Batch_idx: 320 |  Loss: (0.0217) | Acc: (99.26%) (40785/41088)\n",
            "Epoch: 96 | Batch_idx: 330 |  Loss: (0.0218) | Acc: (99.26%) (42053/42368)\n",
            "Epoch: 96 | Batch_idx: 340 |  Loss: (0.0218) | Acc: (99.25%) (43322/43648)\n",
            "Epoch: 96 | Batch_idx: 350 |  Loss: (0.0222) | Acc: (99.24%) (44585/44928)\n",
            "Epoch: 96 | Batch_idx: 360 |  Loss: (0.0222) | Acc: (99.24%) (45856/46208)\n",
            "Epoch: 96 | Batch_idx: 370 |  Loss: (0.0222) | Acc: (99.24%) (47125/47488)\n",
            "Epoch: 96 | Batch_idx: 380 |  Loss: (0.0221) | Acc: (99.24%) (48399/48768)\n",
            "Epoch: 96 | Batch_idx: 390 |  Loss: (0.0221) | Acc: (99.24%) (49621/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4027) | Acc: (91.11%) (9111/10000)\n",
            "Epoch: 97 | Batch_idx: 0 |  Loss: (0.0401) | Acc: (99.22%) (127/128)\n",
            "Epoch: 97 | Batch_idx: 10 |  Loss: (0.0211) | Acc: (99.15%) (1396/1408)\n",
            "Epoch: 97 | Batch_idx: 20 |  Loss: (0.0196) | Acc: (99.22%) (2667/2688)\n",
            "Epoch: 97 | Batch_idx: 30 |  Loss: (0.0188) | Acc: (99.29%) (3940/3968)\n",
            "Epoch: 97 | Batch_idx: 40 |  Loss: (0.0216) | Acc: (99.26%) (5209/5248)\n",
            "Epoch: 97 | Batch_idx: 50 |  Loss: (0.0226) | Acc: (99.19%) (6475/6528)\n",
            "Epoch: 97 | Batch_idx: 60 |  Loss: (0.0224) | Acc: (99.22%) (7747/7808)\n",
            "Epoch: 97 | Batch_idx: 70 |  Loss: (0.0217) | Acc: (99.23%) (9018/9088)\n",
            "Epoch: 97 | Batch_idx: 80 |  Loss: (0.0220) | Acc: (99.24%) (10289/10368)\n",
            "Epoch: 97 | Batch_idx: 90 |  Loss: (0.0224) | Acc: (99.24%) (11559/11648)\n",
            "Epoch: 97 | Batch_idx: 100 |  Loss: (0.0216) | Acc: (99.27%) (12834/12928)\n",
            "Epoch: 97 | Batch_idx: 110 |  Loss: (0.0214) | Acc: (99.27%) (14104/14208)\n",
            "Epoch: 97 | Batch_idx: 120 |  Loss: (0.0218) | Acc: (99.24%) (15371/15488)\n",
            "Epoch: 97 | Batch_idx: 130 |  Loss: (0.0218) | Acc: (99.25%) (16642/16768)\n",
            "Epoch: 97 | Batch_idx: 140 |  Loss: (0.0219) | Acc: (99.24%) (17911/18048)\n",
            "Epoch: 97 | Batch_idx: 150 |  Loss: (0.0216) | Acc: (99.24%) (19182/19328)\n",
            "Epoch: 97 | Batch_idx: 160 |  Loss: (0.0222) | Acc: (99.21%) (20446/20608)\n",
            "Epoch: 97 | Batch_idx: 170 |  Loss: (0.0215) | Acc: (99.25%) (21723/21888)\n",
            "Epoch: 97 | Batch_idx: 180 |  Loss: (0.0218) | Acc: (99.25%) (22995/23168)\n",
            "Epoch: 97 | Batch_idx: 190 |  Loss: (0.0214) | Acc: (99.27%) (24269/24448)\n",
            "Epoch: 97 | Batch_idx: 200 |  Loss: (0.0214) | Acc: (99.28%) (25542/25728)\n",
            "Epoch: 97 | Batch_idx: 210 |  Loss: (0.0212) | Acc: (99.28%) (26813/27008)\n",
            "Epoch: 97 | Batch_idx: 220 |  Loss: (0.0210) | Acc: (99.28%) (28085/28288)\n",
            "Epoch: 97 | Batch_idx: 230 |  Loss: (0.0207) | Acc: (99.29%) (29357/29568)\n",
            "Epoch: 97 | Batch_idx: 240 |  Loss: (0.0209) | Acc: (99.28%) (30626/30848)\n",
            "Epoch: 97 | Batch_idx: 250 |  Loss: (0.0211) | Acc: (99.27%) (31894/32128)\n",
            "Epoch: 97 | Batch_idx: 260 |  Loss: (0.0212) | Acc: (99.27%) (33163/33408)\n",
            "Epoch: 97 | Batch_idx: 270 |  Loss: (0.0213) | Acc: (99.26%) (34433/34688)\n",
            "Epoch: 97 | Batch_idx: 280 |  Loss: (0.0214) | Acc: (99.27%) (35705/35968)\n",
            "Epoch: 97 | Batch_idx: 290 |  Loss: (0.0212) | Acc: (99.28%) (36979/37248)\n",
            "Epoch: 97 | Batch_idx: 300 |  Loss: (0.0211) | Acc: (99.28%) (38252/38528)\n",
            "Epoch: 97 | Batch_idx: 310 |  Loss: (0.0213) | Acc: (99.27%) (39519/39808)\n",
            "Epoch: 97 | Batch_idx: 320 |  Loss: (0.0212) | Acc: (99.28%) (40794/41088)\n",
            "Epoch: 97 | Batch_idx: 330 |  Loss: (0.0215) | Acc: (99.27%) (42060/42368)\n",
            "Epoch: 97 | Batch_idx: 340 |  Loss: (0.0215) | Acc: (99.27%) (43331/43648)\n",
            "Epoch: 97 | Batch_idx: 350 |  Loss: (0.0216) | Acc: (99.27%) (44598/44928)\n",
            "Epoch: 97 | Batch_idx: 360 |  Loss: (0.0216) | Acc: (99.26%) (45865/46208)\n",
            "Epoch: 97 | Batch_idx: 370 |  Loss: (0.0217) | Acc: (99.26%) (47137/47488)\n",
            "Epoch: 97 | Batch_idx: 380 |  Loss: (0.0217) | Acc: (99.26%) (48407/48768)\n",
            "Epoch: 97 | Batch_idx: 390 |  Loss: (0.0216) | Acc: (99.26%) (49632/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4044) | Acc: (91.32%) (9132/10000)\n",
            "Epoch: 98 | Batch_idx: 0 |  Loss: (0.0084) | Acc: (100.00%) (128/128)\n",
            "Epoch: 98 | Batch_idx: 10 |  Loss: (0.0186) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 98 | Batch_idx: 20 |  Loss: (0.0172) | Acc: (99.26%) (2668/2688)\n",
            "Epoch: 98 | Batch_idx: 30 |  Loss: (0.0175) | Acc: (99.32%) (3941/3968)\n",
            "Epoch: 98 | Batch_idx: 40 |  Loss: (0.0172) | Acc: (99.33%) (5213/5248)\n",
            "Epoch: 98 | Batch_idx: 50 |  Loss: (0.0165) | Acc: (99.33%) (6484/6528)\n",
            "Epoch: 98 | Batch_idx: 60 |  Loss: (0.0167) | Acc: (99.33%) (7756/7808)\n",
            "Epoch: 98 | Batch_idx: 70 |  Loss: (0.0183) | Acc: (99.30%) (9024/9088)\n",
            "Epoch: 98 | Batch_idx: 80 |  Loss: (0.0195) | Acc: (99.25%) (10290/10368)\n",
            "Epoch: 98 | Batch_idx: 90 |  Loss: (0.0197) | Acc: (99.26%) (11562/11648)\n",
            "Epoch: 98 | Batch_idx: 100 |  Loss: (0.0207) | Acc: (99.26%) (12832/12928)\n",
            "Epoch: 98 | Batch_idx: 110 |  Loss: (0.0202) | Acc: (99.27%) (14104/14208)\n",
            "Epoch: 98 | Batch_idx: 120 |  Loss: (0.0195) | Acc: (99.28%) (15376/15488)\n",
            "Epoch: 98 | Batch_idx: 130 |  Loss: (0.0193) | Acc: (99.27%) (16646/16768)\n",
            "Epoch: 98 | Batch_idx: 140 |  Loss: (0.0195) | Acc: (99.29%) (17920/18048)\n",
            "Epoch: 98 | Batch_idx: 150 |  Loss: (0.0197) | Acc: (99.29%) (19191/19328)\n",
            "Epoch: 98 | Batch_idx: 160 |  Loss: (0.0197) | Acc: (99.28%) (20460/20608)\n",
            "Epoch: 98 | Batch_idx: 170 |  Loss: (0.0193) | Acc: (99.29%) (21733/21888)\n",
            "Epoch: 98 | Batch_idx: 180 |  Loss: (0.0195) | Acc: (99.30%) (23005/23168)\n",
            "Epoch: 98 | Batch_idx: 190 |  Loss: (0.0193) | Acc: (99.30%) (24278/24448)\n",
            "Epoch: 98 | Batch_idx: 200 |  Loss: (0.0194) | Acc: (99.30%) (25549/25728)\n",
            "Epoch: 98 | Batch_idx: 210 |  Loss: (0.0191) | Acc: (99.32%) (26824/27008)\n",
            "Epoch: 98 | Batch_idx: 220 |  Loss: (0.0187) | Acc: (99.34%) (28100/28288)\n",
            "Epoch: 98 | Batch_idx: 230 |  Loss: (0.0185) | Acc: (99.35%) (29375/29568)\n",
            "Epoch: 98 | Batch_idx: 240 |  Loss: (0.0182) | Acc: (99.35%) (30649/30848)\n",
            "Epoch: 98 | Batch_idx: 250 |  Loss: (0.0179) | Acc: (99.37%) (31926/32128)\n",
            "Epoch: 98 | Batch_idx: 260 |  Loss: (0.0184) | Acc: (99.36%) (33194/33408)\n",
            "Epoch: 98 | Batch_idx: 270 |  Loss: (0.0182) | Acc: (99.37%) (34471/34688)\n",
            "Epoch: 98 | Batch_idx: 280 |  Loss: (0.0180) | Acc: (99.38%) (35744/35968)\n",
            "Epoch: 98 | Batch_idx: 290 |  Loss: (0.0179) | Acc: (99.38%) (37017/37248)\n",
            "Epoch: 98 | Batch_idx: 300 |  Loss: (0.0178) | Acc: (99.38%) (38289/38528)\n",
            "Epoch: 98 | Batch_idx: 310 |  Loss: (0.0179) | Acc: (99.38%) (39562/39808)\n",
            "Epoch: 98 | Batch_idx: 320 |  Loss: (0.0180) | Acc: (99.39%) (40836/41088)\n",
            "Epoch: 98 | Batch_idx: 330 |  Loss: (0.0180) | Acc: (99.39%) (42109/42368)\n",
            "Epoch: 98 | Batch_idx: 340 |  Loss: (0.0178) | Acc: (99.40%) (43386/43648)\n",
            "Epoch: 98 | Batch_idx: 350 |  Loss: (0.0177) | Acc: (99.41%) (44661/44928)\n",
            "Epoch: 98 | Batch_idx: 360 |  Loss: (0.0178) | Acc: (99.39%) (45927/46208)\n",
            "Epoch: 98 | Batch_idx: 370 |  Loss: (0.0178) | Acc: (99.39%) (47200/47488)\n",
            "Epoch: 98 | Batch_idx: 380 |  Loss: (0.0176) | Acc: (99.40%) (48477/48768)\n",
            "Epoch: 98 | Batch_idx: 390 |  Loss: (0.0175) | Acc: (99.40%) (49702/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4105) | Acc: (91.38%) (9138/10000)\n",
            "Epoch: 99 | Batch_idx: 0 |  Loss: (0.0038) | Acc: (100.00%) (128/128)\n",
            "Epoch: 99 | Batch_idx: 10 |  Loss: (0.0145) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 99 | Batch_idx: 20 |  Loss: (0.0127) | Acc: (99.63%) (2678/2688)\n",
            "Epoch: 99 | Batch_idx: 30 |  Loss: (0.0126) | Acc: (99.62%) (3953/3968)\n",
            "Epoch: 99 | Batch_idx: 40 |  Loss: (0.0148) | Acc: (99.54%) (5224/5248)\n",
            "Epoch: 99 | Batch_idx: 50 |  Loss: (0.0145) | Acc: (99.56%) (6499/6528)\n",
            "Epoch: 99 | Batch_idx: 60 |  Loss: (0.0143) | Acc: (99.58%) (7775/7808)\n",
            "Epoch: 99 | Batch_idx: 70 |  Loss: (0.0151) | Acc: (99.54%) (9046/9088)\n",
            "Epoch: 99 | Batch_idx: 80 |  Loss: (0.0152) | Acc: (99.52%) (10318/10368)\n",
            "Epoch: 99 | Batch_idx: 90 |  Loss: (0.0164) | Acc: (99.48%) (11587/11648)\n",
            "Epoch: 99 | Batch_idx: 100 |  Loss: (0.0161) | Acc: (99.48%) (12861/12928)\n",
            "Epoch: 99 | Batch_idx: 110 |  Loss: (0.0157) | Acc: (99.49%) (14136/14208)\n",
            "Epoch: 99 | Batch_idx: 120 |  Loss: (0.0158) | Acc: (99.48%) (15407/15488)\n",
            "Epoch: 99 | Batch_idx: 130 |  Loss: (0.0160) | Acc: (99.46%) (16677/16768)\n",
            "Epoch: 99 | Batch_idx: 140 |  Loss: (0.0161) | Acc: (99.46%) (17951/18048)\n",
            "Epoch: 99 | Batch_idx: 150 |  Loss: (0.0166) | Acc: (99.45%) (19222/19328)\n",
            "Epoch: 99 | Batch_idx: 160 |  Loss: (0.0166) | Acc: (99.46%) (20496/20608)\n",
            "Epoch: 99 | Batch_idx: 170 |  Loss: (0.0169) | Acc: (99.44%) (21766/21888)\n",
            "Epoch: 99 | Batch_idx: 180 |  Loss: (0.0175) | Acc: (99.41%) (23032/23168)\n",
            "Epoch: 99 | Batch_idx: 190 |  Loss: (0.0179) | Acc: (99.39%) (24299/24448)\n",
            "Epoch: 99 | Batch_idx: 200 |  Loss: (0.0181) | Acc: (99.39%) (25570/25728)\n",
            "Epoch: 99 | Batch_idx: 210 |  Loss: (0.0180) | Acc: (99.39%) (26842/27008)\n",
            "Epoch: 99 | Batch_idx: 220 |  Loss: (0.0178) | Acc: (99.38%) (28114/28288)\n",
            "Epoch: 99 | Batch_idx: 230 |  Loss: (0.0177) | Acc: (99.39%) (29387/29568)\n",
            "Epoch: 99 | Batch_idx: 240 |  Loss: (0.0176) | Acc: (99.38%) (30658/30848)\n",
            "Epoch: 99 | Batch_idx: 250 |  Loss: (0.0180) | Acc: (99.37%) (31925/32128)\n",
            "Epoch: 99 | Batch_idx: 260 |  Loss: (0.0179) | Acc: (99.37%) (33199/33408)\n",
            "Epoch: 99 | Batch_idx: 270 |  Loss: (0.0180) | Acc: (99.37%) (34468/34688)\n",
            "Epoch: 99 | Batch_idx: 280 |  Loss: (0.0178) | Acc: (99.37%) (35743/35968)\n",
            "Epoch: 99 | Batch_idx: 290 |  Loss: (0.0177) | Acc: (99.37%) (37014/37248)\n",
            "Epoch: 99 | Batch_idx: 300 |  Loss: (0.0176) | Acc: (99.38%) (38289/38528)\n",
            "Epoch: 99 | Batch_idx: 310 |  Loss: (0.0177) | Acc: (99.38%) (39561/39808)\n",
            "Epoch: 99 | Batch_idx: 320 |  Loss: (0.0176) | Acc: (99.39%) (40836/41088)\n",
            "Epoch: 99 | Batch_idx: 330 |  Loss: (0.0177) | Acc: (99.39%) (42109/42368)\n",
            "Epoch: 99 | Batch_idx: 340 |  Loss: (0.0177) | Acc: (99.39%) (43382/43648)\n",
            "Epoch: 99 | Batch_idx: 350 |  Loss: (0.0174) | Acc: (99.40%) (44659/44928)\n",
            "Epoch: 99 | Batch_idx: 360 |  Loss: (0.0174) | Acc: (99.41%) (45934/46208)\n",
            "Epoch: 99 | Batch_idx: 370 |  Loss: (0.0175) | Acc: (99.41%) (47206/47488)\n",
            "Epoch: 99 | Batch_idx: 380 |  Loss: (0.0174) | Acc: (99.41%) (48479/48768)\n",
            "Epoch: 99 | Batch_idx: 390 |  Loss: (0.0178) | Acc: (99.40%) (49698/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4068) | Acc: (91.39%) (9139/10000)\n",
            "Epoch: 100 | Batch_idx: 0 |  Loss: (0.0081) | Acc: (100.00%) (128/128)\n",
            "Epoch: 100 | Batch_idx: 10 |  Loss: (0.0134) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 100 | Batch_idx: 20 |  Loss: (0.0167) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 100 | Batch_idx: 30 |  Loss: (0.0163) | Acc: (99.47%) (3947/3968)\n",
            "Epoch: 100 | Batch_idx: 40 |  Loss: (0.0178) | Acc: (99.35%) (5214/5248)\n",
            "Epoch: 100 | Batch_idx: 50 |  Loss: (0.0210) | Acc: (99.34%) (6485/6528)\n",
            "Epoch: 100 | Batch_idx: 60 |  Loss: (0.0200) | Acc: (99.35%) (7757/7808)\n",
            "Epoch: 100 | Batch_idx: 70 |  Loss: (0.0199) | Acc: (99.36%) (9030/9088)\n",
            "Epoch: 100 | Batch_idx: 80 |  Loss: (0.0195) | Acc: (99.34%) (10300/10368)\n",
            "Epoch: 100 | Batch_idx: 90 |  Loss: (0.0189) | Acc: (99.37%) (11575/11648)\n",
            "Epoch: 100 | Batch_idx: 100 |  Loss: (0.0184) | Acc: (99.38%) (12848/12928)\n",
            "Epoch: 100 | Batch_idx: 110 |  Loss: (0.0178) | Acc: (99.41%) (14124/14208)\n",
            "Epoch: 100 | Batch_idx: 120 |  Loss: (0.0182) | Acc: (99.41%) (15397/15488)\n",
            "Epoch: 100 | Batch_idx: 130 |  Loss: (0.0183) | Acc: (99.42%) (16670/16768)\n",
            "Epoch: 100 | Batch_idx: 140 |  Loss: (0.0184) | Acc: (99.41%) (17941/18048)\n",
            "Epoch: 100 | Batch_idx: 150 |  Loss: (0.0185) | Acc: (99.41%) (19213/19328)\n",
            "Epoch: 100 | Batch_idx: 160 |  Loss: (0.0191) | Acc: (99.36%) (20476/20608)\n",
            "Epoch: 100 | Batch_idx: 170 |  Loss: (0.0192) | Acc: (99.36%) (21748/21888)\n",
            "Epoch: 100 | Batch_idx: 180 |  Loss: (0.0193) | Acc: (99.36%) (23019/23168)\n",
            "Epoch: 100 | Batch_idx: 190 |  Loss: (0.0190) | Acc: (99.37%) (24293/24448)\n",
            "Epoch: 100 | Batch_idx: 200 |  Loss: (0.0191) | Acc: (99.37%) (25565/25728)\n",
            "Epoch: 100 | Batch_idx: 210 |  Loss: (0.0195) | Acc: (99.36%) (26834/27008)\n",
            "Epoch: 100 | Batch_idx: 220 |  Loss: (0.0197) | Acc: (99.34%) (28101/28288)\n",
            "Epoch: 100 | Batch_idx: 230 |  Loss: (0.0196) | Acc: (99.34%) (29374/29568)\n",
            "Epoch: 100 | Batch_idx: 240 |  Loss: (0.0194) | Acc: (99.35%) (30649/30848)\n",
            "Epoch: 100 | Batch_idx: 250 |  Loss: (0.0197) | Acc: (99.34%) (31917/32128)\n",
            "Epoch: 100 | Batch_idx: 260 |  Loss: (0.0196) | Acc: (99.35%) (33192/33408)\n",
            "Epoch: 100 | Batch_idx: 270 |  Loss: (0.0192) | Acc: (99.35%) (34464/34688)\n",
            "Epoch: 100 | Batch_idx: 280 |  Loss: (0.0193) | Acc: (99.35%) (35735/35968)\n",
            "Epoch: 100 | Batch_idx: 290 |  Loss: (0.0193) | Acc: (99.35%) (37007/37248)\n",
            "Epoch: 100 | Batch_idx: 300 |  Loss: (0.0192) | Acc: (99.36%) (38282/38528)\n",
            "Epoch: 100 | Batch_idx: 310 |  Loss: (0.0192) | Acc: (99.36%) (39552/39808)\n",
            "Epoch: 100 | Batch_idx: 320 |  Loss: (0.0194) | Acc: (99.35%) (40819/41088)\n",
            "Epoch: 100 | Batch_idx: 330 |  Loss: (0.0196) | Acc: (99.34%) (42087/42368)\n",
            "Epoch: 100 | Batch_idx: 340 |  Loss: (0.0194) | Acc: (99.34%) (43361/43648)\n",
            "Epoch: 100 | Batch_idx: 350 |  Loss: (0.0194) | Acc: (99.34%) (44630/44928)\n",
            "Epoch: 100 | Batch_idx: 360 |  Loss: (0.0195) | Acc: (99.32%) (45894/46208)\n",
            "Epoch: 100 | Batch_idx: 370 |  Loss: (0.0193) | Acc: (99.33%) (47168/47488)\n",
            "Epoch: 100 | Batch_idx: 380 |  Loss: (0.0193) | Acc: (99.33%) (48441/48768)\n",
            "Epoch: 100 | Batch_idx: 390 |  Loss: (0.0193) | Acc: (99.33%) (49665/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4015) | Acc: (91.55%) (9155/10000)\n",
            "Epoch: 101 | Batch_idx: 0 |  Loss: (0.0033) | Acc: (100.00%) (128/128)\n",
            "Epoch: 101 | Batch_idx: 10 |  Loss: (0.0142) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 101 | Batch_idx: 20 |  Loss: (0.0197) | Acc: (99.26%) (2668/2688)\n",
            "Epoch: 101 | Batch_idx: 30 |  Loss: (0.0185) | Acc: (99.27%) (3939/3968)\n",
            "Epoch: 101 | Batch_idx: 40 |  Loss: (0.0177) | Acc: (99.33%) (5213/5248)\n",
            "Epoch: 101 | Batch_idx: 50 |  Loss: (0.0195) | Acc: (99.26%) (6480/6528)\n",
            "Epoch: 101 | Batch_idx: 60 |  Loss: (0.0184) | Acc: (99.31%) (7754/7808)\n",
            "Epoch: 101 | Batch_idx: 70 |  Loss: (0.0178) | Acc: (99.35%) (9029/9088)\n",
            "Epoch: 101 | Batch_idx: 80 |  Loss: (0.0175) | Acc: (99.37%) (10303/10368)\n",
            "Epoch: 101 | Batch_idx: 90 |  Loss: (0.0183) | Acc: (99.33%) (11570/11648)\n",
            "Epoch: 101 | Batch_idx: 100 |  Loss: (0.0182) | Acc: (99.31%) (12839/12928)\n",
            "Epoch: 101 | Batch_idx: 110 |  Loss: (0.0180) | Acc: (99.32%) (14112/14208)\n",
            "Epoch: 101 | Batch_idx: 120 |  Loss: (0.0180) | Acc: (99.33%) (15384/15488)\n",
            "Epoch: 101 | Batch_idx: 130 |  Loss: (0.0188) | Acc: (99.31%) (16652/16768)\n",
            "Epoch: 101 | Batch_idx: 140 |  Loss: (0.0184) | Acc: (99.34%) (17929/18048)\n",
            "Epoch: 101 | Batch_idx: 150 |  Loss: (0.0182) | Acc: (99.34%) (19201/19328)\n",
            "Epoch: 101 | Batch_idx: 160 |  Loss: (0.0185) | Acc: (99.33%) (20469/20608)\n",
            "Epoch: 101 | Batch_idx: 170 |  Loss: (0.0185) | Acc: (99.32%) (21739/21888)\n",
            "Epoch: 101 | Batch_idx: 180 |  Loss: (0.0187) | Acc: (99.33%) (23012/23168)\n",
            "Epoch: 101 | Batch_idx: 190 |  Loss: (0.0190) | Acc: (99.32%) (24281/24448)\n",
            "Epoch: 101 | Batch_idx: 200 |  Loss: (0.0187) | Acc: (99.33%) (25556/25728)\n",
            "Epoch: 101 | Batch_idx: 210 |  Loss: (0.0193) | Acc: (99.30%) (26819/27008)\n",
            "Epoch: 101 | Batch_idx: 220 |  Loss: (0.0194) | Acc: (99.31%) (28092/28288)\n",
            "Epoch: 101 | Batch_idx: 230 |  Loss: (0.0197) | Acc: (99.30%) (29361/29568)\n",
            "Epoch: 101 | Batch_idx: 240 |  Loss: (0.0194) | Acc: (99.31%) (30634/30848)\n",
            "Epoch: 101 | Batch_idx: 250 |  Loss: (0.0193) | Acc: (99.32%) (31908/32128)\n",
            "Epoch: 101 | Batch_idx: 260 |  Loss: (0.0194) | Acc: (99.32%) (33180/33408)\n",
            "Epoch: 101 | Batch_idx: 270 |  Loss: (0.0193) | Acc: (99.31%) (34450/34688)\n",
            "Epoch: 101 | Batch_idx: 280 |  Loss: (0.0191) | Acc: (99.32%) (35725/35968)\n",
            "Epoch: 101 | Batch_idx: 290 |  Loss: (0.0189) | Acc: (99.34%) (37002/37248)\n",
            "Epoch: 101 | Batch_idx: 300 |  Loss: (0.0189) | Acc: (99.34%) (38272/38528)\n",
            "Epoch: 101 | Batch_idx: 310 |  Loss: (0.0191) | Acc: (99.33%) (39542/39808)\n",
            "Epoch: 101 | Batch_idx: 320 |  Loss: (0.0189) | Acc: (99.34%) (40818/41088)\n",
            "Epoch: 101 | Batch_idx: 330 |  Loss: (0.0189) | Acc: (99.34%) (42089/42368)\n",
            "Epoch: 101 | Batch_idx: 340 |  Loss: (0.0189) | Acc: (99.34%) (43361/43648)\n",
            "Epoch: 101 | Batch_idx: 350 |  Loss: (0.0187) | Acc: (99.35%) (44634/44928)\n",
            "Epoch: 101 | Batch_idx: 360 |  Loss: (0.0185) | Acc: (99.36%) (45912/46208)\n",
            "Epoch: 101 | Batch_idx: 370 |  Loss: (0.0185) | Acc: (99.35%) (47178/47488)\n",
            "Epoch: 101 | Batch_idx: 380 |  Loss: (0.0182) | Acc: (99.36%) (48454/48768)\n",
            "Epoch: 101 | Batch_idx: 390 |  Loss: (0.0182) | Acc: (99.35%) (49677/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4078) | Acc: (91.39%) (9139/10000)\n",
            "Epoch: 102 | Batch_idx: 0 |  Loss: (0.0339) | Acc: (98.44%) (126/128)\n",
            "Epoch: 102 | Batch_idx: 10 |  Loss: (0.0175) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 102 | Batch_idx: 20 |  Loss: (0.0155) | Acc: (99.33%) (2670/2688)\n",
            "Epoch: 102 | Batch_idx: 30 |  Loss: (0.0141) | Acc: (99.42%) (3945/3968)\n",
            "Epoch: 102 | Batch_idx: 40 |  Loss: (0.0127) | Acc: (99.49%) (5221/5248)\n",
            "Epoch: 102 | Batch_idx: 50 |  Loss: (0.0139) | Acc: (99.46%) (6493/6528)\n",
            "Epoch: 102 | Batch_idx: 60 |  Loss: (0.0140) | Acc: (99.45%) (7765/7808)\n",
            "Epoch: 102 | Batch_idx: 70 |  Loss: (0.0142) | Acc: (99.44%) (9037/9088)\n",
            "Epoch: 102 | Batch_idx: 80 |  Loss: (0.0137) | Acc: (99.47%) (10313/10368)\n",
            "Epoch: 102 | Batch_idx: 90 |  Loss: (0.0149) | Acc: (99.44%) (11583/11648)\n",
            "Epoch: 102 | Batch_idx: 100 |  Loss: (0.0158) | Acc: (99.42%) (12853/12928)\n",
            "Epoch: 102 | Batch_idx: 110 |  Loss: (0.0156) | Acc: (99.42%) (14126/14208)\n",
            "Epoch: 102 | Batch_idx: 120 |  Loss: (0.0161) | Acc: (99.40%) (15395/15488)\n",
            "Epoch: 102 | Batch_idx: 130 |  Loss: (0.0163) | Acc: (99.39%) (16665/16768)\n",
            "Epoch: 102 | Batch_idx: 140 |  Loss: (0.0163) | Acc: (99.39%) (17938/18048)\n",
            "Epoch: 102 | Batch_idx: 150 |  Loss: (0.0162) | Acc: (99.39%) (19211/19328)\n",
            "Epoch: 102 | Batch_idx: 160 |  Loss: (0.0165) | Acc: (99.39%) (20482/20608)\n",
            "Epoch: 102 | Batch_idx: 170 |  Loss: (0.0164) | Acc: (99.39%) (21755/21888)\n",
            "Epoch: 102 | Batch_idx: 180 |  Loss: (0.0167) | Acc: (99.38%) (23024/23168)\n",
            "Epoch: 102 | Batch_idx: 190 |  Loss: (0.0175) | Acc: (99.35%) (24290/24448)\n",
            "Epoch: 102 | Batch_idx: 200 |  Loss: (0.0172) | Acc: (99.37%) (25566/25728)\n",
            "Epoch: 102 | Batch_idx: 210 |  Loss: (0.0169) | Acc: (99.39%) (26842/27008)\n",
            "Epoch: 102 | Batch_idx: 220 |  Loss: (0.0170) | Acc: (99.38%) (28114/28288)\n",
            "Epoch: 102 | Batch_idx: 230 |  Loss: (0.0168) | Acc: (99.39%) (29389/29568)\n",
            "Epoch: 102 | Batch_idx: 240 |  Loss: (0.0169) | Acc: (99.39%) (30660/30848)\n",
            "Epoch: 102 | Batch_idx: 250 |  Loss: (0.0170) | Acc: (99.39%) (31933/32128)\n",
            "Epoch: 102 | Batch_idx: 260 |  Loss: (0.0169) | Acc: (99.40%) (33206/33408)\n",
            "Epoch: 102 | Batch_idx: 270 |  Loss: (0.0172) | Acc: (99.39%) (34475/34688)\n",
            "Epoch: 102 | Batch_idx: 280 |  Loss: (0.0177) | Acc: (99.37%) (35743/35968)\n",
            "Epoch: 102 | Batch_idx: 290 |  Loss: (0.0178) | Acc: (99.36%) (37011/37248)\n",
            "Epoch: 102 | Batch_idx: 300 |  Loss: (0.0180) | Acc: (99.36%) (38283/38528)\n",
            "Epoch: 102 | Batch_idx: 310 |  Loss: (0.0181) | Acc: (99.36%) (39552/39808)\n",
            "Epoch: 102 | Batch_idx: 320 |  Loss: (0.0186) | Acc: (99.34%) (40817/41088)\n",
            "Epoch: 102 | Batch_idx: 330 |  Loss: (0.0187) | Acc: (99.34%) (42090/42368)\n",
            "Epoch: 102 | Batch_idx: 340 |  Loss: (0.0186) | Acc: (99.35%) (43363/43648)\n",
            "Epoch: 102 | Batch_idx: 350 |  Loss: (0.0186) | Acc: (99.35%) (44635/44928)\n",
            "Epoch: 102 | Batch_idx: 360 |  Loss: (0.0186) | Acc: (99.35%) (45906/46208)\n",
            "Epoch: 102 | Batch_idx: 370 |  Loss: (0.0186) | Acc: (99.35%) (47177/47488)\n",
            "Epoch: 102 | Batch_idx: 380 |  Loss: (0.0185) | Acc: (99.35%) (48451/48768)\n",
            "Epoch: 102 | Batch_idx: 390 |  Loss: (0.0183) | Acc: (99.35%) (49677/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4009) | Acc: (91.48%) (9148/10000)\n",
            "Epoch: 103 | Batch_idx: 0 |  Loss: (0.0051) | Acc: (100.00%) (128/128)\n",
            "Epoch: 103 | Batch_idx: 10 |  Loss: (0.0112) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 103 | Batch_idx: 20 |  Loss: (0.0136) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 103 | Batch_idx: 30 |  Loss: (0.0164) | Acc: (99.37%) (3943/3968)\n",
            "Epoch: 103 | Batch_idx: 40 |  Loss: (0.0168) | Acc: (99.39%) (5216/5248)\n",
            "Epoch: 103 | Batch_idx: 50 |  Loss: (0.0178) | Acc: (99.31%) (6483/6528)\n",
            "Epoch: 103 | Batch_idx: 60 |  Loss: (0.0195) | Acc: (99.27%) (7751/7808)\n",
            "Epoch: 103 | Batch_idx: 70 |  Loss: (0.0182) | Acc: (99.32%) (9026/9088)\n",
            "Epoch: 103 | Batch_idx: 80 |  Loss: (0.0186) | Acc: (99.32%) (10298/10368)\n",
            "Epoch: 103 | Batch_idx: 90 |  Loss: (0.0185) | Acc: (99.34%) (11571/11648)\n",
            "Epoch: 103 | Batch_idx: 100 |  Loss: (0.0191) | Acc: (99.31%) (12839/12928)\n",
            "Epoch: 103 | Batch_idx: 110 |  Loss: (0.0194) | Acc: (99.30%) (14109/14208)\n",
            "Epoch: 103 | Batch_idx: 120 |  Loss: (0.0188) | Acc: (99.32%) (15383/15488)\n",
            "Epoch: 103 | Batch_idx: 130 |  Loss: (0.0180) | Acc: (99.36%) (16660/16768)\n",
            "Epoch: 103 | Batch_idx: 140 |  Loss: (0.0183) | Acc: (99.36%) (17932/18048)\n",
            "Epoch: 103 | Batch_idx: 150 |  Loss: (0.0182) | Acc: (99.37%) (19206/19328)\n",
            "Epoch: 103 | Batch_idx: 160 |  Loss: (0.0181) | Acc: (99.38%) (20480/20608)\n",
            "Epoch: 103 | Batch_idx: 170 |  Loss: (0.0184) | Acc: (99.37%) (21750/21888)\n",
            "Epoch: 103 | Batch_idx: 180 |  Loss: (0.0185) | Acc: (99.37%) (23022/23168)\n",
            "Epoch: 103 | Batch_idx: 190 |  Loss: (0.0180) | Acc: (99.39%) (24298/24448)\n",
            "Epoch: 103 | Batch_idx: 200 |  Loss: (0.0176) | Acc: (99.39%) (25572/25728)\n",
            "Epoch: 103 | Batch_idx: 210 |  Loss: (0.0178) | Acc: (99.39%) (26842/27008)\n",
            "Epoch: 103 | Batch_idx: 220 |  Loss: (0.0174) | Acc: (99.40%) (28117/28288)\n",
            "Epoch: 103 | Batch_idx: 230 |  Loss: (0.0176) | Acc: (99.39%) (29389/29568)\n",
            "Epoch: 103 | Batch_idx: 240 |  Loss: (0.0180) | Acc: (99.37%) (30655/30848)\n",
            "Epoch: 103 | Batch_idx: 250 |  Loss: (0.0180) | Acc: (99.37%) (31927/32128)\n",
            "Epoch: 103 | Batch_idx: 260 |  Loss: (0.0181) | Acc: (99.36%) (33195/33408)\n",
            "Epoch: 103 | Batch_idx: 270 |  Loss: (0.0180) | Acc: (99.37%) (34468/34688)\n",
            "Epoch: 103 | Batch_idx: 280 |  Loss: (0.0180) | Acc: (99.36%) (35739/35968)\n",
            "Epoch: 103 | Batch_idx: 290 |  Loss: (0.0180) | Acc: (99.37%) (37012/37248)\n",
            "Epoch: 103 | Batch_idx: 300 |  Loss: (0.0179) | Acc: (99.37%) (38286/38528)\n",
            "Epoch: 103 | Batch_idx: 310 |  Loss: (0.0178) | Acc: (99.37%) (39558/39808)\n",
            "Epoch: 103 | Batch_idx: 320 |  Loss: (0.0177) | Acc: (99.37%) (40831/41088)\n",
            "Epoch: 103 | Batch_idx: 330 |  Loss: (0.0179) | Acc: (99.37%) (42100/42368)\n",
            "Epoch: 103 | Batch_idx: 340 |  Loss: (0.0178) | Acc: (99.37%) (43374/43648)\n",
            "Epoch: 103 | Batch_idx: 350 |  Loss: (0.0179) | Acc: (99.37%) (44644/44928)\n",
            "Epoch: 103 | Batch_idx: 360 |  Loss: (0.0181) | Acc: (99.36%) (45913/46208)\n",
            "Epoch: 103 | Batch_idx: 370 |  Loss: (0.0182) | Acc: (99.36%) (47183/47488)\n",
            "Epoch: 103 | Batch_idx: 380 |  Loss: (0.0182) | Acc: (99.36%) (48454/48768)\n",
            "Epoch: 103 | Batch_idx: 390 |  Loss: (0.0180) | Acc: (99.35%) (49677/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4028) | Acc: (91.46%) (9146/10000)\n",
            "Epoch: 104 | Batch_idx: 0 |  Loss: (0.0118) | Acc: (99.22%) (127/128)\n",
            "Epoch: 104 | Batch_idx: 10 |  Loss: (0.0183) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 104 | Batch_idx: 20 |  Loss: (0.0205) | Acc: (99.33%) (2670/2688)\n",
            "Epoch: 104 | Batch_idx: 30 |  Loss: (0.0218) | Acc: (99.34%) (3942/3968)\n",
            "Epoch: 104 | Batch_idx: 40 |  Loss: (0.0205) | Acc: (99.39%) (5216/5248)\n",
            "Epoch: 104 | Batch_idx: 50 |  Loss: (0.0190) | Acc: (99.46%) (6493/6528)\n",
            "Epoch: 104 | Batch_idx: 60 |  Loss: (0.0175) | Acc: (99.50%) (7769/7808)\n",
            "Epoch: 104 | Batch_idx: 70 |  Loss: (0.0176) | Acc: (99.46%) (9039/9088)\n",
            "Epoch: 104 | Batch_idx: 80 |  Loss: (0.0171) | Acc: (99.47%) (10313/10368)\n",
            "Epoch: 104 | Batch_idx: 90 |  Loss: (0.0170) | Acc: (99.45%) (11584/11648)\n",
            "Epoch: 104 | Batch_idx: 100 |  Loss: (0.0169) | Acc: (99.45%) (12857/12928)\n",
            "Epoch: 104 | Batch_idx: 110 |  Loss: (0.0167) | Acc: (99.47%) (14133/14208)\n",
            "Epoch: 104 | Batch_idx: 120 |  Loss: (0.0164) | Acc: (99.47%) (15406/15488)\n",
            "Epoch: 104 | Batch_idx: 130 |  Loss: (0.0162) | Acc: (99.47%) (16679/16768)\n",
            "Epoch: 104 | Batch_idx: 140 |  Loss: (0.0161) | Acc: (99.47%) (17952/18048)\n",
            "Epoch: 104 | Batch_idx: 150 |  Loss: (0.0165) | Acc: (99.45%) (19221/19328)\n",
            "Epoch: 104 | Batch_idx: 160 |  Loss: (0.0163) | Acc: (99.46%) (20496/20608)\n",
            "Epoch: 104 | Batch_idx: 170 |  Loss: (0.0162) | Acc: (99.47%) (21771/21888)\n",
            "Epoch: 104 | Batch_idx: 180 |  Loss: (0.0166) | Acc: (99.44%) (23038/23168)\n",
            "Epoch: 104 | Batch_idx: 190 |  Loss: (0.0166) | Acc: (99.43%) (24309/24448)\n",
            "Epoch: 104 | Batch_idx: 200 |  Loss: (0.0169) | Acc: (99.41%) (25577/25728)\n",
            "Epoch: 104 | Batch_idx: 210 |  Loss: (0.0170) | Acc: (99.41%) (26848/27008)\n",
            "Epoch: 104 | Batch_idx: 220 |  Loss: (0.0168) | Acc: (99.41%) (28122/28288)\n",
            "Epoch: 104 | Batch_idx: 230 |  Loss: (0.0168) | Acc: (99.42%) (29397/29568)\n",
            "Epoch: 104 | Batch_idx: 240 |  Loss: (0.0165) | Acc: (99.43%) (30672/30848)\n",
            "Epoch: 104 | Batch_idx: 250 |  Loss: (0.0161) | Acc: (99.44%) (31947/32128)\n",
            "Epoch: 104 | Batch_idx: 260 |  Loss: (0.0160) | Acc: (99.44%) (33222/33408)\n",
            "Epoch: 104 | Batch_idx: 270 |  Loss: (0.0163) | Acc: (99.44%) (34495/34688)\n",
            "Epoch: 104 | Batch_idx: 280 |  Loss: (0.0162) | Acc: (99.45%) (35771/35968)\n",
            "Epoch: 104 | Batch_idx: 290 |  Loss: (0.0161) | Acc: (99.44%) (37041/37248)\n",
            "Epoch: 104 | Batch_idx: 300 |  Loss: (0.0160) | Acc: (99.44%) (38314/38528)\n",
            "Epoch: 104 | Batch_idx: 310 |  Loss: (0.0156) | Acc: (99.46%) (39592/39808)\n",
            "Epoch: 104 | Batch_idx: 320 |  Loss: (0.0154) | Acc: (99.47%) (40870/41088)\n",
            "Epoch: 104 | Batch_idx: 330 |  Loss: (0.0158) | Acc: (99.45%) (42134/42368)\n",
            "Epoch: 104 | Batch_idx: 340 |  Loss: (0.0157) | Acc: (99.45%) (43407/43648)\n",
            "Epoch: 104 | Batch_idx: 350 |  Loss: (0.0157) | Acc: (99.45%) (44682/44928)\n",
            "Epoch: 104 | Batch_idx: 360 |  Loss: (0.0155) | Acc: (99.46%) (45959/46208)\n",
            "Epoch: 104 | Batch_idx: 370 |  Loss: (0.0153) | Acc: (99.46%) (47232/47488)\n",
            "Epoch: 104 | Batch_idx: 380 |  Loss: (0.0153) | Acc: (99.46%) (48507/48768)\n",
            "Epoch: 104 | Batch_idx: 390 |  Loss: (0.0154) | Acc: (99.47%) (49734/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4069) | Acc: (91.59%) (9159/10000)\n",
            "Epoch: 105 | Batch_idx: 0 |  Loss: (0.0043) | Acc: (100.00%) (128/128)\n",
            "Epoch: 105 | Batch_idx: 10 |  Loss: (0.0134) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 105 | Batch_idx: 20 |  Loss: (0.0147) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 105 | Batch_idx: 30 |  Loss: (0.0151) | Acc: (99.47%) (3947/3968)\n",
            "Epoch: 105 | Batch_idx: 40 |  Loss: (0.0157) | Acc: (99.47%) (5220/5248)\n",
            "Epoch: 105 | Batch_idx: 50 |  Loss: (0.0139) | Acc: (99.54%) (6498/6528)\n",
            "Epoch: 105 | Batch_idx: 60 |  Loss: (0.0134) | Acc: (99.55%) (7773/7808)\n",
            "Epoch: 105 | Batch_idx: 70 |  Loss: (0.0138) | Acc: (99.52%) (9044/9088)\n",
            "Epoch: 105 | Batch_idx: 80 |  Loss: (0.0133) | Acc: (99.53%) (10319/10368)\n",
            "Epoch: 105 | Batch_idx: 90 |  Loss: (0.0132) | Acc: (99.53%) (11593/11648)\n",
            "Epoch: 105 | Batch_idx: 100 |  Loss: (0.0136) | Acc: (99.49%) (12862/12928)\n",
            "Epoch: 105 | Batch_idx: 110 |  Loss: (0.0134) | Acc: (99.49%) (14136/14208)\n",
            "Epoch: 105 | Batch_idx: 120 |  Loss: (0.0144) | Acc: (99.48%) (15408/15488)\n",
            "Epoch: 105 | Batch_idx: 130 |  Loss: (0.0147) | Acc: (99.48%) (16680/16768)\n",
            "Epoch: 105 | Batch_idx: 140 |  Loss: (0.0151) | Acc: (99.46%) (17950/18048)\n",
            "Epoch: 105 | Batch_idx: 150 |  Loss: (0.0147) | Acc: (99.47%) (19226/19328)\n",
            "Epoch: 105 | Batch_idx: 160 |  Loss: (0.0153) | Acc: (99.45%) (20495/20608)\n",
            "Epoch: 105 | Batch_idx: 170 |  Loss: (0.0152) | Acc: (99.46%) (21770/21888)\n",
            "Epoch: 105 | Batch_idx: 180 |  Loss: (0.0151) | Acc: (99.46%) (23043/23168)\n",
            "Epoch: 105 | Batch_idx: 190 |  Loss: (0.0154) | Acc: (99.45%) (24314/24448)\n",
            "Epoch: 105 | Batch_idx: 200 |  Loss: (0.0154) | Acc: (99.44%) (25585/25728)\n",
            "Epoch: 105 | Batch_idx: 210 |  Loss: (0.0154) | Acc: (99.43%) (26855/27008)\n",
            "Epoch: 105 | Batch_idx: 220 |  Loss: (0.0153) | Acc: (99.44%) (28129/28288)\n",
            "Epoch: 105 | Batch_idx: 230 |  Loss: (0.0155) | Acc: (99.43%) (29399/29568)\n",
            "Epoch: 105 | Batch_idx: 240 |  Loss: (0.0153) | Acc: (99.43%) (30673/30848)\n",
            "Epoch: 105 | Batch_idx: 250 |  Loss: (0.0153) | Acc: (99.44%) (31949/32128)\n",
            "Epoch: 105 | Batch_idx: 260 |  Loss: (0.0152) | Acc: (99.44%) (33221/33408)\n",
            "Epoch: 105 | Batch_idx: 270 |  Loss: (0.0152) | Acc: (99.44%) (34495/34688)\n",
            "Epoch: 105 | Batch_idx: 280 |  Loss: (0.0152) | Acc: (99.44%) (35768/35968)\n",
            "Epoch: 105 | Batch_idx: 290 |  Loss: (0.0157) | Acc: (99.44%) (37040/37248)\n",
            "Epoch: 105 | Batch_idx: 300 |  Loss: (0.0158) | Acc: (99.43%) (38309/38528)\n",
            "Epoch: 105 | Batch_idx: 310 |  Loss: (0.0158) | Acc: (99.43%) (39580/39808)\n",
            "Epoch: 105 | Batch_idx: 320 |  Loss: (0.0161) | Acc: (99.42%) (40850/41088)\n",
            "Epoch: 105 | Batch_idx: 330 |  Loss: (0.0159) | Acc: (99.43%) (42126/42368)\n",
            "Epoch: 105 | Batch_idx: 340 |  Loss: (0.0160) | Acc: (99.43%) (43398/43648)\n",
            "Epoch: 105 | Batch_idx: 350 |  Loss: (0.0159) | Acc: (99.43%) (44671/44928)\n",
            "Epoch: 105 | Batch_idx: 360 |  Loss: (0.0161) | Acc: (99.42%) (45942/46208)\n",
            "Epoch: 105 | Batch_idx: 370 |  Loss: (0.0161) | Acc: (99.43%) (47216/47488)\n",
            "Epoch: 105 | Batch_idx: 380 |  Loss: (0.0162) | Acc: (99.42%) (48487/48768)\n",
            "Epoch: 105 | Batch_idx: 390 |  Loss: (0.0160) | Acc: (99.43%) (49715/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4073) | Acc: (91.65%) (9165/10000)\n",
            "Epoch: 106 | Batch_idx: 0 |  Loss: (0.0009) | Acc: (100.00%) (128/128)\n",
            "Epoch: 106 | Batch_idx: 10 |  Loss: (0.0183) | Acc: (99.22%) (1397/1408)\n",
            "Epoch: 106 | Batch_idx: 20 |  Loss: (0.0153) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 106 | Batch_idx: 30 |  Loss: (0.0140) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 106 | Batch_idx: 40 |  Loss: (0.0154) | Acc: (99.43%) (5218/5248)\n",
            "Epoch: 106 | Batch_idx: 50 |  Loss: (0.0157) | Acc: (99.37%) (6487/6528)\n",
            "Epoch: 106 | Batch_idx: 60 |  Loss: (0.0158) | Acc: (99.37%) (7759/7808)\n",
            "Epoch: 106 | Batch_idx: 70 |  Loss: (0.0161) | Acc: (99.43%) (9036/9088)\n",
            "Epoch: 106 | Batch_idx: 80 |  Loss: (0.0173) | Acc: (99.41%) (10307/10368)\n",
            "Epoch: 106 | Batch_idx: 90 |  Loss: (0.0173) | Acc: (99.41%) (11579/11648)\n",
            "Epoch: 106 | Batch_idx: 100 |  Loss: (0.0178) | Acc: (99.37%) (12846/12928)\n",
            "Epoch: 106 | Batch_idx: 110 |  Loss: (0.0169) | Acc: (99.40%) (14123/14208)\n",
            "Epoch: 106 | Batch_idx: 120 |  Loss: (0.0174) | Acc: (99.39%) (15393/15488)\n",
            "Epoch: 106 | Batch_idx: 130 |  Loss: (0.0170) | Acc: (99.41%) (16669/16768)\n",
            "Epoch: 106 | Batch_idx: 140 |  Loss: (0.0176) | Acc: (99.39%) (17938/18048)\n",
            "Epoch: 106 | Batch_idx: 150 |  Loss: (0.0171) | Acc: (99.42%) (19215/19328)\n",
            "Epoch: 106 | Batch_idx: 160 |  Loss: (0.0173) | Acc: (99.41%) (20486/20608)\n",
            "Epoch: 106 | Batch_idx: 170 |  Loss: (0.0170) | Acc: (99.42%) (21762/21888)\n",
            "Epoch: 106 | Batch_idx: 180 |  Loss: (0.0175) | Acc: (99.41%) (23031/23168)\n",
            "Epoch: 106 | Batch_idx: 190 |  Loss: (0.0178) | Acc: (99.41%) (24304/24448)\n",
            "Epoch: 106 | Batch_idx: 200 |  Loss: (0.0180) | Acc: (99.41%) (25577/25728)\n",
            "Epoch: 106 | Batch_idx: 210 |  Loss: (0.0176) | Acc: (99.43%) (26853/27008)\n",
            "Epoch: 106 | Batch_idx: 220 |  Loss: (0.0178) | Acc: (99.42%) (28125/28288)\n",
            "Epoch: 106 | Batch_idx: 230 |  Loss: (0.0176) | Acc: (99.43%) (29398/29568)\n",
            "Epoch: 106 | Batch_idx: 240 |  Loss: (0.0174) | Acc: (99.43%) (30671/30848)\n",
            "Epoch: 106 | Batch_idx: 250 |  Loss: (0.0172) | Acc: (99.43%) (31945/32128)\n",
            "Epoch: 106 | Batch_idx: 260 |  Loss: (0.0174) | Acc: (99.44%) (33220/33408)\n",
            "Epoch: 106 | Batch_idx: 270 |  Loss: (0.0176) | Acc: (99.43%) (34489/34688)\n",
            "Epoch: 106 | Batch_idx: 280 |  Loss: (0.0175) | Acc: (99.42%) (35761/35968)\n",
            "Epoch: 106 | Batch_idx: 290 |  Loss: (0.0177) | Acc: (99.41%) (37028/37248)\n",
            "Epoch: 106 | Batch_idx: 300 |  Loss: (0.0176) | Acc: (99.42%) (38304/38528)\n",
            "Epoch: 106 | Batch_idx: 310 |  Loss: (0.0173) | Acc: (99.43%) (39580/39808)\n",
            "Epoch: 106 | Batch_idx: 320 |  Loss: (0.0174) | Acc: (99.42%) (40849/41088)\n",
            "Epoch: 106 | Batch_idx: 330 |  Loss: (0.0174) | Acc: (99.41%) (42120/42368)\n",
            "Epoch: 106 | Batch_idx: 340 |  Loss: (0.0174) | Acc: (99.41%) (43389/43648)\n",
            "Epoch: 106 | Batch_idx: 350 |  Loss: (0.0175) | Acc: (99.41%) (44661/44928)\n",
            "Epoch: 106 | Batch_idx: 360 |  Loss: (0.0174) | Acc: (99.41%) (45935/46208)\n",
            "Epoch: 106 | Batch_idx: 370 |  Loss: (0.0174) | Acc: (99.41%) (47209/47488)\n",
            "Epoch: 106 | Batch_idx: 380 |  Loss: (0.0174) | Acc: (99.41%) (48482/48768)\n",
            "Epoch: 106 | Batch_idx: 390 |  Loss: (0.0173) | Acc: (99.41%) (49707/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4032) | Acc: (91.46%) (9146/10000)\n",
            "Epoch: 107 | Batch_idx: 0 |  Loss: (0.0108) | Acc: (99.22%) (127/128)\n",
            "Epoch: 107 | Batch_idx: 10 |  Loss: (0.0136) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 107 | Batch_idx: 20 |  Loss: (0.0128) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 107 | Batch_idx: 30 |  Loss: (0.0133) | Acc: (99.42%) (3945/3968)\n",
            "Epoch: 107 | Batch_idx: 40 |  Loss: (0.0128) | Acc: (99.47%) (5220/5248)\n",
            "Epoch: 107 | Batch_idx: 50 |  Loss: (0.0126) | Acc: (99.48%) (6494/6528)\n",
            "Epoch: 107 | Batch_idx: 60 |  Loss: (0.0125) | Acc: (99.47%) (7767/7808)\n",
            "Epoch: 107 | Batch_idx: 70 |  Loss: (0.0122) | Acc: (99.48%) (9041/9088)\n",
            "Epoch: 107 | Batch_idx: 80 |  Loss: (0.0126) | Acc: (99.51%) (10317/10368)\n",
            "Epoch: 107 | Batch_idx: 90 |  Loss: (0.0138) | Acc: (99.49%) (11589/11648)\n",
            "Epoch: 107 | Batch_idx: 100 |  Loss: (0.0140) | Acc: (99.49%) (12862/12928)\n",
            "Epoch: 107 | Batch_idx: 110 |  Loss: (0.0137) | Acc: (99.49%) (14136/14208)\n",
            "Epoch: 107 | Batch_idx: 120 |  Loss: (0.0140) | Acc: (99.50%) (15410/15488)\n",
            "Epoch: 107 | Batch_idx: 130 |  Loss: (0.0142) | Acc: (99.50%) (16684/16768)\n",
            "Epoch: 107 | Batch_idx: 140 |  Loss: (0.0140) | Acc: (99.49%) (17956/18048)\n",
            "Epoch: 107 | Batch_idx: 150 |  Loss: (0.0141) | Acc: (99.49%) (19229/19328)\n",
            "Epoch: 107 | Batch_idx: 160 |  Loss: (0.0142) | Acc: (99.48%) (20501/20608)\n",
            "Epoch: 107 | Batch_idx: 170 |  Loss: (0.0143) | Acc: (99.49%) (21777/21888)\n",
            "Epoch: 107 | Batch_idx: 180 |  Loss: (0.0150) | Acc: (99.46%) (23044/23168)\n",
            "Epoch: 107 | Batch_idx: 190 |  Loss: (0.0150) | Acc: (99.46%) (24317/24448)\n",
            "Epoch: 107 | Batch_idx: 200 |  Loss: (0.0153) | Acc: (99.46%) (25588/25728)\n",
            "Epoch: 107 | Batch_idx: 210 |  Loss: (0.0155) | Acc: (99.45%) (26860/27008)\n",
            "Epoch: 107 | Batch_idx: 220 |  Loss: (0.0152) | Acc: (99.46%) (28134/28288)\n",
            "Epoch: 107 | Batch_idx: 230 |  Loss: (0.0153) | Acc: (99.45%) (29406/29568)\n",
            "Epoch: 107 | Batch_idx: 240 |  Loss: (0.0158) | Acc: (99.44%) (30676/30848)\n",
            "Epoch: 107 | Batch_idx: 250 |  Loss: (0.0157) | Acc: (99.45%) (31951/32128)\n",
            "Epoch: 107 | Batch_idx: 260 |  Loss: (0.0160) | Acc: (99.43%) (33219/33408)\n",
            "Epoch: 107 | Batch_idx: 270 |  Loss: (0.0158) | Acc: (99.44%) (34494/34688)\n",
            "Epoch: 107 | Batch_idx: 280 |  Loss: (0.0159) | Acc: (99.43%) (35764/35968)\n",
            "Epoch: 107 | Batch_idx: 290 |  Loss: (0.0162) | Acc: (99.43%) (37034/37248)\n",
            "Epoch: 107 | Batch_idx: 300 |  Loss: (0.0160) | Acc: (99.43%) (38310/38528)\n",
            "Epoch: 107 | Batch_idx: 310 |  Loss: (0.0163) | Acc: (99.43%) (39580/39808)\n",
            "Epoch: 107 | Batch_idx: 320 |  Loss: (0.0161) | Acc: (99.44%) (40856/41088)\n",
            "Epoch: 107 | Batch_idx: 330 |  Loss: (0.0162) | Acc: (99.44%) (42129/42368)\n",
            "Epoch: 107 | Batch_idx: 340 |  Loss: (0.0161) | Acc: (99.44%) (43403/43648)\n",
            "Epoch: 107 | Batch_idx: 350 |  Loss: (0.0160) | Acc: (99.44%) (44677/44928)\n",
            "Epoch: 107 | Batch_idx: 360 |  Loss: (0.0160) | Acc: (99.44%) (45947/46208)\n",
            "Epoch: 107 | Batch_idx: 370 |  Loss: (0.0161) | Acc: (99.43%) (47217/47488)\n",
            "Epoch: 107 | Batch_idx: 380 |  Loss: (0.0158) | Acc: (99.44%) (48495/48768)\n",
            "Epoch: 107 | Batch_idx: 390 |  Loss: (0.0159) | Acc: (99.44%) (49719/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4078) | Acc: (91.28%) (9128/10000)\n",
            "Epoch: 108 | Batch_idx: 0 |  Loss: (0.0014) | Acc: (100.00%) (128/128)\n",
            "Epoch: 108 | Batch_idx: 10 |  Loss: (0.0162) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 108 | Batch_idx: 20 |  Loss: (0.0152) | Acc: (99.52%) (2675/2688)\n",
            "Epoch: 108 | Batch_idx: 30 |  Loss: (0.0148) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 108 | Batch_idx: 40 |  Loss: (0.0130) | Acc: (99.58%) (5226/5248)\n",
            "Epoch: 108 | Batch_idx: 50 |  Loss: (0.0127) | Acc: (99.56%) (6499/6528)\n",
            "Epoch: 108 | Batch_idx: 60 |  Loss: (0.0137) | Acc: (99.54%) (7772/7808)\n",
            "Epoch: 108 | Batch_idx: 70 |  Loss: (0.0140) | Acc: (99.49%) (9042/9088)\n",
            "Epoch: 108 | Batch_idx: 80 |  Loss: (0.0150) | Acc: (99.49%) (10315/10368)\n",
            "Epoch: 108 | Batch_idx: 90 |  Loss: (0.0147) | Acc: (99.51%) (11591/11648)\n",
            "Epoch: 108 | Batch_idx: 100 |  Loss: (0.0149) | Acc: (99.50%) (12863/12928)\n",
            "Epoch: 108 | Batch_idx: 110 |  Loss: (0.0156) | Acc: (99.51%) (14138/14208)\n",
            "Epoch: 108 | Batch_idx: 120 |  Loss: (0.0156) | Acc: (99.51%) (15412/15488)\n",
            "Epoch: 108 | Batch_idx: 130 |  Loss: (0.0150) | Acc: (99.53%) (16689/16768)\n",
            "Epoch: 108 | Batch_idx: 140 |  Loss: (0.0152) | Acc: (99.51%) (17959/18048)\n",
            "Epoch: 108 | Batch_idx: 150 |  Loss: (0.0149) | Acc: (99.52%) (19235/19328)\n",
            "Epoch: 108 | Batch_idx: 160 |  Loss: (0.0148) | Acc: (99.51%) (20508/20608)\n",
            "Epoch: 108 | Batch_idx: 170 |  Loss: (0.0147) | Acc: (99.52%) (21784/21888)\n",
            "Epoch: 108 | Batch_idx: 180 |  Loss: (0.0145) | Acc: (99.52%) (23057/23168)\n",
            "Epoch: 108 | Batch_idx: 190 |  Loss: (0.0147) | Acc: (99.51%) (24328/24448)\n",
            "Epoch: 108 | Batch_idx: 200 |  Loss: (0.0148) | Acc: (99.51%) (25603/25728)\n",
            "Epoch: 108 | Batch_idx: 210 |  Loss: (0.0148) | Acc: (99.51%) (26876/27008)\n",
            "Epoch: 108 | Batch_idx: 220 |  Loss: (0.0149) | Acc: (99.50%) (28147/28288)\n",
            "Epoch: 108 | Batch_idx: 230 |  Loss: (0.0148) | Acc: (99.51%) (29422/29568)\n",
            "Epoch: 108 | Batch_idx: 240 |  Loss: (0.0147) | Acc: (99.51%) (30697/30848)\n",
            "Epoch: 108 | Batch_idx: 250 |  Loss: (0.0145) | Acc: (99.51%) (31970/32128)\n",
            "Epoch: 108 | Batch_idx: 260 |  Loss: (0.0146) | Acc: (99.50%) (33242/33408)\n",
            "Epoch: 108 | Batch_idx: 270 |  Loss: (0.0145) | Acc: (99.51%) (34518/34688)\n",
            "Epoch: 108 | Batch_idx: 280 |  Loss: (0.0146) | Acc: (99.50%) (35789/35968)\n",
            "Epoch: 108 | Batch_idx: 290 |  Loss: (0.0145) | Acc: (99.50%) (37062/37248)\n",
            "Epoch: 108 | Batch_idx: 300 |  Loss: (0.0145) | Acc: (99.49%) (38332/38528)\n",
            "Epoch: 108 | Batch_idx: 310 |  Loss: (0.0143) | Acc: (99.50%) (39609/39808)\n",
            "Epoch: 108 | Batch_idx: 320 |  Loss: (0.0143) | Acc: (99.50%) (40884/41088)\n",
            "Epoch: 108 | Batch_idx: 330 |  Loss: (0.0141) | Acc: (99.51%) (42162/42368)\n",
            "Epoch: 108 | Batch_idx: 340 |  Loss: (0.0143) | Acc: (99.51%) (43433/43648)\n",
            "Epoch: 108 | Batch_idx: 350 |  Loss: (0.0143) | Acc: (99.50%) (44704/44928)\n",
            "Epoch: 108 | Batch_idx: 360 |  Loss: (0.0143) | Acc: (99.50%) (45977/46208)\n",
            "Epoch: 108 | Batch_idx: 370 |  Loss: (0.0144) | Acc: (99.50%) (47250/47488)\n",
            "Epoch: 108 | Batch_idx: 380 |  Loss: (0.0145) | Acc: (99.50%) (48524/48768)\n",
            "Epoch: 108 | Batch_idx: 390 |  Loss: (0.0145) | Acc: (99.50%) (49748/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4153) | Acc: (91.46%) (9146/10000)\n",
            "Epoch: 109 | Batch_idx: 0 |  Loss: (0.0370) | Acc: (99.22%) (127/128)\n",
            "Epoch: 109 | Batch_idx: 10 |  Loss: (0.0238) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 109 | Batch_idx: 20 |  Loss: (0.0284) | Acc: (99.00%) (2661/2688)\n",
            "Epoch: 109 | Batch_idx: 30 |  Loss: (0.0243) | Acc: (99.14%) (3934/3968)\n",
            "Epoch: 109 | Batch_idx: 40 |  Loss: (0.0205) | Acc: (99.26%) (5209/5248)\n",
            "Epoch: 109 | Batch_idx: 50 |  Loss: (0.0188) | Acc: (99.33%) (6484/6528)\n",
            "Epoch: 109 | Batch_idx: 60 |  Loss: (0.0177) | Acc: (99.37%) (7759/7808)\n",
            "Epoch: 109 | Batch_idx: 70 |  Loss: (0.0172) | Acc: (99.41%) (9034/9088)\n",
            "Epoch: 109 | Batch_idx: 80 |  Loss: (0.0165) | Acc: (99.42%) (10308/10368)\n",
            "Epoch: 109 | Batch_idx: 90 |  Loss: (0.0168) | Acc: (99.41%) (11579/11648)\n",
            "Epoch: 109 | Batch_idx: 100 |  Loss: (0.0160) | Acc: (99.45%) (12857/12928)\n",
            "Epoch: 109 | Batch_idx: 110 |  Loss: (0.0159) | Acc: (99.42%) (14126/14208)\n",
            "Epoch: 109 | Batch_idx: 120 |  Loss: (0.0153) | Acc: (99.44%) (15401/15488)\n",
            "Epoch: 109 | Batch_idx: 130 |  Loss: (0.0157) | Acc: (99.43%) (16673/16768)\n",
            "Epoch: 109 | Batch_idx: 140 |  Loss: (0.0164) | Acc: (99.42%) (17944/18048)\n",
            "Epoch: 109 | Batch_idx: 150 |  Loss: (0.0160) | Acc: (99.44%) (19220/19328)\n",
            "Epoch: 109 | Batch_idx: 160 |  Loss: (0.0161) | Acc: (99.43%) (20490/20608)\n",
            "Epoch: 109 | Batch_idx: 170 |  Loss: (0.0158) | Acc: (99.42%) (21762/21888)\n",
            "Epoch: 109 | Batch_idx: 180 |  Loss: (0.0158) | Acc: (99.43%) (23037/23168)\n",
            "Epoch: 109 | Batch_idx: 190 |  Loss: (0.0155) | Acc: (99.44%) (24312/24448)\n",
            "Epoch: 109 | Batch_idx: 200 |  Loss: (0.0155) | Acc: (99.43%) (25582/25728)\n",
            "Epoch: 109 | Batch_idx: 210 |  Loss: (0.0155) | Acc: (99.43%) (26854/27008)\n",
            "Epoch: 109 | Batch_idx: 220 |  Loss: (0.0153) | Acc: (99.43%) (28127/28288)\n",
            "Epoch: 109 | Batch_idx: 230 |  Loss: (0.0157) | Acc: (99.41%) (29395/29568)\n",
            "Epoch: 109 | Batch_idx: 240 |  Loss: (0.0155) | Acc: (99.43%) (30671/30848)\n",
            "Epoch: 109 | Batch_idx: 250 |  Loss: (0.0153) | Acc: (99.43%) (31946/32128)\n",
            "Epoch: 109 | Batch_idx: 260 |  Loss: (0.0158) | Acc: (99.41%) (33210/33408)\n",
            "Epoch: 109 | Batch_idx: 270 |  Loss: (0.0155) | Acc: (99.42%) (34488/34688)\n",
            "Epoch: 109 | Batch_idx: 280 |  Loss: (0.0151) | Acc: (99.44%) (35767/35968)\n",
            "Epoch: 109 | Batch_idx: 290 |  Loss: (0.0150) | Acc: (99.45%) (37043/37248)\n",
            "Epoch: 109 | Batch_idx: 300 |  Loss: (0.0149) | Acc: (99.46%) (38319/38528)\n",
            "Epoch: 109 | Batch_idx: 310 |  Loss: (0.0149) | Acc: (99.45%) (39590/39808)\n",
            "Epoch: 109 | Batch_idx: 320 |  Loss: (0.0147) | Acc: (99.46%) (40866/41088)\n",
            "Epoch: 109 | Batch_idx: 330 |  Loss: (0.0146) | Acc: (99.47%) (42143/42368)\n",
            "Epoch: 109 | Batch_idx: 340 |  Loss: (0.0143) | Acc: (99.48%) (43423/43648)\n",
            "Epoch: 109 | Batch_idx: 350 |  Loss: (0.0142) | Acc: (99.49%) (44700/44928)\n",
            "Epoch: 109 | Batch_idx: 360 |  Loss: (0.0142) | Acc: (99.49%) (45974/46208)\n",
            "Epoch: 109 | Batch_idx: 370 |  Loss: (0.0141) | Acc: (99.50%) (47249/47488)\n",
            "Epoch: 109 | Batch_idx: 380 |  Loss: (0.0140) | Acc: (99.50%) (48524/48768)\n",
            "Epoch: 109 | Batch_idx: 390 |  Loss: (0.0139) | Acc: (99.51%) (49754/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4105) | Acc: (91.68%) (9168/10000)\n",
            "Epoch: 110 | Batch_idx: 0 |  Loss: (0.0013) | Acc: (100.00%) (128/128)\n",
            "Epoch: 110 | Batch_idx: 10 |  Loss: (0.0115) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 110 | Batch_idx: 20 |  Loss: (0.0115) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 110 | Batch_idx: 30 |  Loss: (0.0114) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 110 | Batch_idx: 40 |  Loss: (0.0124) | Acc: (99.56%) (5225/5248)\n",
            "Epoch: 110 | Batch_idx: 50 |  Loss: (0.0138) | Acc: (99.51%) (6496/6528)\n",
            "Epoch: 110 | Batch_idx: 60 |  Loss: (0.0127) | Acc: (99.55%) (7773/7808)\n",
            "Epoch: 110 | Batch_idx: 70 |  Loss: (0.0121) | Acc: (99.57%) (9049/9088)\n",
            "Epoch: 110 | Batch_idx: 80 |  Loss: (0.0128) | Acc: (99.55%) (10321/10368)\n",
            "Epoch: 110 | Batch_idx: 90 |  Loss: (0.0131) | Acc: (99.55%) (11596/11648)\n",
            "Epoch: 110 | Batch_idx: 100 |  Loss: (0.0135) | Acc: (99.54%) (12869/12928)\n",
            "Epoch: 110 | Batch_idx: 110 |  Loss: (0.0136) | Acc: (99.54%) (14142/14208)\n",
            "Epoch: 110 | Batch_idx: 120 |  Loss: (0.0142) | Acc: (99.54%) (15417/15488)\n",
            "Epoch: 110 | Batch_idx: 130 |  Loss: (0.0136) | Acc: (99.56%) (16694/16768)\n",
            "Epoch: 110 | Batch_idx: 140 |  Loss: (0.0145) | Acc: (99.53%) (17964/18048)\n",
            "Epoch: 110 | Batch_idx: 150 |  Loss: (0.0143) | Acc: (99.54%) (19240/19328)\n",
            "Epoch: 110 | Batch_idx: 160 |  Loss: (0.0141) | Acc: (99.55%) (20516/20608)\n",
            "Epoch: 110 | Batch_idx: 170 |  Loss: (0.0138) | Acc: (99.56%) (21792/21888)\n",
            "Epoch: 110 | Batch_idx: 180 |  Loss: (0.0138) | Acc: (99.56%) (23065/23168)\n",
            "Epoch: 110 | Batch_idx: 190 |  Loss: (0.0142) | Acc: (99.54%) (24336/24448)\n",
            "Epoch: 110 | Batch_idx: 200 |  Loss: (0.0141) | Acc: (99.55%) (25613/25728)\n",
            "Epoch: 110 | Batch_idx: 210 |  Loss: (0.0139) | Acc: (99.57%) (26891/27008)\n",
            "Epoch: 110 | Batch_idx: 220 |  Loss: (0.0146) | Acc: (99.55%) (28161/28288)\n",
            "Epoch: 110 | Batch_idx: 230 |  Loss: (0.0145) | Acc: (99.56%) (29437/29568)\n",
            "Epoch: 110 | Batch_idx: 240 |  Loss: (0.0142) | Acc: (99.57%) (30714/30848)\n",
            "Epoch: 110 | Batch_idx: 250 |  Loss: (0.0142) | Acc: (99.57%) (31990/32128)\n",
            "Epoch: 110 | Batch_idx: 260 |  Loss: (0.0143) | Acc: (99.57%) (33264/33408)\n",
            "Epoch: 110 | Batch_idx: 270 |  Loss: (0.0142) | Acc: (99.57%) (34538/34688)\n",
            "Epoch: 110 | Batch_idx: 280 |  Loss: (0.0144) | Acc: (99.55%) (35807/35968)\n",
            "Epoch: 110 | Batch_idx: 290 |  Loss: (0.0144) | Acc: (99.55%) (37081/37248)\n",
            "Epoch: 110 | Batch_idx: 300 |  Loss: (0.0143) | Acc: (99.54%) (38352/38528)\n",
            "Epoch: 110 | Batch_idx: 310 |  Loss: (0.0143) | Acc: (99.55%) (39627/39808)\n",
            "Epoch: 110 | Batch_idx: 320 |  Loss: (0.0143) | Acc: (99.55%) (40902/41088)\n",
            "Epoch: 110 | Batch_idx: 330 |  Loss: (0.0142) | Acc: (99.55%) (42177/42368)\n",
            "Epoch: 110 | Batch_idx: 340 |  Loss: (0.0142) | Acc: (99.55%) (43450/43648)\n",
            "Epoch: 110 | Batch_idx: 350 |  Loss: (0.0142) | Acc: (99.55%) (44725/44928)\n",
            "Epoch: 110 | Batch_idx: 360 |  Loss: (0.0141) | Acc: (99.55%) (45999/46208)\n",
            "Epoch: 110 | Batch_idx: 370 |  Loss: (0.0141) | Acc: (99.55%) (47273/47488)\n",
            "Epoch: 110 | Batch_idx: 380 |  Loss: (0.0140) | Acc: (99.55%) (48549/48768)\n",
            "Epoch: 110 | Batch_idx: 390 |  Loss: (0.0141) | Acc: (99.54%) (49772/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4164) | Acc: (91.42%) (9142/10000)\n",
            "Epoch: 111 | Batch_idx: 0 |  Loss: (0.0331) | Acc: (99.22%) (127/128)\n",
            "Epoch: 111 | Batch_idx: 10 |  Loss: (0.0157) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 111 | Batch_idx: 20 |  Loss: (0.0116) | Acc: (99.52%) (2675/2688)\n",
            "Epoch: 111 | Batch_idx: 30 |  Loss: (0.0159) | Acc: (99.40%) (3944/3968)\n",
            "Epoch: 111 | Batch_idx: 40 |  Loss: (0.0186) | Acc: (99.24%) (5208/5248)\n",
            "Epoch: 111 | Batch_idx: 50 |  Loss: (0.0174) | Acc: (99.31%) (6483/6528)\n",
            "Epoch: 111 | Batch_idx: 60 |  Loss: (0.0180) | Acc: (99.35%) (7757/7808)\n",
            "Epoch: 111 | Batch_idx: 70 |  Loss: (0.0174) | Acc: (99.37%) (9031/9088)\n",
            "Epoch: 111 | Batch_idx: 80 |  Loss: (0.0186) | Acc: (99.35%) (10301/10368)\n",
            "Epoch: 111 | Batch_idx: 90 |  Loss: (0.0180) | Acc: (99.38%) (11576/11648)\n",
            "Epoch: 111 | Batch_idx: 100 |  Loss: (0.0177) | Acc: (99.40%) (12851/12928)\n",
            "Epoch: 111 | Batch_idx: 110 |  Loss: (0.0170) | Acc: (99.42%) (14126/14208)\n",
            "Epoch: 111 | Batch_idx: 120 |  Loss: (0.0169) | Acc: (99.41%) (15396/15488)\n",
            "Epoch: 111 | Batch_idx: 130 |  Loss: (0.0163) | Acc: (99.43%) (16673/16768)\n",
            "Epoch: 111 | Batch_idx: 140 |  Loss: (0.0167) | Acc: (99.41%) (17942/18048)\n",
            "Epoch: 111 | Batch_idx: 150 |  Loss: (0.0164) | Acc: (99.43%) (19218/19328)\n",
            "Epoch: 111 | Batch_idx: 160 |  Loss: (0.0169) | Acc: (99.41%) (20487/20608)\n",
            "Epoch: 111 | Batch_idx: 170 |  Loss: (0.0167) | Acc: (99.42%) (21761/21888)\n",
            "Epoch: 111 | Batch_idx: 180 |  Loss: (0.0167) | Acc: (99.41%) (23032/23168)\n",
            "Epoch: 111 | Batch_idx: 190 |  Loss: (0.0164) | Acc: (99.42%) (24306/24448)\n",
            "Epoch: 111 | Batch_idx: 200 |  Loss: (0.0167) | Acc: (99.41%) (25576/25728)\n",
            "Epoch: 111 | Batch_idx: 210 |  Loss: (0.0163) | Acc: (99.42%) (26851/27008)\n",
            "Epoch: 111 | Batch_idx: 220 |  Loss: (0.0161) | Acc: (99.42%) (28124/28288)\n",
            "Epoch: 111 | Batch_idx: 230 |  Loss: (0.0159) | Acc: (99.44%) (29401/29568)\n",
            "Epoch: 111 | Batch_idx: 240 |  Loss: (0.0157) | Acc: (99.44%) (30675/30848)\n",
            "Epoch: 111 | Batch_idx: 250 |  Loss: (0.0155) | Acc: (99.45%) (31950/32128)\n",
            "Epoch: 111 | Batch_idx: 260 |  Loss: (0.0151) | Acc: (99.46%) (33228/33408)\n",
            "Epoch: 111 | Batch_idx: 270 |  Loss: (0.0148) | Acc: (99.47%) (34505/34688)\n",
            "Epoch: 111 | Batch_idx: 280 |  Loss: (0.0147) | Acc: (99.47%) (35778/35968)\n",
            "Epoch: 111 | Batch_idx: 290 |  Loss: (0.0145) | Acc: (99.47%) (37052/37248)\n",
            "Epoch: 111 | Batch_idx: 300 |  Loss: (0.0144) | Acc: (99.48%) (38327/38528)\n",
            "Epoch: 111 | Batch_idx: 310 |  Loss: (0.0146) | Acc: (99.48%) (39601/39808)\n",
            "Epoch: 111 | Batch_idx: 320 |  Loss: (0.0146) | Acc: (99.48%) (40876/41088)\n",
            "Epoch: 111 | Batch_idx: 330 |  Loss: (0.0147) | Acc: (99.48%) (42149/42368)\n",
            "Epoch: 111 | Batch_idx: 340 |  Loss: (0.0146) | Acc: (99.48%) (43422/43648)\n",
            "Epoch: 111 | Batch_idx: 350 |  Loss: (0.0147) | Acc: (99.48%) (44695/44928)\n",
            "Epoch: 111 | Batch_idx: 360 |  Loss: (0.0149) | Acc: (99.47%) (45965/46208)\n",
            "Epoch: 111 | Batch_idx: 370 |  Loss: (0.0150) | Acc: (99.47%) (47237/47488)\n",
            "Epoch: 111 | Batch_idx: 380 |  Loss: (0.0148) | Acc: (99.48%) (48513/48768)\n",
            "Epoch: 111 | Batch_idx: 390 |  Loss: (0.0147) | Acc: (99.48%) (49741/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4246) | Acc: (91.08%) (9108/10000)\n",
            "Epoch: 112 | Batch_idx: 0 |  Loss: (0.0045) | Acc: (100.00%) (128/128)\n",
            "Epoch: 112 | Batch_idx: 10 |  Loss: (0.0092) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 112 | Batch_idx: 20 |  Loss: (0.0100) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 112 | Batch_idx: 30 |  Loss: (0.0105) | Acc: (99.65%) (3954/3968)\n",
            "Epoch: 112 | Batch_idx: 40 |  Loss: (0.0121) | Acc: (99.58%) (5226/5248)\n",
            "Epoch: 112 | Batch_idx: 50 |  Loss: (0.0134) | Acc: (99.54%) (6498/6528)\n",
            "Epoch: 112 | Batch_idx: 60 |  Loss: (0.0127) | Acc: (99.58%) (7775/7808)\n",
            "Epoch: 112 | Batch_idx: 70 |  Loss: (0.0133) | Acc: (99.55%) (9047/9088)\n",
            "Epoch: 112 | Batch_idx: 80 |  Loss: (0.0130) | Acc: (99.57%) (10323/10368)\n",
            "Epoch: 112 | Batch_idx: 90 |  Loss: (0.0125) | Acc: (99.57%) (11598/11648)\n",
            "Epoch: 112 | Batch_idx: 100 |  Loss: (0.0120) | Acc: (99.59%) (12875/12928)\n",
            "Epoch: 112 | Batch_idx: 110 |  Loss: (0.0121) | Acc: (99.58%) (14149/14208)\n",
            "Epoch: 112 | Batch_idx: 120 |  Loss: (0.0129) | Acc: (99.55%) (15419/15488)\n",
            "Epoch: 112 | Batch_idx: 130 |  Loss: (0.0127) | Acc: (99.56%) (16695/16768)\n",
            "Epoch: 112 | Batch_idx: 140 |  Loss: (0.0127) | Acc: (99.56%) (17968/18048)\n",
            "Epoch: 112 | Batch_idx: 150 |  Loss: (0.0126) | Acc: (99.56%) (19243/19328)\n",
            "Epoch: 112 | Batch_idx: 160 |  Loss: (0.0128) | Acc: (99.55%) (20515/20608)\n",
            "Epoch: 112 | Batch_idx: 170 |  Loss: (0.0127) | Acc: (99.56%) (21791/21888)\n",
            "Epoch: 112 | Batch_idx: 180 |  Loss: (0.0126) | Acc: (99.55%) (23064/23168)\n",
            "Epoch: 112 | Batch_idx: 190 |  Loss: (0.0131) | Acc: (99.54%) (24335/24448)\n",
            "Epoch: 112 | Batch_idx: 200 |  Loss: (0.0133) | Acc: (99.53%) (25608/25728)\n",
            "Epoch: 112 | Batch_idx: 210 |  Loss: (0.0134) | Acc: (99.53%) (26882/27008)\n",
            "Epoch: 112 | Batch_idx: 220 |  Loss: (0.0132) | Acc: (99.54%) (28157/28288)\n",
            "Epoch: 112 | Batch_idx: 230 |  Loss: (0.0137) | Acc: (99.51%) (29424/29568)\n",
            "Epoch: 112 | Batch_idx: 240 |  Loss: (0.0133) | Acc: (99.53%) (30703/30848)\n",
            "Epoch: 112 | Batch_idx: 250 |  Loss: (0.0133) | Acc: (99.53%) (31978/32128)\n",
            "Epoch: 112 | Batch_idx: 260 |  Loss: (0.0133) | Acc: (99.53%) (33251/33408)\n",
            "Epoch: 112 | Batch_idx: 270 |  Loss: (0.0133) | Acc: (99.52%) (34522/34688)\n",
            "Epoch: 112 | Batch_idx: 280 |  Loss: (0.0134) | Acc: (99.52%) (35795/35968)\n",
            "Epoch: 112 | Batch_idx: 290 |  Loss: (0.0133) | Acc: (99.52%) (37069/37248)\n",
            "Epoch: 112 | Batch_idx: 300 |  Loss: (0.0131) | Acc: (99.53%) (38346/38528)\n",
            "Epoch: 112 | Batch_idx: 310 |  Loss: (0.0129) | Acc: (99.54%) (39624/39808)\n",
            "Epoch: 112 | Batch_idx: 320 |  Loss: (0.0133) | Acc: (99.53%) (40896/41088)\n",
            "Epoch: 112 | Batch_idx: 330 |  Loss: (0.0130) | Acc: (99.54%) (42174/42368)\n",
            "Epoch: 112 | Batch_idx: 340 |  Loss: (0.0129) | Acc: (99.54%) (43447/43648)\n",
            "Epoch: 112 | Batch_idx: 350 |  Loss: (0.0129) | Acc: (99.54%) (44722/44928)\n",
            "Epoch: 112 | Batch_idx: 360 |  Loss: (0.0128) | Acc: (99.54%) (45995/46208)\n",
            "Epoch: 112 | Batch_idx: 370 |  Loss: (0.0130) | Acc: (99.54%) (47269/47488)\n",
            "Epoch: 112 | Batch_idx: 380 |  Loss: (0.0129) | Acc: (99.54%) (48546/48768)\n",
            "Epoch: 112 | Batch_idx: 390 |  Loss: (0.0131) | Acc: (99.54%) (49769/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4164) | Acc: (91.35%) (9135/10000)\n",
            "Epoch: 113 | Batch_idx: 0 |  Loss: (0.0054) | Acc: (100.00%) (128/128)\n",
            "Epoch: 113 | Batch_idx: 10 |  Loss: (0.0192) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 113 | Batch_idx: 20 |  Loss: (0.0163) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 113 | Batch_idx: 30 |  Loss: (0.0154) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 113 | Batch_idx: 40 |  Loss: (0.0168) | Acc: (99.49%) (5221/5248)\n",
            "Epoch: 113 | Batch_idx: 50 |  Loss: (0.0174) | Acc: (99.48%) (6494/6528)\n",
            "Epoch: 113 | Batch_idx: 60 |  Loss: (0.0162) | Acc: (99.49%) (7768/7808)\n",
            "Epoch: 113 | Batch_idx: 70 |  Loss: (0.0161) | Acc: (99.52%) (9044/9088)\n",
            "Epoch: 113 | Batch_idx: 80 |  Loss: (0.0156) | Acc: (99.54%) (10320/10368)\n",
            "Epoch: 113 | Batch_idx: 90 |  Loss: (0.0156) | Acc: (99.53%) (11593/11648)\n",
            "Epoch: 113 | Batch_idx: 100 |  Loss: (0.0155) | Acc: (99.53%) (12867/12928)\n",
            "Epoch: 113 | Batch_idx: 110 |  Loss: (0.0149) | Acc: (99.54%) (14142/14208)\n",
            "Epoch: 113 | Batch_idx: 120 |  Loss: (0.0160) | Acc: (99.51%) (15412/15488)\n",
            "Epoch: 113 | Batch_idx: 130 |  Loss: (0.0160) | Acc: (99.51%) (16685/16768)\n",
            "Epoch: 113 | Batch_idx: 140 |  Loss: (0.0156) | Acc: (99.52%) (17961/18048)\n",
            "Epoch: 113 | Batch_idx: 150 |  Loss: (0.0152) | Acc: (99.52%) (19236/19328)\n",
            "Epoch: 113 | Batch_idx: 160 |  Loss: (0.0154) | Acc: (99.51%) (20508/20608)\n",
            "Epoch: 113 | Batch_idx: 170 |  Loss: (0.0154) | Acc: (99.52%) (21782/21888)\n",
            "Epoch: 113 | Batch_idx: 180 |  Loss: (0.0149) | Acc: (99.53%) (23059/23168)\n",
            "Epoch: 113 | Batch_idx: 190 |  Loss: (0.0149) | Acc: (99.53%) (24332/24448)\n",
            "Epoch: 113 | Batch_idx: 200 |  Loss: (0.0152) | Acc: (99.50%) (25600/25728)\n",
            "Epoch: 113 | Batch_idx: 210 |  Loss: (0.0151) | Acc: (99.50%) (26874/27008)\n",
            "Epoch: 113 | Batch_idx: 220 |  Loss: (0.0155) | Acc: (99.49%) (28143/28288)\n",
            "Epoch: 113 | Batch_idx: 230 |  Loss: (0.0153) | Acc: (99.48%) (29415/29568)\n",
            "Epoch: 113 | Batch_idx: 240 |  Loss: (0.0157) | Acc: (99.48%) (30687/30848)\n",
            "Epoch: 113 | Batch_idx: 250 |  Loss: (0.0153) | Acc: (99.49%) (31963/32128)\n",
            "Epoch: 113 | Batch_idx: 260 |  Loss: (0.0154) | Acc: (99.48%) (33233/33408)\n",
            "Epoch: 113 | Batch_idx: 270 |  Loss: (0.0154) | Acc: (99.48%) (34506/34688)\n",
            "Epoch: 113 | Batch_idx: 280 |  Loss: (0.0154) | Acc: (99.48%) (35781/35968)\n",
            "Epoch: 113 | Batch_idx: 290 |  Loss: (0.0154) | Acc: (99.48%) (37053/37248)\n",
            "Epoch: 113 | Batch_idx: 300 |  Loss: (0.0151) | Acc: (99.49%) (38330/38528)\n",
            "Epoch: 113 | Batch_idx: 310 |  Loss: (0.0150) | Acc: (99.49%) (39605/39808)\n",
            "Epoch: 113 | Batch_idx: 320 |  Loss: (0.0149) | Acc: (99.49%) (40880/41088)\n",
            "Epoch: 113 | Batch_idx: 330 |  Loss: (0.0150) | Acc: (99.49%) (42153/42368)\n",
            "Epoch: 113 | Batch_idx: 340 |  Loss: (0.0149) | Acc: (99.50%) (43429/43648)\n",
            "Epoch: 113 | Batch_idx: 350 |  Loss: (0.0148) | Acc: (99.50%) (44702/44928)\n",
            "Epoch: 113 | Batch_idx: 360 |  Loss: (0.0147) | Acc: (99.50%) (45979/46208)\n",
            "Epoch: 113 | Batch_idx: 370 |  Loss: (0.0147) | Acc: (99.50%) (47252/47488)\n",
            "Epoch: 113 | Batch_idx: 380 |  Loss: (0.0148) | Acc: (99.50%) (48523/48768)\n",
            "Epoch: 113 | Batch_idx: 390 |  Loss: (0.0148) | Acc: (99.50%) (49749/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4166) | Acc: (91.45%) (9145/10000)\n",
            "Epoch: 114 | Batch_idx: 0 |  Loss: (0.0194) | Acc: (99.22%) (127/128)\n",
            "Epoch: 114 | Batch_idx: 10 |  Loss: (0.0125) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 114 | Batch_idx: 20 |  Loss: (0.0163) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 114 | Batch_idx: 30 |  Loss: (0.0152) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 114 | Batch_idx: 40 |  Loss: (0.0149) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 114 | Batch_idx: 50 |  Loss: (0.0134) | Acc: (99.51%) (6496/6528)\n",
            "Epoch: 114 | Batch_idx: 60 |  Loss: (0.0134) | Acc: (99.50%) (7769/7808)\n",
            "Epoch: 114 | Batch_idx: 70 |  Loss: (0.0144) | Acc: (99.49%) (9042/9088)\n",
            "Epoch: 114 | Batch_idx: 80 |  Loss: (0.0146) | Acc: (99.48%) (10314/10368)\n",
            "Epoch: 114 | Batch_idx: 90 |  Loss: (0.0136) | Acc: (99.52%) (11592/11648)\n",
            "Epoch: 114 | Batch_idx: 100 |  Loss: (0.0137) | Acc: (99.50%) (12864/12928)\n",
            "Epoch: 114 | Batch_idx: 110 |  Loss: (0.0146) | Acc: (99.47%) (14133/14208)\n",
            "Epoch: 114 | Batch_idx: 120 |  Loss: (0.0145) | Acc: (99.46%) (15405/15488)\n",
            "Epoch: 114 | Batch_idx: 130 |  Loss: (0.0142) | Acc: (99.48%) (16681/16768)\n",
            "Epoch: 114 | Batch_idx: 140 |  Loss: (0.0143) | Acc: (99.49%) (17956/18048)\n",
            "Epoch: 114 | Batch_idx: 150 |  Loss: (0.0144) | Acc: (99.48%) (19228/19328)\n",
            "Epoch: 114 | Batch_idx: 160 |  Loss: (0.0142) | Acc: (99.49%) (20502/20608)\n",
            "Epoch: 114 | Batch_idx: 170 |  Loss: (0.0146) | Acc: (99.48%) (21775/21888)\n",
            "Epoch: 114 | Batch_idx: 180 |  Loss: (0.0143) | Acc: (99.49%) (23049/23168)\n",
            "Epoch: 114 | Batch_idx: 190 |  Loss: (0.0142) | Acc: (99.48%) (24322/24448)\n",
            "Epoch: 114 | Batch_idx: 200 |  Loss: (0.0143) | Acc: (99.49%) (25596/25728)\n",
            "Epoch: 114 | Batch_idx: 210 |  Loss: (0.0148) | Acc: (99.47%) (26865/27008)\n",
            "Epoch: 114 | Batch_idx: 220 |  Loss: (0.0143) | Acc: (99.48%) (28142/28288)\n",
            "Epoch: 114 | Batch_idx: 230 |  Loss: (0.0142) | Acc: (99.49%) (29418/29568)\n",
            "Epoch: 114 | Batch_idx: 240 |  Loss: (0.0143) | Acc: (99.49%) (30692/30848)\n",
            "Epoch: 114 | Batch_idx: 250 |  Loss: (0.0141) | Acc: (99.49%) (31964/32128)\n",
            "Epoch: 114 | Batch_idx: 260 |  Loss: (0.0143) | Acc: (99.49%) (33236/33408)\n",
            "Epoch: 114 | Batch_idx: 270 |  Loss: (0.0142) | Acc: (99.48%) (34507/34688)\n",
            "Epoch: 114 | Batch_idx: 280 |  Loss: (0.0140) | Acc: (99.49%) (35783/35968)\n",
            "Epoch: 114 | Batch_idx: 290 |  Loss: (0.0139) | Acc: (99.49%) (37057/37248)\n",
            "Epoch: 114 | Batch_idx: 300 |  Loss: (0.0138) | Acc: (99.49%) (38332/38528)\n",
            "Epoch: 114 | Batch_idx: 310 |  Loss: (0.0136) | Acc: (99.50%) (39608/39808)\n",
            "Epoch: 114 | Batch_idx: 320 |  Loss: (0.0138) | Acc: (99.49%) (40879/41088)\n",
            "Epoch: 114 | Batch_idx: 330 |  Loss: (0.0137) | Acc: (99.50%) (42156/42368)\n",
            "Epoch: 114 | Batch_idx: 340 |  Loss: (0.0136) | Acc: (99.50%) (43430/43648)\n",
            "Epoch: 114 | Batch_idx: 350 |  Loss: (0.0136) | Acc: (99.50%) (44705/44928)\n",
            "Epoch: 114 | Batch_idx: 360 |  Loss: (0.0134) | Acc: (99.51%) (45981/46208)\n",
            "Epoch: 114 | Batch_idx: 370 |  Loss: (0.0133) | Acc: (99.51%) (47254/47488)\n",
            "Epoch: 114 | Batch_idx: 380 |  Loss: (0.0135) | Acc: (99.50%) (48523/48768)\n",
            "Epoch: 114 | Batch_idx: 390 |  Loss: (0.0135) | Acc: (99.50%) (49750/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4116) | Acc: (91.53%) (9153/10000)\n",
            "Epoch: 115 | Batch_idx: 0 |  Loss: (0.0005) | Acc: (100.00%) (128/128)\n",
            "Epoch: 115 | Batch_idx: 10 |  Loss: (0.0126) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 115 | Batch_idx: 20 |  Loss: (0.0160) | Acc: (99.52%) (2675/2688)\n",
            "Epoch: 115 | Batch_idx: 30 |  Loss: (0.0146) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 115 | Batch_idx: 40 |  Loss: (0.0151) | Acc: (99.47%) (5220/5248)\n",
            "Epoch: 115 | Batch_idx: 50 |  Loss: (0.0130) | Acc: (99.56%) (6499/6528)\n",
            "Epoch: 115 | Batch_idx: 60 |  Loss: (0.0120) | Acc: (99.60%) (7777/7808)\n",
            "Epoch: 115 | Batch_idx: 70 |  Loss: (0.0120) | Acc: (99.60%) (9052/9088)\n",
            "Epoch: 115 | Batch_idx: 80 |  Loss: (0.0119) | Acc: (99.59%) (10326/10368)\n",
            "Epoch: 115 | Batch_idx: 90 |  Loss: (0.0131) | Acc: (99.53%) (11593/11648)\n",
            "Epoch: 115 | Batch_idx: 100 |  Loss: (0.0123) | Acc: (99.57%) (12872/12928)\n",
            "Epoch: 115 | Batch_idx: 110 |  Loss: (0.0116) | Acc: (99.60%) (14151/14208)\n",
            "Epoch: 115 | Batch_idx: 120 |  Loss: (0.0122) | Acc: (99.57%) (15421/15488)\n",
            "Epoch: 115 | Batch_idx: 130 |  Loss: (0.0126) | Acc: (99.57%) (16696/16768)\n",
            "Epoch: 115 | Batch_idx: 140 |  Loss: (0.0123) | Acc: (99.58%) (17973/18048)\n",
            "Epoch: 115 | Batch_idx: 150 |  Loss: (0.0127) | Acc: (99.56%) (19242/19328)\n",
            "Epoch: 115 | Batch_idx: 160 |  Loss: (0.0127) | Acc: (99.56%) (20518/20608)\n",
            "Epoch: 115 | Batch_idx: 170 |  Loss: (0.0128) | Acc: (99.55%) (21790/21888)\n",
            "Epoch: 115 | Batch_idx: 180 |  Loss: (0.0130) | Acc: (99.55%) (23063/23168)\n",
            "Epoch: 115 | Batch_idx: 190 |  Loss: (0.0126) | Acc: (99.56%) (24340/24448)\n",
            "Epoch: 115 | Batch_idx: 200 |  Loss: (0.0126) | Acc: (99.56%) (25614/25728)\n",
            "Epoch: 115 | Batch_idx: 210 |  Loss: (0.0125) | Acc: (99.57%) (26891/27008)\n",
            "Epoch: 115 | Batch_idx: 220 |  Loss: (0.0124) | Acc: (99.57%) (28166/28288)\n",
            "Epoch: 115 | Batch_idx: 230 |  Loss: (0.0123) | Acc: (99.57%) (29441/29568)\n",
            "Epoch: 115 | Batch_idx: 240 |  Loss: (0.0123) | Acc: (99.58%) (30717/30848)\n",
            "Epoch: 115 | Batch_idx: 250 |  Loss: (0.0122) | Acc: (99.57%) (31991/32128)\n",
            "Epoch: 115 | Batch_idx: 260 |  Loss: (0.0120) | Acc: (99.57%) (33265/33408)\n",
            "Epoch: 115 | Batch_idx: 270 |  Loss: (0.0121) | Acc: (99.57%) (34540/34688)\n",
            "Epoch: 115 | Batch_idx: 280 |  Loss: (0.0122) | Acc: (99.57%) (35813/35968)\n",
            "Epoch: 115 | Batch_idx: 290 |  Loss: (0.0121) | Acc: (99.57%) (37089/37248)\n",
            "Epoch: 115 | Batch_idx: 300 |  Loss: (0.0122) | Acc: (99.57%) (38361/38528)\n",
            "Epoch: 115 | Batch_idx: 310 |  Loss: (0.0122) | Acc: (99.56%) (39633/39808)\n",
            "Epoch: 115 | Batch_idx: 320 |  Loss: (0.0120) | Acc: (99.56%) (40909/41088)\n",
            "Epoch: 115 | Batch_idx: 330 |  Loss: (0.0121) | Acc: (99.57%) (42185/42368)\n",
            "Epoch: 115 | Batch_idx: 340 |  Loss: (0.0120) | Acc: (99.57%) (43460/43648)\n",
            "Epoch: 115 | Batch_idx: 350 |  Loss: (0.0120) | Acc: (99.57%) (44734/44928)\n",
            "Epoch: 115 | Batch_idx: 360 |  Loss: (0.0120) | Acc: (99.57%) (46010/46208)\n",
            "Epoch: 115 | Batch_idx: 370 |  Loss: (0.0118) | Acc: (99.58%) (47287/47488)\n",
            "Epoch: 115 | Batch_idx: 380 |  Loss: (0.0117) | Acc: (99.58%) (48562/48768)\n",
            "Epoch: 115 | Batch_idx: 390 |  Loss: (0.0119) | Acc: (99.57%) (49785/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4165) | Acc: (91.48%) (9148/10000)\n",
            "Epoch: 116 | Batch_idx: 0 |  Loss: (0.0021) | Acc: (100.00%) (128/128)\n",
            "Epoch: 116 | Batch_idx: 10 |  Loss: (0.0107) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 116 | Batch_idx: 20 |  Loss: (0.0094) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 116 | Batch_idx: 30 |  Loss: (0.0123) | Acc: (99.55%) (3950/3968)\n",
            "Epoch: 116 | Batch_idx: 40 |  Loss: (0.0116) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 116 | Batch_idx: 50 |  Loss: (0.0105) | Acc: (99.57%) (6500/6528)\n",
            "Epoch: 116 | Batch_idx: 60 |  Loss: (0.0123) | Acc: (99.55%) (7773/7808)\n",
            "Epoch: 116 | Batch_idx: 70 |  Loss: (0.0118) | Acc: (99.57%) (9049/9088)\n",
            "Epoch: 116 | Batch_idx: 80 |  Loss: (0.0131) | Acc: (99.54%) (10320/10368)\n",
            "Epoch: 116 | Batch_idx: 90 |  Loss: (0.0129) | Acc: (99.54%) (11595/11648)\n",
            "Epoch: 116 | Batch_idx: 100 |  Loss: (0.0126) | Acc: (99.57%) (12873/12928)\n",
            "Epoch: 116 | Batch_idx: 110 |  Loss: (0.0131) | Acc: (99.55%) (14144/14208)\n",
            "Epoch: 116 | Batch_idx: 120 |  Loss: (0.0133) | Acc: (99.52%) (15413/15488)\n",
            "Epoch: 116 | Batch_idx: 130 |  Loss: (0.0129) | Acc: (99.54%) (16691/16768)\n",
            "Epoch: 116 | Batch_idx: 140 |  Loss: (0.0128) | Acc: (99.55%) (17967/18048)\n",
            "Epoch: 116 | Batch_idx: 150 |  Loss: (0.0131) | Acc: (99.53%) (19238/19328)\n",
            "Epoch: 116 | Batch_idx: 160 |  Loss: (0.0128) | Acc: (99.55%) (20516/20608)\n",
            "Epoch: 116 | Batch_idx: 170 |  Loss: (0.0125) | Acc: (99.57%) (21793/21888)\n",
            "Epoch: 116 | Batch_idx: 180 |  Loss: (0.0125) | Acc: (99.57%) (23068/23168)\n",
            "Epoch: 116 | Batch_idx: 190 |  Loss: (0.0123) | Acc: (99.57%) (24342/24448)\n",
            "Epoch: 116 | Batch_idx: 200 |  Loss: (0.0126) | Acc: (99.55%) (25612/25728)\n",
            "Epoch: 116 | Batch_idx: 210 |  Loss: (0.0123) | Acc: (99.56%) (26888/27008)\n",
            "Epoch: 116 | Batch_idx: 220 |  Loss: (0.0125) | Acc: (99.55%) (28160/28288)\n",
            "Epoch: 116 | Batch_idx: 230 |  Loss: (0.0125) | Acc: (99.56%) (29437/29568)\n",
            "Epoch: 116 | Batch_idx: 240 |  Loss: (0.0124) | Acc: (99.56%) (30711/30848)\n",
            "Epoch: 116 | Batch_idx: 250 |  Loss: (0.0121) | Acc: (99.56%) (31988/32128)\n",
            "Epoch: 116 | Batch_idx: 260 |  Loss: (0.0120) | Acc: (99.57%) (33263/33408)\n",
            "Epoch: 116 | Batch_idx: 270 |  Loss: (0.0119) | Acc: (99.56%) (34537/34688)\n",
            "Epoch: 116 | Batch_idx: 280 |  Loss: (0.0116) | Acc: (99.58%) (35816/35968)\n",
            "Epoch: 116 | Batch_idx: 290 |  Loss: (0.0114) | Acc: (99.59%) (37094/37248)\n",
            "Epoch: 116 | Batch_idx: 300 |  Loss: (0.0114) | Acc: (99.58%) (38368/38528)\n",
            "Epoch: 116 | Batch_idx: 310 |  Loss: (0.0114) | Acc: (99.59%) (39643/39808)\n",
            "Epoch: 116 | Batch_idx: 320 |  Loss: (0.0114) | Acc: (99.58%) (40916/41088)\n",
            "Epoch: 116 | Batch_idx: 330 |  Loss: (0.0113) | Acc: (99.59%) (42193/42368)\n",
            "Epoch: 116 | Batch_idx: 340 |  Loss: (0.0114) | Acc: (99.58%) (43465/43648)\n",
            "Epoch: 116 | Batch_idx: 350 |  Loss: (0.0113) | Acc: (99.59%) (44742/44928)\n",
            "Epoch: 116 | Batch_idx: 360 |  Loss: (0.0111) | Acc: (99.60%) (46021/46208)\n",
            "Epoch: 116 | Batch_idx: 370 |  Loss: (0.0112) | Acc: (99.59%) (47294/47488)\n",
            "Epoch: 116 | Batch_idx: 380 |  Loss: (0.0113) | Acc: (99.59%) (48568/48768)\n",
            "Epoch: 116 | Batch_idx: 390 |  Loss: (0.0111) | Acc: (99.60%) (49799/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4139) | Acc: (91.39%) (9139/10000)\n",
            "Epoch: 117 | Batch_idx: 0 |  Loss: (0.0040) | Acc: (100.00%) (128/128)\n",
            "Epoch: 117 | Batch_idx: 10 |  Loss: (0.0185) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 117 | Batch_idx: 20 |  Loss: (0.0163) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 117 | Batch_idx: 30 |  Loss: (0.0153) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 117 | Batch_idx: 40 |  Loss: (0.0150) | Acc: (99.49%) (5221/5248)\n",
            "Epoch: 117 | Batch_idx: 50 |  Loss: (0.0151) | Acc: (99.48%) (6494/6528)\n",
            "Epoch: 117 | Batch_idx: 60 |  Loss: (0.0155) | Acc: (99.51%) (7770/7808)\n",
            "Epoch: 117 | Batch_idx: 70 |  Loss: (0.0158) | Acc: (99.49%) (9042/9088)\n",
            "Epoch: 117 | Batch_idx: 80 |  Loss: (0.0156) | Acc: (99.51%) (10317/10368)\n",
            "Epoch: 117 | Batch_idx: 90 |  Loss: (0.0153) | Acc: (99.52%) (11592/11648)\n",
            "Epoch: 117 | Batch_idx: 100 |  Loss: (0.0150) | Acc: (99.54%) (12869/12928)\n",
            "Epoch: 117 | Batch_idx: 110 |  Loss: (0.0146) | Acc: (99.55%) (14144/14208)\n",
            "Epoch: 117 | Batch_idx: 120 |  Loss: (0.0141) | Acc: (99.55%) (15419/15488)\n",
            "Epoch: 117 | Batch_idx: 130 |  Loss: (0.0141) | Acc: (99.54%) (16691/16768)\n",
            "Epoch: 117 | Batch_idx: 140 |  Loss: (0.0141) | Acc: (99.55%) (17966/18048)\n",
            "Epoch: 117 | Batch_idx: 150 |  Loss: (0.0143) | Acc: (99.54%) (19240/19328)\n",
            "Epoch: 117 | Batch_idx: 160 |  Loss: (0.0139) | Acc: (99.56%) (20517/20608)\n",
            "Epoch: 117 | Batch_idx: 170 |  Loss: (0.0140) | Acc: (99.56%) (21791/21888)\n",
            "Epoch: 117 | Batch_idx: 180 |  Loss: (0.0135) | Acc: (99.57%) (23069/23168)\n",
            "Epoch: 117 | Batch_idx: 190 |  Loss: (0.0132) | Acc: (99.58%) (24346/24448)\n",
            "Epoch: 117 | Batch_idx: 200 |  Loss: (0.0129) | Acc: (99.59%) (25622/25728)\n",
            "Epoch: 117 | Batch_idx: 210 |  Loss: (0.0127) | Acc: (99.59%) (26897/27008)\n",
            "Epoch: 117 | Batch_idx: 220 |  Loss: (0.0126) | Acc: (99.59%) (28172/28288)\n",
            "Epoch: 117 | Batch_idx: 230 |  Loss: (0.0124) | Acc: (99.59%) (29448/29568)\n",
            "Epoch: 117 | Batch_idx: 240 |  Loss: (0.0126) | Acc: (99.59%) (30723/30848)\n",
            "Epoch: 117 | Batch_idx: 250 |  Loss: (0.0126) | Acc: (99.59%) (31996/32128)\n",
            "Epoch: 117 | Batch_idx: 260 |  Loss: (0.0129) | Acc: (99.57%) (33266/33408)\n",
            "Epoch: 117 | Batch_idx: 270 |  Loss: (0.0131) | Acc: (99.58%) (34541/34688)\n",
            "Epoch: 117 | Batch_idx: 280 |  Loss: (0.0129) | Acc: (99.58%) (35816/35968)\n",
            "Epoch: 117 | Batch_idx: 290 |  Loss: (0.0130) | Acc: (99.57%) (37087/37248)\n",
            "Epoch: 117 | Batch_idx: 300 |  Loss: (0.0132) | Acc: (99.57%) (38361/38528)\n",
            "Epoch: 117 | Batch_idx: 310 |  Loss: (0.0132) | Acc: (99.57%) (39635/39808)\n",
            "Epoch: 117 | Batch_idx: 320 |  Loss: (0.0132) | Acc: (99.56%) (40906/41088)\n",
            "Epoch: 117 | Batch_idx: 330 |  Loss: (0.0129) | Acc: (99.57%) (42184/42368)\n",
            "Epoch: 117 | Batch_idx: 340 |  Loss: (0.0132) | Acc: (99.56%) (43455/43648)\n",
            "Epoch: 117 | Batch_idx: 350 |  Loss: (0.0133) | Acc: (99.55%) (44728/44928)\n",
            "Epoch: 117 | Batch_idx: 360 |  Loss: (0.0132) | Acc: (99.56%) (46004/46208)\n",
            "Epoch: 117 | Batch_idx: 370 |  Loss: (0.0134) | Acc: (99.55%) (47275/47488)\n",
            "Epoch: 117 | Batch_idx: 380 |  Loss: (0.0134) | Acc: (99.55%) (48549/48768)\n",
            "Epoch: 117 | Batch_idx: 390 |  Loss: (0.0133) | Acc: (99.55%) (49777/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4207) | Acc: (91.04%) (9104/10000)\n",
            "Epoch: 118 | Batch_idx: 0 |  Loss: (0.0131) | Acc: (99.22%) (127/128)\n",
            "Epoch: 118 | Batch_idx: 10 |  Loss: (0.0054) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 118 | Batch_idx: 20 |  Loss: (0.0091) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 118 | Batch_idx: 30 |  Loss: (0.0121) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 118 | Batch_idx: 40 |  Loss: (0.0113) | Acc: (99.58%) (5226/5248)\n",
            "Epoch: 118 | Batch_idx: 50 |  Loss: (0.0118) | Acc: (99.57%) (6500/6528)\n",
            "Epoch: 118 | Batch_idx: 60 |  Loss: (0.0117) | Acc: (99.58%) (7775/7808)\n",
            "Epoch: 118 | Batch_idx: 70 |  Loss: (0.0114) | Acc: (99.59%) (9051/9088)\n",
            "Epoch: 118 | Batch_idx: 80 |  Loss: (0.0117) | Acc: (99.60%) (10327/10368)\n",
            "Epoch: 118 | Batch_idx: 90 |  Loss: (0.0112) | Acc: (99.63%) (11605/11648)\n",
            "Epoch: 118 | Batch_idx: 100 |  Loss: (0.0111) | Acc: (99.64%) (12882/12928)\n",
            "Epoch: 118 | Batch_idx: 110 |  Loss: (0.0109) | Acc: (99.66%) (14160/14208)\n",
            "Epoch: 118 | Batch_idx: 120 |  Loss: (0.0110) | Acc: (99.66%) (15436/15488)\n",
            "Epoch: 118 | Batch_idx: 130 |  Loss: (0.0112) | Acc: (99.65%) (16709/16768)\n",
            "Epoch: 118 | Batch_idx: 140 |  Loss: (0.0112) | Acc: (99.65%) (17984/18048)\n",
            "Epoch: 118 | Batch_idx: 150 |  Loss: (0.0116) | Acc: (99.63%) (19257/19328)\n",
            "Epoch: 118 | Batch_idx: 160 |  Loss: (0.0116) | Acc: (99.64%) (20534/20608)\n",
            "Epoch: 118 | Batch_idx: 170 |  Loss: (0.0119) | Acc: (99.63%) (21807/21888)\n",
            "Epoch: 118 | Batch_idx: 180 |  Loss: (0.0116) | Acc: (99.65%) (23086/23168)\n",
            "Epoch: 118 | Batch_idx: 190 |  Loss: (0.0114) | Acc: (99.65%) (24363/24448)\n",
            "Epoch: 118 | Batch_idx: 200 |  Loss: (0.0119) | Acc: (99.64%) (25635/25728)\n",
            "Epoch: 118 | Batch_idx: 210 |  Loss: (0.0122) | Acc: (99.63%) (26909/27008)\n",
            "Epoch: 118 | Batch_idx: 220 |  Loss: (0.0119) | Acc: (99.64%) (28186/28288)\n",
            "Epoch: 118 | Batch_idx: 230 |  Loss: (0.0119) | Acc: (99.64%) (29461/29568)\n",
            "Epoch: 118 | Batch_idx: 240 |  Loss: (0.0119) | Acc: (99.64%) (30737/30848)\n",
            "Epoch: 118 | Batch_idx: 250 |  Loss: (0.0119) | Acc: (99.63%) (32008/32128)\n",
            "Epoch: 118 | Batch_idx: 260 |  Loss: (0.0120) | Acc: (99.63%) (33283/33408)\n",
            "Epoch: 118 | Batch_idx: 270 |  Loss: (0.0120) | Acc: (99.63%) (34559/34688)\n",
            "Epoch: 118 | Batch_idx: 280 |  Loss: (0.0119) | Acc: (99.62%) (35831/35968)\n",
            "Epoch: 118 | Batch_idx: 290 |  Loss: (0.0119) | Acc: (99.62%) (37107/37248)\n",
            "Epoch: 118 | Batch_idx: 300 |  Loss: (0.0119) | Acc: (99.62%) (38383/38528)\n",
            "Epoch: 118 | Batch_idx: 310 |  Loss: (0.0118) | Acc: (99.62%) (39658/39808)\n",
            "Epoch: 118 | Batch_idx: 320 |  Loss: (0.0120) | Acc: (99.61%) (40929/41088)\n",
            "Epoch: 118 | Batch_idx: 330 |  Loss: (0.0120) | Acc: (99.61%) (42204/42368)\n",
            "Epoch: 118 | Batch_idx: 340 |  Loss: (0.0120) | Acc: (99.60%) (43475/43648)\n",
            "Epoch: 118 | Batch_idx: 350 |  Loss: (0.0121) | Acc: (99.60%) (44749/44928)\n",
            "Epoch: 118 | Batch_idx: 360 |  Loss: (0.0121) | Acc: (99.60%) (46023/46208)\n",
            "Epoch: 118 | Batch_idx: 370 |  Loss: (0.0120) | Acc: (99.61%) (47301/47488)\n",
            "Epoch: 118 | Batch_idx: 380 |  Loss: (0.0119) | Acc: (99.61%) (48577/48768)\n",
            "Epoch: 118 | Batch_idx: 390 |  Loss: (0.0119) | Acc: (99.61%) (49803/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4238) | Acc: (91.26%) (9126/10000)\n",
            "Epoch: 119 | Batch_idx: 0 |  Loss: (0.0227) | Acc: (99.22%) (127/128)\n",
            "Epoch: 119 | Batch_idx: 10 |  Loss: (0.0134) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 119 | Batch_idx: 20 |  Loss: (0.0109) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 119 | Batch_idx: 30 |  Loss: (0.0113) | Acc: (99.60%) (3952/3968)\n",
            "Epoch: 119 | Batch_idx: 40 |  Loss: (0.0105) | Acc: (99.62%) (5228/5248)\n",
            "Epoch: 119 | Batch_idx: 50 |  Loss: (0.0120) | Acc: (99.57%) (6500/6528)\n",
            "Epoch: 119 | Batch_idx: 60 |  Loss: (0.0116) | Acc: (99.60%) (7777/7808)\n",
            "Epoch: 119 | Batch_idx: 70 |  Loss: (0.0116) | Acc: (99.63%) (9054/9088)\n",
            "Epoch: 119 | Batch_idx: 80 |  Loss: (0.0108) | Acc: (99.65%) (10332/10368)\n",
            "Epoch: 119 | Batch_idx: 90 |  Loss: (0.0102) | Acc: (99.67%) (11610/11648)\n",
            "Epoch: 119 | Batch_idx: 100 |  Loss: (0.0102) | Acc: (99.67%) (12885/12928)\n",
            "Epoch: 119 | Batch_idx: 110 |  Loss: (0.0108) | Acc: (99.64%) (14157/14208)\n",
            "Epoch: 119 | Batch_idx: 120 |  Loss: (0.0109) | Acc: (99.63%) (15430/15488)\n",
            "Epoch: 119 | Batch_idx: 130 |  Loss: (0.0110) | Acc: (99.61%) (16703/16768)\n",
            "Epoch: 119 | Batch_idx: 140 |  Loss: (0.0111) | Acc: (99.61%) (17978/18048)\n",
            "Epoch: 119 | Batch_idx: 150 |  Loss: (0.0110) | Acc: (99.61%) (19253/19328)\n",
            "Epoch: 119 | Batch_idx: 160 |  Loss: (0.0111) | Acc: (99.60%) (20526/20608)\n",
            "Epoch: 119 | Batch_idx: 170 |  Loss: (0.0112) | Acc: (99.60%) (21801/21888)\n",
            "Epoch: 119 | Batch_idx: 180 |  Loss: (0.0114) | Acc: (99.60%) (23076/23168)\n",
            "Epoch: 119 | Batch_idx: 190 |  Loss: (0.0116) | Acc: (99.60%) (24350/24448)\n",
            "Epoch: 119 | Batch_idx: 200 |  Loss: (0.0114) | Acc: (99.61%) (25628/25728)\n",
            "Epoch: 119 | Batch_idx: 210 |  Loss: (0.0120) | Acc: (99.60%) (26899/27008)\n",
            "Epoch: 119 | Batch_idx: 220 |  Loss: (0.0118) | Acc: (99.60%) (28174/28288)\n",
            "Epoch: 119 | Batch_idx: 230 |  Loss: (0.0118) | Acc: (99.60%) (29451/29568)\n",
            "Epoch: 119 | Batch_idx: 240 |  Loss: (0.0121) | Acc: (99.59%) (30722/30848)\n",
            "Epoch: 119 | Batch_idx: 250 |  Loss: (0.0120) | Acc: (99.59%) (31997/32128)\n",
            "Epoch: 119 | Batch_idx: 260 |  Loss: (0.0122) | Acc: (99.59%) (33271/33408)\n",
            "Epoch: 119 | Batch_idx: 270 |  Loss: (0.0125) | Acc: (99.59%) (34545/34688)\n",
            "Epoch: 119 | Batch_idx: 280 |  Loss: (0.0123) | Acc: (99.59%) (35821/35968)\n",
            "Epoch: 119 | Batch_idx: 290 |  Loss: (0.0122) | Acc: (99.59%) (37094/37248)\n",
            "Epoch: 119 | Batch_idx: 300 |  Loss: (0.0122) | Acc: (99.58%) (38367/38528)\n",
            "Epoch: 119 | Batch_idx: 310 |  Loss: (0.0122) | Acc: (99.58%) (39641/39808)\n",
            "Epoch: 119 | Batch_idx: 320 |  Loss: (0.0122) | Acc: (99.58%) (40915/41088)\n",
            "Epoch: 119 | Batch_idx: 330 |  Loss: (0.0124) | Acc: (99.57%) (42185/42368)\n",
            "Epoch: 119 | Batch_idx: 340 |  Loss: (0.0126) | Acc: (99.56%) (43456/43648)\n",
            "Epoch: 119 | Batch_idx: 350 |  Loss: (0.0126) | Acc: (99.57%) (44733/44928)\n",
            "Epoch: 119 | Batch_idx: 360 |  Loss: (0.0127) | Acc: (99.57%) (46008/46208)\n",
            "Epoch: 119 | Batch_idx: 370 |  Loss: (0.0128) | Acc: (99.56%) (47277/47488)\n",
            "Epoch: 119 | Batch_idx: 380 |  Loss: (0.0129) | Acc: (99.55%) (48549/48768)\n",
            "Epoch: 119 | Batch_idx: 390 |  Loss: (0.0130) | Acc: (99.55%) (49773/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4222) | Acc: (91.37%) (9137/10000)\n",
            "Epoch: 120 | Batch_idx: 0 |  Loss: (0.0591) | Acc: (98.44%) (126/128)\n",
            "Epoch: 120 | Batch_idx: 10 |  Loss: (0.0138) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 120 | Batch_idx: 20 |  Loss: (0.0125) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 120 | Batch_idx: 30 |  Loss: (0.0127) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 120 | Batch_idx: 40 |  Loss: (0.0130) | Acc: (99.62%) (5228/5248)\n",
            "Epoch: 120 | Batch_idx: 50 |  Loss: (0.0120) | Acc: (99.60%) (6502/6528)\n",
            "Epoch: 120 | Batch_idx: 60 |  Loss: (0.0111) | Acc: (99.62%) (7778/7808)\n",
            "Epoch: 120 | Batch_idx: 70 |  Loss: (0.0111) | Acc: (99.61%) (9053/9088)\n",
            "Epoch: 120 | Batch_idx: 80 |  Loss: (0.0109) | Acc: (99.63%) (10330/10368)\n",
            "Epoch: 120 | Batch_idx: 90 |  Loss: (0.0104) | Acc: (99.65%) (11607/11648)\n",
            "Epoch: 120 | Batch_idx: 100 |  Loss: (0.0106) | Acc: (99.64%) (12882/12928)\n",
            "Epoch: 120 | Batch_idx: 110 |  Loss: (0.0111) | Acc: (99.64%) (14157/14208)\n",
            "Epoch: 120 | Batch_idx: 120 |  Loss: (0.0109) | Acc: (99.65%) (15434/15488)\n",
            "Epoch: 120 | Batch_idx: 130 |  Loss: (0.0119) | Acc: (99.61%) (16702/16768)\n",
            "Epoch: 120 | Batch_idx: 140 |  Loss: (0.0117) | Acc: (99.62%) (17979/18048)\n",
            "Epoch: 120 | Batch_idx: 150 |  Loss: (0.0113) | Acc: (99.63%) (19257/19328)\n",
            "Epoch: 120 | Batch_idx: 160 |  Loss: (0.0111) | Acc: (99.65%) (20535/20608)\n",
            "Epoch: 120 | Batch_idx: 170 |  Loss: (0.0110) | Acc: (99.65%) (21811/21888)\n",
            "Epoch: 120 | Batch_idx: 180 |  Loss: (0.0109) | Acc: (99.65%) (23088/23168)\n",
            "Epoch: 120 | Batch_idx: 190 |  Loss: (0.0106) | Acc: (99.66%) (24365/24448)\n",
            "Epoch: 120 | Batch_idx: 200 |  Loss: (0.0105) | Acc: (99.66%) (25641/25728)\n",
            "Epoch: 120 | Batch_idx: 210 |  Loss: (0.0106) | Acc: (99.66%) (26917/27008)\n",
            "Epoch: 120 | Batch_idx: 220 |  Loss: (0.0104) | Acc: (99.66%) (28193/28288)\n",
            "Epoch: 120 | Batch_idx: 230 |  Loss: (0.0104) | Acc: (99.67%) (29471/29568)\n",
            "Epoch: 120 | Batch_idx: 240 |  Loss: (0.0102) | Acc: (99.68%) (30750/30848)\n",
            "Epoch: 120 | Batch_idx: 250 |  Loss: (0.0102) | Acc: (99.68%) (32025/32128)\n",
            "Epoch: 120 | Batch_idx: 260 |  Loss: (0.0100) | Acc: (99.68%) (33302/33408)\n",
            "Epoch: 120 | Batch_idx: 270 |  Loss: (0.0106) | Acc: (99.66%) (34570/34688)\n",
            "Epoch: 120 | Batch_idx: 280 |  Loss: (0.0106) | Acc: (99.66%) (35845/35968)\n",
            "Epoch: 120 | Batch_idx: 290 |  Loss: (0.0106) | Acc: (99.65%) (37119/37248)\n",
            "Epoch: 120 | Batch_idx: 300 |  Loss: (0.0105) | Acc: (99.65%) (38395/38528)\n",
            "Epoch: 120 | Batch_idx: 310 |  Loss: (0.0105) | Acc: (99.65%) (39670/39808)\n",
            "Epoch: 120 | Batch_idx: 320 |  Loss: (0.0105) | Acc: (99.65%) (40946/41088)\n",
            "Epoch: 120 | Batch_idx: 330 |  Loss: (0.0106) | Acc: (99.66%) (42222/42368)\n",
            "Epoch: 120 | Batch_idx: 340 |  Loss: (0.0105) | Acc: (99.66%) (43498/43648)\n",
            "Epoch: 120 | Batch_idx: 350 |  Loss: (0.0107) | Acc: (99.66%) (44773/44928)\n",
            "Epoch: 120 | Batch_idx: 360 |  Loss: (0.0106) | Acc: (99.66%) (46051/46208)\n",
            "Epoch: 120 | Batch_idx: 370 |  Loss: (0.0105) | Acc: (99.67%) (47329/47488)\n",
            "Epoch: 120 | Batch_idx: 380 |  Loss: (0.0105) | Acc: (99.67%) (48605/48768)\n",
            "Epoch: 120 | Batch_idx: 390 |  Loss: (0.0104) | Acc: (99.67%) (49834/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4112) | Acc: (91.58%) (9158/10000)\n",
            "Epoch: 121 | Batch_idx: 0 |  Loss: (0.0121) | Acc: (99.22%) (127/128)\n",
            "Epoch: 121 | Batch_idx: 10 |  Loss: (0.0150) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 121 | Batch_idx: 20 |  Loss: (0.0131) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 121 | Batch_idx: 30 |  Loss: (0.0123) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 121 | Batch_idx: 40 |  Loss: (0.0117) | Acc: (99.58%) (5226/5248)\n",
            "Epoch: 121 | Batch_idx: 50 |  Loss: (0.0108) | Acc: (99.60%) (6502/6528)\n",
            "Epoch: 121 | Batch_idx: 60 |  Loss: (0.0111) | Acc: (99.58%) (7775/7808)\n",
            "Epoch: 121 | Batch_idx: 70 |  Loss: (0.0108) | Acc: (99.61%) (9053/9088)\n",
            "Epoch: 121 | Batch_idx: 80 |  Loss: (0.0106) | Acc: (99.62%) (10329/10368)\n",
            "Epoch: 121 | Batch_idx: 90 |  Loss: (0.0103) | Acc: (99.61%) (11602/11648)\n",
            "Epoch: 121 | Batch_idx: 100 |  Loss: (0.0102) | Acc: (99.61%) (12878/12928)\n",
            "Epoch: 121 | Batch_idx: 110 |  Loss: (0.0108) | Acc: (99.59%) (14150/14208)\n",
            "Epoch: 121 | Batch_idx: 120 |  Loss: (0.0106) | Acc: (99.61%) (15427/15488)\n",
            "Epoch: 121 | Batch_idx: 130 |  Loss: (0.0102) | Acc: (99.62%) (16705/16768)\n",
            "Epoch: 121 | Batch_idx: 140 |  Loss: (0.0105) | Acc: (99.63%) (17981/18048)\n",
            "Epoch: 121 | Batch_idx: 150 |  Loss: (0.0109) | Acc: (99.61%) (19253/19328)\n",
            "Epoch: 121 | Batch_idx: 160 |  Loss: (0.0105) | Acc: (99.63%) (20532/20608)\n",
            "Epoch: 121 | Batch_idx: 170 |  Loss: (0.0104) | Acc: (99.63%) (21808/21888)\n",
            "Epoch: 121 | Batch_idx: 180 |  Loss: (0.0104) | Acc: (99.63%) (23082/23168)\n",
            "Epoch: 121 | Batch_idx: 190 |  Loss: (0.0105) | Acc: (99.62%) (24356/24448)\n",
            "Epoch: 121 | Batch_idx: 200 |  Loss: (0.0105) | Acc: (99.63%) (25632/25728)\n",
            "Epoch: 121 | Batch_idx: 210 |  Loss: (0.0107) | Acc: (99.63%) (26907/27008)\n",
            "Epoch: 121 | Batch_idx: 220 |  Loss: (0.0104) | Acc: (99.64%) (28185/28288)\n",
            "Epoch: 121 | Batch_idx: 230 |  Loss: (0.0103) | Acc: (99.64%) (29463/29568)\n",
            "Epoch: 121 | Batch_idx: 240 |  Loss: (0.0102) | Acc: (99.65%) (30740/30848)\n",
            "Epoch: 121 | Batch_idx: 250 |  Loss: (0.0099) | Acc: (99.66%) (32019/32128)\n",
            "Epoch: 121 | Batch_idx: 260 |  Loss: (0.0099) | Acc: (99.66%) (33296/33408)\n",
            "Epoch: 121 | Batch_idx: 270 |  Loss: (0.0097) | Acc: (99.67%) (34574/34688)\n",
            "Epoch: 121 | Batch_idx: 280 |  Loss: (0.0097) | Acc: (99.66%) (35847/35968)\n",
            "Epoch: 121 | Batch_idx: 290 |  Loss: (0.0098) | Acc: (99.66%) (37123/37248)\n",
            "Epoch: 121 | Batch_idx: 300 |  Loss: (0.0097) | Acc: (99.67%) (38400/38528)\n",
            "Epoch: 121 | Batch_idx: 310 |  Loss: (0.0098) | Acc: (99.67%) (39676/39808)\n",
            "Epoch: 121 | Batch_idx: 320 |  Loss: (0.0097) | Acc: (99.67%) (40953/41088)\n",
            "Epoch: 121 | Batch_idx: 330 |  Loss: (0.0097) | Acc: (99.67%) (42228/42368)\n",
            "Epoch: 121 | Batch_idx: 340 |  Loss: (0.0097) | Acc: (99.67%) (43502/43648)\n",
            "Epoch: 121 | Batch_idx: 350 |  Loss: (0.0097) | Acc: (99.67%) (44778/44928)\n",
            "Epoch: 121 | Batch_idx: 360 |  Loss: (0.0096) | Acc: (99.67%) (46057/46208)\n",
            "Epoch: 121 | Batch_idx: 370 |  Loss: (0.0096) | Acc: (99.67%) (47333/47488)\n",
            "Epoch: 121 | Batch_idx: 380 |  Loss: (0.0096) | Acc: (99.68%) (48610/48768)\n",
            "Epoch: 121 | Batch_idx: 390 |  Loss: (0.0095) | Acc: (99.68%) (49839/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4121) | Acc: (91.65%) (9165/10000)\n",
            "Epoch: 122 | Batch_idx: 0 |  Loss: (0.0056) | Acc: (100.00%) (128/128)\n",
            "Epoch: 122 | Batch_idx: 10 |  Loss: (0.0064) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 122 | Batch_idx: 20 |  Loss: (0.0085) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 122 | Batch_idx: 30 |  Loss: (0.0112) | Acc: (99.72%) (3957/3968)\n",
            "Epoch: 122 | Batch_idx: 40 |  Loss: (0.0099) | Acc: (99.75%) (5235/5248)\n",
            "Epoch: 122 | Batch_idx: 50 |  Loss: (0.0099) | Acc: (99.71%) (6509/6528)\n",
            "Epoch: 122 | Batch_idx: 60 |  Loss: (0.0094) | Acc: (99.71%) (7785/7808)\n",
            "Epoch: 122 | Batch_idx: 70 |  Loss: (0.0090) | Acc: (99.72%) (9063/9088)\n",
            "Epoch: 122 | Batch_idx: 80 |  Loss: (0.0093) | Acc: (99.69%) (10336/10368)\n",
            "Epoch: 122 | Batch_idx: 90 |  Loss: (0.0097) | Acc: (99.69%) (11612/11648)\n",
            "Epoch: 122 | Batch_idx: 100 |  Loss: (0.0098) | Acc: (99.68%) (12887/12928)\n",
            "Epoch: 122 | Batch_idx: 110 |  Loss: (0.0100) | Acc: (99.68%) (14162/14208)\n",
            "Epoch: 122 | Batch_idx: 120 |  Loss: (0.0098) | Acc: (99.68%) (15438/15488)\n",
            "Epoch: 122 | Batch_idx: 130 |  Loss: (0.0096) | Acc: (99.68%) (16714/16768)\n",
            "Epoch: 122 | Batch_idx: 140 |  Loss: (0.0094) | Acc: (99.68%) (17990/18048)\n",
            "Epoch: 122 | Batch_idx: 150 |  Loss: (0.0090) | Acc: (99.69%) (19269/19328)\n",
            "Epoch: 122 | Batch_idx: 160 |  Loss: (0.0087) | Acc: (99.71%) (20548/20608)\n",
            "Epoch: 122 | Batch_idx: 170 |  Loss: (0.0085) | Acc: (99.71%) (21825/21888)\n",
            "Epoch: 122 | Batch_idx: 180 |  Loss: (0.0083) | Acc: (99.71%) (23101/23168)\n",
            "Epoch: 122 | Batch_idx: 190 |  Loss: (0.0081) | Acc: (99.72%) (24379/24448)\n",
            "Epoch: 122 | Batch_idx: 200 |  Loss: (0.0082) | Acc: (99.72%) (25657/25728)\n",
            "Epoch: 122 | Batch_idx: 210 |  Loss: (0.0083) | Acc: (99.71%) (26930/27008)\n",
            "Epoch: 122 | Batch_idx: 220 |  Loss: (0.0081) | Acc: (99.71%) (28207/28288)\n",
            "Epoch: 122 | Batch_idx: 230 |  Loss: (0.0080) | Acc: (99.72%) (29484/29568)\n",
            "Epoch: 122 | Batch_idx: 240 |  Loss: (0.0079) | Acc: (99.72%) (30763/30848)\n",
            "Epoch: 122 | Batch_idx: 250 |  Loss: (0.0079) | Acc: (99.72%) (32039/32128)\n",
            "Epoch: 122 | Batch_idx: 260 |  Loss: (0.0080) | Acc: (99.72%) (33315/33408)\n",
            "Epoch: 122 | Batch_idx: 270 |  Loss: (0.0079) | Acc: (99.73%) (34593/34688)\n",
            "Epoch: 122 | Batch_idx: 280 |  Loss: (0.0079) | Acc: (99.72%) (35869/35968)\n",
            "Epoch: 122 | Batch_idx: 290 |  Loss: (0.0081) | Acc: (99.71%) (37141/37248)\n",
            "Epoch: 122 | Batch_idx: 300 |  Loss: (0.0080) | Acc: (99.72%) (38419/38528)\n",
            "Epoch: 122 | Batch_idx: 310 |  Loss: (0.0079) | Acc: (99.72%) (39698/39808)\n",
            "Epoch: 122 | Batch_idx: 320 |  Loss: (0.0080) | Acc: (99.72%) (40975/41088)\n",
            "Epoch: 122 | Batch_idx: 330 |  Loss: (0.0081) | Acc: (99.72%) (42251/42368)\n",
            "Epoch: 122 | Batch_idx: 340 |  Loss: (0.0081) | Acc: (99.72%) (43527/43648)\n",
            "Epoch: 122 | Batch_idx: 350 |  Loss: (0.0079) | Acc: (99.73%) (44806/44928)\n",
            "Epoch: 122 | Batch_idx: 360 |  Loss: (0.0079) | Acc: (99.73%) (46083/46208)\n",
            "Epoch: 122 | Batch_idx: 370 |  Loss: (0.0079) | Acc: (99.73%) (47361/47488)\n",
            "Epoch: 122 | Batch_idx: 380 |  Loss: (0.0080) | Acc: (99.73%) (48635/48768)\n",
            "Epoch: 122 | Batch_idx: 390 |  Loss: (0.0080) | Acc: (99.73%) (49864/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4069) | Acc: (91.66%) (9166/10000)\n",
            "Epoch: 123 | Batch_idx: 0 |  Loss: (0.0011) | Acc: (100.00%) (128/128)\n",
            "Epoch: 123 | Batch_idx: 10 |  Loss: (0.0132) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 123 | Batch_idx: 20 |  Loss: (0.0089) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 123 | Batch_idx: 30 |  Loss: (0.0079) | Acc: (99.72%) (3957/3968)\n",
            "Epoch: 123 | Batch_idx: 40 |  Loss: (0.0084) | Acc: (99.73%) (5234/5248)\n",
            "Epoch: 123 | Batch_idx: 50 |  Loss: (0.0084) | Acc: (99.74%) (6511/6528)\n",
            "Epoch: 123 | Batch_idx: 60 |  Loss: (0.0104) | Acc: (99.68%) (7783/7808)\n",
            "Epoch: 123 | Batch_idx: 70 |  Loss: (0.0100) | Acc: (99.70%) (9061/9088)\n",
            "Epoch: 123 | Batch_idx: 80 |  Loss: (0.0096) | Acc: (99.71%) (10338/10368)\n",
            "Epoch: 123 | Batch_idx: 90 |  Loss: (0.0098) | Acc: (99.69%) (11612/11648)\n",
            "Epoch: 123 | Batch_idx: 100 |  Loss: (0.0105) | Acc: (99.65%) (12883/12928)\n",
            "Epoch: 123 | Batch_idx: 110 |  Loss: (0.0100) | Acc: (99.67%) (14161/14208)\n",
            "Epoch: 123 | Batch_idx: 120 |  Loss: (0.0097) | Acc: (99.68%) (15439/15488)\n",
            "Epoch: 123 | Batch_idx: 130 |  Loss: (0.0093) | Acc: (99.70%) (16718/16768)\n",
            "Epoch: 123 | Batch_idx: 140 |  Loss: (0.0093) | Acc: (99.70%) (17993/18048)\n",
            "Epoch: 123 | Batch_idx: 150 |  Loss: (0.0093) | Acc: (99.68%) (19267/19328)\n",
            "Epoch: 123 | Batch_idx: 160 |  Loss: (0.0091) | Acc: (99.69%) (20545/20608)\n",
            "Epoch: 123 | Batch_idx: 170 |  Loss: (0.0088) | Acc: (99.71%) (21825/21888)\n",
            "Epoch: 123 | Batch_idx: 180 |  Loss: (0.0087) | Acc: (99.72%) (23102/23168)\n",
            "Epoch: 123 | Batch_idx: 190 |  Loss: (0.0085) | Acc: (99.72%) (24380/24448)\n",
            "Epoch: 123 | Batch_idx: 200 |  Loss: (0.0087) | Acc: (99.72%) (25655/25728)\n",
            "Epoch: 123 | Batch_idx: 210 |  Loss: (0.0086) | Acc: (99.72%) (26933/27008)\n",
            "Epoch: 123 | Batch_idx: 220 |  Loss: (0.0086) | Acc: (99.72%) (28209/28288)\n",
            "Epoch: 123 | Batch_idx: 230 |  Loss: (0.0088) | Acc: (99.72%) (29484/29568)\n",
            "Epoch: 123 | Batch_idx: 240 |  Loss: (0.0088) | Acc: (99.71%) (30759/30848)\n",
            "Epoch: 123 | Batch_idx: 250 |  Loss: (0.0088) | Acc: (99.71%) (32035/32128)\n",
            "Epoch: 123 | Batch_idx: 260 |  Loss: (0.0087) | Acc: (99.72%) (33313/33408)\n",
            "Epoch: 123 | Batch_idx: 270 |  Loss: (0.0088) | Acc: (99.71%) (34589/34688)\n",
            "Epoch: 123 | Batch_idx: 280 |  Loss: (0.0087) | Acc: (99.72%) (35867/35968)\n",
            "Epoch: 123 | Batch_idx: 290 |  Loss: (0.0088) | Acc: (99.71%) (37141/37248)\n",
            "Epoch: 123 | Batch_idx: 300 |  Loss: (0.0087) | Acc: (99.71%) (38416/38528)\n",
            "Epoch: 123 | Batch_idx: 310 |  Loss: (0.0087) | Acc: (99.71%) (39691/39808)\n",
            "Epoch: 123 | Batch_idx: 320 |  Loss: (0.0088) | Acc: (99.70%) (40965/41088)\n",
            "Epoch: 123 | Batch_idx: 330 |  Loss: (0.0088) | Acc: (99.70%) (42242/42368)\n",
            "Epoch: 123 | Batch_idx: 340 |  Loss: (0.0088) | Acc: (99.70%) (43518/43648)\n",
            "Epoch: 123 | Batch_idx: 350 |  Loss: (0.0088) | Acc: (99.70%) (44795/44928)\n",
            "Epoch: 123 | Batch_idx: 360 |  Loss: (0.0086) | Acc: (99.71%) (46073/46208)\n",
            "Epoch: 123 | Batch_idx: 370 |  Loss: (0.0086) | Acc: (99.71%) (47348/47488)\n",
            "Epoch: 123 | Batch_idx: 380 |  Loss: (0.0086) | Acc: (99.71%) (48626/48768)\n",
            "Epoch: 123 | Batch_idx: 390 |  Loss: (0.0087) | Acc: (99.71%) (49855/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4094) | Acc: (91.67%) (9167/10000)\n",
            "Epoch: 124 | Batch_idx: 0 |  Loss: (0.0037) | Acc: (100.00%) (128/128)\n",
            "Epoch: 124 | Batch_idx: 10 |  Loss: (0.0103) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 124 | Batch_idx: 20 |  Loss: (0.0077) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 124 | Batch_idx: 30 |  Loss: (0.0073) | Acc: (99.75%) (3958/3968)\n",
            "Epoch: 124 | Batch_idx: 40 |  Loss: (0.0071) | Acc: (99.79%) (5237/5248)\n",
            "Epoch: 124 | Batch_idx: 50 |  Loss: (0.0067) | Acc: (99.79%) (6514/6528)\n",
            "Epoch: 124 | Batch_idx: 60 |  Loss: (0.0071) | Acc: (99.76%) (7789/7808)\n",
            "Epoch: 124 | Batch_idx: 70 |  Loss: (0.0071) | Acc: (99.76%) (9066/9088)\n",
            "Epoch: 124 | Batch_idx: 80 |  Loss: (0.0077) | Acc: (99.74%) (10341/10368)\n",
            "Epoch: 124 | Batch_idx: 90 |  Loss: (0.0075) | Acc: (99.75%) (11619/11648)\n",
            "Epoch: 124 | Batch_idx: 100 |  Loss: (0.0076) | Acc: (99.76%) (12897/12928)\n",
            "Epoch: 124 | Batch_idx: 110 |  Loss: (0.0075) | Acc: (99.77%) (14175/14208)\n",
            "Epoch: 124 | Batch_idx: 120 |  Loss: (0.0074) | Acc: (99.77%) (15452/15488)\n",
            "Epoch: 124 | Batch_idx: 130 |  Loss: (0.0072) | Acc: (99.78%) (16731/16768)\n",
            "Epoch: 124 | Batch_idx: 140 |  Loss: (0.0072) | Acc: (99.78%) (18008/18048)\n",
            "Epoch: 124 | Batch_idx: 150 |  Loss: (0.0072) | Acc: (99.77%) (19284/19328)\n",
            "Epoch: 124 | Batch_idx: 160 |  Loss: (0.0073) | Acc: (99.77%) (20561/20608)\n",
            "Epoch: 124 | Batch_idx: 170 |  Loss: (0.0075) | Acc: (99.77%) (21837/21888)\n",
            "Epoch: 124 | Batch_idx: 180 |  Loss: (0.0075) | Acc: (99.76%) (23113/23168)\n",
            "Epoch: 124 | Batch_idx: 190 |  Loss: (0.0077) | Acc: (99.75%) (24388/24448)\n",
            "Epoch: 124 | Batch_idx: 200 |  Loss: (0.0075) | Acc: (99.76%) (25667/25728)\n",
            "Epoch: 124 | Batch_idx: 210 |  Loss: (0.0078) | Acc: (99.75%) (26941/27008)\n",
            "Epoch: 124 | Batch_idx: 220 |  Loss: (0.0078) | Acc: (99.75%) (28217/28288)\n",
            "Epoch: 124 | Batch_idx: 230 |  Loss: (0.0080) | Acc: (99.75%) (29493/29568)\n",
            "Epoch: 124 | Batch_idx: 240 |  Loss: (0.0082) | Acc: (99.74%) (30767/30848)\n",
            "Epoch: 124 | Batch_idx: 250 |  Loss: (0.0080) | Acc: (99.74%) (32046/32128)\n",
            "Epoch: 124 | Batch_idx: 260 |  Loss: (0.0078) | Acc: (99.75%) (33324/33408)\n",
            "Epoch: 124 | Batch_idx: 270 |  Loss: (0.0079) | Acc: (99.75%) (34600/34688)\n",
            "Epoch: 124 | Batch_idx: 280 |  Loss: (0.0081) | Acc: (99.74%) (35874/35968)\n",
            "Epoch: 124 | Batch_idx: 290 |  Loss: (0.0080) | Acc: (99.74%) (37151/37248)\n",
            "Epoch: 124 | Batch_idx: 300 |  Loss: (0.0081) | Acc: (99.73%) (38425/38528)\n",
            "Epoch: 124 | Batch_idx: 310 |  Loss: (0.0085) | Acc: (99.71%) (39694/39808)\n",
            "Epoch: 124 | Batch_idx: 320 |  Loss: (0.0085) | Acc: (99.72%) (40971/41088)\n",
            "Epoch: 124 | Batch_idx: 330 |  Loss: (0.0084) | Acc: (99.72%) (42249/42368)\n",
            "Epoch: 124 | Batch_idx: 340 |  Loss: (0.0084) | Acc: (99.72%) (43526/43648)\n",
            "Epoch: 124 | Batch_idx: 350 |  Loss: (0.0083) | Acc: (99.72%) (44804/44928)\n",
            "Epoch: 124 | Batch_idx: 360 |  Loss: (0.0081) | Acc: (99.73%) (46083/46208)\n",
            "Epoch: 124 | Batch_idx: 370 |  Loss: (0.0084) | Acc: (99.72%) (47356/47488)\n",
            "Epoch: 124 | Batch_idx: 380 |  Loss: (0.0084) | Acc: (99.72%) (48633/48768)\n",
            "Epoch: 124 | Batch_idx: 390 |  Loss: (0.0084) | Acc: (99.73%) (49863/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4091) | Acc: (91.74%) (9174/10000)\n",
            "Epoch: 125 | Batch_idx: 0 |  Loss: (0.0012) | Acc: (100.00%) (128/128)\n",
            "Epoch: 125 | Batch_idx: 10 |  Loss: (0.0038) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 125 | Batch_idx: 20 |  Loss: (0.0059) | Acc: (99.81%) (2683/2688)\n",
            "Epoch: 125 | Batch_idx: 30 |  Loss: (0.0071) | Acc: (99.80%) (3960/3968)\n",
            "Epoch: 125 | Batch_idx: 40 |  Loss: (0.0088) | Acc: (99.71%) (5233/5248)\n",
            "Epoch: 125 | Batch_idx: 50 |  Loss: (0.0084) | Acc: (99.74%) (6511/6528)\n",
            "Epoch: 125 | Batch_idx: 60 |  Loss: (0.0086) | Acc: (99.73%) (7787/7808)\n",
            "Epoch: 125 | Batch_idx: 70 |  Loss: (0.0087) | Acc: (99.71%) (9062/9088)\n",
            "Epoch: 125 | Batch_idx: 80 |  Loss: (0.0083) | Acc: (99.73%) (10340/10368)\n",
            "Epoch: 125 | Batch_idx: 90 |  Loss: (0.0078) | Acc: (99.76%) (11620/11648)\n",
            "Epoch: 125 | Batch_idx: 100 |  Loss: (0.0080) | Acc: (99.76%) (12897/12928)\n",
            "Epoch: 125 | Batch_idx: 110 |  Loss: (0.0079) | Acc: (99.77%) (14175/14208)\n",
            "Epoch: 125 | Batch_idx: 120 |  Loss: (0.0076) | Acc: (99.79%) (15455/15488)\n",
            "Epoch: 125 | Batch_idx: 130 |  Loss: (0.0073) | Acc: (99.80%) (16734/16768)\n",
            "Epoch: 125 | Batch_idx: 140 |  Loss: (0.0071) | Acc: (99.79%) (18011/18048)\n",
            "Epoch: 125 | Batch_idx: 150 |  Loss: (0.0074) | Acc: (99.78%) (19285/19328)\n",
            "Epoch: 125 | Batch_idx: 160 |  Loss: (0.0074) | Acc: (99.78%) (20562/20608)\n",
            "Epoch: 125 | Batch_idx: 170 |  Loss: (0.0073) | Acc: (99.79%) (21841/21888)\n",
            "Epoch: 125 | Batch_idx: 180 |  Loss: (0.0073) | Acc: (99.79%) (23119/23168)\n",
            "Epoch: 125 | Batch_idx: 190 |  Loss: (0.0074) | Acc: (99.78%) (24395/24448)\n",
            "Epoch: 125 | Batch_idx: 200 |  Loss: (0.0075) | Acc: (99.77%) (25670/25728)\n",
            "Epoch: 125 | Batch_idx: 210 |  Loss: (0.0074) | Acc: (99.77%) (26946/27008)\n",
            "Epoch: 125 | Batch_idx: 220 |  Loss: (0.0075) | Acc: (99.76%) (28221/28288)\n",
            "Epoch: 125 | Batch_idx: 230 |  Loss: (0.0075) | Acc: (99.76%) (29498/29568)\n",
            "Epoch: 125 | Batch_idx: 240 |  Loss: (0.0074) | Acc: (99.76%) (30775/30848)\n",
            "Epoch: 125 | Batch_idx: 250 |  Loss: (0.0074) | Acc: (99.76%) (32051/32128)\n",
            "Epoch: 125 | Batch_idx: 260 |  Loss: (0.0073) | Acc: (99.76%) (33328/33408)\n",
            "Epoch: 125 | Batch_idx: 270 |  Loss: (0.0075) | Acc: (99.76%) (34604/34688)\n",
            "Epoch: 125 | Batch_idx: 280 |  Loss: (0.0073) | Acc: (99.77%) (35884/35968)\n",
            "Epoch: 125 | Batch_idx: 290 |  Loss: (0.0075) | Acc: (99.76%) (37158/37248)\n",
            "Epoch: 125 | Batch_idx: 300 |  Loss: (0.0075) | Acc: (99.76%) (38435/38528)\n",
            "Epoch: 125 | Batch_idx: 310 |  Loss: (0.0074) | Acc: (99.76%) (39713/39808)\n",
            "Epoch: 125 | Batch_idx: 320 |  Loss: (0.0074) | Acc: (99.76%) (40990/41088)\n",
            "Epoch: 125 | Batch_idx: 330 |  Loss: (0.0076) | Acc: (99.76%) (42266/42368)\n",
            "Epoch: 125 | Batch_idx: 340 |  Loss: (0.0079) | Acc: (99.75%) (43537/43648)\n",
            "Epoch: 125 | Batch_idx: 350 |  Loss: (0.0080) | Acc: (99.75%) (44814/44928)\n",
            "Epoch: 125 | Batch_idx: 360 |  Loss: (0.0080) | Acc: (99.75%) (46091/46208)\n",
            "Epoch: 125 | Batch_idx: 370 |  Loss: (0.0080) | Acc: (99.75%) (47367/47488)\n",
            "Epoch: 125 | Batch_idx: 380 |  Loss: (0.0080) | Acc: (99.75%) (48645/48768)\n",
            "Epoch: 125 | Batch_idx: 390 |  Loss: (0.0080) | Acc: (99.75%) (49873/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4107) | Acc: (91.66%) (9166/10000)\n",
            "Epoch: 126 | Batch_idx: 0 |  Loss: (0.0045) | Acc: (100.00%) (128/128)\n",
            "Epoch: 126 | Batch_idx: 10 |  Loss: (0.0067) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 126 | Batch_idx: 20 |  Loss: (0.0094) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 126 | Batch_idx: 30 |  Loss: (0.0075) | Acc: (99.77%) (3959/3968)\n",
            "Epoch: 126 | Batch_idx: 40 |  Loss: (0.0083) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 126 | Batch_idx: 50 |  Loss: (0.0084) | Acc: (99.72%) (6510/6528)\n",
            "Epoch: 126 | Batch_idx: 60 |  Loss: (0.0086) | Acc: (99.72%) (7786/7808)\n",
            "Epoch: 126 | Batch_idx: 70 |  Loss: (0.0077) | Acc: (99.75%) (9065/9088)\n",
            "Epoch: 126 | Batch_idx: 80 |  Loss: (0.0079) | Acc: (99.74%) (10341/10368)\n",
            "Epoch: 126 | Batch_idx: 90 |  Loss: (0.0083) | Acc: (99.75%) (11619/11648)\n",
            "Epoch: 126 | Batch_idx: 100 |  Loss: (0.0090) | Acc: (99.73%) (12893/12928)\n",
            "Epoch: 126 | Batch_idx: 110 |  Loss: (0.0088) | Acc: (99.73%) (14170/14208)\n",
            "Epoch: 126 | Batch_idx: 120 |  Loss: (0.0089) | Acc: (99.72%) (15445/15488)\n",
            "Epoch: 126 | Batch_idx: 130 |  Loss: (0.0089) | Acc: (99.72%) (16721/16768)\n",
            "Epoch: 126 | Batch_idx: 140 |  Loss: (0.0086) | Acc: (99.73%) (17999/18048)\n",
            "Epoch: 126 | Batch_idx: 150 |  Loss: (0.0082) | Acc: (99.74%) (19278/19328)\n",
            "Epoch: 126 | Batch_idx: 160 |  Loss: (0.0082) | Acc: (99.74%) (20555/20608)\n",
            "Epoch: 126 | Batch_idx: 170 |  Loss: (0.0081) | Acc: (99.75%) (21833/21888)\n",
            "Epoch: 126 | Batch_idx: 180 |  Loss: (0.0083) | Acc: (99.74%) (23108/23168)\n",
            "Epoch: 126 | Batch_idx: 190 |  Loss: (0.0081) | Acc: (99.75%) (24387/24448)\n",
            "Epoch: 126 | Batch_idx: 200 |  Loss: (0.0079) | Acc: (99.76%) (25665/25728)\n",
            "Epoch: 126 | Batch_idx: 210 |  Loss: (0.0077) | Acc: (99.76%) (26944/27008)\n",
            "Epoch: 126 | Batch_idx: 220 |  Loss: (0.0077) | Acc: (99.77%) (28222/28288)\n",
            "Epoch: 126 | Batch_idx: 230 |  Loss: (0.0076) | Acc: (99.76%) (29498/29568)\n",
            "Epoch: 126 | Batch_idx: 240 |  Loss: (0.0077) | Acc: (99.76%) (30774/30848)\n",
            "Epoch: 126 | Batch_idx: 250 |  Loss: (0.0076) | Acc: (99.76%) (32052/32128)\n",
            "Epoch: 126 | Batch_idx: 260 |  Loss: (0.0078) | Acc: (99.76%) (33327/33408)\n",
            "Epoch: 126 | Batch_idx: 270 |  Loss: (0.0080) | Acc: (99.75%) (34602/34688)\n",
            "Epoch: 126 | Batch_idx: 280 |  Loss: (0.0081) | Acc: (99.75%) (35879/35968)\n",
            "Epoch: 126 | Batch_idx: 290 |  Loss: (0.0080) | Acc: (99.76%) (37157/37248)\n",
            "Epoch: 126 | Batch_idx: 300 |  Loss: (0.0080) | Acc: (99.76%) (38434/38528)\n",
            "Epoch: 126 | Batch_idx: 310 |  Loss: (0.0079) | Acc: (99.76%) (39712/39808)\n",
            "Epoch: 126 | Batch_idx: 320 |  Loss: (0.0078) | Acc: (99.76%) (40991/41088)\n",
            "Epoch: 126 | Batch_idx: 330 |  Loss: (0.0077) | Acc: (99.76%) (42268/42368)\n",
            "Epoch: 126 | Batch_idx: 340 |  Loss: (0.0076) | Acc: (99.77%) (43547/43648)\n",
            "Epoch: 126 | Batch_idx: 350 |  Loss: (0.0077) | Acc: (99.76%) (44822/44928)\n",
            "Epoch: 126 | Batch_idx: 360 |  Loss: (0.0078) | Acc: (99.76%) (46097/46208)\n",
            "Epoch: 126 | Batch_idx: 370 |  Loss: (0.0078) | Acc: (99.75%) (47371/47488)\n",
            "Epoch: 126 | Batch_idx: 380 |  Loss: (0.0078) | Acc: (99.75%) (48647/48768)\n",
            "Epoch: 126 | Batch_idx: 390 |  Loss: (0.0078) | Acc: (99.75%) (49876/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4060) | Acc: (91.69%) (9169/10000)\n",
            "Epoch: 127 | Batch_idx: 0 |  Loss: (0.0005) | Acc: (100.00%) (128/128)\n",
            "Epoch: 127 | Batch_idx: 10 |  Loss: (0.0076) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 127 | Batch_idx: 20 |  Loss: (0.0061) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 127 | Batch_idx: 30 |  Loss: (0.0061) | Acc: (99.75%) (3958/3968)\n",
            "Epoch: 127 | Batch_idx: 40 |  Loss: (0.0061) | Acc: (99.75%) (5235/5248)\n",
            "Epoch: 127 | Batch_idx: 50 |  Loss: (0.0066) | Acc: (99.77%) (6513/6528)\n",
            "Epoch: 127 | Batch_idx: 60 |  Loss: (0.0063) | Acc: (99.78%) (7791/7808)\n",
            "Epoch: 127 | Batch_idx: 70 |  Loss: (0.0058) | Acc: (99.81%) (9071/9088)\n",
            "Epoch: 127 | Batch_idx: 80 |  Loss: (0.0059) | Acc: (99.81%) (10348/10368)\n",
            "Epoch: 127 | Batch_idx: 90 |  Loss: (0.0058) | Acc: (99.81%) (11626/11648)\n",
            "Epoch: 127 | Batch_idx: 100 |  Loss: (0.0062) | Acc: (99.80%) (12902/12928)\n",
            "Epoch: 127 | Batch_idx: 110 |  Loss: (0.0071) | Acc: (99.77%) (14175/14208)\n",
            "Epoch: 127 | Batch_idx: 120 |  Loss: (0.0069) | Acc: (99.78%) (15454/15488)\n",
            "Epoch: 127 | Batch_idx: 130 |  Loss: (0.0067) | Acc: (99.78%) (16731/16768)\n",
            "Epoch: 127 | Batch_idx: 140 |  Loss: (0.0067) | Acc: (99.78%) (18008/18048)\n",
            "Epoch: 127 | Batch_idx: 150 |  Loss: (0.0067) | Acc: (99.77%) (19284/19328)\n",
            "Epoch: 127 | Batch_idx: 160 |  Loss: (0.0065) | Acc: (99.78%) (20563/20608)\n",
            "Epoch: 127 | Batch_idx: 170 |  Loss: (0.0064) | Acc: (99.79%) (21842/21888)\n",
            "Epoch: 127 | Batch_idx: 180 |  Loss: (0.0063) | Acc: (99.80%) (23121/23168)\n",
            "Epoch: 127 | Batch_idx: 190 |  Loss: (0.0064) | Acc: (99.80%) (24398/24448)\n",
            "Epoch: 127 | Batch_idx: 200 |  Loss: (0.0063) | Acc: (99.80%) (25676/25728)\n",
            "Epoch: 127 | Batch_idx: 210 |  Loss: (0.0067) | Acc: (99.79%) (26950/27008)\n",
            "Epoch: 127 | Batch_idx: 220 |  Loss: (0.0067) | Acc: (99.79%) (28228/28288)\n",
            "Epoch: 127 | Batch_idx: 230 |  Loss: (0.0067) | Acc: (99.78%) (29504/29568)\n",
            "Epoch: 127 | Batch_idx: 240 |  Loss: (0.0068) | Acc: (99.78%) (30780/30848)\n",
            "Epoch: 127 | Batch_idx: 250 |  Loss: (0.0067) | Acc: (99.78%) (32057/32128)\n",
            "Epoch: 127 | Batch_idx: 260 |  Loss: (0.0068) | Acc: (99.78%) (33333/33408)\n",
            "Epoch: 127 | Batch_idx: 270 |  Loss: (0.0068) | Acc: (99.77%) (34609/34688)\n",
            "Epoch: 127 | Batch_idx: 280 |  Loss: (0.0069) | Acc: (99.77%) (35885/35968)\n",
            "Epoch: 127 | Batch_idx: 290 |  Loss: (0.0069) | Acc: (99.77%) (37162/37248)\n",
            "Epoch: 127 | Batch_idx: 300 |  Loss: (0.0068) | Acc: (99.77%) (38439/38528)\n",
            "Epoch: 127 | Batch_idx: 310 |  Loss: (0.0069) | Acc: (99.76%) (39714/39808)\n",
            "Epoch: 127 | Batch_idx: 320 |  Loss: (0.0068) | Acc: (99.77%) (40992/41088)\n",
            "Epoch: 127 | Batch_idx: 330 |  Loss: (0.0067) | Acc: (99.77%) (42271/42368)\n",
            "Epoch: 127 | Batch_idx: 340 |  Loss: (0.0069) | Acc: (99.76%) (43545/43648)\n",
            "Epoch: 127 | Batch_idx: 350 |  Loss: (0.0068) | Acc: (99.77%) (44824/44928)\n",
            "Epoch: 127 | Batch_idx: 360 |  Loss: (0.0068) | Acc: (99.77%) (46102/46208)\n",
            "Epoch: 127 | Batch_idx: 370 |  Loss: (0.0068) | Acc: (99.77%) (47379/47488)\n",
            "Epoch: 127 | Batch_idx: 380 |  Loss: (0.0069) | Acc: (99.77%) (48655/48768)\n",
            "Epoch: 127 | Batch_idx: 390 |  Loss: (0.0069) | Acc: (99.77%) (49883/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4111) | Acc: (91.70%) (9170/10000)\n",
            "Epoch: 128 | Batch_idx: 0 |  Loss: (0.0011) | Acc: (100.00%) (128/128)\n",
            "Epoch: 128 | Batch_idx: 10 |  Loss: (0.0064) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 128 | Batch_idx: 20 |  Loss: (0.0065) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 128 | Batch_idx: 30 |  Loss: (0.0062) | Acc: (99.82%) (3961/3968)\n",
            "Epoch: 128 | Batch_idx: 40 |  Loss: (0.0075) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 128 | Batch_idx: 50 |  Loss: (0.0075) | Acc: (99.77%) (6513/6528)\n",
            "Epoch: 128 | Batch_idx: 60 |  Loss: (0.0071) | Acc: (99.78%) (7791/7808)\n",
            "Epoch: 128 | Batch_idx: 70 |  Loss: (0.0068) | Acc: (99.78%) (9068/9088)\n",
            "Epoch: 128 | Batch_idx: 80 |  Loss: (0.0064) | Acc: (99.79%) (10346/10368)\n",
            "Epoch: 128 | Batch_idx: 90 |  Loss: (0.0063) | Acc: (99.79%) (11623/11648)\n",
            "Epoch: 128 | Batch_idx: 100 |  Loss: (0.0061) | Acc: (99.80%) (12902/12928)\n",
            "Epoch: 128 | Batch_idx: 110 |  Loss: (0.0062) | Acc: (99.80%) (14180/14208)\n",
            "Epoch: 128 | Batch_idx: 120 |  Loss: (0.0063) | Acc: (99.79%) (15455/15488)\n",
            "Epoch: 128 | Batch_idx: 130 |  Loss: (0.0064) | Acc: (99.79%) (16732/16768)\n",
            "Epoch: 128 | Batch_idx: 140 |  Loss: (0.0066) | Acc: (99.78%) (18008/18048)\n",
            "Epoch: 128 | Batch_idx: 150 |  Loss: (0.0064) | Acc: (99.78%) (19286/19328)\n",
            "Epoch: 128 | Batch_idx: 160 |  Loss: (0.0064) | Acc: (99.77%) (20561/20608)\n",
            "Epoch: 128 | Batch_idx: 170 |  Loss: (0.0065) | Acc: (99.76%) (21835/21888)\n",
            "Epoch: 128 | Batch_idx: 180 |  Loss: (0.0066) | Acc: (99.75%) (23111/23168)\n",
            "Epoch: 128 | Batch_idx: 190 |  Loss: (0.0065) | Acc: (99.76%) (24389/24448)\n",
            "Epoch: 128 | Batch_idx: 200 |  Loss: (0.0065) | Acc: (99.76%) (25666/25728)\n",
            "Epoch: 128 | Batch_idx: 210 |  Loss: (0.0065) | Acc: (99.76%) (26943/27008)\n",
            "Epoch: 128 | Batch_idx: 220 |  Loss: (0.0064) | Acc: (99.76%) (28221/28288)\n",
            "Epoch: 128 | Batch_idx: 230 |  Loss: (0.0066) | Acc: (99.76%) (29497/29568)\n",
            "Epoch: 128 | Batch_idx: 240 |  Loss: (0.0066) | Acc: (99.76%) (30775/30848)\n",
            "Epoch: 128 | Batch_idx: 250 |  Loss: (0.0068) | Acc: (99.76%) (32051/32128)\n",
            "Epoch: 128 | Batch_idx: 260 |  Loss: (0.0066) | Acc: (99.77%) (33330/33408)\n",
            "Epoch: 128 | Batch_idx: 270 |  Loss: (0.0068) | Acc: (99.76%) (34606/34688)\n",
            "Epoch: 128 | Batch_idx: 280 |  Loss: (0.0068) | Acc: (99.77%) (35884/35968)\n",
            "Epoch: 128 | Batch_idx: 290 |  Loss: (0.0068) | Acc: (99.77%) (37161/37248)\n",
            "Epoch: 128 | Batch_idx: 300 |  Loss: (0.0068) | Acc: (99.77%) (38438/38528)\n",
            "Epoch: 128 | Batch_idx: 310 |  Loss: (0.0070) | Acc: (99.76%) (39713/39808)\n",
            "Epoch: 128 | Batch_idx: 320 |  Loss: (0.0069) | Acc: (99.76%) (40989/41088)\n",
            "Epoch: 128 | Batch_idx: 330 |  Loss: (0.0070) | Acc: (99.76%) (42265/42368)\n",
            "Epoch: 128 | Batch_idx: 340 |  Loss: (0.0072) | Acc: (99.75%) (43538/43648)\n",
            "Epoch: 128 | Batch_idx: 350 |  Loss: (0.0072) | Acc: (99.75%) (44816/44928)\n",
            "Epoch: 128 | Batch_idx: 360 |  Loss: (0.0071) | Acc: (99.75%) (46094/46208)\n",
            "Epoch: 128 | Batch_idx: 370 |  Loss: (0.0071) | Acc: (99.76%) (47372/47488)\n",
            "Epoch: 128 | Batch_idx: 380 |  Loss: (0.0070) | Acc: (99.76%) (48649/48768)\n",
            "Epoch: 128 | Batch_idx: 390 |  Loss: (0.0070) | Acc: (99.75%) (49876/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4111) | Acc: (91.63%) (9163/10000)\n",
            "Epoch: 129 | Batch_idx: 0 |  Loss: (0.0015) | Acc: (100.00%) (128/128)\n",
            "Epoch: 129 | Batch_idx: 10 |  Loss: (0.0067) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 129 | Batch_idx: 20 |  Loss: (0.0063) | Acc: (99.81%) (2683/2688)\n",
            "Epoch: 129 | Batch_idx: 30 |  Loss: (0.0058) | Acc: (99.80%) (3960/3968)\n",
            "Epoch: 129 | Batch_idx: 40 |  Loss: (0.0063) | Acc: (99.81%) (5238/5248)\n",
            "Epoch: 129 | Batch_idx: 50 |  Loss: (0.0062) | Acc: (99.80%) (6515/6528)\n",
            "Epoch: 129 | Batch_idx: 60 |  Loss: (0.0065) | Acc: (99.80%) (7792/7808)\n",
            "Epoch: 129 | Batch_idx: 70 |  Loss: (0.0067) | Acc: (99.81%) (9071/9088)\n",
            "Epoch: 129 | Batch_idx: 80 |  Loss: (0.0070) | Acc: (99.80%) (10347/10368)\n",
            "Epoch: 129 | Batch_idx: 90 |  Loss: (0.0071) | Acc: (99.79%) (11623/11648)\n",
            "Epoch: 129 | Batch_idx: 100 |  Loss: (0.0069) | Acc: (99.78%) (12900/12928)\n",
            "Epoch: 129 | Batch_idx: 110 |  Loss: (0.0070) | Acc: (99.78%) (14177/14208)\n",
            "Epoch: 129 | Batch_idx: 120 |  Loss: (0.0069) | Acc: (99.78%) (15454/15488)\n",
            "Epoch: 129 | Batch_idx: 130 |  Loss: (0.0069) | Acc: (99.78%) (16731/16768)\n",
            "Epoch: 129 | Batch_idx: 140 |  Loss: (0.0071) | Acc: (99.77%) (18007/18048)\n",
            "Epoch: 129 | Batch_idx: 150 |  Loss: (0.0073) | Acc: (99.76%) (19282/19328)\n",
            "Epoch: 129 | Batch_idx: 160 |  Loss: (0.0072) | Acc: (99.77%) (20560/20608)\n",
            "Epoch: 129 | Batch_idx: 170 |  Loss: (0.0070) | Acc: (99.78%) (21840/21888)\n",
            "Epoch: 129 | Batch_idx: 180 |  Loss: (0.0070) | Acc: (99.78%) (23117/23168)\n",
            "Epoch: 129 | Batch_idx: 190 |  Loss: (0.0069) | Acc: (99.79%) (24396/24448)\n",
            "Epoch: 129 | Batch_idx: 200 |  Loss: (0.0068) | Acc: (99.79%) (25675/25728)\n",
            "Epoch: 129 | Batch_idx: 210 |  Loss: (0.0069) | Acc: (99.78%) (26949/27008)\n",
            "Epoch: 129 | Batch_idx: 220 |  Loss: (0.0069) | Acc: (99.79%) (28228/28288)\n",
            "Epoch: 129 | Batch_idx: 230 |  Loss: (0.0070) | Acc: (99.79%) (29505/29568)\n",
            "Epoch: 129 | Batch_idx: 240 |  Loss: (0.0070) | Acc: (99.79%) (30783/30848)\n",
            "Epoch: 129 | Batch_idx: 250 |  Loss: (0.0070) | Acc: (99.79%) (32061/32128)\n",
            "Epoch: 129 | Batch_idx: 260 |  Loss: (0.0069) | Acc: (99.79%) (33337/33408)\n",
            "Epoch: 129 | Batch_idx: 270 |  Loss: (0.0071) | Acc: (99.78%) (34610/34688)\n",
            "Epoch: 129 | Batch_idx: 280 |  Loss: (0.0071) | Acc: (99.77%) (35886/35968)\n",
            "Epoch: 129 | Batch_idx: 290 |  Loss: (0.0070) | Acc: (99.77%) (37163/37248)\n",
            "Epoch: 129 | Batch_idx: 300 |  Loss: (0.0069) | Acc: (99.77%) (38441/38528)\n",
            "Epoch: 129 | Batch_idx: 310 |  Loss: (0.0068) | Acc: (99.78%) (39720/39808)\n",
            "Epoch: 129 | Batch_idx: 320 |  Loss: (0.0067) | Acc: (99.78%) (40999/41088)\n",
            "Epoch: 129 | Batch_idx: 330 |  Loss: (0.0066) | Acc: (99.79%) (42279/42368)\n",
            "Epoch: 129 | Batch_idx: 340 |  Loss: (0.0065) | Acc: (99.79%) (43557/43648)\n",
            "Epoch: 129 | Batch_idx: 350 |  Loss: (0.0065) | Acc: (99.79%) (44834/44928)\n",
            "Epoch: 129 | Batch_idx: 360 |  Loss: (0.0064) | Acc: (99.79%) (46113/46208)\n",
            "Epoch: 129 | Batch_idx: 370 |  Loss: (0.0065) | Acc: (99.79%) (47389/47488)\n",
            "Epoch: 129 | Batch_idx: 380 |  Loss: (0.0066) | Acc: (99.79%) (48664/48768)\n",
            "Epoch: 129 | Batch_idx: 390 |  Loss: (0.0066) | Acc: (99.79%) (49893/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4097) | Acc: (91.72%) (9172/10000)\n",
            "Epoch: 130 | Batch_idx: 0 |  Loss: (0.0013) | Acc: (100.00%) (128/128)\n",
            "Epoch: 130 | Batch_idx: 10 |  Loss: (0.0122) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 130 | Batch_idx: 20 |  Loss: (0.0109) | Acc: (99.70%) (2680/2688)\n",
            "Epoch: 130 | Batch_idx: 30 |  Loss: (0.0105) | Acc: (99.67%) (3955/3968)\n",
            "Epoch: 130 | Batch_idx: 40 |  Loss: (0.0089) | Acc: (99.73%) (5234/5248)\n",
            "Epoch: 130 | Batch_idx: 50 |  Loss: (0.0085) | Acc: (99.72%) (6510/6528)\n",
            "Epoch: 130 | Batch_idx: 60 |  Loss: (0.0082) | Acc: (99.71%) (7785/7808)\n",
            "Epoch: 130 | Batch_idx: 70 |  Loss: (0.0078) | Acc: (99.72%) (9063/9088)\n",
            "Epoch: 130 | Batch_idx: 80 |  Loss: (0.0073) | Acc: (99.75%) (10342/10368)\n",
            "Epoch: 130 | Batch_idx: 90 |  Loss: (0.0068) | Acc: (99.77%) (11621/11648)\n",
            "Epoch: 130 | Batch_idx: 100 |  Loss: (0.0066) | Acc: (99.78%) (12899/12928)\n",
            "Epoch: 130 | Batch_idx: 110 |  Loss: (0.0063) | Acc: (99.80%) (14179/14208)\n",
            "Epoch: 130 | Batch_idx: 120 |  Loss: (0.0062) | Acc: (99.79%) (15456/15488)\n",
            "Epoch: 130 | Batch_idx: 130 |  Loss: (0.0059) | Acc: (99.80%) (16735/16768)\n",
            "Epoch: 130 | Batch_idx: 140 |  Loss: (0.0057) | Acc: (99.81%) (18013/18048)\n",
            "Epoch: 130 | Batch_idx: 150 |  Loss: (0.0056) | Acc: (99.81%) (19292/19328)\n",
            "Epoch: 130 | Batch_idx: 160 |  Loss: (0.0058) | Acc: (99.82%) (20570/20608)\n",
            "Epoch: 130 | Batch_idx: 170 |  Loss: (0.0061) | Acc: (99.81%) (21846/21888)\n",
            "Epoch: 130 | Batch_idx: 180 |  Loss: (0.0060) | Acc: (99.81%) (23124/23168)\n",
            "Epoch: 130 | Batch_idx: 190 |  Loss: (0.0060) | Acc: (99.81%) (24402/24448)\n",
            "Epoch: 130 | Batch_idx: 200 |  Loss: (0.0059) | Acc: (99.81%) (25680/25728)\n",
            "Epoch: 130 | Batch_idx: 210 |  Loss: (0.0058) | Acc: (99.82%) (26959/27008)\n",
            "Epoch: 130 | Batch_idx: 220 |  Loss: (0.0058) | Acc: (99.81%) (28235/28288)\n",
            "Epoch: 130 | Batch_idx: 230 |  Loss: (0.0064) | Acc: (99.79%) (29505/29568)\n",
            "Epoch: 130 | Batch_idx: 240 |  Loss: (0.0066) | Acc: (99.78%) (30781/30848)\n",
            "Epoch: 130 | Batch_idx: 250 |  Loss: (0.0066) | Acc: (99.78%) (32057/32128)\n",
            "Epoch: 130 | Batch_idx: 260 |  Loss: (0.0066) | Acc: (99.78%) (33335/33408)\n",
            "Epoch: 130 | Batch_idx: 270 |  Loss: (0.0070) | Acc: (99.78%) (34610/34688)\n",
            "Epoch: 130 | Batch_idx: 280 |  Loss: (0.0072) | Acc: (99.77%) (35885/35968)\n",
            "Epoch: 130 | Batch_idx: 290 |  Loss: (0.0071) | Acc: (99.77%) (37163/37248)\n",
            "Epoch: 130 | Batch_idx: 300 |  Loss: (0.0070) | Acc: (99.77%) (38441/38528)\n",
            "Epoch: 130 | Batch_idx: 310 |  Loss: (0.0071) | Acc: (99.77%) (39717/39808)\n",
            "Epoch: 130 | Batch_idx: 320 |  Loss: (0.0072) | Acc: (99.77%) (40994/41088)\n",
            "Epoch: 130 | Batch_idx: 330 |  Loss: (0.0071) | Acc: (99.77%) (42271/42368)\n",
            "Epoch: 130 | Batch_idx: 340 |  Loss: (0.0070) | Acc: (99.77%) (43548/43648)\n",
            "Epoch: 130 | Batch_idx: 350 |  Loss: (0.0071) | Acc: (99.76%) (44821/44928)\n",
            "Epoch: 130 | Batch_idx: 360 |  Loss: (0.0071) | Acc: (99.76%) (46097/46208)\n",
            "Epoch: 130 | Batch_idx: 370 |  Loss: (0.0073) | Acc: (99.75%) (47369/47488)\n",
            "Epoch: 130 | Batch_idx: 380 |  Loss: (0.0074) | Acc: (99.75%) (48645/48768)\n",
            "Epoch: 130 | Batch_idx: 390 |  Loss: (0.0074) | Acc: (99.75%) (49873/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4149) | Acc: (91.77%) (9177/10000)\n",
            "Epoch: 131 | Batch_idx: 0 |  Loss: (0.0087) | Acc: (99.22%) (127/128)\n",
            "Epoch: 131 | Batch_idx: 10 |  Loss: (0.0070) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 131 | Batch_idx: 20 |  Loss: (0.0063) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 131 | Batch_idx: 30 |  Loss: (0.0060) | Acc: (99.77%) (3959/3968)\n",
            "Epoch: 131 | Batch_idx: 40 |  Loss: (0.0060) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 131 | Batch_idx: 50 |  Loss: (0.0068) | Acc: (99.79%) (6514/6528)\n",
            "Epoch: 131 | Batch_idx: 60 |  Loss: (0.0063) | Acc: (99.81%) (7793/7808)\n",
            "Epoch: 131 | Batch_idx: 70 |  Loss: (0.0060) | Acc: (99.81%) (9071/9088)\n",
            "Epoch: 131 | Batch_idx: 80 |  Loss: (0.0062) | Acc: (99.81%) (10348/10368)\n",
            "Epoch: 131 | Batch_idx: 90 |  Loss: (0.0062) | Acc: (99.81%) (11626/11648)\n",
            "Epoch: 131 | Batch_idx: 100 |  Loss: (0.0059) | Acc: (99.81%) (12904/12928)\n",
            "Epoch: 131 | Batch_idx: 110 |  Loss: (0.0066) | Acc: (99.79%) (14178/14208)\n",
            "Epoch: 131 | Batch_idx: 120 |  Loss: (0.0063) | Acc: (99.80%) (15457/15488)\n",
            "Epoch: 131 | Batch_idx: 130 |  Loss: (0.0071) | Acc: (99.77%) (16730/16768)\n",
            "Epoch: 131 | Batch_idx: 140 |  Loss: (0.0068) | Acc: (99.78%) (18009/18048)\n",
            "Epoch: 131 | Batch_idx: 150 |  Loss: (0.0068) | Acc: (99.78%) (19286/19328)\n",
            "Epoch: 131 | Batch_idx: 160 |  Loss: (0.0068) | Acc: (99.78%) (20562/20608)\n",
            "Epoch: 131 | Batch_idx: 170 |  Loss: (0.0068) | Acc: (99.78%) (21840/21888)\n",
            "Epoch: 131 | Batch_idx: 180 |  Loss: (0.0067) | Acc: (99.78%) (23118/23168)\n",
            "Epoch: 131 | Batch_idx: 190 |  Loss: (0.0067) | Acc: (99.78%) (24394/24448)\n",
            "Epoch: 131 | Batch_idx: 200 |  Loss: (0.0065) | Acc: (99.79%) (25674/25728)\n",
            "Epoch: 131 | Batch_idx: 210 |  Loss: (0.0065) | Acc: (99.79%) (26951/27008)\n",
            "Epoch: 131 | Batch_idx: 220 |  Loss: (0.0065) | Acc: (99.79%) (28229/28288)\n",
            "Epoch: 131 | Batch_idx: 230 |  Loss: (0.0064) | Acc: (99.80%) (29508/29568)\n",
            "Epoch: 131 | Batch_idx: 240 |  Loss: (0.0067) | Acc: (99.78%) (30781/30848)\n",
            "Epoch: 131 | Batch_idx: 250 |  Loss: (0.0067) | Acc: (99.79%) (32059/32128)\n",
            "Epoch: 131 | Batch_idx: 260 |  Loss: (0.0067) | Acc: (99.78%) (33335/33408)\n",
            "Epoch: 131 | Batch_idx: 270 |  Loss: (0.0066) | Acc: (99.78%) (34613/34688)\n",
            "Epoch: 131 | Batch_idx: 280 |  Loss: (0.0066) | Acc: (99.79%) (35892/35968)\n",
            "Epoch: 131 | Batch_idx: 290 |  Loss: (0.0065) | Acc: (99.79%) (37170/37248)\n",
            "Epoch: 131 | Batch_idx: 300 |  Loss: (0.0064) | Acc: (99.80%) (38450/38528)\n",
            "Epoch: 131 | Batch_idx: 310 |  Loss: (0.0065) | Acc: (99.79%) (39725/39808)\n",
            "Epoch: 131 | Batch_idx: 320 |  Loss: (0.0067) | Acc: (99.79%) (41001/41088)\n",
            "Epoch: 131 | Batch_idx: 330 |  Loss: (0.0066) | Acc: (99.78%) (42276/42368)\n",
            "Epoch: 131 | Batch_idx: 340 |  Loss: (0.0066) | Acc: (99.78%) (43554/43648)\n",
            "Epoch: 131 | Batch_idx: 350 |  Loss: (0.0067) | Acc: (99.78%) (44830/44928)\n",
            "Epoch: 131 | Batch_idx: 360 |  Loss: (0.0068) | Acc: (99.78%) (46107/46208)\n",
            "Epoch: 131 | Batch_idx: 370 |  Loss: (0.0067) | Acc: (99.78%) (47384/47488)\n",
            "Epoch: 131 | Batch_idx: 380 |  Loss: (0.0068) | Acc: (99.78%) (48660/48768)\n",
            "Epoch: 131 | Batch_idx: 390 |  Loss: (0.0068) | Acc: (99.78%) (49888/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4125) | Acc: (91.72%) (9172/10000)\n",
            "Epoch: 132 | Batch_idx: 0 |  Loss: (0.0106) | Acc: (99.22%) (127/128)\n",
            "Epoch: 132 | Batch_idx: 10 |  Loss: (0.0083) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 132 | Batch_idx: 20 |  Loss: (0.0061) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 132 | Batch_idx: 30 |  Loss: (0.0064) | Acc: (99.82%) (3961/3968)\n",
            "Epoch: 132 | Batch_idx: 40 |  Loss: (0.0067) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 132 | Batch_idx: 50 |  Loss: (0.0066) | Acc: (99.75%) (6512/6528)\n",
            "Epoch: 132 | Batch_idx: 60 |  Loss: (0.0069) | Acc: (99.74%) (7788/7808)\n",
            "Epoch: 132 | Batch_idx: 70 |  Loss: (0.0078) | Acc: (99.70%) (9061/9088)\n",
            "Epoch: 132 | Batch_idx: 80 |  Loss: (0.0078) | Acc: (99.71%) (10338/10368)\n",
            "Epoch: 132 | Batch_idx: 90 |  Loss: (0.0076) | Acc: (99.72%) (11615/11648)\n",
            "Epoch: 132 | Batch_idx: 100 |  Loss: (0.0075) | Acc: (99.72%) (12892/12928)\n",
            "Epoch: 132 | Batch_idx: 110 |  Loss: (0.0076) | Acc: (99.73%) (14169/14208)\n",
            "Epoch: 132 | Batch_idx: 120 |  Loss: (0.0075) | Acc: (99.74%) (15447/15488)\n",
            "Epoch: 132 | Batch_idx: 130 |  Loss: (0.0078) | Acc: (99.73%) (16723/16768)\n",
            "Epoch: 132 | Batch_idx: 140 |  Loss: (0.0077) | Acc: (99.73%) (18000/18048)\n",
            "Epoch: 132 | Batch_idx: 150 |  Loss: (0.0074) | Acc: (99.74%) (19278/19328)\n",
            "Epoch: 132 | Batch_idx: 160 |  Loss: (0.0073) | Acc: (99.75%) (20556/20608)\n",
            "Epoch: 132 | Batch_idx: 170 |  Loss: (0.0077) | Acc: (99.74%) (21830/21888)\n",
            "Epoch: 132 | Batch_idx: 180 |  Loss: (0.0075) | Acc: (99.75%) (23109/23168)\n",
            "Epoch: 132 | Batch_idx: 190 |  Loss: (0.0075) | Acc: (99.75%) (24386/24448)\n",
            "Epoch: 132 | Batch_idx: 200 |  Loss: (0.0076) | Acc: (99.74%) (25660/25728)\n",
            "Epoch: 132 | Batch_idx: 210 |  Loss: (0.0076) | Acc: (99.73%) (26935/27008)\n",
            "Epoch: 132 | Batch_idx: 220 |  Loss: (0.0075) | Acc: (99.73%) (28212/28288)\n",
            "Epoch: 132 | Batch_idx: 230 |  Loss: (0.0073) | Acc: (99.74%) (29492/29568)\n",
            "Epoch: 132 | Batch_idx: 240 |  Loss: (0.0071) | Acc: (99.75%) (30772/30848)\n",
            "Epoch: 132 | Batch_idx: 250 |  Loss: (0.0071) | Acc: (99.75%) (32049/32128)\n",
            "Epoch: 132 | Batch_idx: 260 |  Loss: (0.0071) | Acc: (99.75%) (33325/33408)\n",
            "Epoch: 132 | Batch_idx: 270 |  Loss: (0.0075) | Acc: (99.74%) (34598/34688)\n",
            "Epoch: 132 | Batch_idx: 280 |  Loss: (0.0075) | Acc: (99.74%) (35875/35968)\n",
            "Epoch: 132 | Batch_idx: 290 |  Loss: (0.0075) | Acc: (99.74%) (37153/37248)\n",
            "Epoch: 132 | Batch_idx: 300 |  Loss: (0.0073) | Acc: (99.75%) (38432/38528)\n",
            "Epoch: 132 | Batch_idx: 310 |  Loss: (0.0073) | Acc: (99.76%) (39711/39808)\n",
            "Epoch: 132 | Batch_idx: 320 |  Loss: (0.0073) | Acc: (99.76%) (40988/41088)\n",
            "Epoch: 132 | Batch_idx: 330 |  Loss: (0.0072) | Acc: (99.76%) (42267/42368)\n",
            "Epoch: 132 | Batch_idx: 340 |  Loss: (0.0072) | Acc: (99.76%) (43543/43648)\n",
            "Epoch: 132 | Batch_idx: 350 |  Loss: (0.0072) | Acc: (99.76%) (44820/44928)\n",
            "Epoch: 132 | Batch_idx: 360 |  Loss: (0.0072) | Acc: (99.76%) (46096/46208)\n",
            "Epoch: 132 | Batch_idx: 370 |  Loss: (0.0071) | Acc: (99.76%) (47375/47488)\n",
            "Epoch: 132 | Batch_idx: 380 |  Loss: (0.0071) | Acc: (99.76%) (48650/48768)\n",
            "Epoch: 132 | Batch_idx: 390 |  Loss: (0.0070) | Acc: (99.76%) (49881/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4192) | Acc: (91.67%) (9167/10000)\n",
            "Epoch: 133 | Batch_idx: 0 |  Loss: (0.0245) | Acc: (99.22%) (127/128)\n",
            "Epoch: 133 | Batch_idx: 10 |  Loss: (0.0069) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 133 | Batch_idx: 20 |  Loss: (0.0076) | Acc: (99.70%) (2680/2688)\n",
            "Epoch: 133 | Batch_idx: 30 |  Loss: (0.0084) | Acc: (99.70%) (3956/3968)\n",
            "Epoch: 133 | Batch_idx: 40 |  Loss: (0.0080) | Acc: (99.70%) (5232/5248)\n",
            "Epoch: 133 | Batch_idx: 50 |  Loss: (0.0072) | Acc: (99.72%) (6510/6528)\n",
            "Epoch: 133 | Batch_idx: 60 |  Loss: (0.0082) | Acc: (99.68%) (7783/7808)\n",
            "Epoch: 133 | Batch_idx: 70 |  Loss: (0.0076) | Acc: (99.70%) (9061/9088)\n",
            "Epoch: 133 | Batch_idx: 80 |  Loss: (0.0075) | Acc: (99.73%) (10340/10368)\n",
            "Epoch: 133 | Batch_idx: 90 |  Loss: (0.0081) | Acc: (99.70%) (11613/11648)\n",
            "Epoch: 133 | Batch_idx: 100 |  Loss: (0.0083) | Acc: (99.71%) (12890/12928)\n",
            "Epoch: 133 | Batch_idx: 110 |  Loss: (0.0084) | Acc: (99.70%) (14165/14208)\n",
            "Epoch: 133 | Batch_idx: 120 |  Loss: (0.0089) | Acc: (99.69%) (15440/15488)\n",
            "Epoch: 133 | Batch_idx: 130 |  Loss: (0.0085) | Acc: (99.71%) (16719/16768)\n",
            "Epoch: 133 | Batch_idx: 140 |  Loss: (0.0084) | Acc: (99.71%) (17996/18048)\n",
            "Epoch: 133 | Batch_idx: 150 |  Loss: (0.0081) | Acc: (99.73%) (19275/19328)\n",
            "Epoch: 133 | Batch_idx: 160 |  Loss: (0.0081) | Acc: (99.72%) (20551/20608)\n",
            "Epoch: 133 | Batch_idx: 170 |  Loss: (0.0079) | Acc: (99.74%) (21830/21888)\n",
            "Epoch: 133 | Batch_idx: 180 |  Loss: (0.0078) | Acc: (99.74%) (23107/23168)\n",
            "Epoch: 133 | Batch_idx: 190 |  Loss: (0.0079) | Acc: (99.73%) (24383/24448)\n",
            "Epoch: 133 | Batch_idx: 200 |  Loss: (0.0078) | Acc: (99.74%) (25660/25728)\n",
            "Epoch: 133 | Batch_idx: 210 |  Loss: (0.0078) | Acc: (99.73%) (26936/27008)\n",
            "Epoch: 133 | Batch_idx: 220 |  Loss: (0.0078) | Acc: (99.73%) (28212/28288)\n",
            "Epoch: 133 | Batch_idx: 230 |  Loss: (0.0076) | Acc: (99.74%) (29491/29568)\n",
            "Epoch: 133 | Batch_idx: 240 |  Loss: (0.0076) | Acc: (99.74%) (30768/30848)\n",
            "Epoch: 133 | Batch_idx: 250 |  Loss: (0.0075) | Acc: (99.74%) (32045/32128)\n",
            "Epoch: 133 | Batch_idx: 260 |  Loss: (0.0073) | Acc: (99.75%) (33324/33408)\n",
            "Epoch: 133 | Batch_idx: 270 |  Loss: (0.0072) | Acc: (99.75%) (34601/34688)\n",
            "Epoch: 133 | Batch_idx: 280 |  Loss: (0.0073) | Acc: (99.75%) (35877/35968)\n",
            "Epoch: 133 | Batch_idx: 290 |  Loss: (0.0074) | Acc: (99.75%) (37154/37248)\n",
            "Epoch: 133 | Batch_idx: 300 |  Loss: (0.0073) | Acc: (99.75%) (38433/38528)\n",
            "Epoch: 133 | Batch_idx: 310 |  Loss: (0.0073) | Acc: (99.75%) (39710/39808)\n",
            "Epoch: 133 | Batch_idx: 320 |  Loss: (0.0073) | Acc: (99.76%) (40988/41088)\n",
            "Epoch: 133 | Batch_idx: 330 |  Loss: (0.0074) | Acc: (99.75%) (42262/42368)\n",
            "Epoch: 133 | Batch_idx: 340 |  Loss: (0.0073) | Acc: (99.75%) (43540/43648)\n",
            "Epoch: 133 | Batch_idx: 350 |  Loss: (0.0072) | Acc: (99.76%) (44820/44928)\n",
            "Epoch: 133 | Batch_idx: 360 |  Loss: (0.0072) | Acc: (99.76%) (46098/46208)\n",
            "Epoch: 133 | Batch_idx: 370 |  Loss: (0.0072) | Acc: (99.76%) (47376/47488)\n",
            "Epoch: 133 | Batch_idx: 380 |  Loss: (0.0071) | Acc: (99.76%) (48653/48768)\n",
            "Epoch: 133 | Batch_idx: 390 |  Loss: (0.0072) | Acc: (99.76%) (49881/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4131) | Acc: (91.83%) (9183/10000)\n",
            "Epoch: 134 | Batch_idx: 0 |  Loss: (0.0079) | Acc: (99.22%) (127/128)\n",
            "Epoch: 134 | Batch_idx: 10 |  Loss: (0.0063) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 134 | Batch_idx: 20 |  Loss: (0.0058) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 134 | Batch_idx: 30 |  Loss: (0.0072) | Acc: (99.77%) (3959/3968)\n",
            "Epoch: 134 | Batch_idx: 40 |  Loss: (0.0068) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 134 | Batch_idx: 50 |  Loss: (0.0069) | Acc: (99.75%) (6512/6528)\n",
            "Epoch: 134 | Batch_idx: 60 |  Loss: (0.0070) | Acc: (99.76%) (7789/7808)\n",
            "Epoch: 134 | Batch_idx: 70 |  Loss: (0.0069) | Acc: (99.77%) (9067/9088)\n",
            "Epoch: 134 | Batch_idx: 80 |  Loss: (0.0069) | Acc: (99.79%) (10346/10368)\n",
            "Epoch: 134 | Batch_idx: 90 |  Loss: (0.0065) | Acc: (99.79%) (11624/11648)\n",
            "Epoch: 134 | Batch_idx: 100 |  Loss: (0.0065) | Acc: (99.80%) (12902/12928)\n",
            "Epoch: 134 | Batch_idx: 110 |  Loss: (0.0067) | Acc: (99.80%) (14179/14208)\n",
            "Epoch: 134 | Batch_idx: 120 |  Loss: (0.0067) | Acc: (99.79%) (15456/15488)\n",
            "Epoch: 134 | Batch_idx: 130 |  Loss: (0.0068) | Acc: (99.79%) (16732/16768)\n",
            "Epoch: 134 | Batch_idx: 140 |  Loss: (0.0068) | Acc: (99.78%) (18008/18048)\n",
            "Epoch: 134 | Batch_idx: 150 |  Loss: (0.0066) | Acc: (99.79%) (19287/19328)\n",
            "Epoch: 134 | Batch_idx: 160 |  Loss: (0.0066) | Acc: (99.79%) (20564/20608)\n",
            "Epoch: 134 | Batch_idx: 170 |  Loss: (0.0064) | Acc: (99.79%) (21843/21888)\n",
            "Epoch: 134 | Batch_idx: 180 |  Loss: (0.0062) | Acc: (99.80%) (23121/23168)\n",
            "Epoch: 134 | Batch_idx: 190 |  Loss: (0.0062) | Acc: (99.80%) (24399/24448)\n",
            "Epoch: 134 | Batch_idx: 200 |  Loss: (0.0063) | Acc: (99.80%) (25676/25728)\n",
            "Epoch: 134 | Batch_idx: 210 |  Loss: (0.0065) | Acc: (99.79%) (26952/27008)\n",
            "Epoch: 134 | Batch_idx: 220 |  Loss: (0.0068) | Acc: (99.78%) (28227/28288)\n",
            "Epoch: 134 | Batch_idx: 230 |  Loss: (0.0066) | Acc: (99.79%) (29507/29568)\n",
            "Epoch: 134 | Batch_idx: 240 |  Loss: (0.0065) | Acc: (99.79%) (30783/30848)\n",
            "Epoch: 134 | Batch_idx: 250 |  Loss: (0.0064) | Acc: (99.79%) (32061/32128)\n",
            "Epoch: 134 | Batch_idx: 260 |  Loss: (0.0063) | Acc: (99.80%) (33341/33408)\n",
            "Epoch: 134 | Batch_idx: 270 |  Loss: (0.0062) | Acc: (99.80%) (34619/34688)\n",
            "Epoch: 134 | Batch_idx: 280 |  Loss: (0.0063) | Acc: (99.80%) (35896/35968)\n",
            "Epoch: 134 | Batch_idx: 290 |  Loss: (0.0064) | Acc: (99.80%) (37173/37248)\n",
            "Epoch: 134 | Batch_idx: 300 |  Loss: (0.0063) | Acc: (99.80%) (38451/38528)\n",
            "Epoch: 134 | Batch_idx: 310 |  Loss: (0.0062) | Acc: (99.80%) (39729/39808)\n",
            "Epoch: 134 | Batch_idx: 320 |  Loss: (0.0062) | Acc: (99.80%) (41007/41088)\n",
            "Epoch: 134 | Batch_idx: 330 |  Loss: (0.0060) | Acc: (99.81%) (42287/42368)\n",
            "Epoch: 134 | Batch_idx: 340 |  Loss: (0.0060) | Acc: (99.81%) (43566/43648)\n",
            "Epoch: 134 | Batch_idx: 350 |  Loss: (0.0060) | Acc: (99.81%) (44842/44928)\n",
            "Epoch: 134 | Batch_idx: 360 |  Loss: (0.0059) | Acc: (99.81%) (46120/46208)\n",
            "Epoch: 134 | Batch_idx: 370 |  Loss: (0.0059) | Acc: (99.81%) (47398/47488)\n",
            "Epoch: 134 | Batch_idx: 380 |  Loss: (0.0059) | Acc: (99.81%) (48676/48768)\n",
            "Epoch: 134 | Batch_idx: 390 |  Loss: (0.0059) | Acc: (99.81%) (49907/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4134) | Acc: (91.81%) (9181/10000)\n",
            "Epoch: 135 | Batch_idx: 0 |  Loss: (0.0009) | Acc: (100.00%) (128/128)\n",
            "Epoch: 135 | Batch_idx: 10 |  Loss: (0.0061) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 135 | Batch_idx: 20 |  Loss: (0.0070) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 135 | Batch_idx: 30 |  Loss: (0.0083) | Acc: (99.72%) (3957/3968)\n",
            "Epoch: 135 | Batch_idx: 40 |  Loss: (0.0070) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 135 | Batch_idx: 50 |  Loss: (0.0066) | Acc: (99.77%) (6513/6528)\n",
            "Epoch: 135 | Batch_idx: 60 |  Loss: (0.0068) | Acc: (99.78%) (7791/7808)\n",
            "Epoch: 135 | Batch_idx: 70 |  Loss: (0.0073) | Acc: (99.76%) (9066/9088)\n",
            "Epoch: 135 | Batch_idx: 80 |  Loss: (0.0070) | Acc: (99.76%) (10343/10368)\n",
            "Epoch: 135 | Batch_idx: 90 |  Loss: (0.0067) | Acc: (99.77%) (11621/11648)\n",
            "Epoch: 135 | Batch_idx: 100 |  Loss: (0.0066) | Acc: (99.78%) (12900/12928)\n",
            "Epoch: 135 | Batch_idx: 110 |  Loss: (0.0066) | Acc: (99.77%) (14176/14208)\n",
            "Epoch: 135 | Batch_idx: 120 |  Loss: (0.0067) | Acc: (99.77%) (15453/15488)\n",
            "Epoch: 135 | Batch_idx: 130 |  Loss: (0.0064) | Acc: (99.79%) (16733/16768)\n",
            "Epoch: 135 | Batch_idx: 140 |  Loss: (0.0062) | Acc: (99.79%) (18011/18048)\n",
            "Epoch: 135 | Batch_idx: 150 |  Loss: (0.0066) | Acc: (99.77%) (19284/19328)\n",
            "Epoch: 135 | Batch_idx: 160 |  Loss: (0.0069) | Acc: (99.77%) (20560/20608)\n",
            "Epoch: 135 | Batch_idx: 170 |  Loss: (0.0068) | Acc: (99.76%) (21836/21888)\n",
            "Epoch: 135 | Batch_idx: 180 |  Loss: (0.0070) | Acc: (99.76%) (23112/23168)\n",
            "Epoch: 135 | Batch_idx: 190 |  Loss: (0.0068) | Acc: (99.76%) (24390/24448)\n",
            "Epoch: 135 | Batch_idx: 200 |  Loss: (0.0068) | Acc: (99.76%) (25666/25728)\n",
            "Epoch: 135 | Batch_idx: 210 |  Loss: (0.0067) | Acc: (99.76%) (26944/27008)\n",
            "Epoch: 135 | Batch_idx: 220 |  Loss: (0.0067) | Acc: (99.76%) (28221/28288)\n",
            "Epoch: 135 | Batch_idx: 230 |  Loss: (0.0066) | Acc: (99.77%) (29500/29568)\n",
            "Epoch: 135 | Batch_idx: 240 |  Loss: (0.0065) | Acc: (99.77%) (30778/30848)\n",
            "Epoch: 135 | Batch_idx: 250 |  Loss: (0.0065) | Acc: (99.77%) (32054/32128)\n",
            "Epoch: 135 | Batch_idx: 260 |  Loss: (0.0066) | Acc: (99.76%) (33329/33408)\n",
            "Epoch: 135 | Batch_idx: 270 |  Loss: (0.0066) | Acc: (99.76%) (34606/34688)\n",
            "Epoch: 135 | Batch_idx: 280 |  Loss: (0.0065) | Acc: (99.77%) (35884/35968)\n",
            "Epoch: 135 | Batch_idx: 290 |  Loss: (0.0064) | Acc: (99.77%) (37162/37248)\n",
            "Epoch: 135 | Batch_idx: 300 |  Loss: (0.0065) | Acc: (99.76%) (38435/38528)\n",
            "Epoch: 135 | Batch_idx: 310 |  Loss: (0.0067) | Acc: (99.75%) (39710/39808)\n",
            "Epoch: 135 | Batch_idx: 320 |  Loss: (0.0066) | Acc: (99.76%) (40988/41088)\n",
            "Epoch: 135 | Batch_idx: 330 |  Loss: (0.0066) | Acc: (99.76%) (42266/42368)\n",
            "Epoch: 135 | Batch_idx: 340 |  Loss: (0.0065) | Acc: (99.76%) (43544/43648)\n",
            "Epoch: 135 | Batch_idx: 350 |  Loss: (0.0070) | Acc: (99.75%) (44815/44928)\n",
            "Epoch: 135 | Batch_idx: 360 |  Loss: (0.0069) | Acc: (99.75%) (46092/46208)\n",
            "Epoch: 135 | Batch_idx: 370 |  Loss: (0.0069) | Acc: (99.75%) (47369/47488)\n",
            "Epoch: 135 | Batch_idx: 380 |  Loss: (0.0068) | Acc: (99.75%) (48648/48768)\n",
            "Epoch: 135 | Batch_idx: 390 |  Loss: (0.0067) | Acc: (99.76%) (49879/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4159) | Acc: (91.90%) (9190/10000)\n",
            "Epoch: 136 | Batch_idx: 0 |  Loss: (0.0021) | Acc: (100.00%) (128/128)\n",
            "Epoch: 136 | Batch_idx: 10 |  Loss: (0.0068) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 136 | Batch_idx: 20 |  Loss: (0.0053) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 136 | Batch_idx: 30 |  Loss: (0.0063) | Acc: (99.80%) (3960/3968)\n",
            "Epoch: 136 | Batch_idx: 40 |  Loss: (0.0077) | Acc: (99.73%) (5234/5248)\n",
            "Epoch: 136 | Batch_idx: 50 |  Loss: (0.0073) | Acc: (99.72%) (6510/6528)\n",
            "Epoch: 136 | Batch_idx: 60 |  Loss: (0.0068) | Acc: (99.74%) (7788/7808)\n",
            "Epoch: 136 | Batch_idx: 70 |  Loss: (0.0063) | Acc: (99.77%) (9067/9088)\n",
            "Epoch: 136 | Batch_idx: 80 |  Loss: (0.0064) | Acc: (99.76%) (10343/10368)\n",
            "Epoch: 136 | Batch_idx: 90 |  Loss: (0.0063) | Acc: (99.76%) (11620/11648)\n",
            "Epoch: 136 | Batch_idx: 100 |  Loss: (0.0062) | Acc: (99.76%) (12897/12928)\n",
            "Epoch: 136 | Batch_idx: 110 |  Loss: (0.0061) | Acc: (99.77%) (14175/14208)\n",
            "Epoch: 136 | Batch_idx: 120 |  Loss: (0.0061) | Acc: (99.77%) (15452/15488)\n",
            "Epoch: 136 | Batch_idx: 130 |  Loss: (0.0062) | Acc: (99.77%) (16729/16768)\n",
            "Epoch: 136 | Batch_idx: 140 |  Loss: (0.0064) | Acc: (99.77%) (18006/18048)\n",
            "Epoch: 136 | Batch_idx: 150 |  Loss: (0.0061) | Acc: (99.78%) (19286/19328)\n",
            "Epoch: 136 | Batch_idx: 160 |  Loss: (0.0060) | Acc: (99.79%) (20565/20608)\n",
            "Epoch: 136 | Batch_idx: 170 |  Loss: (0.0063) | Acc: (99.79%) (21842/21888)\n",
            "Epoch: 136 | Batch_idx: 180 |  Loss: (0.0065) | Acc: (99.78%) (23117/23168)\n",
            "Epoch: 136 | Batch_idx: 190 |  Loss: (0.0067) | Acc: (99.78%) (24393/24448)\n",
            "Epoch: 136 | Batch_idx: 200 |  Loss: (0.0072) | Acc: (99.77%) (25668/25728)\n",
            "Epoch: 136 | Batch_idx: 210 |  Loss: (0.0076) | Acc: (99.76%) (26942/27008)\n",
            "Epoch: 136 | Batch_idx: 220 |  Loss: (0.0075) | Acc: (99.76%) (28219/28288)\n",
            "Epoch: 136 | Batch_idx: 230 |  Loss: (0.0074) | Acc: (99.76%) (29496/29568)\n",
            "Epoch: 136 | Batch_idx: 240 |  Loss: (0.0076) | Acc: (99.75%) (30770/30848)\n",
            "Epoch: 136 | Batch_idx: 250 |  Loss: (0.0076) | Acc: (99.75%) (32048/32128)\n",
            "Epoch: 136 | Batch_idx: 260 |  Loss: (0.0074) | Acc: (99.76%) (33328/33408)\n",
            "Epoch: 136 | Batch_idx: 270 |  Loss: (0.0074) | Acc: (99.76%) (34606/34688)\n",
            "Epoch: 136 | Batch_idx: 280 |  Loss: (0.0075) | Acc: (99.76%) (35881/35968)\n",
            "Epoch: 136 | Batch_idx: 290 |  Loss: (0.0076) | Acc: (99.75%) (37155/37248)\n",
            "Epoch: 136 | Batch_idx: 300 |  Loss: (0.0076) | Acc: (99.75%) (38432/38528)\n",
            "Epoch: 136 | Batch_idx: 310 |  Loss: (0.0074) | Acc: (99.76%) (39711/39808)\n",
            "Epoch: 136 | Batch_idx: 320 |  Loss: (0.0074) | Acc: (99.76%) (40988/41088)\n",
            "Epoch: 136 | Batch_idx: 330 |  Loss: (0.0074) | Acc: (99.76%) (42265/42368)\n",
            "Epoch: 136 | Batch_idx: 340 |  Loss: (0.0073) | Acc: (99.76%) (43544/43648)\n",
            "Epoch: 136 | Batch_idx: 350 |  Loss: (0.0071) | Acc: (99.77%) (44824/44928)\n",
            "Epoch: 136 | Batch_idx: 360 |  Loss: (0.0071) | Acc: (99.77%) (46103/46208)\n",
            "Epoch: 136 | Batch_idx: 370 |  Loss: (0.0072) | Acc: (99.77%) (47378/47488)\n",
            "Epoch: 136 | Batch_idx: 380 |  Loss: (0.0073) | Acc: (99.76%) (48651/48768)\n",
            "Epoch: 136 | Batch_idx: 390 |  Loss: (0.0075) | Acc: (99.75%) (49876/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4142) | Acc: (91.84%) (9184/10000)\n",
            "Epoch: 137 | Batch_idx: 0 |  Loss: (0.0019) | Acc: (100.00%) (128/128)\n",
            "Epoch: 137 | Batch_idx: 10 |  Loss: (0.0081) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 137 | Batch_idx: 20 |  Loss: (0.0072) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 137 | Batch_idx: 30 |  Loss: (0.0083) | Acc: (99.82%) (3961/3968)\n",
            "Epoch: 137 | Batch_idx: 40 |  Loss: (0.0088) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 137 | Batch_idx: 50 |  Loss: (0.0090) | Acc: (99.72%) (6510/6528)\n",
            "Epoch: 137 | Batch_idx: 60 |  Loss: (0.0082) | Acc: (99.74%) (7788/7808)\n",
            "Epoch: 137 | Batch_idx: 70 |  Loss: (0.0076) | Acc: (99.75%) (9065/9088)\n",
            "Epoch: 137 | Batch_idx: 80 |  Loss: (0.0080) | Acc: (99.73%) (10340/10368)\n",
            "Epoch: 137 | Batch_idx: 90 |  Loss: (0.0077) | Acc: (99.74%) (11618/11648)\n",
            "Epoch: 137 | Batch_idx: 100 |  Loss: (0.0075) | Acc: (99.75%) (12896/12928)\n",
            "Epoch: 137 | Batch_idx: 110 |  Loss: (0.0070) | Acc: (99.77%) (14176/14208)\n",
            "Epoch: 137 | Batch_idx: 120 |  Loss: (0.0071) | Acc: (99.76%) (15451/15488)\n",
            "Epoch: 137 | Batch_idx: 130 |  Loss: (0.0069) | Acc: (99.77%) (16729/16768)\n",
            "Epoch: 137 | Batch_idx: 140 |  Loss: (0.0073) | Acc: (99.76%) (18004/18048)\n",
            "Epoch: 137 | Batch_idx: 150 |  Loss: (0.0077) | Acc: (99.75%) (19279/19328)\n",
            "Epoch: 137 | Batch_idx: 160 |  Loss: (0.0077) | Acc: (99.75%) (20556/20608)\n",
            "Epoch: 137 | Batch_idx: 170 |  Loss: (0.0074) | Acc: (99.76%) (21835/21888)\n",
            "Epoch: 137 | Batch_idx: 180 |  Loss: (0.0072) | Acc: (99.77%) (23115/23168)\n",
            "Epoch: 137 | Batch_idx: 190 |  Loss: (0.0071) | Acc: (99.78%) (24394/24448)\n",
            "Epoch: 137 | Batch_idx: 200 |  Loss: (0.0070) | Acc: (99.78%) (25672/25728)\n",
            "Epoch: 137 | Batch_idx: 210 |  Loss: (0.0069) | Acc: (99.79%) (26951/27008)\n",
            "Epoch: 137 | Batch_idx: 220 |  Loss: (0.0067) | Acc: (99.79%) (28230/28288)\n",
            "Epoch: 137 | Batch_idx: 230 |  Loss: (0.0067) | Acc: (99.79%) (29507/29568)\n",
            "Epoch: 137 | Batch_idx: 240 |  Loss: (0.0070) | Acc: (99.78%) (30780/30848)\n",
            "Epoch: 137 | Batch_idx: 250 |  Loss: (0.0070) | Acc: (99.78%) (32056/32128)\n",
            "Epoch: 137 | Batch_idx: 260 |  Loss: (0.0072) | Acc: (99.77%) (33331/33408)\n",
            "Epoch: 137 | Batch_idx: 270 |  Loss: (0.0071) | Acc: (99.77%) (34609/34688)\n",
            "Epoch: 137 | Batch_idx: 280 |  Loss: (0.0070) | Acc: (99.77%) (35887/35968)\n",
            "Epoch: 137 | Batch_idx: 290 |  Loss: (0.0069) | Acc: (99.78%) (37165/37248)\n",
            "Epoch: 137 | Batch_idx: 300 |  Loss: (0.0069) | Acc: (99.78%) (38442/38528)\n",
            "Epoch: 137 | Batch_idx: 310 |  Loss: (0.0071) | Acc: (99.78%) (39719/39808)\n",
            "Epoch: 137 | Batch_idx: 320 |  Loss: (0.0070) | Acc: (99.77%) (40995/41088)\n",
            "Epoch: 137 | Batch_idx: 330 |  Loss: (0.0069) | Acc: (99.78%) (42273/42368)\n",
            "Epoch: 137 | Batch_idx: 340 |  Loss: (0.0069) | Acc: (99.77%) (43549/43648)\n",
            "Epoch: 137 | Batch_idx: 350 |  Loss: (0.0070) | Acc: (99.77%) (44825/44928)\n",
            "Epoch: 137 | Batch_idx: 360 |  Loss: (0.0069) | Acc: (99.77%) (46104/46208)\n",
            "Epoch: 137 | Batch_idx: 370 |  Loss: (0.0069) | Acc: (99.78%) (47382/47488)\n",
            "Epoch: 137 | Batch_idx: 380 |  Loss: (0.0068) | Acc: (99.78%) (48661/48768)\n",
            "Epoch: 137 | Batch_idx: 390 |  Loss: (0.0069) | Acc: (99.78%) (49890/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4138) | Acc: (91.90%) (9190/10000)\n",
            "Epoch: 138 | Batch_idx: 0 |  Loss: (0.0028) | Acc: (100.00%) (128/128)\n",
            "Epoch: 138 | Batch_idx: 10 |  Loss: (0.0136) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 138 | Batch_idx: 20 |  Loss: (0.0105) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 138 | Batch_idx: 30 |  Loss: (0.0089) | Acc: (99.67%) (3955/3968)\n",
            "Epoch: 138 | Batch_idx: 40 |  Loss: (0.0089) | Acc: (99.71%) (5233/5248)\n",
            "Epoch: 138 | Batch_idx: 50 |  Loss: (0.0077) | Acc: (99.74%) (6511/6528)\n",
            "Epoch: 138 | Batch_idx: 60 |  Loss: (0.0071) | Acc: (99.77%) (7790/7808)\n",
            "Epoch: 138 | Batch_idx: 70 |  Loss: (0.0076) | Acc: (99.75%) (9065/9088)\n",
            "Epoch: 138 | Batch_idx: 80 |  Loss: (0.0074) | Acc: (99.76%) (10343/10368)\n",
            "Epoch: 138 | Batch_idx: 90 |  Loss: (0.0070) | Acc: (99.78%) (11622/11648)\n",
            "Epoch: 138 | Batch_idx: 100 |  Loss: (0.0070) | Acc: (99.77%) (12898/12928)\n",
            "Epoch: 138 | Batch_idx: 110 |  Loss: (0.0070) | Acc: (99.77%) (14175/14208)\n",
            "Epoch: 138 | Batch_idx: 120 |  Loss: (0.0068) | Acc: (99.77%) (15453/15488)\n",
            "Epoch: 138 | Batch_idx: 130 |  Loss: (0.0066) | Acc: (99.79%) (16732/16768)\n",
            "Epoch: 138 | Batch_idx: 140 |  Loss: (0.0066) | Acc: (99.79%) (18011/18048)\n",
            "Epoch: 138 | Batch_idx: 150 |  Loss: (0.0065) | Acc: (99.80%) (19289/19328)\n",
            "Epoch: 138 | Batch_idx: 160 |  Loss: (0.0065) | Acc: (99.80%) (20566/20608)\n",
            "Epoch: 138 | Batch_idx: 170 |  Loss: (0.0063) | Acc: (99.81%) (21846/21888)\n",
            "Epoch: 138 | Batch_idx: 180 |  Loss: (0.0064) | Acc: (99.81%) (23123/23168)\n",
            "Epoch: 138 | Batch_idx: 190 |  Loss: (0.0061) | Acc: (99.82%) (24403/24448)\n",
            "Epoch: 138 | Batch_idx: 200 |  Loss: (0.0060) | Acc: (99.83%) (25683/25728)\n",
            "Epoch: 138 | Batch_idx: 210 |  Loss: (0.0060) | Acc: (99.82%) (26960/27008)\n",
            "Epoch: 138 | Batch_idx: 220 |  Loss: (0.0060) | Acc: (99.83%) (28239/28288)\n",
            "Epoch: 138 | Batch_idx: 230 |  Loss: (0.0061) | Acc: (99.82%) (29515/29568)\n",
            "Epoch: 138 | Batch_idx: 240 |  Loss: (0.0059) | Acc: (99.83%) (30795/30848)\n",
            "Epoch: 138 | Batch_idx: 250 |  Loss: (0.0059) | Acc: (99.83%) (32073/32128)\n",
            "Epoch: 138 | Batch_idx: 260 |  Loss: (0.0060) | Acc: (99.82%) (33349/33408)\n",
            "Epoch: 138 | Batch_idx: 270 |  Loss: (0.0058) | Acc: (99.83%) (34629/34688)\n",
            "Epoch: 138 | Batch_idx: 280 |  Loss: (0.0058) | Acc: (99.83%) (35908/35968)\n",
            "Epoch: 138 | Batch_idx: 290 |  Loss: (0.0059) | Acc: (99.83%) (37185/37248)\n",
            "Epoch: 138 | Batch_idx: 300 |  Loss: (0.0058) | Acc: (99.83%) (38464/38528)\n",
            "Epoch: 138 | Batch_idx: 310 |  Loss: (0.0059) | Acc: (99.83%) (39741/39808)\n",
            "Epoch: 138 | Batch_idx: 320 |  Loss: (0.0060) | Acc: (99.83%) (41019/41088)\n",
            "Epoch: 138 | Batch_idx: 330 |  Loss: (0.0059) | Acc: (99.83%) (42298/42368)\n",
            "Epoch: 138 | Batch_idx: 340 |  Loss: (0.0059) | Acc: (99.83%) (43575/43648)\n",
            "Epoch: 138 | Batch_idx: 350 |  Loss: (0.0059) | Acc: (99.83%) (44851/44928)\n",
            "Epoch: 138 | Batch_idx: 360 |  Loss: (0.0060) | Acc: (99.82%) (46126/46208)\n",
            "Epoch: 138 | Batch_idx: 370 |  Loss: (0.0062) | Acc: (99.82%) (47403/47488)\n",
            "Epoch: 138 | Batch_idx: 380 |  Loss: (0.0063) | Acc: (99.82%) (48679/48768)\n",
            "Epoch: 138 | Batch_idx: 390 |  Loss: (0.0063) | Acc: (99.82%) (49909/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4143) | Acc: (91.88%) (9188/10000)\n",
            "Epoch: 139 | Batch_idx: 0 |  Loss: (0.0001) | Acc: (100.00%) (128/128)\n",
            "Epoch: 139 | Batch_idx: 10 |  Loss: (0.0049) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 139 | Batch_idx: 20 |  Loss: (0.0085) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 139 | Batch_idx: 30 |  Loss: (0.0075) | Acc: (99.77%) (3959/3968)\n",
            "Epoch: 139 | Batch_idx: 40 |  Loss: (0.0068) | Acc: (99.81%) (5238/5248)\n",
            "Epoch: 139 | Batch_idx: 50 |  Loss: (0.0062) | Acc: (99.83%) (6517/6528)\n",
            "Epoch: 139 | Batch_idx: 60 |  Loss: (0.0059) | Acc: (99.85%) (7796/7808)\n",
            "Epoch: 139 | Batch_idx: 70 |  Loss: (0.0053) | Acc: (99.87%) (9076/9088)\n",
            "Epoch: 139 | Batch_idx: 80 |  Loss: (0.0053) | Acc: (99.86%) (10353/10368)\n",
            "Epoch: 139 | Batch_idx: 90 |  Loss: (0.0055) | Acc: (99.85%) (11630/11648)\n",
            "Epoch: 139 | Batch_idx: 100 |  Loss: (0.0053) | Acc: (99.85%) (12909/12928)\n",
            "Epoch: 139 | Batch_idx: 110 |  Loss: (0.0056) | Acc: (99.85%) (14186/14208)\n",
            "Epoch: 139 | Batch_idx: 120 |  Loss: (0.0057) | Acc: (99.84%) (15463/15488)\n",
            "Epoch: 139 | Batch_idx: 130 |  Loss: (0.0058) | Acc: (99.84%) (16742/16768)\n",
            "Epoch: 139 | Batch_idx: 140 |  Loss: (0.0056) | Acc: (99.84%) (18020/18048)\n",
            "Epoch: 139 | Batch_idx: 150 |  Loss: (0.0056) | Acc: (99.84%) (19298/19328)\n",
            "Epoch: 139 | Batch_idx: 160 |  Loss: (0.0058) | Acc: (99.84%) (20574/20608)\n",
            "Epoch: 139 | Batch_idx: 170 |  Loss: (0.0057) | Acc: (99.83%) (21851/21888)\n",
            "Epoch: 139 | Batch_idx: 180 |  Loss: (0.0056) | Acc: (99.84%) (23130/23168)\n",
            "Epoch: 139 | Batch_idx: 190 |  Loss: (0.0057) | Acc: (99.83%) (24407/24448)\n",
            "Epoch: 139 | Batch_idx: 200 |  Loss: (0.0057) | Acc: (99.83%) (25684/25728)\n",
            "Epoch: 139 | Batch_idx: 210 |  Loss: (0.0060) | Acc: (99.82%) (26959/27008)\n",
            "Epoch: 139 | Batch_idx: 220 |  Loss: (0.0060) | Acc: (99.82%) (28236/28288)\n",
            "Epoch: 139 | Batch_idx: 230 |  Loss: (0.0060) | Acc: (99.81%) (29513/29568)\n",
            "Epoch: 139 | Batch_idx: 240 |  Loss: (0.0060) | Acc: (99.82%) (30792/30848)\n",
            "Epoch: 139 | Batch_idx: 250 |  Loss: (0.0059) | Acc: (99.82%) (32070/32128)\n",
            "Epoch: 139 | Batch_idx: 260 |  Loss: (0.0059) | Acc: (99.82%) (33347/33408)\n",
            "Epoch: 139 | Batch_idx: 270 |  Loss: (0.0058) | Acc: (99.82%) (34626/34688)\n",
            "Epoch: 139 | Batch_idx: 280 |  Loss: (0.0058) | Acc: (99.82%) (35903/35968)\n",
            "Epoch: 139 | Batch_idx: 290 |  Loss: (0.0059) | Acc: (99.82%) (37180/37248)\n",
            "Epoch: 139 | Batch_idx: 300 |  Loss: (0.0060) | Acc: (99.81%) (38456/38528)\n",
            "Epoch: 139 | Batch_idx: 310 |  Loss: (0.0060) | Acc: (99.81%) (39733/39808)\n",
            "Epoch: 139 | Batch_idx: 320 |  Loss: (0.0060) | Acc: (99.81%) (41010/41088)\n",
            "Epoch: 139 | Batch_idx: 330 |  Loss: (0.0062) | Acc: (99.81%) (42286/42368)\n",
            "Epoch: 139 | Batch_idx: 340 |  Loss: (0.0061) | Acc: (99.81%) (43565/43648)\n",
            "Epoch: 139 | Batch_idx: 350 |  Loss: (0.0060) | Acc: (99.81%) (44843/44928)\n",
            "Epoch: 139 | Batch_idx: 360 |  Loss: (0.0062) | Acc: (99.80%) (46117/46208)\n",
            "Epoch: 139 | Batch_idx: 370 |  Loss: (0.0060) | Acc: (99.81%) (47397/47488)\n",
            "Epoch: 139 | Batch_idx: 380 |  Loss: (0.0060) | Acc: (99.81%) (48676/48768)\n",
            "Epoch: 139 | Batch_idx: 390 |  Loss: (0.0059) | Acc: (99.81%) (49907/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4141) | Acc: (91.89%) (9189/10000)\n",
            "Epoch: 140 | Batch_idx: 0 |  Loss: (0.0037) | Acc: (100.00%) (128/128)\n",
            "Epoch: 140 | Batch_idx: 10 |  Loss: (0.0082) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 140 | Batch_idx: 20 |  Loss: (0.0072) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 140 | Batch_idx: 30 |  Loss: (0.0079) | Acc: (99.80%) (3960/3968)\n",
            "Epoch: 140 | Batch_idx: 40 |  Loss: (0.0069) | Acc: (99.83%) (5239/5248)\n",
            "Epoch: 140 | Batch_idx: 50 |  Loss: (0.0067) | Acc: (99.85%) (6518/6528)\n",
            "Epoch: 140 | Batch_idx: 60 |  Loss: (0.0062) | Acc: (99.86%) (7797/7808)\n",
            "Epoch: 140 | Batch_idx: 70 |  Loss: (0.0060) | Acc: (99.87%) (9076/9088)\n",
            "Epoch: 140 | Batch_idx: 80 |  Loss: (0.0060) | Acc: (99.85%) (10352/10368)\n",
            "Epoch: 140 | Batch_idx: 90 |  Loss: (0.0059) | Acc: (99.85%) (11630/11648)\n",
            "Epoch: 140 | Batch_idx: 100 |  Loss: (0.0066) | Acc: (99.82%) (12905/12928)\n",
            "Epoch: 140 | Batch_idx: 110 |  Loss: (0.0063) | Acc: (99.82%) (14183/14208)\n",
            "Epoch: 140 | Batch_idx: 120 |  Loss: (0.0061) | Acc: (99.84%) (15463/15488)\n",
            "Epoch: 140 | Batch_idx: 130 |  Loss: (0.0062) | Acc: (99.83%) (16739/16768)\n",
            "Epoch: 140 | Batch_idx: 140 |  Loss: (0.0061) | Acc: (99.82%) (18016/18048)\n",
            "Epoch: 140 | Batch_idx: 150 |  Loss: (0.0060) | Acc: (99.83%) (19295/19328)\n",
            "Epoch: 140 | Batch_idx: 160 |  Loss: (0.0058) | Acc: (99.84%) (20575/20608)\n",
            "Epoch: 140 | Batch_idx: 170 |  Loss: (0.0058) | Acc: (99.84%) (21853/21888)\n",
            "Epoch: 140 | Batch_idx: 180 |  Loss: (0.0058) | Acc: (99.83%) (23129/23168)\n",
            "Epoch: 140 | Batch_idx: 190 |  Loss: (0.0060) | Acc: (99.83%) (24406/24448)\n",
            "Epoch: 140 | Batch_idx: 200 |  Loss: (0.0059) | Acc: (99.83%) (25685/25728)\n",
            "Epoch: 140 | Batch_idx: 210 |  Loss: (0.0059) | Acc: (99.83%) (26961/27008)\n",
            "Epoch: 140 | Batch_idx: 220 |  Loss: (0.0059) | Acc: (99.82%) (28237/28288)\n",
            "Epoch: 140 | Batch_idx: 230 |  Loss: (0.0058) | Acc: (99.82%) (29515/29568)\n",
            "Epoch: 140 | Batch_idx: 240 |  Loss: (0.0058) | Acc: (99.82%) (30793/30848)\n",
            "Epoch: 140 | Batch_idx: 250 |  Loss: (0.0058) | Acc: (99.82%) (32071/32128)\n",
            "Epoch: 140 | Batch_idx: 260 |  Loss: (0.0059) | Acc: (99.82%) (33347/33408)\n",
            "Epoch: 140 | Batch_idx: 270 |  Loss: (0.0060) | Acc: (99.82%) (34625/34688)\n",
            "Epoch: 140 | Batch_idx: 280 |  Loss: (0.0060) | Acc: (99.82%) (35902/35968)\n",
            "Epoch: 140 | Batch_idx: 290 |  Loss: (0.0060) | Acc: (99.82%) (37180/37248)\n",
            "Epoch: 140 | Batch_idx: 300 |  Loss: (0.0059) | Acc: (99.82%) (38458/38528)\n",
            "Epoch: 140 | Batch_idx: 310 |  Loss: (0.0060) | Acc: (99.81%) (39734/39808)\n",
            "Epoch: 140 | Batch_idx: 320 |  Loss: (0.0060) | Acc: (99.81%) (41008/41088)\n",
            "Epoch: 140 | Batch_idx: 330 |  Loss: (0.0061) | Acc: (99.81%) (42286/42368)\n",
            "Epoch: 140 | Batch_idx: 340 |  Loss: (0.0060) | Acc: (99.81%) (43565/43648)\n",
            "Epoch: 140 | Batch_idx: 350 |  Loss: (0.0060) | Acc: (99.81%) (44842/44928)\n",
            "Epoch: 140 | Batch_idx: 360 |  Loss: (0.0061) | Acc: (99.81%) (46119/46208)\n",
            "Epoch: 140 | Batch_idx: 370 |  Loss: (0.0063) | Acc: (99.80%) (47392/47488)\n",
            "Epoch: 140 | Batch_idx: 380 |  Loss: (0.0064) | Acc: (99.79%) (48668/48768)\n",
            "Epoch: 140 | Batch_idx: 390 |  Loss: (0.0064) | Acc: (99.79%) (49897/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4175) | Acc: (91.90%) (9190/10000)\n",
            "Epoch: 141 | Batch_idx: 0 |  Loss: (0.0036) | Acc: (100.00%) (128/128)\n",
            "Epoch: 141 | Batch_idx: 10 |  Loss: (0.0051) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 141 | Batch_idx: 20 |  Loss: (0.0046) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 141 | Batch_idx: 30 |  Loss: (0.0042) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 141 | Batch_idx: 40 |  Loss: (0.0044) | Acc: (99.89%) (5242/5248)\n",
            "Epoch: 141 | Batch_idx: 50 |  Loss: (0.0041) | Acc: (99.89%) (6521/6528)\n",
            "Epoch: 141 | Batch_idx: 60 |  Loss: (0.0048) | Acc: (99.86%) (7797/7808)\n",
            "Epoch: 141 | Batch_idx: 70 |  Loss: (0.0051) | Acc: (99.83%) (9073/9088)\n",
            "Epoch: 141 | Batch_idx: 80 |  Loss: (0.0050) | Acc: (99.83%) (10350/10368)\n",
            "Epoch: 141 | Batch_idx: 90 |  Loss: (0.0048) | Acc: (99.84%) (11629/11648)\n",
            "Epoch: 141 | Batch_idx: 100 |  Loss: (0.0048) | Acc: (99.85%) (12908/12928)\n",
            "Epoch: 141 | Batch_idx: 110 |  Loss: (0.0051) | Acc: (99.84%) (14185/14208)\n",
            "Epoch: 141 | Batch_idx: 120 |  Loss: (0.0052) | Acc: (99.84%) (15463/15488)\n",
            "Epoch: 141 | Batch_idx: 130 |  Loss: (0.0053) | Acc: (99.83%) (16740/16768)\n",
            "Epoch: 141 | Batch_idx: 140 |  Loss: (0.0053) | Acc: (99.83%) (18018/18048)\n",
            "Epoch: 141 | Batch_idx: 150 |  Loss: (0.0053) | Acc: (99.84%) (19297/19328)\n",
            "Epoch: 141 | Batch_idx: 160 |  Loss: (0.0054) | Acc: (99.83%) (20572/20608)\n",
            "Epoch: 141 | Batch_idx: 170 |  Loss: (0.0052) | Acc: (99.83%) (21851/21888)\n",
            "Epoch: 141 | Batch_idx: 180 |  Loss: (0.0052) | Acc: (99.83%) (23128/23168)\n",
            "Epoch: 141 | Batch_idx: 190 |  Loss: (0.0054) | Acc: (99.81%) (24402/24448)\n",
            "Epoch: 141 | Batch_idx: 200 |  Loss: (0.0055) | Acc: (99.81%) (25679/25728)\n",
            "Epoch: 141 | Batch_idx: 210 |  Loss: (0.0056) | Acc: (99.81%) (26956/27008)\n",
            "Epoch: 141 | Batch_idx: 220 |  Loss: (0.0055) | Acc: (99.81%) (28235/28288)\n",
            "Epoch: 141 | Batch_idx: 230 |  Loss: (0.0056) | Acc: (99.81%) (29512/29568)\n",
            "Epoch: 141 | Batch_idx: 240 |  Loss: (0.0056) | Acc: (99.81%) (30789/30848)\n",
            "Epoch: 141 | Batch_idx: 250 |  Loss: (0.0056) | Acc: (99.81%) (32066/32128)\n",
            "Epoch: 141 | Batch_idx: 260 |  Loss: (0.0056) | Acc: (99.81%) (33345/33408)\n",
            "Epoch: 141 | Batch_idx: 270 |  Loss: (0.0058) | Acc: (99.80%) (34618/34688)\n",
            "Epoch: 141 | Batch_idx: 280 |  Loss: (0.0059) | Acc: (99.79%) (35894/35968)\n",
            "Epoch: 141 | Batch_idx: 290 |  Loss: (0.0057) | Acc: (99.80%) (37174/37248)\n",
            "Epoch: 141 | Batch_idx: 300 |  Loss: (0.0056) | Acc: (99.81%) (38453/38528)\n",
            "Epoch: 141 | Batch_idx: 310 |  Loss: (0.0059) | Acc: (99.80%) (39729/39808)\n",
            "Epoch: 141 | Batch_idx: 320 |  Loss: (0.0060) | Acc: (99.80%) (41004/41088)\n",
            "Epoch: 141 | Batch_idx: 330 |  Loss: (0.0059) | Acc: (99.80%) (42282/42368)\n",
            "Epoch: 141 | Batch_idx: 340 |  Loss: (0.0059) | Acc: (99.80%) (43559/43648)\n",
            "Epoch: 141 | Batch_idx: 350 |  Loss: (0.0058) | Acc: (99.80%) (44839/44928)\n",
            "Epoch: 141 | Batch_idx: 360 |  Loss: (0.0060) | Acc: (99.80%) (46115/46208)\n",
            "Epoch: 141 | Batch_idx: 370 |  Loss: (0.0060) | Acc: (99.80%) (47391/47488)\n",
            "Epoch: 141 | Batch_idx: 380 |  Loss: (0.0059) | Acc: (99.80%) (48670/48768)\n",
            "Epoch: 141 | Batch_idx: 390 |  Loss: (0.0059) | Acc: (99.80%) (49900/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4169) | Acc: (91.90%) (9190/10000)\n",
            "Epoch: 142 | Batch_idx: 0 |  Loss: (0.0005) | Acc: (100.00%) (128/128)\n",
            "Epoch: 142 | Batch_idx: 10 |  Loss: (0.0057) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 142 | Batch_idx: 20 |  Loss: (0.0038) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 142 | Batch_idx: 30 |  Loss: (0.0038) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 142 | Batch_idx: 40 |  Loss: (0.0039) | Acc: (99.89%) (5242/5248)\n",
            "Epoch: 142 | Batch_idx: 50 |  Loss: (0.0040) | Acc: (99.88%) (6520/6528)\n",
            "Epoch: 142 | Batch_idx: 60 |  Loss: (0.0055) | Acc: (99.83%) (7795/7808)\n",
            "Epoch: 142 | Batch_idx: 70 |  Loss: (0.0059) | Acc: (99.82%) (9072/9088)\n",
            "Epoch: 142 | Batch_idx: 80 |  Loss: (0.0066) | Acc: (99.80%) (10347/10368)\n",
            "Epoch: 142 | Batch_idx: 90 |  Loss: (0.0070) | Acc: (99.77%) (11621/11648)\n",
            "Epoch: 142 | Batch_idx: 100 |  Loss: (0.0068) | Acc: (99.78%) (12900/12928)\n",
            "Epoch: 142 | Batch_idx: 110 |  Loss: (0.0070) | Acc: (99.77%) (14176/14208)\n",
            "Epoch: 142 | Batch_idx: 120 |  Loss: (0.0071) | Acc: (99.77%) (15452/15488)\n",
            "Epoch: 142 | Batch_idx: 130 |  Loss: (0.0072) | Acc: (99.77%) (16729/16768)\n",
            "Epoch: 142 | Batch_idx: 140 |  Loss: (0.0068) | Acc: (99.78%) (18009/18048)\n",
            "Epoch: 142 | Batch_idx: 150 |  Loss: (0.0070) | Acc: (99.78%) (19285/19328)\n",
            "Epoch: 142 | Batch_idx: 160 |  Loss: (0.0068) | Acc: (99.78%) (20563/20608)\n",
            "Epoch: 142 | Batch_idx: 170 |  Loss: (0.0068) | Acc: (99.79%) (21841/21888)\n",
            "Epoch: 142 | Batch_idx: 180 |  Loss: (0.0065) | Acc: (99.79%) (23120/23168)\n",
            "Epoch: 142 | Batch_idx: 190 |  Loss: (0.0063) | Acc: (99.80%) (24400/24448)\n",
            "Epoch: 142 | Batch_idx: 200 |  Loss: (0.0063) | Acc: (99.81%) (25678/25728)\n",
            "Epoch: 142 | Batch_idx: 210 |  Loss: (0.0062) | Acc: (99.80%) (26954/27008)\n",
            "Epoch: 142 | Batch_idx: 220 |  Loss: (0.0061) | Acc: (99.80%) (28231/28288)\n",
            "Epoch: 142 | Batch_idx: 230 |  Loss: (0.0060) | Acc: (99.80%) (29509/29568)\n",
            "Epoch: 142 | Batch_idx: 240 |  Loss: (0.0060) | Acc: (99.80%) (30787/30848)\n",
            "Epoch: 142 | Batch_idx: 250 |  Loss: (0.0059) | Acc: (99.80%) (32065/32128)\n",
            "Epoch: 142 | Batch_idx: 260 |  Loss: (0.0057) | Acc: (99.81%) (33344/33408)\n",
            "Epoch: 142 | Batch_idx: 270 |  Loss: (0.0057) | Acc: (99.81%) (34623/34688)\n",
            "Epoch: 142 | Batch_idx: 280 |  Loss: (0.0057) | Acc: (99.81%) (35900/35968)\n",
            "Epoch: 142 | Batch_idx: 290 |  Loss: (0.0056) | Acc: (99.81%) (37178/37248)\n",
            "Epoch: 142 | Batch_idx: 300 |  Loss: (0.0057) | Acc: (99.81%) (38454/38528)\n",
            "Epoch: 142 | Batch_idx: 310 |  Loss: (0.0058) | Acc: (99.81%) (39732/39808)\n",
            "Epoch: 142 | Batch_idx: 320 |  Loss: (0.0057) | Acc: (99.81%) (41010/41088)\n",
            "Epoch: 142 | Batch_idx: 330 |  Loss: (0.0057) | Acc: (99.81%) (42287/42368)\n",
            "Epoch: 142 | Batch_idx: 340 |  Loss: (0.0056) | Acc: (99.81%) (43564/43648)\n",
            "Epoch: 142 | Batch_idx: 350 |  Loss: (0.0056) | Acc: (99.81%) (44841/44928)\n",
            "Epoch: 142 | Batch_idx: 360 |  Loss: (0.0057) | Acc: (99.81%) (46119/46208)\n",
            "Epoch: 142 | Batch_idx: 370 |  Loss: (0.0057) | Acc: (99.81%) (47397/47488)\n",
            "Epoch: 142 | Batch_idx: 380 |  Loss: (0.0057) | Acc: (99.81%) (48676/48768)\n",
            "Epoch: 142 | Batch_idx: 390 |  Loss: (0.0056) | Acc: (99.81%) (49907/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4194) | Acc: (91.75%) (9175/10000)\n",
            "Epoch: 143 | Batch_idx: 0 |  Loss: (0.0002) | Acc: (100.00%) (128/128)\n",
            "Epoch: 143 | Batch_idx: 10 |  Loss: (0.0065) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 143 | Batch_idx: 20 |  Loss: (0.0046) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 143 | Batch_idx: 30 |  Loss: (0.0056) | Acc: (99.85%) (3962/3968)\n",
            "Epoch: 143 | Batch_idx: 40 |  Loss: (0.0049) | Acc: (99.87%) (5241/5248)\n",
            "Epoch: 143 | Batch_idx: 50 |  Loss: (0.0048) | Acc: (99.86%) (6519/6528)\n",
            "Epoch: 143 | Batch_idx: 60 |  Loss: (0.0052) | Acc: (99.83%) (7795/7808)\n",
            "Epoch: 143 | Batch_idx: 70 |  Loss: (0.0049) | Acc: (99.83%) (9073/9088)\n",
            "Epoch: 143 | Batch_idx: 80 |  Loss: (0.0050) | Acc: (99.85%) (10352/10368)\n",
            "Epoch: 143 | Batch_idx: 90 |  Loss: (0.0055) | Acc: (99.82%) (11627/11648)\n",
            "Epoch: 143 | Batch_idx: 100 |  Loss: (0.0053) | Acc: (99.83%) (12906/12928)\n",
            "Epoch: 143 | Batch_idx: 110 |  Loss: (0.0055) | Acc: (99.81%) (14181/14208)\n",
            "Epoch: 143 | Batch_idx: 120 |  Loss: (0.0055) | Acc: (99.81%) (15459/15488)\n",
            "Epoch: 143 | Batch_idx: 130 |  Loss: (0.0052) | Acc: (99.83%) (16739/16768)\n",
            "Epoch: 143 | Batch_idx: 140 |  Loss: (0.0049) | Acc: (99.84%) (18019/18048)\n",
            "Epoch: 143 | Batch_idx: 150 |  Loss: (0.0053) | Acc: (99.82%) (19294/19328)\n",
            "Epoch: 143 | Batch_idx: 160 |  Loss: (0.0053) | Acc: (99.83%) (20573/20608)\n",
            "Epoch: 143 | Batch_idx: 170 |  Loss: (0.0053) | Acc: (99.83%) (21850/21888)\n",
            "Epoch: 143 | Batch_idx: 180 |  Loss: (0.0057) | Acc: (99.81%) (23124/23168)\n",
            "Epoch: 143 | Batch_idx: 190 |  Loss: (0.0056) | Acc: (99.82%) (24403/24448)\n",
            "Epoch: 143 | Batch_idx: 200 |  Loss: (0.0058) | Acc: (99.81%) (25679/25728)\n",
            "Epoch: 143 | Batch_idx: 210 |  Loss: (0.0058) | Acc: (99.81%) (26957/27008)\n",
            "Epoch: 143 | Batch_idx: 220 |  Loss: (0.0057) | Acc: (99.81%) (28235/28288)\n",
            "Epoch: 143 | Batch_idx: 230 |  Loss: (0.0057) | Acc: (99.81%) (29513/29568)\n",
            "Epoch: 143 | Batch_idx: 240 |  Loss: (0.0058) | Acc: (99.81%) (30790/30848)\n",
            "Epoch: 143 | Batch_idx: 250 |  Loss: (0.0058) | Acc: (99.81%) (32068/32128)\n",
            "Epoch: 143 | Batch_idx: 260 |  Loss: (0.0058) | Acc: (99.81%) (33345/33408)\n",
            "Epoch: 143 | Batch_idx: 270 |  Loss: (0.0059) | Acc: (99.81%) (34621/34688)\n",
            "Epoch: 143 | Batch_idx: 280 |  Loss: (0.0059) | Acc: (99.81%) (35899/35968)\n",
            "Epoch: 143 | Batch_idx: 290 |  Loss: (0.0058) | Acc: (99.81%) (37176/37248)\n",
            "Epoch: 143 | Batch_idx: 300 |  Loss: (0.0058) | Acc: (99.81%) (38454/38528)\n",
            "Epoch: 143 | Batch_idx: 310 |  Loss: (0.0057) | Acc: (99.81%) (39732/39808)\n",
            "Epoch: 143 | Batch_idx: 320 |  Loss: (0.0058) | Acc: (99.81%) (41010/41088)\n",
            "Epoch: 143 | Batch_idx: 330 |  Loss: (0.0058) | Acc: (99.81%) (42289/42368)\n",
            "Epoch: 143 | Batch_idx: 340 |  Loss: (0.0059) | Acc: (99.81%) (43564/43648)\n",
            "Epoch: 143 | Batch_idx: 350 |  Loss: (0.0059) | Acc: (99.81%) (44841/44928)\n",
            "Epoch: 143 | Batch_idx: 360 |  Loss: (0.0059) | Acc: (99.81%) (46119/46208)\n",
            "Epoch: 143 | Batch_idx: 370 |  Loss: (0.0058) | Acc: (99.81%) (47397/47488)\n",
            "Epoch: 143 | Batch_idx: 380 |  Loss: (0.0057) | Acc: (99.81%) (48676/48768)\n",
            "Epoch: 143 | Batch_idx: 390 |  Loss: (0.0058) | Acc: (99.81%) (49905/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4182) | Acc: (91.87%) (9187/10000)\n",
            "Epoch: 144 | Batch_idx: 0 |  Loss: (0.0003) | Acc: (100.00%) (128/128)\n",
            "Epoch: 144 | Batch_idx: 10 |  Loss: (0.0055) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 144 | Batch_idx: 20 |  Loss: (0.0047) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 144 | Batch_idx: 30 |  Loss: (0.0059) | Acc: (99.82%) (3961/3968)\n",
            "Epoch: 144 | Batch_idx: 40 |  Loss: (0.0052) | Acc: (99.83%) (5239/5248)\n",
            "Epoch: 144 | Batch_idx: 50 |  Loss: (0.0045) | Acc: (99.86%) (6519/6528)\n",
            "Epoch: 144 | Batch_idx: 60 |  Loss: (0.0046) | Acc: (99.87%) (7798/7808)\n",
            "Epoch: 144 | Batch_idx: 70 |  Loss: (0.0045) | Acc: (99.88%) (9077/9088)\n",
            "Epoch: 144 | Batch_idx: 80 |  Loss: (0.0046) | Acc: (99.86%) (10354/10368)\n",
            "Epoch: 144 | Batch_idx: 90 |  Loss: (0.0045) | Acc: (99.87%) (11633/11648)\n",
            "Epoch: 144 | Batch_idx: 100 |  Loss: (0.0044) | Acc: (99.87%) (12911/12928)\n",
            "Epoch: 144 | Batch_idx: 110 |  Loss: (0.0049) | Acc: (99.85%) (14186/14208)\n",
            "Epoch: 144 | Batch_idx: 120 |  Loss: (0.0050) | Acc: (99.85%) (15464/15488)\n",
            "Epoch: 144 | Batch_idx: 130 |  Loss: (0.0052) | Acc: (99.83%) (16740/16768)\n",
            "Epoch: 144 | Batch_idx: 140 |  Loss: (0.0051) | Acc: (99.83%) (18018/18048)\n",
            "Epoch: 144 | Batch_idx: 150 |  Loss: (0.0051) | Acc: (99.83%) (19296/19328)\n",
            "Epoch: 144 | Batch_idx: 160 |  Loss: (0.0051) | Acc: (99.84%) (20575/20608)\n",
            "Epoch: 144 | Batch_idx: 170 |  Loss: (0.0052) | Acc: (99.84%) (21853/21888)\n",
            "Epoch: 144 | Batch_idx: 180 |  Loss: (0.0051) | Acc: (99.84%) (23132/23168)\n",
            "Epoch: 144 | Batch_idx: 190 |  Loss: (0.0052) | Acc: (99.84%) (24408/24448)\n",
            "Epoch: 144 | Batch_idx: 200 |  Loss: (0.0053) | Acc: (99.83%) (25683/25728)\n",
            "Epoch: 144 | Batch_idx: 210 |  Loss: (0.0053) | Acc: (99.83%) (26961/27008)\n",
            "Epoch: 144 | Batch_idx: 220 |  Loss: (0.0055) | Acc: (99.82%) (28236/28288)\n",
            "Epoch: 144 | Batch_idx: 230 |  Loss: (0.0055) | Acc: (99.81%) (29511/29568)\n",
            "Epoch: 144 | Batch_idx: 240 |  Loss: (0.0054) | Acc: (99.81%) (30790/30848)\n",
            "Epoch: 144 | Batch_idx: 250 |  Loss: (0.0053) | Acc: (99.82%) (32069/32128)\n",
            "Epoch: 144 | Batch_idx: 260 |  Loss: (0.0054) | Acc: (99.81%) (33345/33408)\n",
            "Epoch: 144 | Batch_idx: 270 |  Loss: (0.0053) | Acc: (99.82%) (34624/34688)\n",
            "Epoch: 144 | Batch_idx: 280 |  Loss: (0.0053) | Acc: (99.82%) (35903/35968)\n",
            "Epoch: 144 | Batch_idx: 290 |  Loss: (0.0052) | Acc: (99.83%) (37183/37248)\n",
            "Epoch: 144 | Batch_idx: 300 |  Loss: (0.0052) | Acc: (99.83%) (38461/38528)\n",
            "Epoch: 144 | Batch_idx: 310 |  Loss: (0.0053) | Acc: (99.82%) (39738/39808)\n",
            "Epoch: 144 | Batch_idx: 320 |  Loss: (0.0053) | Acc: (99.83%) (41017/41088)\n",
            "Epoch: 144 | Batch_idx: 330 |  Loss: (0.0054) | Acc: (99.83%) (42294/42368)\n",
            "Epoch: 144 | Batch_idx: 340 |  Loss: (0.0056) | Acc: (99.82%) (43568/43648)\n",
            "Epoch: 144 | Batch_idx: 350 |  Loss: (0.0057) | Acc: (99.82%) (44847/44928)\n",
            "Epoch: 144 | Batch_idx: 360 |  Loss: (0.0057) | Acc: (99.82%) (46125/46208)\n",
            "Epoch: 144 | Batch_idx: 370 |  Loss: (0.0057) | Acc: (99.82%) (47403/47488)\n",
            "Epoch: 144 | Batch_idx: 380 |  Loss: (0.0056) | Acc: (99.82%) (48681/48768)\n",
            "Epoch: 144 | Batch_idx: 390 |  Loss: (0.0056) | Acc: (99.82%) (49912/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4214) | Acc: (91.81%) (9181/10000)\n",
            "Epoch: 145 | Batch_idx: 0 |  Loss: (0.0094) | Acc: (99.22%) (127/128)\n",
            "Epoch: 145 | Batch_idx: 10 |  Loss: (0.0038) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 145 | Batch_idx: 20 |  Loss: (0.0046) | Acc: (99.81%) (2683/2688)\n",
            "Epoch: 145 | Batch_idx: 30 |  Loss: (0.0083) | Acc: (99.67%) (3955/3968)\n",
            "Epoch: 145 | Batch_idx: 40 |  Loss: (0.0070) | Acc: (99.73%) (5234/5248)\n",
            "Epoch: 145 | Batch_idx: 50 |  Loss: (0.0062) | Acc: (99.77%) (6513/6528)\n",
            "Epoch: 145 | Batch_idx: 60 |  Loss: (0.0066) | Acc: (99.74%) (7788/7808)\n",
            "Epoch: 145 | Batch_idx: 70 |  Loss: (0.0059) | Acc: (99.78%) (9068/9088)\n",
            "Epoch: 145 | Batch_idx: 80 |  Loss: (0.0055) | Acc: (99.81%) (10348/10368)\n",
            "Epoch: 145 | Batch_idx: 90 |  Loss: (0.0054) | Acc: (99.79%) (11624/11648)\n",
            "Epoch: 145 | Batch_idx: 100 |  Loss: (0.0054) | Acc: (99.80%) (12902/12928)\n",
            "Epoch: 145 | Batch_idx: 110 |  Loss: (0.0052) | Acc: (99.81%) (14181/14208)\n",
            "Epoch: 145 | Batch_idx: 120 |  Loss: (0.0049) | Acc: (99.83%) (15461/15488)\n",
            "Epoch: 145 | Batch_idx: 130 |  Loss: (0.0050) | Acc: (99.82%) (16737/16768)\n",
            "Epoch: 145 | Batch_idx: 140 |  Loss: (0.0051) | Acc: (99.82%) (18015/18048)\n",
            "Epoch: 145 | Batch_idx: 150 |  Loss: (0.0057) | Acc: (99.80%) (19289/19328)\n",
            "Epoch: 145 | Batch_idx: 160 |  Loss: (0.0058) | Acc: (99.80%) (20567/20608)\n",
            "Epoch: 145 | Batch_idx: 170 |  Loss: (0.0057) | Acc: (99.80%) (21845/21888)\n",
            "Epoch: 145 | Batch_idx: 180 |  Loss: (0.0056) | Acc: (99.81%) (23123/23168)\n",
            "Epoch: 145 | Batch_idx: 190 |  Loss: (0.0056) | Acc: (99.80%) (24400/24448)\n",
            "Epoch: 145 | Batch_idx: 200 |  Loss: (0.0056) | Acc: (99.80%) (25677/25728)\n",
            "Epoch: 145 | Batch_idx: 210 |  Loss: (0.0055) | Acc: (99.81%) (26957/27008)\n",
            "Epoch: 145 | Batch_idx: 220 |  Loss: (0.0054) | Acc: (99.81%) (28235/28288)\n",
            "Epoch: 145 | Batch_idx: 230 |  Loss: (0.0056) | Acc: (99.81%) (29513/29568)\n",
            "Epoch: 145 | Batch_idx: 240 |  Loss: (0.0055) | Acc: (99.82%) (30792/30848)\n",
            "Epoch: 145 | Batch_idx: 250 |  Loss: (0.0056) | Acc: (99.81%) (32067/32128)\n",
            "Epoch: 145 | Batch_idx: 260 |  Loss: (0.0055) | Acc: (99.81%) (33345/33408)\n",
            "Epoch: 145 | Batch_idx: 270 |  Loss: (0.0057) | Acc: (99.81%) (34621/34688)\n",
            "Epoch: 145 | Batch_idx: 280 |  Loss: (0.0057) | Acc: (99.81%) (35899/35968)\n",
            "Epoch: 145 | Batch_idx: 290 |  Loss: (0.0057) | Acc: (99.81%) (37178/37248)\n",
            "Epoch: 145 | Batch_idx: 300 |  Loss: (0.0057) | Acc: (99.81%) (38455/38528)\n",
            "Epoch: 145 | Batch_idx: 310 |  Loss: (0.0057) | Acc: (99.81%) (39733/39808)\n",
            "Epoch: 145 | Batch_idx: 320 |  Loss: (0.0057) | Acc: (99.81%) (41011/41088)\n",
            "Epoch: 145 | Batch_idx: 330 |  Loss: (0.0056) | Acc: (99.82%) (42290/42368)\n",
            "Epoch: 145 | Batch_idx: 340 |  Loss: (0.0056) | Acc: (99.82%) (43568/43648)\n",
            "Epoch: 145 | Batch_idx: 350 |  Loss: (0.0055) | Acc: (99.82%) (44846/44928)\n",
            "Epoch: 145 | Batch_idx: 360 |  Loss: (0.0055) | Acc: (99.82%) (46123/46208)\n",
            "Epoch: 145 | Batch_idx: 370 |  Loss: (0.0055) | Acc: (99.81%) (47400/47488)\n",
            "Epoch: 145 | Batch_idx: 380 |  Loss: (0.0055) | Acc: (99.81%) (48677/48768)\n",
            "Epoch: 145 | Batch_idx: 390 |  Loss: (0.0055) | Acc: (99.81%) (49905/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4201) | Acc: (91.86%) (9186/10000)\n",
            "Epoch: 146 | Batch_idx: 0 |  Loss: (0.0009) | Acc: (100.00%) (128/128)\n",
            "Epoch: 146 | Batch_idx: 10 |  Loss: (0.0050) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 146 | Batch_idx: 20 |  Loss: (0.0084) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 146 | Batch_idx: 30 |  Loss: (0.0087) | Acc: (99.65%) (3954/3968)\n",
            "Epoch: 146 | Batch_idx: 40 |  Loss: (0.0082) | Acc: (99.68%) (5231/5248)\n",
            "Epoch: 146 | Batch_idx: 50 |  Loss: (0.0079) | Acc: (99.68%) (6507/6528)\n",
            "Epoch: 146 | Batch_idx: 60 |  Loss: (0.0074) | Acc: (99.71%) (7785/7808)\n",
            "Epoch: 146 | Batch_idx: 70 |  Loss: (0.0069) | Acc: (99.72%) (9063/9088)\n",
            "Epoch: 146 | Batch_idx: 80 |  Loss: (0.0065) | Acc: (99.74%) (10341/10368)\n",
            "Epoch: 146 | Batch_idx: 90 |  Loss: (0.0060) | Acc: (99.77%) (11621/11648)\n",
            "Epoch: 146 | Batch_idx: 100 |  Loss: (0.0059) | Acc: (99.77%) (12898/12928)\n",
            "Epoch: 146 | Batch_idx: 110 |  Loss: (0.0063) | Acc: (99.75%) (14173/14208)\n",
            "Epoch: 146 | Batch_idx: 120 |  Loss: (0.0070) | Acc: (99.74%) (15448/15488)\n",
            "Epoch: 146 | Batch_idx: 130 |  Loss: (0.0077) | Acc: (99.71%) (16719/16768)\n",
            "Epoch: 146 | Batch_idx: 140 |  Loss: (0.0075) | Acc: (99.71%) (17996/18048)\n",
            "Epoch: 146 | Batch_idx: 150 |  Loss: (0.0072) | Acc: (99.73%) (19275/19328)\n",
            "Epoch: 146 | Batch_idx: 160 |  Loss: (0.0072) | Acc: (99.73%) (20552/20608)\n",
            "Epoch: 146 | Batch_idx: 170 |  Loss: (0.0074) | Acc: (99.73%) (21828/21888)\n",
            "Epoch: 146 | Batch_idx: 180 |  Loss: (0.0072) | Acc: (99.74%) (23107/23168)\n",
            "Epoch: 146 | Batch_idx: 190 |  Loss: (0.0075) | Acc: (99.73%) (24381/24448)\n",
            "Epoch: 146 | Batch_idx: 200 |  Loss: (0.0072) | Acc: (99.74%) (25660/25728)\n",
            "Epoch: 146 | Batch_idx: 210 |  Loss: (0.0072) | Acc: (99.73%) (26936/27008)\n",
            "Epoch: 146 | Batch_idx: 220 |  Loss: (0.0075) | Acc: (99.72%) (28209/28288)\n",
            "Epoch: 146 | Batch_idx: 230 |  Loss: (0.0075) | Acc: (99.73%) (29487/29568)\n",
            "Epoch: 146 | Batch_idx: 240 |  Loss: (0.0074) | Acc: (99.73%) (30766/30848)\n",
            "Epoch: 146 | Batch_idx: 250 |  Loss: (0.0072) | Acc: (99.74%) (32044/32128)\n",
            "Epoch: 146 | Batch_idx: 260 |  Loss: (0.0074) | Acc: (99.73%) (33319/33408)\n",
            "Epoch: 146 | Batch_idx: 270 |  Loss: (0.0073) | Acc: (99.74%) (34597/34688)\n",
            "Epoch: 146 | Batch_idx: 280 |  Loss: (0.0073) | Acc: (99.74%) (35873/35968)\n",
            "Epoch: 146 | Batch_idx: 290 |  Loss: (0.0072) | Acc: (99.74%) (37151/37248)\n",
            "Epoch: 146 | Batch_idx: 300 |  Loss: (0.0071) | Acc: (99.74%) (38429/38528)\n",
            "Epoch: 146 | Batch_idx: 310 |  Loss: (0.0072) | Acc: (99.74%) (39705/39808)\n",
            "Epoch: 146 | Batch_idx: 320 |  Loss: (0.0070) | Acc: (99.75%) (40985/41088)\n",
            "Epoch: 146 | Batch_idx: 330 |  Loss: (0.0071) | Acc: (99.75%) (42262/42368)\n",
            "Epoch: 146 | Batch_idx: 340 |  Loss: (0.0071) | Acc: (99.75%) (43539/43648)\n",
            "Epoch: 146 | Batch_idx: 350 |  Loss: (0.0072) | Acc: (99.75%) (44816/44928)\n",
            "Epoch: 146 | Batch_idx: 360 |  Loss: (0.0071) | Acc: (99.75%) (46093/46208)\n",
            "Epoch: 146 | Batch_idx: 370 |  Loss: (0.0072) | Acc: (99.75%) (47369/47488)\n",
            "Epoch: 146 | Batch_idx: 380 |  Loss: (0.0072) | Acc: (99.75%) (48645/48768)\n",
            "Epoch: 146 | Batch_idx: 390 |  Loss: (0.0072) | Acc: (99.74%) (49872/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4186) | Acc: (91.91%) (9191/10000)\n",
            "Epoch: 147 | Batch_idx: 0 |  Loss: (0.0004) | Acc: (100.00%) (128/128)\n",
            "Epoch: 147 | Batch_idx: 10 |  Loss: (0.0050) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 147 | Batch_idx: 20 |  Loss: (0.0084) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 147 | Batch_idx: 30 |  Loss: (0.0072) | Acc: (99.85%) (3962/3968)\n",
            "Epoch: 147 | Batch_idx: 40 |  Loss: (0.0087) | Acc: (99.81%) (5238/5248)\n",
            "Epoch: 147 | Batch_idx: 50 |  Loss: (0.0079) | Acc: (99.80%) (6515/6528)\n",
            "Epoch: 147 | Batch_idx: 60 |  Loss: (0.0074) | Acc: (99.82%) (7794/7808)\n",
            "Epoch: 147 | Batch_idx: 70 |  Loss: (0.0071) | Acc: (99.82%) (9072/9088)\n",
            "Epoch: 147 | Batch_idx: 80 |  Loss: (0.0074) | Acc: (99.81%) (10348/10368)\n",
            "Epoch: 147 | Batch_idx: 90 |  Loss: (0.0076) | Acc: (99.80%) (11625/11648)\n",
            "Epoch: 147 | Batch_idx: 100 |  Loss: (0.0075) | Acc: (99.79%) (12901/12928)\n",
            "Epoch: 147 | Batch_idx: 110 |  Loss: (0.0072) | Acc: (99.80%) (14180/14208)\n",
            "Epoch: 147 | Batch_idx: 120 |  Loss: (0.0073) | Acc: (99.79%) (15456/15488)\n",
            "Epoch: 147 | Batch_idx: 130 |  Loss: (0.0073) | Acc: (99.79%) (16733/16768)\n",
            "Epoch: 147 | Batch_idx: 140 |  Loss: (0.0073) | Acc: (99.78%) (18009/18048)\n",
            "Epoch: 147 | Batch_idx: 150 |  Loss: (0.0072) | Acc: (99.78%) (19286/19328)\n",
            "Epoch: 147 | Batch_idx: 160 |  Loss: (0.0076) | Acc: (99.77%) (20560/20608)\n",
            "Epoch: 147 | Batch_idx: 170 |  Loss: (0.0073) | Acc: (99.77%) (21838/21888)\n",
            "Epoch: 147 | Batch_idx: 180 |  Loss: (0.0070) | Acc: (99.78%) (23117/23168)\n",
            "Epoch: 147 | Batch_idx: 190 |  Loss: (0.0071) | Acc: (99.78%) (24393/24448)\n",
            "Epoch: 147 | Batch_idx: 200 |  Loss: (0.0069) | Acc: (99.78%) (25672/25728)\n",
            "Epoch: 147 | Batch_idx: 210 |  Loss: (0.0075) | Acc: (99.76%) (26944/27008)\n",
            "Epoch: 147 | Batch_idx: 220 |  Loss: (0.0073) | Acc: (99.77%) (28223/28288)\n",
            "Epoch: 147 | Batch_idx: 230 |  Loss: (0.0071) | Acc: (99.78%) (29502/29568)\n",
            "Epoch: 147 | Batch_idx: 240 |  Loss: (0.0072) | Acc: (99.78%) (30779/30848)\n",
            "Epoch: 147 | Batch_idx: 250 |  Loss: (0.0071) | Acc: (99.77%) (32055/32128)\n",
            "Epoch: 147 | Batch_idx: 260 |  Loss: (0.0070) | Acc: (99.78%) (33333/33408)\n",
            "Epoch: 147 | Batch_idx: 270 |  Loss: (0.0073) | Acc: (99.77%) (34608/34688)\n",
            "Epoch: 147 | Batch_idx: 280 |  Loss: (0.0072) | Acc: (99.77%) (35886/35968)\n",
            "Epoch: 147 | Batch_idx: 290 |  Loss: (0.0071) | Acc: (99.77%) (37164/37248)\n",
            "Epoch: 147 | Batch_idx: 300 |  Loss: (0.0069) | Acc: (99.78%) (38443/38528)\n",
            "Epoch: 147 | Batch_idx: 310 |  Loss: (0.0069) | Acc: (99.78%) (39720/39808)\n",
            "Epoch: 147 | Batch_idx: 320 |  Loss: (0.0069) | Acc: (99.78%) (40998/41088)\n",
            "Epoch: 147 | Batch_idx: 330 |  Loss: (0.0068) | Acc: (99.78%) (42274/42368)\n",
            "Epoch: 147 | Batch_idx: 340 |  Loss: (0.0067) | Acc: (99.78%) (43553/43648)\n",
            "Epoch: 147 | Batch_idx: 350 |  Loss: (0.0068) | Acc: (99.78%) (44828/44928)\n",
            "Epoch: 147 | Batch_idx: 360 |  Loss: (0.0070) | Acc: (99.77%) (46102/46208)\n",
            "Epoch: 147 | Batch_idx: 370 |  Loss: (0.0068) | Acc: (99.78%) (47382/47488)\n",
            "Epoch: 147 | Batch_idx: 380 |  Loss: (0.0068) | Acc: (99.78%) (48661/48768)\n",
            "Epoch: 147 | Batch_idx: 390 |  Loss: (0.0067) | Acc: (99.78%) (49891/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4223) | Acc: (91.83%) (9183/10000)\n",
            "Epoch: 148 | Batch_idx: 0 |  Loss: (0.0002) | Acc: (100.00%) (128/128)\n",
            "Epoch: 148 | Batch_idx: 10 |  Loss: (0.0058) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 148 | Batch_idx: 20 |  Loss: (0.0059) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 148 | Batch_idx: 30 |  Loss: (0.0065) | Acc: (99.77%) (3959/3968)\n",
            "Epoch: 148 | Batch_idx: 40 |  Loss: (0.0067) | Acc: (99.75%) (5235/5248)\n",
            "Epoch: 148 | Batch_idx: 50 |  Loss: (0.0061) | Acc: (99.79%) (6514/6528)\n",
            "Epoch: 148 | Batch_idx: 60 |  Loss: (0.0056) | Acc: (99.81%) (7793/7808)\n",
            "Epoch: 148 | Batch_idx: 70 |  Loss: (0.0055) | Acc: (99.81%) (9071/9088)\n",
            "Epoch: 148 | Batch_idx: 80 |  Loss: (0.0058) | Acc: (99.80%) (10347/10368)\n",
            "Epoch: 148 | Batch_idx: 90 |  Loss: (0.0056) | Acc: (99.81%) (11626/11648)\n",
            "Epoch: 148 | Batch_idx: 100 |  Loss: (0.0051) | Acc: (99.83%) (12906/12928)\n",
            "Epoch: 148 | Batch_idx: 110 |  Loss: (0.0050) | Acc: (99.83%) (14184/14208)\n",
            "Epoch: 148 | Batch_idx: 120 |  Loss: (0.0050) | Acc: (99.84%) (15463/15488)\n",
            "Epoch: 148 | Batch_idx: 130 |  Loss: (0.0052) | Acc: (99.83%) (16740/16768)\n",
            "Epoch: 148 | Batch_idx: 140 |  Loss: (0.0053) | Acc: (99.83%) (18017/18048)\n",
            "Epoch: 148 | Batch_idx: 150 |  Loss: (0.0051) | Acc: (99.84%) (19297/19328)\n",
            "Epoch: 148 | Batch_idx: 160 |  Loss: (0.0050) | Acc: (99.85%) (20577/20608)\n",
            "Epoch: 148 | Batch_idx: 170 |  Loss: (0.0053) | Acc: (99.84%) (21852/21888)\n",
            "Epoch: 148 | Batch_idx: 180 |  Loss: (0.0051) | Acc: (99.84%) (23131/23168)\n",
            "Epoch: 148 | Batch_idx: 190 |  Loss: (0.0051) | Acc: (99.84%) (24410/24448)\n",
            "Epoch: 148 | Batch_idx: 200 |  Loss: (0.0051) | Acc: (99.84%) (25688/25728)\n",
            "Epoch: 148 | Batch_idx: 210 |  Loss: (0.0050) | Acc: (99.85%) (26967/27008)\n",
            "Epoch: 148 | Batch_idx: 220 |  Loss: (0.0049) | Acc: (99.86%) (28247/28288)\n",
            "Epoch: 148 | Batch_idx: 230 |  Loss: (0.0049) | Acc: (99.85%) (29524/29568)\n",
            "Epoch: 148 | Batch_idx: 240 |  Loss: (0.0052) | Acc: (99.85%) (30801/30848)\n",
            "Epoch: 148 | Batch_idx: 250 |  Loss: (0.0052) | Acc: (99.84%) (32078/32128)\n",
            "Epoch: 148 | Batch_idx: 260 |  Loss: (0.0053) | Acc: (99.84%) (33354/33408)\n",
            "Epoch: 148 | Batch_idx: 270 |  Loss: (0.0052) | Acc: (99.84%) (34633/34688)\n",
            "Epoch: 148 | Batch_idx: 280 |  Loss: (0.0054) | Acc: (99.83%) (35908/35968)\n",
            "Epoch: 148 | Batch_idx: 290 |  Loss: (0.0053) | Acc: (99.84%) (37187/37248)\n",
            "Epoch: 148 | Batch_idx: 300 |  Loss: (0.0052) | Acc: (99.84%) (38466/38528)\n",
            "Epoch: 148 | Batch_idx: 310 |  Loss: (0.0052) | Acc: (99.84%) (39745/39808)\n",
            "Epoch: 148 | Batch_idx: 320 |  Loss: (0.0052) | Acc: (99.84%) (41023/41088)\n",
            "Epoch: 148 | Batch_idx: 330 |  Loss: (0.0053) | Acc: (99.84%) (42300/42368)\n",
            "Epoch: 148 | Batch_idx: 340 |  Loss: (0.0052) | Acc: (99.84%) (43580/43648)\n",
            "Epoch: 148 | Batch_idx: 350 |  Loss: (0.0052) | Acc: (99.84%) (44858/44928)\n",
            "Epoch: 148 | Batch_idx: 360 |  Loss: (0.0053) | Acc: (99.84%) (46135/46208)\n",
            "Epoch: 148 | Batch_idx: 370 |  Loss: (0.0052) | Acc: (99.84%) (47413/47488)\n",
            "Epoch: 148 | Batch_idx: 380 |  Loss: (0.0053) | Acc: (99.84%) (48690/48768)\n",
            "Epoch: 148 | Batch_idx: 390 |  Loss: (0.0053) | Acc: (99.84%) (49919/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4239) | Acc: (91.85%) (9185/10000)\n",
            "Epoch: 149 | Batch_idx: 0 |  Loss: (0.0005) | Acc: (100.00%) (128/128)\n",
            "Epoch: 149 | Batch_idx: 10 |  Loss: (0.0053) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 149 | Batch_idx: 20 |  Loss: (0.0058) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 149 | Batch_idx: 30 |  Loss: (0.0050) | Acc: (99.82%) (3961/3968)\n",
            "Epoch: 149 | Batch_idx: 40 |  Loss: (0.0056) | Acc: (99.81%) (5238/5248)\n",
            "Epoch: 149 | Batch_idx: 50 |  Loss: (0.0052) | Acc: (99.83%) (6517/6528)\n",
            "Epoch: 149 | Batch_idx: 60 |  Loss: (0.0056) | Acc: (99.81%) (7793/7808)\n",
            "Epoch: 149 | Batch_idx: 70 |  Loss: (0.0057) | Acc: (99.81%) (9071/9088)\n",
            "Epoch: 149 | Batch_idx: 80 |  Loss: (0.0056) | Acc: (99.83%) (10350/10368)\n",
            "Epoch: 149 | Batch_idx: 90 |  Loss: (0.0053) | Acc: (99.84%) (11629/11648)\n",
            "Epoch: 149 | Batch_idx: 100 |  Loss: (0.0060) | Acc: (99.81%) (12904/12928)\n",
            "Epoch: 149 | Batch_idx: 110 |  Loss: (0.0064) | Acc: (99.80%) (14179/14208)\n",
            "Epoch: 149 | Batch_idx: 120 |  Loss: (0.0062) | Acc: (99.80%) (15457/15488)\n",
            "Epoch: 149 | Batch_idx: 130 |  Loss: (0.0061) | Acc: (99.80%) (16734/16768)\n",
            "Epoch: 149 | Batch_idx: 140 |  Loss: (0.0065) | Acc: (99.79%) (18011/18048)\n",
            "Epoch: 149 | Batch_idx: 150 |  Loss: (0.0063) | Acc: (99.79%) (19288/19328)\n",
            "Epoch: 149 | Batch_idx: 160 |  Loss: (0.0063) | Acc: (99.80%) (20566/20608)\n",
            "Epoch: 149 | Batch_idx: 170 |  Loss: (0.0067) | Acc: (99.78%) (21840/21888)\n",
            "Epoch: 149 | Batch_idx: 180 |  Loss: (0.0066) | Acc: (99.78%) (23118/23168)\n",
            "Epoch: 149 | Batch_idx: 190 |  Loss: (0.0066) | Acc: (99.78%) (24394/24448)\n",
            "Epoch: 149 | Batch_idx: 200 |  Loss: (0.0066) | Acc: (99.78%) (25671/25728)\n",
            "Epoch: 149 | Batch_idx: 210 |  Loss: (0.0068) | Acc: (99.78%) (26948/27008)\n",
            "Epoch: 149 | Batch_idx: 220 |  Loss: (0.0067) | Acc: (99.78%) (28226/28288)\n",
            "Epoch: 149 | Batch_idx: 230 |  Loss: (0.0066) | Acc: (99.78%) (29504/29568)\n",
            "Epoch: 149 | Batch_idx: 240 |  Loss: (0.0066) | Acc: (99.78%) (30780/30848)\n",
            "Epoch: 149 | Batch_idx: 250 |  Loss: (0.0066) | Acc: (99.78%) (32056/32128)\n",
            "Epoch: 149 | Batch_idx: 260 |  Loss: (0.0067) | Acc: (99.77%) (33331/33408)\n",
            "Epoch: 149 | Batch_idx: 270 |  Loss: (0.0067) | Acc: (99.77%) (34607/34688)\n",
            "Epoch: 149 | Batch_idx: 280 |  Loss: (0.0071) | Acc: (99.76%) (35881/35968)\n",
            "Epoch: 149 | Batch_idx: 290 |  Loss: (0.0070) | Acc: (99.76%) (37158/37248)\n",
            "Epoch: 149 | Batch_idx: 300 |  Loss: (0.0070) | Acc: (99.76%) (38436/38528)\n",
            "Epoch: 149 | Batch_idx: 310 |  Loss: (0.0071) | Acc: (99.76%) (39712/39808)\n",
            "Epoch: 149 | Batch_idx: 320 |  Loss: (0.0071) | Acc: (99.76%) (40989/41088)\n",
            "Epoch: 149 | Batch_idx: 330 |  Loss: (0.0070) | Acc: (99.76%) (42267/42368)\n",
            "Epoch: 149 | Batch_idx: 340 |  Loss: (0.0071) | Acc: (99.76%) (43543/43648)\n",
            "Epoch: 149 | Batch_idx: 350 |  Loss: (0.0071) | Acc: (99.76%) (44821/44928)\n",
            "Epoch: 149 | Batch_idx: 360 |  Loss: (0.0070) | Acc: (99.77%) (46100/46208)\n",
            "Epoch: 149 | Batch_idx: 370 |  Loss: (0.0070) | Acc: (99.77%) (47377/47488)\n",
            "Epoch: 149 | Batch_idx: 380 |  Loss: (0.0070) | Acc: (99.77%) (48655/48768)\n",
            "Epoch: 149 | Batch_idx: 390 |  Loss: (0.0070) | Acc: (99.77%) (49884/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4207) | Acc: (91.89%) (9189/10000)\n",
            "Epoch: 150 | Batch_idx: 0 |  Loss: (0.0009) | Acc: (100.00%) (128/128)\n",
            "Epoch: 150 | Batch_idx: 10 |  Loss: (0.0054) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 150 | Batch_idx: 20 |  Loss: (0.0055) | Acc: (99.81%) (2683/2688)\n",
            "Epoch: 150 | Batch_idx: 30 |  Loss: (0.0045) | Acc: (99.85%) (3962/3968)\n",
            "Epoch: 150 | Batch_idx: 40 |  Loss: (0.0051) | Acc: (99.81%) (5238/5248)\n",
            "Epoch: 150 | Batch_idx: 50 |  Loss: (0.0048) | Acc: (99.83%) (6517/6528)\n",
            "Epoch: 150 | Batch_idx: 60 |  Loss: (0.0050) | Acc: (99.83%) (7795/7808)\n",
            "Epoch: 150 | Batch_idx: 70 |  Loss: (0.0054) | Acc: (99.81%) (9071/9088)\n",
            "Epoch: 150 | Batch_idx: 80 |  Loss: (0.0053) | Acc: (99.82%) (10349/10368)\n",
            "Epoch: 150 | Batch_idx: 90 |  Loss: (0.0049) | Acc: (99.84%) (11629/11648)\n",
            "Epoch: 150 | Batch_idx: 100 |  Loss: (0.0049) | Acc: (99.83%) (12906/12928)\n",
            "Epoch: 150 | Batch_idx: 110 |  Loss: (0.0048) | Acc: (99.84%) (14185/14208)\n",
            "Epoch: 150 | Batch_idx: 120 |  Loss: (0.0050) | Acc: (99.84%) (15463/15488)\n",
            "Epoch: 150 | Batch_idx: 130 |  Loss: (0.0048) | Acc: (99.85%) (16743/16768)\n",
            "Epoch: 150 | Batch_idx: 140 |  Loss: (0.0051) | Acc: (99.85%) (18021/18048)\n",
            "Epoch: 150 | Batch_idx: 150 |  Loss: (0.0050) | Acc: (99.84%) (19298/19328)\n",
            "Epoch: 150 | Batch_idx: 160 |  Loss: (0.0050) | Acc: (99.84%) (20576/20608)\n",
            "Epoch: 150 | Batch_idx: 170 |  Loss: (0.0048) | Acc: (99.85%) (21856/21888)\n",
            "Epoch: 150 | Batch_idx: 180 |  Loss: (0.0047) | Acc: (99.86%) (23136/23168)\n",
            "Epoch: 150 | Batch_idx: 190 |  Loss: (0.0045) | Acc: (99.87%) (24416/24448)\n",
            "Epoch: 150 | Batch_idx: 200 |  Loss: (0.0044) | Acc: (99.87%) (25694/25728)\n",
            "Epoch: 150 | Batch_idx: 210 |  Loss: (0.0046) | Acc: (99.86%) (26969/27008)\n",
            "Epoch: 150 | Batch_idx: 220 |  Loss: (0.0046) | Acc: (99.86%) (28248/28288)\n",
            "Epoch: 150 | Batch_idx: 230 |  Loss: (0.0047) | Acc: (99.85%) (29525/29568)\n",
            "Epoch: 150 | Batch_idx: 240 |  Loss: (0.0048) | Acc: (99.85%) (30802/30848)\n",
            "Epoch: 150 | Batch_idx: 250 |  Loss: (0.0048) | Acc: (99.85%) (32081/32128)\n",
            "Epoch: 150 | Batch_idx: 260 |  Loss: (0.0048) | Acc: (99.86%) (33360/33408)\n",
            "Epoch: 150 | Batch_idx: 270 |  Loss: (0.0049) | Acc: (99.85%) (34637/34688)\n",
            "Epoch: 150 | Batch_idx: 280 |  Loss: (0.0048) | Acc: (99.86%) (35916/35968)\n",
            "Epoch: 150 | Batch_idx: 290 |  Loss: (0.0048) | Acc: (99.86%) (37194/37248)\n",
            "Epoch: 150 | Batch_idx: 300 |  Loss: (0.0048) | Acc: (99.86%) (38473/38528)\n",
            "Epoch: 150 | Batch_idx: 310 |  Loss: (0.0047) | Acc: (99.86%) (39751/39808)\n",
            "Epoch: 150 | Batch_idx: 320 |  Loss: (0.0048) | Acc: (99.85%) (41026/41088)\n",
            "Epoch: 150 | Batch_idx: 330 |  Loss: (0.0048) | Acc: (99.85%) (42304/42368)\n",
            "Epoch: 150 | Batch_idx: 340 |  Loss: (0.0050) | Acc: (99.84%) (43579/43648)\n",
            "Epoch: 150 | Batch_idx: 350 |  Loss: (0.0048) | Acc: (99.85%) (44859/44928)\n",
            "Epoch: 150 | Batch_idx: 360 |  Loss: (0.0049) | Acc: (99.84%) (46135/46208)\n",
            "Epoch: 150 | Batch_idx: 370 |  Loss: (0.0050) | Acc: (99.83%) (47408/47488)\n",
            "Epoch: 150 | Batch_idx: 380 |  Loss: (0.0051) | Acc: (99.83%) (48685/48768)\n",
            "Epoch: 150 | Batch_idx: 390 |  Loss: (0.0050) | Acc: (99.83%) (49917/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4219) | Acc: (91.91%) (9191/10000)\n",
            "Epoch: 151 | Batch_idx: 0 |  Loss: (0.0115) | Acc: (99.22%) (127/128)\n",
            "Epoch: 151 | Batch_idx: 10 |  Loss: (0.0076) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 151 | Batch_idx: 20 |  Loss: (0.0082) | Acc: (99.63%) (2678/2688)\n",
            "Epoch: 151 | Batch_idx: 30 |  Loss: (0.0074) | Acc: (99.67%) (3955/3968)\n",
            "Epoch: 151 | Batch_idx: 40 |  Loss: (0.0072) | Acc: (99.71%) (5233/5248)\n",
            "Epoch: 151 | Batch_idx: 50 |  Loss: (0.0067) | Acc: (99.72%) (6510/6528)\n",
            "Epoch: 151 | Batch_idx: 60 |  Loss: (0.0062) | Acc: (99.76%) (7789/7808)\n",
            "Epoch: 151 | Batch_idx: 70 |  Loss: (0.0063) | Acc: (99.76%) (9066/9088)\n",
            "Epoch: 151 | Batch_idx: 80 |  Loss: (0.0062) | Acc: (99.76%) (10343/10368)\n",
            "Epoch: 151 | Batch_idx: 90 |  Loss: (0.0059) | Acc: (99.78%) (11622/11648)\n",
            "Epoch: 151 | Batch_idx: 100 |  Loss: (0.0057) | Acc: (99.78%) (12900/12928)\n",
            "Epoch: 151 | Batch_idx: 110 |  Loss: (0.0055) | Acc: (99.79%) (14178/14208)\n",
            "Epoch: 151 | Batch_idx: 120 |  Loss: (0.0056) | Acc: (99.79%) (15456/15488)\n",
            "Epoch: 151 | Batch_idx: 130 |  Loss: (0.0054) | Acc: (99.79%) (16733/16768)\n",
            "Epoch: 151 | Batch_idx: 140 |  Loss: (0.0055) | Acc: (99.77%) (18007/18048)\n",
            "Epoch: 151 | Batch_idx: 150 |  Loss: (0.0055) | Acc: (99.78%) (19286/19328)\n",
            "Epoch: 151 | Batch_idx: 160 |  Loss: (0.0053) | Acc: (99.79%) (20564/20608)\n",
            "Epoch: 151 | Batch_idx: 170 |  Loss: (0.0053) | Acc: (99.78%) (21840/21888)\n",
            "Epoch: 151 | Batch_idx: 180 |  Loss: (0.0051) | Acc: (99.78%) (23118/23168)\n",
            "Epoch: 151 | Batch_idx: 190 |  Loss: (0.0052) | Acc: (99.79%) (24396/24448)\n",
            "Epoch: 151 | Batch_idx: 200 |  Loss: (0.0053) | Acc: (99.79%) (25674/25728)\n",
            "Epoch: 151 | Batch_idx: 210 |  Loss: (0.0053) | Acc: (99.80%) (26953/27008)\n",
            "Epoch: 151 | Batch_idx: 220 |  Loss: (0.0054) | Acc: (99.79%) (28230/28288)\n",
            "Epoch: 151 | Batch_idx: 230 |  Loss: (0.0053) | Acc: (99.80%) (29509/29568)\n",
            "Epoch: 151 | Batch_idx: 240 |  Loss: (0.0055) | Acc: (99.79%) (30784/30848)\n",
            "Epoch: 151 | Batch_idx: 250 |  Loss: (0.0055) | Acc: (99.79%) (32062/32128)\n",
            "Epoch: 151 | Batch_idx: 260 |  Loss: (0.0055) | Acc: (99.80%) (33340/33408)\n",
            "Epoch: 151 | Batch_idx: 270 |  Loss: (0.0054) | Acc: (99.80%) (34617/34688)\n",
            "Epoch: 151 | Batch_idx: 280 |  Loss: (0.0053) | Acc: (99.80%) (35896/35968)\n",
            "Epoch: 151 | Batch_idx: 290 |  Loss: (0.0055) | Acc: (99.80%) (37172/37248)\n",
            "Epoch: 151 | Batch_idx: 300 |  Loss: (0.0056) | Acc: (99.79%) (38448/38528)\n",
            "Epoch: 151 | Batch_idx: 310 |  Loss: (0.0055) | Acc: (99.80%) (39727/39808)\n",
            "Epoch: 151 | Batch_idx: 320 |  Loss: (0.0056) | Acc: (99.79%) (41003/41088)\n",
            "Epoch: 151 | Batch_idx: 330 |  Loss: (0.0056) | Acc: (99.79%) (42281/42368)\n",
            "Epoch: 151 | Batch_idx: 340 |  Loss: (0.0056) | Acc: (99.80%) (43559/43648)\n",
            "Epoch: 151 | Batch_idx: 350 |  Loss: (0.0055) | Acc: (99.80%) (44839/44928)\n",
            "Epoch: 151 | Batch_idx: 360 |  Loss: (0.0056) | Acc: (99.80%) (46115/46208)\n",
            "Epoch: 151 | Batch_idx: 370 |  Loss: (0.0055) | Acc: (99.80%) (47395/47488)\n",
            "Epoch: 151 | Batch_idx: 380 |  Loss: (0.0054) | Acc: (99.81%) (48675/48768)\n",
            "Epoch: 151 | Batch_idx: 390 |  Loss: (0.0055) | Acc: (99.81%) (49903/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4227) | Acc: (91.87%) (9187/10000)\n",
            "Epoch: 152 | Batch_idx: 0 |  Loss: (0.0006) | Acc: (100.00%) (128/128)\n",
            "Epoch: 152 | Batch_idx: 10 |  Loss: (0.0039) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 152 | Batch_idx: 20 |  Loss: (0.0052) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 152 | Batch_idx: 30 |  Loss: (0.0049) | Acc: (99.85%) (3962/3968)\n",
            "Epoch: 152 | Batch_idx: 40 |  Loss: (0.0054) | Acc: (99.85%) (5240/5248)\n",
            "Epoch: 152 | Batch_idx: 50 |  Loss: (0.0048) | Acc: (99.86%) (6519/6528)\n",
            "Epoch: 152 | Batch_idx: 60 |  Loss: (0.0055) | Acc: (99.81%) (7793/7808)\n",
            "Epoch: 152 | Batch_idx: 70 |  Loss: (0.0055) | Acc: (99.79%) (9069/9088)\n",
            "Epoch: 152 | Batch_idx: 80 |  Loss: (0.0052) | Acc: (99.81%) (10348/10368)\n",
            "Epoch: 152 | Batch_idx: 90 |  Loss: (0.0050) | Acc: (99.81%) (11626/11648)\n",
            "Epoch: 152 | Batch_idx: 100 |  Loss: (0.0053) | Acc: (99.81%) (12903/12928)\n",
            "Epoch: 152 | Batch_idx: 110 |  Loss: (0.0054) | Acc: (99.81%) (14181/14208)\n",
            "Epoch: 152 | Batch_idx: 120 |  Loss: (0.0052) | Acc: (99.81%) (15459/15488)\n",
            "Epoch: 152 | Batch_idx: 130 |  Loss: (0.0052) | Acc: (99.81%) (16736/16768)\n",
            "Epoch: 152 | Batch_idx: 140 |  Loss: (0.0049) | Acc: (99.82%) (18016/18048)\n",
            "Epoch: 152 | Batch_idx: 150 |  Loss: (0.0053) | Acc: (99.81%) (19292/19328)\n",
            "Epoch: 152 | Batch_idx: 160 |  Loss: (0.0056) | Acc: (99.81%) (20568/20608)\n",
            "Epoch: 152 | Batch_idx: 170 |  Loss: (0.0055) | Acc: (99.81%) (21847/21888)\n",
            "Epoch: 152 | Batch_idx: 180 |  Loss: (0.0055) | Acc: (99.81%) (23123/23168)\n",
            "Epoch: 152 | Batch_idx: 190 |  Loss: (0.0055) | Acc: (99.81%) (24401/24448)\n",
            "Epoch: 152 | Batch_idx: 200 |  Loss: (0.0053) | Acc: (99.81%) (25680/25728)\n",
            "Epoch: 152 | Batch_idx: 210 |  Loss: (0.0052) | Acc: (99.81%) (26958/27008)\n",
            "Epoch: 152 | Batch_idx: 220 |  Loss: (0.0052) | Acc: (99.82%) (28236/28288)\n",
            "Epoch: 152 | Batch_idx: 230 |  Loss: (0.0050) | Acc: (99.82%) (29516/29568)\n",
            "Epoch: 152 | Batch_idx: 240 |  Loss: (0.0049) | Acc: (99.83%) (30796/30848)\n",
            "Epoch: 152 | Batch_idx: 250 |  Loss: (0.0048) | Acc: (99.84%) (32075/32128)\n",
            "Epoch: 152 | Batch_idx: 260 |  Loss: (0.0049) | Acc: (99.84%) (33354/33408)\n",
            "Epoch: 152 | Batch_idx: 270 |  Loss: (0.0048) | Acc: (99.84%) (34633/34688)\n",
            "Epoch: 152 | Batch_idx: 280 |  Loss: (0.0048) | Acc: (99.84%) (35910/35968)\n",
            "Epoch: 152 | Batch_idx: 290 |  Loss: (0.0048) | Acc: (99.84%) (37189/37248)\n",
            "Epoch: 152 | Batch_idx: 300 |  Loss: (0.0051) | Acc: (99.83%) (38463/38528)\n",
            "Epoch: 152 | Batch_idx: 310 |  Loss: (0.0052) | Acc: (99.83%) (39740/39808)\n",
            "Epoch: 152 | Batch_idx: 320 |  Loss: (0.0052) | Acc: (99.83%) (41017/41088)\n",
            "Epoch: 152 | Batch_idx: 330 |  Loss: (0.0052) | Acc: (99.83%) (42296/42368)\n",
            "Epoch: 152 | Batch_idx: 340 |  Loss: (0.0052) | Acc: (99.83%) (43575/43648)\n",
            "Epoch: 152 | Batch_idx: 350 |  Loss: (0.0051) | Acc: (99.84%) (44854/44928)\n",
            "Epoch: 152 | Batch_idx: 360 |  Loss: (0.0052) | Acc: (99.83%) (46131/46208)\n",
            "Epoch: 152 | Batch_idx: 370 |  Loss: (0.0051) | Acc: (99.84%) (47411/47488)\n",
            "Epoch: 152 | Batch_idx: 380 |  Loss: (0.0050) | Acc: (99.84%) (48690/48768)\n",
            "Epoch: 152 | Batch_idx: 390 |  Loss: (0.0051) | Acc: (99.84%) (49919/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4237) | Acc: (91.89%) (9189/10000)\n",
            "Epoch: 153 | Batch_idx: 0 |  Loss: (0.0099) | Acc: (100.00%) (128/128)\n",
            "Epoch: 153 | Batch_idx: 10 |  Loss: (0.0052) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 153 | Batch_idx: 20 |  Loss: (0.0059) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 153 | Batch_idx: 30 |  Loss: (0.0064) | Acc: (99.85%) (3962/3968)\n",
            "Epoch: 153 | Batch_idx: 40 |  Loss: (0.0061) | Acc: (99.81%) (5238/5248)\n",
            "Epoch: 153 | Batch_idx: 50 |  Loss: (0.0056) | Acc: (99.82%) (6516/6528)\n",
            "Epoch: 153 | Batch_idx: 60 |  Loss: (0.0061) | Acc: (99.78%) (7791/7808)\n",
            "Epoch: 153 | Batch_idx: 70 |  Loss: (0.0056) | Acc: (99.80%) (9070/9088)\n",
            "Epoch: 153 | Batch_idx: 80 |  Loss: (0.0051) | Acc: (99.83%) (10350/10368)\n",
            "Epoch: 153 | Batch_idx: 90 |  Loss: (0.0052) | Acc: (99.82%) (11627/11648)\n",
            "Epoch: 153 | Batch_idx: 100 |  Loss: (0.0051) | Acc: (99.82%) (12905/12928)\n",
            "Epoch: 153 | Batch_idx: 110 |  Loss: (0.0051) | Acc: (99.81%) (14181/14208)\n",
            "Epoch: 153 | Batch_idx: 120 |  Loss: (0.0049) | Acc: (99.82%) (15460/15488)\n",
            "Epoch: 153 | Batch_idx: 130 |  Loss: (0.0048) | Acc: (99.82%) (16738/16768)\n",
            "Epoch: 153 | Batch_idx: 140 |  Loss: (0.0048) | Acc: (99.83%) (18017/18048)\n",
            "Epoch: 153 | Batch_idx: 150 |  Loss: (0.0051) | Acc: (99.82%) (19293/19328)\n",
            "Epoch: 153 | Batch_idx: 160 |  Loss: (0.0052) | Acc: (99.83%) (20572/20608)\n",
            "Epoch: 153 | Batch_idx: 170 |  Loss: (0.0053) | Acc: (99.82%) (21849/21888)\n",
            "Epoch: 153 | Batch_idx: 180 |  Loss: (0.0054) | Acc: (99.82%) (23127/23168)\n",
            "Epoch: 153 | Batch_idx: 190 |  Loss: (0.0052) | Acc: (99.83%) (24407/24448)\n",
            "Epoch: 153 | Batch_idx: 200 |  Loss: (0.0050) | Acc: (99.84%) (25687/25728)\n",
            "Epoch: 153 | Batch_idx: 210 |  Loss: (0.0051) | Acc: (99.84%) (26966/27008)\n",
            "Epoch: 153 | Batch_idx: 220 |  Loss: (0.0054) | Acc: (99.84%) (28243/28288)\n",
            "Epoch: 153 | Batch_idx: 230 |  Loss: (0.0053) | Acc: (99.84%) (29522/29568)\n",
            "Epoch: 153 | Batch_idx: 240 |  Loss: (0.0055) | Acc: (99.84%) (30798/30848)\n",
            "Epoch: 153 | Batch_idx: 250 |  Loss: (0.0056) | Acc: (99.84%) (32075/32128)\n",
            "Epoch: 153 | Batch_idx: 260 |  Loss: (0.0056) | Acc: (99.84%) (33353/33408)\n",
            "Epoch: 153 | Batch_idx: 270 |  Loss: (0.0056) | Acc: (99.84%) (34631/34688)\n",
            "Epoch: 153 | Batch_idx: 280 |  Loss: (0.0055) | Acc: (99.84%) (35910/35968)\n",
            "Epoch: 153 | Batch_idx: 290 |  Loss: (0.0056) | Acc: (99.84%) (37187/37248)\n",
            "Epoch: 153 | Batch_idx: 300 |  Loss: (0.0055) | Acc: (99.84%) (38465/38528)\n",
            "Epoch: 153 | Batch_idx: 310 |  Loss: (0.0056) | Acc: (99.83%) (39742/39808)\n",
            "Epoch: 153 | Batch_idx: 320 |  Loss: (0.0058) | Acc: (99.83%) (41017/41088)\n",
            "Epoch: 153 | Batch_idx: 330 |  Loss: (0.0057) | Acc: (99.83%) (42296/42368)\n",
            "Epoch: 153 | Batch_idx: 340 |  Loss: (0.0056) | Acc: (99.83%) (43575/43648)\n",
            "Epoch: 153 | Batch_idx: 350 |  Loss: (0.0056) | Acc: (99.83%) (44853/44928)\n",
            "Epoch: 153 | Batch_idx: 360 |  Loss: (0.0056) | Acc: (99.83%) (46130/46208)\n",
            "Epoch: 153 | Batch_idx: 370 |  Loss: (0.0057) | Acc: (99.83%) (47405/47488)\n",
            "Epoch: 153 | Batch_idx: 380 |  Loss: (0.0056) | Acc: (99.82%) (48682/48768)\n",
            "Epoch: 153 | Batch_idx: 390 |  Loss: (0.0055) | Acc: (99.83%) (49914/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4213) | Acc: (91.90%) (9190/10000)\n",
            "Epoch: 154 | Batch_idx: 0 |  Loss: (0.0047) | Acc: (100.00%) (128/128)\n",
            "Epoch: 154 | Batch_idx: 10 |  Loss: (0.0073) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 154 | Batch_idx: 20 |  Loss: (0.0051) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 154 | Batch_idx: 30 |  Loss: (0.0047) | Acc: (99.80%) (3960/3968)\n",
            "Epoch: 154 | Batch_idx: 40 |  Loss: (0.0047) | Acc: (99.81%) (5238/5248)\n",
            "Epoch: 154 | Batch_idx: 50 |  Loss: (0.0049) | Acc: (99.82%) (6516/6528)\n",
            "Epoch: 154 | Batch_idx: 60 |  Loss: (0.0054) | Acc: (99.80%) (7792/7808)\n",
            "Epoch: 154 | Batch_idx: 70 |  Loss: (0.0053) | Acc: (99.80%) (9070/9088)\n",
            "Epoch: 154 | Batch_idx: 80 |  Loss: (0.0056) | Acc: (99.81%) (10348/10368)\n",
            "Epoch: 154 | Batch_idx: 90 |  Loss: (0.0053) | Acc: (99.82%) (11627/11648)\n",
            "Epoch: 154 | Batch_idx: 100 |  Loss: (0.0052) | Acc: (99.83%) (12906/12928)\n",
            "Epoch: 154 | Batch_idx: 110 |  Loss: (0.0052) | Acc: (99.83%) (14184/14208)\n",
            "Epoch: 154 | Batch_idx: 120 |  Loss: (0.0056) | Acc: (99.81%) (15459/15488)\n",
            "Epoch: 154 | Batch_idx: 130 |  Loss: (0.0058) | Acc: (99.80%) (16735/16768)\n",
            "Epoch: 154 | Batch_idx: 140 |  Loss: (0.0058) | Acc: (99.81%) (18013/18048)\n",
            "Epoch: 154 | Batch_idx: 150 |  Loss: (0.0056) | Acc: (99.81%) (19292/19328)\n",
            "Epoch: 154 | Batch_idx: 160 |  Loss: (0.0056) | Acc: (99.82%) (20570/20608)\n",
            "Epoch: 154 | Batch_idx: 170 |  Loss: (0.0057) | Acc: (99.81%) (21847/21888)\n",
            "Epoch: 154 | Batch_idx: 180 |  Loss: (0.0056) | Acc: (99.82%) (23126/23168)\n",
            "Epoch: 154 | Batch_idx: 190 |  Loss: (0.0056) | Acc: (99.82%) (24404/24448)\n",
            "Epoch: 154 | Batch_idx: 200 |  Loss: (0.0054) | Acc: (99.82%) (25682/25728)\n",
            "Epoch: 154 | Batch_idx: 210 |  Loss: (0.0055) | Acc: (99.82%) (26960/27008)\n",
            "Epoch: 154 | Batch_idx: 220 |  Loss: (0.0054) | Acc: (99.83%) (28239/28288)\n",
            "Epoch: 154 | Batch_idx: 230 |  Loss: (0.0055) | Acc: (99.82%) (29515/29568)\n",
            "Epoch: 154 | Batch_idx: 240 |  Loss: (0.0055) | Acc: (99.82%) (30792/30848)\n",
            "Epoch: 154 | Batch_idx: 250 |  Loss: (0.0056) | Acc: (99.82%) (32070/32128)\n",
            "Epoch: 154 | Batch_idx: 260 |  Loss: (0.0056) | Acc: (99.82%) (33348/33408)\n",
            "Epoch: 154 | Batch_idx: 270 |  Loss: (0.0056) | Acc: (99.82%) (34625/34688)\n",
            "Epoch: 154 | Batch_idx: 280 |  Loss: (0.0056) | Acc: (99.82%) (35903/35968)\n",
            "Epoch: 154 | Batch_idx: 290 |  Loss: (0.0057) | Acc: (99.82%) (37180/37248)\n",
            "Epoch: 154 | Batch_idx: 300 |  Loss: (0.0057) | Acc: (99.82%) (38457/38528)\n",
            "Epoch: 154 | Batch_idx: 310 |  Loss: (0.0057) | Acc: (99.81%) (39734/39808)\n",
            "Epoch: 154 | Batch_idx: 320 |  Loss: (0.0056) | Acc: (99.82%) (41013/41088)\n",
            "Epoch: 154 | Batch_idx: 330 |  Loss: (0.0056) | Acc: (99.82%) (42290/42368)\n",
            "Epoch: 154 | Batch_idx: 340 |  Loss: (0.0057) | Acc: (99.82%) (43568/43648)\n",
            "Epoch: 154 | Batch_idx: 350 |  Loss: (0.0056) | Acc: (99.82%) (44846/44928)\n",
            "Epoch: 154 | Batch_idx: 360 |  Loss: (0.0056) | Acc: (99.82%) (46125/46208)\n",
            "Epoch: 154 | Batch_idx: 370 |  Loss: (0.0056) | Acc: (99.82%) (47401/47488)\n",
            "Epoch: 154 | Batch_idx: 380 |  Loss: (0.0056) | Acc: (99.82%) (48678/48768)\n",
            "Epoch: 154 | Batch_idx: 390 |  Loss: (0.0055) | Acc: (99.82%) (49909/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4277) | Acc: (91.80%) (9180/10000)\n",
            "Epoch: 155 | Batch_idx: 0 |  Loss: (0.0011) | Acc: (100.00%) (128/128)\n",
            "Epoch: 155 | Batch_idx: 10 |  Loss: (0.0136) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 155 | Batch_idx: 20 |  Loss: (0.0111) | Acc: (99.63%) (2678/2688)\n",
            "Epoch: 155 | Batch_idx: 30 |  Loss: (0.0088) | Acc: (99.72%) (3957/3968)\n",
            "Epoch: 155 | Batch_idx: 40 |  Loss: (0.0076) | Acc: (99.75%) (5235/5248)\n",
            "Epoch: 155 | Batch_idx: 50 |  Loss: (0.0077) | Acc: (99.75%) (6512/6528)\n",
            "Epoch: 155 | Batch_idx: 60 |  Loss: (0.0071) | Acc: (99.77%) (7790/7808)\n",
            "Epoch: 155 | Batch_idx: 70 |  Loss: (0.0065) | Acc: (99.79%) (9069/9088)\n",
            "Epoch: 155 | Batch_idx: 80 |  Loss: (0.0064) | Acc: (99.78%) (10345/10368)\n",
            "Epoch: 155 | Batch_idx: 90 |  Loss: (0.0070) | Acc: (99.77%) (11621/11648)\n",
            "Epoch: 155 | Batch_idx: 100 |  Loss: (0.0070) | Acc: (99.78%) (12899/12928)\n",
            "Epoch: 155 | Batch_idx: 110 |  Loss: (0.0066) | Acc: (99.79%) (14178/14208)\n",
            "Epoch: 155 | Batch_idx: 120 |  Loss: (0.0069) | Acc: (99.78%) (15454/15488)\n",
            "Epoch: 155 | Batch_idx: 130 |  Loss: (0.0071) | Acc: (99.79%) (16732/16768)\n",
            "Epoch: 155 | Batch_idx: 140 |  Loss: (0.0069) | Acc: (99.79%) (18010/18048)\n",
            "Epoch: 155 | Batch_idx: 150 |  Loss: (0.0069) | Acc: (99.78%) (19285/19328)\n",
            "Epoch: 155 | Batch_idx: 160 |  Loss: (0.0067) | Acc: (99.78%) (20562/20608)\n",
            "Epoch: 155 | Batch_idx: 170 |  Loss: (0.0065) | Acc: (99.79%) (21841/21888)\n",
            "Epoch: 155 | Batch_idx: 180 |  Loss: (0.0064) | Acc: (99.79%) (23120/23168)\n",
            "Epoch: 155 | Batch_idx: 190 |  Loss: (0.0062) | Acc: (99.80%) (24398/24448)\n",
            "Epoch: 155 | Batch_idx: 200 |  Loss: (0.0066) | Acc: (99.79%) (25673/25728)\n",
            "Epoch: 155 | Batch_idx: 210 |  Loss: (0.0065) | Acc: (99.79%) (26951/27008)\n",
            "Epoch: 155 | Batch_idx: 220 |  Loss: (0.0070) | Acc: (99.78%) (28225/28288)\n",
            "Epoch: 155 | Batch_idx: 230 |  Loss: (0.0070) | Acc: (99.78%) (29503/29568)\n",
            "Epoch: 155 | Batch_idx: 240 |  Loss: (0.0070) | Acc: (99.79%) (30782/30848)\n",
            "Epoch: 155 | Batch_idx: 250 |  Loss: (0.0069) | Acc: (99.79%) (32060/32128)\n",
            "Epoch: 155 | Batch_idx: 260 |  Loss: (0.0068) | Acc: (99.79%) (33338/33408)\n",
            "Epoch: 155 | Batch_idx: 270 |  Loss: (0.0066) | Acc: (99.80%) (34618/34688)\n",
            "Epoch: 155 | Batch_idx: 280 |  Loss: (0.0066) | Acc: (99.80%) (35895/35968)\n",
            "Epoch: 155 | Batch_idx: 290 |  Loss: (0.0066) | Acc: (99.80%) (37173/37248)\n",
            "Epoch: 155 | Batch_idx: 300 |  Loss: (0.0064) | Acc: (99.81%) (38453/38528)\n",
            "Epoch: 155 | Batch_idx: 310 |  Loss: (0.0063) | Acc: (99.81%) (39732/39808)\n",
            "Epoch: 155 | Batch_idx: 320 |  Loss: (0.0063) | Acc: (99.81%) (41010/41088)\n",
            "Epoch: 155 | Batch_idx: 330 |  Loss: (0.0062) | Acc: (99.81%) (42288/42368)\n",
            "Epoch: 155 | Batch_idx: 340 |  Loss: (0.0062) | Acc: (99.81%) (43567/43648)\n",
            "Epoch: 155 | Batch_idx: 350 |  Loss: (0.0062) | Acc: (99.82%) (44845/44928)\n",
            "Epoch: 155 | Batch_idx: 360 |  Loss: (0.0062) | Acc: (99.82%) (46123/46208)\n",
            "Epoch: 155 | Batch_idx: 370 |  Loss: (0.0061) | Acc: (99.81%) (47400/47488)\n",
            "Epoch: 155 | Batch_idx: 380 |  Loss: (0.0061) | Acc: (99.82%) (48678/48768)\n",
            "Epoch: 155 | Batch_idx: 390 |  Loss: (0.0061) | Acc: (99.82%) (49908/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4256) | Acc: (91.89%) (9189/10000)\n",
            "Epoch: 156 | Batch_idx: 0 |  Loss: (0.0008) | Acc: (100.00%) (128/128)\n",
            "Epoch: 156 | Batch_idx: 10 |  Loss: (0.0017) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 156 | Batch_idx: 20 |  Loss: (0.0038) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 156 | Batch_idx: 30 |  Loss: (0.0039) | Acc: (99.80%) (3960/3968)\n",
            "Epoch: 156 | Batch_idx: 40 |  Loss: (0.0050) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 156 | Batch_idx: 50 |  Loss: (0.0050) | Acc: (99.79%) (6514/6528)\n",
            "Epoch: 156 | Batch_idx: 60 |  Loss: (0.0050) | Acc: (99.78%) (7791/7808)\n",
            "Epoch: 156 | Batch_idx: 70 |  Loss: (0.0056) | Acc: (99.78%) (9068/9088)\n",
            "Epoch: 156 | Batch_idx: 80 |  Loss: (0.0055) | Acc: (99.78%) (10345/10368)\n",
            "Epoch: 156 | Batch_idx: 90 |  Loss: (0.0054) | Acc: (99.78%) (11622/11648)\n",
            "Epoch: 156 | Batch_idx: 100 |  Loss: (0.0055) | Acc: (99.78%) (12900/12928)\n",
            "Epoch: 156 | Batch_idx: 110 |  Loss: (0.0053) | Acc: (99.80%) (14179/14208)\n",
            "Epoch: 156 | Batch_idx: 120 |  Loss: (0.0052) | Acc: (99.79%) (15456/15488)\n",
            "Epoch: 156 | Batch_idx: 130 |  Loss: (0.0053) | Acc: (99.79%) (16732/16768)\n",
            "Epoch: 156 | Batch_idx: 140 |  Loss: (0.0053) | Acc: (99.79%) (18011/18048)\n",
            "Epoch: 156 | Batch_idx: 150 |  Loss: (0.0053) | Acc: (99.79%) (19288/19328)\n",
            "Epoch: 156 | Batch_idx: 160 |  Loss: (0.0053) | Acc: (99.79%) (20565/20608)\n",
            "Epoch: 156 | Batch_idx: 170 |  Loss: (0.0053) | Acc: (99.79%) (21842/21888)\n",
            "Epoch: 156 | Batch_idx: 180 |  Loss: (0.0052) | Acc: (99.80%) (23121/23168)\n",
            "Epoch: 156 | Batch_idx: 190 |  Loss: (0.0051) | Acc: (99.80%) (24400/24448)\n",
            "Epoch: 156 | Batch_idx: 200 |  Loss: (0.0050) | Acc: (99.81%) (25679/25728)\n",
            "Epoch: 156 | Batch_idx: 210 |  Loss: (0.0049) | Acc: (99.82%) (26959/27008)\n",
            "Epoch: 156 | Batch_idx: 220 |  Loss: (0.0048) | Acc: (99.82%) (28238/28288)\n",
            "Epoch: 156 | Batch_idx: 230 |  Loss: (0.0049) | Acc: (99.82%) (29514/29568)\n",
            "Epoch: 156 | Batch_idx: 240 |  Loss: (0.0051) | Acc: (99.82%) (30791/30848)\n",
            "Epoch: 156 | Batch_idx: 250 |  Loss: (0.0050) | Acc: (99.82%) (32071/32128)\n",
            "Epoch: 156 | Batch_idx: 260 |  Loss: (0.0049) | Acc: (99.83%) (33350/33408)\n",
            "Epoch: 156 | Batch_idx: 270 |  Loss: (0.0050) | Acc: (99.82%) (34627/34688)\n",
            "Epoch: 156 | Batch_idx: 280 |  Loss: (0.0049) | Acc: (99.83%) (35907/35968)\n",
            "Epoch: 156 | Batch_idx: 290 |  Loss: (0.0048) | Acc: (99.84%) (37187/37248)\n",
            "Epoch: 156 | Batch_idx: 300 |  Loss: (0.0049) | Acc: (99.84%) (38465/38528)\n",
            "Epoch: 156 | Batch_idx: 310 |  Loss: (0.0048) | Acc: (99.84%) (39744/39808)\n",
            "Epoch: 156 | Batch_idx: 320 |  Loss: (0.0047) | Acc: (99.84%) (41024/41088)\n",
            "Epoch: 156 | Batch_idx: 330 |  Loss: (0.0047) | Acc: (99.84%) (42301/42368)\n",
            "Epoch: 156 | Batch_idx: 340 |  Loss: (0.0047) | Acc: (99.84%) (43580/43648)\n",
            "Epoch: 156 | Batch_idx: 350 |  Loss: (0.0047) | Acc: (99.84%) (44857/44928)\n",
            "Epoch: 156 | Batch_idx: 360 |  Loss: (0.0047) | Acc: (99.84%) (46136/46208)\n",
            "Epoch: 156 | Batch_idx: 370 |  Loss: (0.0047) | Acc: (99.84%) (47412/47488)\n",
            "Epoch: 156 | Batch_idx: 380 |  Loss: (0.0048) | Acc: (99.84%) (48690/48768)\n",
            "Epoch: 156 | Batch_idx: 390 |  Loss: (0.0047) | Acc: (99.84%) (49921/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4209) | Acc: (91.84%) (9184/10000)\n",
            "Epoch: 157 | Batch_idx: 0 |  Loss: (0.0037) | Acc: (100.00%) (128/128)\n",
            "Epoch: 157 | Batch_idx: 10 |  Loss: (0.0051) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 157 | Batch_idx: 20 |  Loss: (0.0030) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 157 | Batch_idx: 30 |  Loss: (0.0030) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 157 | Batch_idx: 40 |  Loss: (0.0045) | Acc: (99.83%) (5239/5248)\n",
            "Epoch: 157 | Batch_idx: 50 |  Loss: (0.0050) | Acc: (99.80%) (6515/6528)\n",
            "Epoch: 157 | Batch_idx: 60 |  Loss: (0.0048) | Acc: (99.81%) (7793/7808)\n",
            "Epoch: 157 | Batch_idx: 70 |  Loss: (0.0045) | Acc: (99.81%) (9071/9088)\n",
            "Epoch: 157 | Batch_idx: 80 |  Loss: (0.0045) | Acc: (99.83%) (10350/10368)\n",
            "Epoch: 157 | Batch_idx: 90 |  Loss: (0.0043) | Acc: (99.84%) (11629/11648)\n",
            "Epoch: 157 | Batch_idx: 100 |  Loss: (0.0044) | Acc: (99.84%) (12907/12928)\n",
            "Epoch: 157 | Batch_idx: 110 |  Loss: (0.0048) | Acc: (99.83%) (14184/14208)\n",
            "Epoch: 157 | Batch_idx: 120 |  Loss: (0.0047) | Acc: (99.83%) (15462/15488)\n",
            "Epoch: 157 | Batch_idx: 130 |  Loss: (0.0049) | Acc: (99.82%) (16738/16768)\n",
            "Epoch: 157 | Batch_idx: 140 |  Loss: (0.0047) | Acc: (99.83%) (18018/18048)\n",
            "Epoch: 157 | Batch_idx: 150 |  Loss: (0.0046) | Acc: (99.84%) (19297/19328)\n",
            "Epoch: 157 | Batch_idx: 160 |  Loss: (0.0047) | Acc: (99.84%) (20575/20608)\n",
            "Epoch: 157 | Batch_idx: 170 |  Loss: (0.0045) | Acc: (99.84%) (21854/21888)\n",
            "Epoch: 157 | Batch_idx: 180 |  Loss: (0.0045) | Acc: (99.84%) (23130/23168)\n",
            "Epoch: 157 | Batch_idx: 190 |  Loss: (0.0045) | Acc: (99.84%) (24408/24448)\n",
            "Epoch: 157 | Batch_idx: 200 |  Loss: (0.0045) | Acc: (99.84%) (25686/25728)\n",
            "Epoch: 157 | Batch_idx: 210 |  Loss: (0.0045) | Acc: (99.84%) (26965/27008)\n",
            "Epoch: 157 | Batch_idx: 220 |  Loss: (0.0044) | Acc: (99.85%) (28245/28288)\n",
            "Epoch: 157 | Batch_idx: 230 |  Loss: (0.0044) | Acc: (99.85%) (29523/29568)\n",
            "Epoch: 157 | Batch_idx: 240 |  Loss: (0.0045) | Acc: (99.85%) (30801/30848)\n",
            "Epoch: 157 | Batch_idx: 250 |  Loss: (0.0044) | Acc: (99.85%) (32081/32128)\n",
            "Epoch: 157 | Batch_idx: 260 |  Loss: (0.0045) | Acc: (99.85%) (33358/33408)\n",
            "Epoch: 157 | Batch_idx: 270 |  Loss: (0.0045) | Acc: (99.85%) (34636/34688)\n",
            "Epoch: 157 | Batch_idx: 280 |  Loss: (0.0046) | Acc: (99.85%) (35914/35968)\n",
            "Epoch: 157 | Batch_idx: 290 |  Loss: (0.0046) | Acc: (99.85%) (37192/37248)\n",
            "Epoch: 157 | Batch_idx: 300 |  Loss: (0.0045) | Acc: (99.85%) (38469/38528)\n",
            "Epoch: 157 | Batch_idx: 310 |  Loss: (0.0047) | Acc: (99.84%) (39745/39808)\n",
            "Epoch: 157 | Batch_idx: 320 |  Loss: (0.0048) | Acc: (99.84%) (41022/41088)\n",
            "Epoch: 157 | Batch_idx: 330 |  Loss: (0.0048) | Acc: (99.84%) (42301/42368)\n",
            "Epoch: 157 | Batch_idx: 340 |  Loss: (0.0048) | Acc: (99.84%) (43578/43648)\n",
            "Epoch: 157 | Batch_idx: 350 |  Loss: (0.0049) | Acc: (99.84%) (44855/44928)\n",
            "Epoch: 157 | Batch_idx: 360 |  Loss: (0.0048) | Acc: (99.84%) (46135/46208)\n",
            "Epoch: 157 | Batch_idx: 370 |  Loss: (0.0047) | Acc: (99.85%) (47415/47488)\n",
            "Epoch: 157 | Batch_idx: 380 |  Loss: (0.0047) | Acc: (99.85%) (48693/48768)\n",
            "Epoch: 157 | Batch_idx: 390 |  Loss: (0.0048) | Acc: (99.84%) (49921/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4245) | Acc: (91.92%) (9192/10000)\n",
            "Epoch: 158 | Batch_idx: 0 |  Loss: (0.0011) | Acc: (100.00%) (128/128)\n",
            "Epoch: 158 | Batch_idx: 10 |  Loss: (0.0057) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 158 | Batch_idx: 20 |  Loss: (0.0047) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 158 | Batch_idx: 30 |  Loss: (0.0045) | Acc: (99.90%) (3964/3968)\n",
            "Epoch: 158 | Batch_idx: 40 |  Loss: (0.0048) | Acc: (99.85%) (5240/5248)\n",
            "Epoch: 158 | Batch_idx: 50 |  Loss: (0.0042) | Acc: (99.88%) (6520/6528)\n",
            "Epoch: 158 | Batch_idx: 60 |  Loss: (0.0044) | Acc: (99.88%) (7799/7808)\n",
            "Epoch: 158 | Batch_idx: 70 |  Loss: (0.0043) | Acc: (99.90%) (9079/9088)\n",
            "Epoch: 158 | Batch_idx: 80 |  Loss: (0.0041) | Acc: (99.91%) (10359/10368)\n",
            "Epoch: 158 | Batch_idx: 90 |  Loss: (0.0044) | Acc: (99.91%) (11637/11648)\n",
            "Epoch: 158 | Batch_idx: 100 |  Loss: (0.0044) | Acc: (99.90%) (12915/12928)\n",
            "Epoch: 158 | Batch_idx: 110 |  Loss: (0.0043) | Acc: (99.90%) (14194/14208)\n",
            "Epoch: 158 | Batch_idx: 120 |  Loss: (0.0044) | Acc: (99.90%) (15472/15488)\n",
            "Epoch: 158 | Batch_idx: 130 |  Loss: (0.0042) | Acc: (99.90%) (16751/16768)\n",
            "Epoch: 158 | Batch_idx: 140 |  Loss: (0.0042) | Acc: (99.89%) (18029/18048)\n",
            "Epoch: 158 | Batch_idx: 150 |  Loss: (0.0042) | Acc: (99.90%) (19308/19328)\n",
            "Epoch: 158 | Batch_idx: 160 |  Loss: (0.0041) | Acc: (99.89%) (20586/20608)\n",
            "Epoch: 158 | Batch_idx: 170 |  Loss: (0.0042) | Acc: (99.89%) (21863/21888)\n",
            "Epoch: 158 | Batch_idx: 180 |  Loss: (0.0041) | Acc: (99.89%) (23143/23168)\n",
            "Epoch: 158 | Batch_idx: 190 |  Loss: (0.0044) | Acc: (99.87%) (24417/24448)\n",
            "Epoch: 158 | Batch_idx: 200 |  Loss: (0.0043) | Acc: (99.88%) (25697/25728)\n",
            "Epoch: 158 | Batch_idx: 210 |  Loss: (0.0044) | Acc: (99.87%) (26973/27008)\n",
            "Epoch: 158 | Batch_idx: 220 |  Loss: (0.0043) | Acc: (99.87%) (28252/28288)\n",
            "Epoch: 158 | Batch_idx: 230 |  Loss: (0.0044) | Acc: (99.87%) (29529/29568)\n",
            "Epoch: 158 | Batch_idx: 240 |  Loss: (0.0044) | Acc: (99.86%) (30804/30848)\n",
            "Epoch: 158 | Batch_idx: 250 |  Loss: (0.0045) | Acc: (99.85%) (32081/32128)\n",
            "Epoch: 158 | Batch_idx: 260 |  Loss: (0.0046) | Acc: (99.85%) (33358/33408)\n",
            "Epoch: 158 | Batch_idx: 270 |  Loss: (0.0045) | Acc: (99.86%) (34638/34688)\n",
            "Epoch: 158 | Batch_idx: 280 |  Loss: (0.0046) | Acc: (99.85%) (35915/35968)\n",
            "Epoch: 158 | Batch_idx: 290 |  Loss: (0.0048) | Acc: (99.85%) (37191/37248)\n",
            "Epoch: 158 | Batch_idx: 300 |  Loss: (0.0048) | Acc: (99.85%) (38471/38528)\n",
            "Epoch: 158 | Batch_idx: 310 |  Loss: (0.0047) | Acc: (99.85%) (39750/39808)\n",
            "Epoch: 158 | Batch_idx: 320 |  Loss: (0.0046) | Acc: (99.86%) (41030/41088)\n",
            "Epoch: 158 | Batch_idx: 330 |  Loss: (0.0047) | Acc: (99.86%) (42308/42368)\n",
            "Epoch: 158 | Batch_idx: 340 |  Loss: (0.0048) | Acc: (99.86%) (43586/43648)\n",
            "Epoch: 158 | Batch_idx: 350 |  Loss: (0.0047) | Acc: (99.86%) (44866/44928)\n",
            "Epoch: 158 | Batch_idx: 360 |  Loss: (0.0046) | Acc: (99.86%) (46145/46208)\n",
            "Epoch: 158 | Batch_idx: 370 |  Loss: (0.0046) | Acc: (99.86%) (47423/47488)\n",
            "Epoch: 158 | Batch_idx: 380 |  Loss: (0.0048) | Acc: (99.85%) (48697/48768)\n",
            "Epoch: 158 | Batch_idx: 390 |  Loss: (0.0047) | Acc: (99.86%) (49929/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4257) | Acc: (91.94%) (9194/10000)\n",
            "Epoch: 159 | Batch_idx: 0 |  Loss: (0.0001) | Acc: (100.00%) (128/128)\n",
            "Epoch: 159 | Batch_idx: 10 |  Loss: (0.0020) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 159 | Batch_idx: 20 |  Loss: (0.0032) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 159 | Batch_idx: 30 |  Loss: (0.0030) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 159 | Batch_idx: 40 |  Loss: (0.0036) | Acc: (99.89%) (5242/5248)\n",
            "Epoch: 159 | Batch_idx: 50 |  Loss: (0.0033) | Acc: (99.91%) (6522/6528)\n",
            "Epoch: 159 | Batch_idx: 60 |  Loss: (0.0036) | Acc: (99.91%) (7801/7808)\n",
            "Epoch: 159 | Batch_idx: 70 |  Loss: (0.0034) | Acc: (99.91%) (9080/9088)\n",
            "Epoch: 159 | Batch_idx: 80 |  Loss: (0.0046) | Acc: (99.88%) (10356/10368)\n",
            "Epoch: 159 | Batch_idx: 90 |  Loss: (0.0044) | Acc: (99.88%) (11634/11648)\n",
            "Epoch: 159 | Batch_idx: 100 |  Loss: (0.0045) | Acc: (99.88%) (12912/12928)\n",
            "Epoch: 159 | Batch_idx: 110 |  Loss: (0.0047) | Acc: (99.87%) (14189/14208)\n",
            "Epoch: 159 | Batch_idx: 120 |  Loss: (0.0049) | Acc: (99.86%) (15467/15488)\n",
            "Epoch: 159 | Batch_idx: 130 |  Loss: (0.0048) | Acc: (99.86%) (16745/16768)\n",
            "Epoch: 159 | Batch_idx: 140 |  Loss: (0.0046) | Acc: (99.87%) (18024/18048)\n",
            "Epoch: 159 | Batch_idx: 150 |  Loss: (0.0047) | Acc: (99.86%) (19301/19328)\n",
            "Epoch: 159 | Batch_idx: 160 |  Loss: (0.0050) | Acc: (99.86%) (20579/20608)\n",
            "Epoch: 159 | Batch_idx: 170 |  Loss: (0.0054) | Acc: (99.85%) (21856/21888)\n",
            "Epoch: 159 | Batch_idx: 180 |  Loss: (0.0053) | Acc: (99.85%) (23134/23168)\n",
            "Epoch: 159 | Batch_idx: 190 |  Loss: (0.0054) | Acc: (99.85%) (24412/24448)\n",
            "Epoch: 159 | Batch_idx: 200 |  Loss: (0.0055) | Acc: (99.85%) (25689/25728)\n",
            "Epoch: 159 | Batch_idx: 210 |  Loss: (0.0054) | Acc: (99.85%) (26967/27008)\n",
            "Epoch: 159 | Batch_idx: 220 |  Loss: (0.0060) | Acc: (99.83%) (28239/28288)\n",
            "Epoch: 159 | Batch_idx: 230 |  Loss: (0.0060) | Acc: (99.83%) (29517/29568)\n",
            "Epoch: 159 | Batch_idx: 240 |  Loss: (0.0060) | Acc: (99.82%) (30794/30848)\n",
            "Epoch: 159 | Batch_idx: 250 |  Loss: (0.0061) | Acc: (99.82%) (32070/32128)\n",
            "Epoch: 159 | Batch_idx: 260 |  Loss: (0.0063) | Acc: (99.82%) (33347/33408)\n",
            "Epoch: 159 | Batch_idx: 270 |  Loss: (0.0061) | Acc: (99.82%) (34627/34688)\n",
            "Epoch: 159 | Batch_idx: 280 |  Loss: (0.0062) | Acc: (99.82%) (35904/35968)\n",
            "Epoch: 159 | Batch_idx: 290 |  Loss: (0.0063) | Acc: (99.82%) (37181/37248)\n",
            "Epoch: 159 | Batch_idx: 300 |  Loss: (0.0062) | Acc: (99.82%) (38460/38528)\n",
            "Epoch: 159 | Batch_idx: 310 |  Loss: (0.0061) | Acc: (99.83%) (39740/39808)\n",
            "Epoch: 159 | Batch_idx: 320 |  Loss: (0.0061) | Acc: (99.83%) (41018/41088)\n",
            "Epoch: 159 | Batch_idx: 330 |  Loss: (0.0061) | Acc: (99.83%) (42297/42368)\n",
            "Epoch: 159 | Batch_idx: 340 |  Loss: (0.0061) | Acc: (99.83%) (43574/43648)\n",
            "Epoch: 159 | Batch_idx: 350 |  Loss: (0.0060) | Acc: (99.83%) (44853/44928)\n",
            "Epoch: 159 | Batch_idx: 360 |  Loss: (0.0060) | Acc: (99.84%) (46132/46208)\n",
            "Epoch: 159 | Batch_idx: 370 |  Loss: (0.0059) | Acc: (99.84%) (47411/47488)\n",
            "Epoch: 159 | Batch_idx: 380 |  Loss: (0.0059) | Acc: (99.84%) (48689/48768)\n",
            "Epoch: 159 | Batch_idx: 390 |  Loss: (0.0058) | Acc: (99.84%) (49920/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4243) | Acc: (91.83%) (9183/10000)\n",
            "Epoch: 160 | Batch_idx: 0 |  Loss: (0.0144) | Acc: (99.22%) (127/128)\n",
            "Epoch: 160 | Batch_idx: 10 |  Loss: (0.0084) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 160 | Batch_idx: 20 |  Loss: (0.0056) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 160 | Batch_idx: 30 |  Loss: (0.0069) | Acc: (99.72%) (3957/3968)\n",
            "Epoch: 160 | Batch_idx: 40 |  Loss: (0.0059) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 160 | Batch_idx: 50 |  Loss: (0.0056) | Acc: (99.80%) (6515/6528)\n",
            "Epoch: 160 | Batch_idx: 60 |  Loss: (0.0065) | Acc: (99.78%) (7791/7808)\n",
            "Epoch: 160 | Batch_idx: 70 |  Loss: (0.0060) | Acc: (99.80%) (9070/9088)\n",
            "Epoch: 160 | Batch_idx: 80 |  Loss: (0.0057) | Acc: (99.82%) (10349/10368)\n",
            "Epoch: 160 | Batch_idx: 90 |  Loss: (0.0054) | Acc: (99.82%) (11627/11648)\n",
            "Epoch: 160 | Batch_idx: 100 |  Loss: (0.0051) | Acc: (99.84%) (12907/12928)\n",
            "Epoch: 160 | Batch_idx: 110 |  Loss: (0.0052) | Acc: (99.84%) (14185/14208)\n",
            "Epoch: 160 | Batch_idx: 120 |  Loss: (0.0049) | Acc: (99.85%) (15465/15488)\n",
            "Epoch: 160 | Batch_idx: 130 |  Loss: (0.0049) | Acc: (99.84%) (16742/16768)\n",
            "Epoch: 160 | Batch_idx: 140 |  Loss: (0.0049) | Acc: (99.84%) (18019/18048)\n",
            "Epoch: 160 | Batch_idx: 150 |  Loss: (0.0048) | Acc: (99.84%) (19297/19328)\n",
            "Epoch: 160 | Batch_idx: 160 |  Loss: (0.0050) | Acc: (99.84%) (20575/20608)\n",
            "Epoch: 160 | Batch_idx: 170 |  Loss: (0.0049) | Acc: (99.84%) (21852/21888)\n",
            "Epoch: 160 | Batch_idx: 180 |  Loss: (0.0051) | Acc: (99.83%) (23128/23168)\n",
            "Epoch: 160 | Batch_idx: 190 |  Loss: (0.0058) | Acc: (99.80%) (24400/24448)\n",
            "Epoch: 160 | Batch_idx: 200 |  Loss: (0.0059) | Acc: (99.80%) (25677/25728)\n",
            "Epoch: 160 | Batch_idx: 210 |  Loss: (0.0058) | Acc: (99.81%) (26956/27008)\n",
            "Epoch: 160 | Batch_idx: 220 |  Loss: (0.0057) | Acc: (99.81%) (28235/28288)\n",
            "Epoch: 160 | Batch_idx: 230 |  Loss: (0.0056) | Acc: (99.82%) (29514/29568)\n",
            "Epoch: 160 | Batch_idx: 240 |  Loss: (0.0055) | Acc: (99.82%) (30793/30848)\n",
            "Epoch: 160 | Batch_idx: 250 |  Loss: (0.0056) | Acc: (99.82%) (32071/32128)\n",
            "Epoch: 160 | Batch_idx: 260 |  Loss: (0.0054) | Acc: (99.82%) (33349/33408)\n",
            "Epoch: 160 | Batch_idx: 270 |  Loss: (0.0053) | Acc: (99.83%) (34629/34688)\n",
            "Epoch: 160 | Batch_idx: 280 |  Loss: (0.0054) | Acc: (99.82%) (35905/35968)\n",
            "Epoch: 160 | Batch_idx: 290 |  Loss: (0.0054) | Acc: (99.83%) (37183/37248)\n",
            "Epoch: 160 | Batch_idx: 300 |  Loss: (0.0052) | Acc: (99.83%) (38462/38528)\n",
            "Epoch: 160 | Batch_idx: 310 |  Loss: (0.0052) | Acc: (99.83%) (39739/39808)\n",
            "Epoch: 160 | Batch_idx: 320 |  Loss: (0.0052) | Acc: (99.83%) (41018/41088)\n",
            "Epoch: 160 | Batch_idx: 330 |  Loss: (0.0051) | Acc: (99.83%) (42296/42368)\n",
            "Epoch: 160 | Batch_idx: 340 |  Loss: (0.0051) | Acc: (99.83%) (43573/43648)\n",
            "Epoch: 160 | Batch_idx: 350 |  Loss: (0.0051) | Acc: (99.83%) (44851/44928)\n",
            "Epoch: 160 | Batch_idx: 360 |  Loss: (0.0051) | Acc: (99.83%) (46130/46208)\n",
            "Epoch: 160 | Batch_idx: 370 |  Loss: (0.0052) | Acc: (99.83%) (47406/47488)\n",
            "Epoch: 160 | Batch_idx: 380 |  Loss: (0.0055) | Acc: (99.82%) (48680/48768)\n",
            "Epoch: 160 | Batch_idx: 390 |  Loss: (0.0055) | Acc: (99.82%) (49910/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4305) | Acc: (91.82%) (9182/10000)\n",
            "Epoch: 161 | Batch_idx: 0 |  Loss: (0.0210) | Acc: (99.22%) (127/128)\n",
            "Epoch: 161 | Batch_idx: 10 |  Loss: (0.0035) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 161 | Batch_idx: 20 |  Loss: (0.0029) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 161 | Batch_idx: 30 |  Loss: (0.0030) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 161 | Batch_idx: 40 |  Loss: (0.0041) | Acc: (99.87%) (5241/5248)\n",
            "Epoch: 161 | Batch_idx: 50 |  Loss: (0.0047) | Acc: (99.86%) (6519/6528)\n",
            "Epoch: 161 | Batch_idx: 60 |  Loss: (0.0047) | Acc: (99.86%) (7797/7808)\n",
            "Epoch: 161 | Batch_idx: 70 |  Loss: (0.0048) | Acc: (99.85%) (9074/9088)\n",
            "Epoch: 161 | Batch_idx: 80 |  Loss: (0.0050) | Acc: (99.85%) (10352/10368)\n",
            "Epoch: 161 | Batch_idx: 90 |  Loss: (0.0048) | Acc: (99.85%) (11631/11648)\n",
            "Epoch: 161 | Batch_idx: 100 |  Loss: (0.0050) | Acc: (99.84%) (12907/12928)\n",
            "Epoch: 161 | Batch_idx: 110 |  Loss: (0.0050) | Acc: (99.83%) (14184/14208)\n",
            "Epoch: 161 | Batch_idx: 120 |  Loss: (0.0048) | Acc: (99.84%) (15463/15488)\n",
            "Epoch: 161 | Batch_idx: 130 |  Loss: (0.0051) | Acc: (99.83%) (16739/16768)\n",
            "Epoch: 161 | Batch_idx: 140 |  Loss: (0.0051) | Acc: (99.82%) (18016/18048)\n",
            "Epoch: 161 | Batch_idx: 150 |  Loss: (0.0051) | Acc: (99.82%) (19294/19328)\n",
            "Epoch: 161 | Batch_idx: 160 |  Loss: (0.0051) | Acc: (99.82%) (20571/20608)\n",
            "Epoch: 161 | Batch_idx: 170 |  Loss: (0.0050) | Acc: (99.82%) (21849/21888)\n",
            "Epoch: 161 | Batch_idx: 180 |  Loss: (0.0049) | Acc: (99.83%) (23128/23168)\n",
            "Epoch: 161 | Batch_idx: 190 |  Loss: (0.0048) | Acc: (99.83%) (24407/24448)\n",
            "Epoch: 161 | Batch_idx: 200 |  Loss: (0.0049) | Acc: (99.84%) (25686/25728)\n",
            "Epoch: 161 | Batch_idx: 210 |  Loss: (0.0048) | Acc: (99.84%) (26965/27008)\n",
            "Epoch: 161 | Batch_idx: 220 |  Loss: (0.0050) | Acc: (99.83%) (28241/28288)\n",
            "Epoch: 161 | Batch_idx: 230 |  Loss: (0.0050) | Acc: (99.83%) (29519/29568)\n",
            "Epoch: 161 | Batch_idx: 240 |  Loss: (0.0050) | Acc: (99.83%) (30797/30848)\n",
            "Epoch: 161 | Batch_idx: 250 |  Loss: (0.0048) | Acc: (99.84%) (32077/32128)\n",
            "Epoch: 161 | Batch_idx: 260 |  Loss: (0.0048) | Acc: (99.84%) (33356/33408)\n",
            "Epoch: 161 | Batch_idx: 270 |  Loss: (0.0052) | Acc: (99.84%) (34631/34688)\n",
            "Epoch: 161 | Batch_idx: 280 |  Loss: (0.0052) | Acc: (99.84%) (35909/35968)\n",
            "Epoch: 161 | Batch_idx: 290 |  Loss: (0.0052) | Acc: (99.83%) (37186/37248)\n",
            "Epoch: 161 | Batch_idx: 300 |  Loss: (0.0051) | Acc: (99.84%) (38465/38528)\n",
            "Epoch: 161 | Batch_idx: 310 |  Loss: (0.0050) | Acc: (99.84%) (39744/39808)\n",
            "Epoch: 161 | Batch_idx: 320 |  Loss: (0.0051) | Acc: (99.83%) (41020/41088)\n",
            "Epoch: 161 | Batch_idx: 330 |  Loss: (0.0051) | Acc: (99.83%) (42298/42368)\n",
            "Epoch: 161 | Batch_idx: 340 |  Loss: (0.0053) | Acc: (99.83%) (43574/43648)\n",
            "Epoch: 161 | Batch_idx: 350 |  Loss: (0.0053) | Acc: (99.83%) (44851/44928)\n",
            "Epoch: 161 | Batch_idx: 360 |  Loss: (0.0054) | Acc: (99.82%) (46127/46208)\n",
            "Epoch: 161 | Batch_idx: 370 |  Loss: (0.0054) | Acc: (99.82%) (47403/47488)\n",
            "Epoch: 161 | Batch_idx: 380 |  Loss: (0.0053) | Acc: (99.82%) (48682/48768)\n",
            "Epoch: 161 | Batch_idx: 390 |  Loss: (0.0054) | Acc: (99.82%) (49910/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4321) | Acc: (91.84%) (9184/10000)\n",
            "Epoch: 162 | Batch_idx: 0 |  Loss: (0.0033) | Acc: (100.00%) (128/128)\n",
            "Epoch: 162 | Batch_idx: 10 |  Loss: (0.0033) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 162 | Batch_idx: 20 |  Loss: (0.0072) | Acc: (99.81%) (2683/2688)\n",
            "Epoch: 162 | Batch_idx: 30 |  Loss: (0.0057) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 162 | Batch_idx: 40 |  Loss: (0.0048) | Acc: (99.89%) (5242/5248)\n",
            "Epoch: 162 | Batch_idx: 50 |  Loss: (0.0045) | Acc: (99.88%) (6520/6528)\n",
            "Epoch: 162 | Batch_idx: 60 |  Loss: (0.0042) | Acc: (99.88%) (7799/7808)\n",
            "Epoch: 162 | Batch_idx: 70 |  Loss: (0.0039) | Acc: (99.90%) (9079/9088)\n",
            "Epoch: 162 | Batch_idx: 80 |  Loss: (0.0040) | Acc: (99.87%) (10355/10368)\n",
            "Epoch: 162 | Batch_idx: 90 |  Loss: (0.0041) | Acc: (99.86%) (11632/11648)\n",
            "Epoch: 162 | Batch_idx: 100 |  Loss: (0.0044) | Acc: (99.85%) (12909/12928)\n",
            "Epoch: 162 | Batch_idx: 110 |  Loss: (0.0042) | Acc: (99.86%) (14188/14208)\n",
            "Epoch: 162 | Batch_idx: 120 |  Loss: (0.0040) | Acc: (99.87%) (15468/15488)\n",
            "Epoch: 162 | Batch_idx: 130 |  Loss: (0.0038) | Acc: (99.88%) (16748/16768)\n",
            "Epoch: 162 | Batch_idx: 140 |  Loss: (0.0038) | Acc: (99.88%) (18026/18048)\n",
            "Epoch: 162 | Batch_idx: 150 |  Loss: (0.0039) | Acc: (99.88%) (19304/19328)\n",
            "Epoch: 162 | Batch_idx: 160 |  Loss: (0.0038) | Acc: (99.88%) (20583/20608)\n",
            "Epoch: 162 | Batch_idx: 170 |  Loss: (0.0037) | Acc: (99.89%) (21863/21888)\n",
            "Epoch: 162 | Batch_idx: 180 |  Loss: (0.0037) | Acc: (99.88%) (23141/23168)\n",
            "Epoch: 162 | Batch_idx: 190 |  Loss: (0.0038) | Acc: (99.88%) (24418/24448)\n",
            "Epoch: 162 | Batch_idx: 200 |  Loss: (0.0037) | Acc: (99.88%) (25696/25728)\n",
            "Epoch: 162 | Batch_idx: 210 |  Loss: (0.0037) | Acc: (99.88%) (26975/27008)\n",
            "Epoch: 162 | Batch_idx: 220 |  Loss: (0.0037) | Acc: (99.88%) (28254/28288)\n",
            "Epoch: 162 | Batch_idx: 230 |  Loss: (0.0037) | Acc: (99.87%) (29531/29568)\n",
            "Epoch: 162 | Batch_idx: 240 |  Loss: (0.0040) | Acc: (99.86%) (30806/30848)\n",
            "Epoch: 162 | Batch_idx: 250 |  Loss: (0.0040) | Acc: (99.86%) (32084/32128)\n",
            "Epoch: 162 | Batch_idx: 260 |  Loss: (0.0040) | Acc: (99.87%) (33363/33408)\n",
            "Epoch: 162 | Batch_idx: 270 |  Loss: (0.0040) | Acc: (99.87%) (34642/34688)\n",
            "Epoch: 162 | Batch_idx: 280 |  Loss: (0.0039) | Acc: (99.87%) (35922/35968)\n",
            "Epoch: 162 | Batch_idx: 290 |  Loss: (0.0040) | Acc: (99.87%) (37198/37248)\n",
            "Epoch: 162 | Batch_idx: 300 |  Loss: (0.0040) | Acc: (99.87%) (38476/38528)\n",
            "Epoch: 162 | Batch_idx: 310 |  Loss: (0.0041) | Acc: (99.86%) (39754/39808)\n",
            "Epoch: 162 | Batch_idx: 320 |  Loss: (0.0041) | Acc: (99.87%) (41033/41088)\n",
            "Epoch: 162 | Batch_idx: 330 |  Loss: (0.0041) | Acc: (99.87%) (42311/42368)\n",
            "Epoch: 162 | Batch_idx: 340 |  Loss: (0.0042) | Acc: (99.86%) (43589/43648)\n",
            "Epoch: 162 | Batch_idx: 350 |  Loss: (0.0041) | Acc: (99.87%) (44868/44928)\n",
            "Epoch: 162 | Batch_idx: 360 |  Loss: (0.0042) | Acc: (99.87%) (46147/46208)\n",
            "Epoch: 162 | Batch_idx: 370 |  Loss: (0.0043) | Acc: (99.87%) (47424/47488)\n",
            "Epoch: 162 | Batch_idx: 380 |  Loss: (0.0043) | Acc: (99.86%) (48701/48768)\n",
            "Epoch: 162 | Batch_idx: 390 |  Loss: (0.0042) | Acc: (99.87%) (49933/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4272) | Acc: (91.88%) (9188/10000)\n",
            "Epoch: 163 | Batch_idx: 0 |  Loss: (0.0065) | Acc: (100.00%) (128/128)\n",
            "Epoch: 163 | Batch_idx: 10 |  Loss: (0.0056) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 163 | Batch_idx: 20 |  Loss: (0.0062) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 163 | Batch_idx: 30 |  Loss: (0.0064) | Acc: (99.75%) (3958/3968)\n",
            "Epoch: 163 | Batch_idx: 40 |  Loss: (0.0057) | Acc: (99.75%) (5235/5248)\n",
            "Epoch: 163 | Batch_idx: 50 |  Loss: (0.0062) | Acc: (99.75%) (6512/6528)\n",
            "Epoch: 163 | Batch_idx: 60 |  Loss: (0.0060) | Acc: (99.78%) (7791/7808)\n",
            "Epoch: 163 | Batch_idx: 70 |  Loss: (0.0054) | Acc: (99.81%) (9071/9088)\n",
            "Epoch: 163 | Batch_idx: 80 |  Loss: (0.0051) | Acc: (99.83%) (10350/10368)\n",
            "Epoch: 163 | Batch_idx: 90 |  Loss: (0.0050) | Acc: (99.83%) (11628/11648)\n",
            "Epoch: 163 | Batch_idx: 100 |  Loss: (0.0049) | Acc: (99.82%) (12905/12928)\n",
            "Epoch: 163 | Batch_idx: 110 |  Loss: (0.0048) | Acc: (99.82%) (14183/14208)\n",
            "Epoch: 163 | Batch_idx: 120 |  Loss: (0.0048) | Acc: (99.83%) (15461/15488)\n",
            "Epoch: 163 | Batch_idx: 130 |  Loss: (0.0049) | Acc: (99.83%) (16740/16768)\n",
            "Epoch: 163 | Batch_idx: 140 |  Loss: (0.0046) | Acc: (99.84%) (18020/18048)\n",
            "Epoch: 163 | Batch_idx: 150 |  Loss: (0.0046) | Acc: (99.84%) (19298/19328)\n",
            "Epoch: 163 | Batch_idx: 160 |  Loss: (0.0050) | Acc: (99.83%) (20573/20608)\n",
            "Epoch: 163 | Batch_idx: 170 |  Loss: (0.0050) | Acc: (99.83%) (21850/21888)\n",
            "Epoch: 163 | Batch_idx: 180 |  Loss: (0.0052) | Acc: (99.83%) (23128/23168)\n",
            "Epoch: 163 | Batch_idx: 190 |  Loss: (0.0054) | Acc: (99.82%) (24404/24448)\n",
            "Epoch: 163 | Batch_idx: 200 |  Loss: (0.0055) | Acc: (99.82%) (25681/25728)\n",
            "Epoch: 163 | Batch_idx: 210 |  Loss: (0.0055) | Acc: (99.81%) (26958/27008)\n",
            "Epoch: 163 | Batch_idx: 220 |  Loss: (0.0056) | Acc: (99.81%) (28235/28288)\n",
            "Epoch: 163 | Batch_idx: 230 |  Loss: (0.0057) | Acc: (99.81%) (29511/29568)\n",
            "Epoch: 163 | Batch_idx: 240 |  Loss: (0.0058) | Acc: (99.80%) (30787/30848)\n",
            "Epoch: 163 | Batch_idx: 250 |  Loss: (0.0058) | Acc: (99.80%) (32064/32128)\n",
            "Epoch: 163 | Batch_idx: 260 |  Loss: (0.0057) | Acc: (99.80%) (33342/33408)\n",
            "Epoch: 163 | Batch_idx: 270 |  Loss: (0.0057) | Acc: (99.80%) (34620/34688)\n",
            "Epoch: 163 | Batch_idx: 280 |  Loss: (0.0058) | Acc: (99.80%) (35896/35968)\n",
            "Epoch: 163 | Batch_idx: 290 |  Loss: (0.0056) | Acc: (99.81%) (37176/37248)\n",
            "Epoch: 163 | Batch_idx: 300 |  Loss: (0.0055) | Acc: (99.81%) (38455/38528)\n",
            "Epoch: 163 | Batch_idx: 310 |  Loss: (0.0055) | Acc: (99.81%) (39732/39808)\n",
            "Epoch: 163 | Batch_idx: 320 |  Loss: (0.0056) | Acc: (99.81%) (41010/41088)\n",
            "Epoch: 163 | Batch_idx: 330 |  Loss: (0.0055) | Acc: (99.81%) (42289/42368)\n",
            "Epoch: 163 | Batch_idx: 340 |  Loss: (0.0055) | Acc: (99.82%) (43569/43648)\n",
            "Epoch: 163 | Batch_idx: 350 |  Loss: (0.0054) | Acc: (99.82%) (44846/44928)\n",
            "Epoch: 163 | Batch_idx: 360 |  Loss: (0.0054) | Acc: (99.82%) (46124/46208)\n",
            "Epoch: 163 | Batch_idx: 370 |  Loss: (0.0054) | Acc: (99.82%) (47403/47488)\n",
            "Epoch: 163 | Batch_idx: 380 |  Loss: (0.0054) | Acc: (99.82%) (48679/48768)\n",
            "Epoch: 163 | Batch_idx: 390 |  Loss: (0.0055) | Acc: (99.81%) (49907/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4259) | Acc: (91.83%) (9183/10000)\n",
            "Epoch: 164 | Batch_idx: 0 |  Loss: (0.0110) | Acc: (99.22%) (127/128)\n",
            "Epoch: 164 | Batch_idx: 10 |  Loss: (0.0067) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 164 | Batch_idx: 20 |  Loss: (0.0063) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 164 | Batch_idx: 30 |  Loss: (0.0071) | Acc: (99.65%) (3954/3968)\n",
            "Epoch: 164 | Batch_idx: 40 |  Loss: (0.0065) | Acc: (99.68%) (5231/5248)\n",
            "Epoch: 164 | Batch_idx: 50 |  Loss: (0.0059) | Acc: (99.72%) (6510/6528)\n",
            "Epoch: 164 | Batch_idx: 60 |  Loss: (0.0069) | Acc: (99.72%) (7786/7808)\n",
            "Epoch: 164 | Batch_idx: 70 |  Loss: (0.0066) | Acc: (99.75%) (9065/9088)\n",
            "Epoch: 164 | Batch_idx: 80 |  Loss: (0.0061) | Acc: (99.78%) (10345/10368)\n",
            "Epoch: 164 | Batch_idx: 90 |  Loss: (0.0061) | Acc: (99.79%) (11623/11648)\n",
            "Epoch: 164 | Batch_idx: 100 |  Loss: (0.0060) | Acc: (99.78%) (12900/12928)\n",
            "Epoch: 164 | Batch_idx: 110 |  Loss: (0.0061) | Acc: (99.78%) (14177/14208)\n",
            "Epoch: 164 | Batch_idx: 120 |  Loss: (0.0058) | Acc: (99.80%) (15457/15488)\n",
            "Epoch: 164 | Batch_idx: 130 |  Loss: (0.0055) | Acc: (99.82%) (16737/16768)\n",
            "Epoch: 164 | Batch_idx: 140 |  Loss: (0.0055) | Acc: (99.81%) (18014/18048)\n",
            "Epoch: 164 | Batch_idx: 150 |  Loss: (0.0057) | Acc: (99.80%) (19290/19328)\n",
            "Epoch: 164 | Batch_idx: 160 |  Loss: (0.0054) | Acc: (99.82%) (20570/20608)\n",
            "Epoch: 164 | Batch_idx: 170 |  Loss: (0.0054) | Acc: (99.81%) (21847/21888)\n",
            "Epoch: 164 | Batch_idx: 180 |  Loss: (0.0055) | Acc: (99.81%) (23123/23168)\n",
            "Epoch: 164 | Batch_idx: 190 |  Loss: (0.0054) | Acc: (99.81%) (24402/24448)\n",
            "Epoch: 164 | Batch_idx: 200 |  Loss: (0.0053) | Acc: (99.82%) (25681/25728)\n",
            "Epoch: 164 | Batch_idx: 210 |  Loss: (0.0052) | Acc: (99.82%) (26960/27008)\n",
            "Epoch: 164 | Batch_idx: 220 |  Loss: (0.0051) | Acc: (99.83%) (28239/28288)\n",
            "Epoch: 164 | Batch_idx: 230 |  Loss: (0.0050) | Acc: (99.83%) (29519/29568)\n",
            "Epoch: 164 | Batch_idx: 240 |  Loss: (0.0049) | Acc: (99.84%) (30798/30848)\n",
            "Epoch: 164 | Batch_idx: 250 |  Loss: (0.0049) | Acc: (99.84%) (32075/32128)\n",
            "Epoch: 164 | Batch_idx: 260 |  Loss: (0.0048) | Acc: (99.84%) (33354/33408)\n",
            "Epoch: 164 | Batch_idx: 270 |  Loss: (0.0047) | Acc: (99.84%) (34633/34688)\n",
            "Epoch: 164 | Batch_idx: 280 |  Loss: (0.0046) | Acc: (99.84%) (35912/35968)\n",
            "Epoch: 164 | Batch_idx: 290 |  Loss: (0.0048) | Acc: (99.84%) (37188/37248)\n",
            "Epoch: 164 | Batch_idx: 300 |  Loss: (0.0048) | Acc: (99.84%) (38465/38528)\n",
            "Epoch: 164 | Batch_idx: 310 |  Loss: (0.0047) | Acc: (99.84%) (39745/39808)\n",
            "Epoch: 164 | Batch_idx: 320 |  Loss: (0.0047) | Acc: (99.84%) (41023/41088)\n",
            "Epoch: 164 | Batch_idx: 330 |  Loss: (0.0049) | Acc: (99.84%) (42299/42368)\n",
            "Epoch: 164 | Batch_idx: 340 |  Loss: (0.0049) | Acc: (99.83%) (43575/43648)\n",
            "Epoch: 164 | Batch_idx: 350 |  Loss: (0.0048) | Acc: (99.83%) (44853/44928)\n",
            "Epoch: 164 | Batch_idx: 360 |  Loss: (0.0049) | Acc: (99.83%) (46129/46208)\n",
            "Epoch: 164 | Batch_idx: 370 |  Loss: (0.0050) | Acc: (99.82%) (47404/47488)\n",
            "Epoch: 164 | Batch_idx: 380 |  Loss: (0.0050) | Acc: (99.83%) (48683/48768)\n",
            "Epoch: 164 | Batch_idx: 390 |  Loss: (0.0050) | Acc: (99.82%) (49911/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4254) | Acc: (91.81%) (9181/10000)\n",
            "0 hours 54 mins 37 secs for training\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import os\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'                # GPU Number \n",
        "start_time = time.time()\n",
        "batch_size = 128\n",
        "learning_rate = 0.1 # Changed the initial Learning rate\n",
        "root_dir = 'drive/app/cifar10/'\n",
        "default_directory = 'drive/app/torch/save_models'\n",
        "\n",
        "# Data Augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),               # Random Position Crop\n",
        "    transforms.RandomHorizontalFlip(),                  # right and left flip\n",
        "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
        "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
        "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
        "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
        "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
        "])\n",
        "\n",
        "# automatically download\n",
        "train_dataset = datasets.CIFAR10(root=root_dir,\n",
        "                                 train=True,\n",
        "                                 transform=transform_train,\n",
        "                                 download=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root=root_dir,\n",
        "                                train=False,\n",
        "                                transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,            # at Training Procedure, Data Shuffle = True\n",
        "                                           num_workers=4)           # CPU loader number\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,            # at Test Procedure, Data Shuffle = False\n",
        "                                          num_workers=4)            # CPU loader number\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.1),                                       ################### Added\n",
        "\t    \n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.1),                                       ################### Added\n",
        "\t    \n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.1), #################### Dropout value set to 0.1\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.1), #################### Dropout value set to 0.1\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "model = VGG()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), learning_rate,\n",
        "                                momentum=0.9,\n",
        "                                weight_decay=1e-4,\n",
        "                                nesterov=True)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "if torch.cuda.device_count() > 0:\n",
        "    print(\"USE\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model).cuda()\n",
        "    cudnn.benchmark = True\n",
        "else:\n",
        "    print(\"USE ONLY CPU!\")\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0 \n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
        "        else:\n",
        "            data, target = Variable(data), Variable(target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.data).cpu().sum()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Epoch: {} | Batch_idx: {} |  Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
        "                  .format(epoch, batch_idx, train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
        "        else:\n",
        "            data, target = Variable(data), Variable(target)\n",
        "\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, target)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.data).cpu().sum()\n",
        "    print('# TEST : Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
        "          .format(test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "\n",
        "\n",
        "def save_checkpoint(directory, state, filename='latest.tar.gz'):\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    model_filename = os.path.join(directory, filename)\n",
        "    torch.save(state, model_filename)\n",
        "    print(\"=> saving checkpoint\")\n",
        "\n",
        "def load_checkpoint(directory, filename='latest.tar.gz'):\n",
        "\n",
        "    model_filename = os.path.join(directory, filename)\n",
        "    if os.path.exists(model_filename):\n",
        "        print(\"=> loading checkpoint\")\n",
        "        state = torch.load(model_filename)\n",
        "        return state\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "start_epoch = 0\n",
        "\n",
        "for epoch in range(start_epoch, 165):#################### Changing epoch\n",
        "\n",
        "    if epoch < 80:\n",
        "        lr = learning_rate\n",
        "    elif epoch < 120:\n",
        "        lr = learning_rate * 0.1\n",
        "    else:\n",
        "        lr = learning_rate * 0.01\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    train(epoch)\n",
        "    save_checkpoint(default_directory, {\n",
        "        'epoch': epoch,\n",
        "        'model': model,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "    })\n",
        "    test()  \n",
        "\n",
        "now = time.gmtime(time.time() - start_time)\n",
        "print('{} hours {} mins {} secs for training'.format(now.tm_hour, now.tm_min, now.tm_sec))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "z3679FisFAmj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}