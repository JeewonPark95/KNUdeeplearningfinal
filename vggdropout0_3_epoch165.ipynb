{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vggdropout0.3_epoch165.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNx4CBmf+67g0Navp8o21KA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "67447911655d492e96201fed4763dab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4f51e50b78d412db401794eb9856e40",
              "IPY_MODEL_a60dfdf7944e452b98a8a8bcdad6e811",
              "IPY_MODEL_07273ff055e84e2086d250b92ea2f5d8"
            ],
            "layout": "IPY_MODEL_91b72d29b4e247c795a8da2fa47ad0bd"
          }
        },
        "c4f51e50b78d412db401794eb9856e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb578752939c461fa4b5b7079e2b3eee",
            "placeholder": "​",
            "style": "IPY_MODEL_28e31df15cb74263a00c90acd097aa8a",
            "value": ""
          }
        },
        "a60dfdf7944e452b98a8a8bcdad6e811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15e41e58bbeb4caa90d8c96cb1892b0d",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_582aac93cc854882986ad8c1f5f72e84",
            "value": 170498071
          }
        },
        "07273ff055e84e2086d250b92ea2f5d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_602ad54dda014c9cbaf72efe9669542c",
            "placeholder": "​",
            "style": "IPY_MODEL_93fcf5b0422b408d87c240f0effc0e2a",
            "value": " 170499072/? [00:05&lt;00:00, 52601130.31it/s]"
          }
        },
        "91b72d29b4e247c795a8da2fa47ad0bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb578752939c461fa4b5b7079e2b3eee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28e31df15cb74263a00c90acd097aa8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15e41e58bbeb4caa90d8c96cb1892b0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "582aac93cc854882986ad8c1f5f72e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "602ad54dda014c9cbaf72efe9669542c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93fcf5b0422b408d87c240f0effc0e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeewonPark95/KNUdeeplearningfinal/blob/main/vggdropout0_3_epoch165.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "67447911655d492e96201fed4763dab6",
            "c4f51e50b78d412db401794eb9856e40",
            "a60dfdf7944e452b98a8a8bcdad6e811",
            "07273ff055e84e2086d250b92ea2f5d8",
            "91b72d29b4e247c795a8da2fa47ad0bd",
            "eb578752939c461fa4b5b7079e2b3eee",
            "28e31df15cb74263a00c90acd097aa8a",
            "15e41e58bbeb4caa90d8c96cb1892b0d",
            "582aac93cc854882986ad8c1f5f72e84",
            "602ad54dda014c9cbaf72efe9669542c",
            "93fcf5b0422b408d87c240f0effc0e2a"
          ]
        },
        "id": "yLAxLnRsEvAb",
        "outputId": "c1d5e570-09f5-4f42-8ea6-8aaf97103d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to drive/app/cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67447911655d492e96201fed4763dab6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting drive/app/cifar10/cifar-10-python.tar.gz to drive/app/cifar10/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "# TEST : Loss: (0.4375) | Acc: (86.51%) (8651/10000)\n",
            "Epoch: 46 | Batch_idx: 0 |  Loss: (0.3112) | Acc: (91.41%) (117/128)\n",
            "Epoch: 46 | Batch_idx: 10 |  Loss: (0.2846) | Acc: (90.55%) (1275/1408)\n",
            "Epoch: 46 | Batch_idx: 20 |  Loss: (0.2807) | Acc: (90.96%) (2445/2688)\n",
            "Epoch: 46 | Batch_idx: 30 |  Loss: (0.2922) | Acc: (90.37%) (3586/3968)\n",
            "Epoch: 46 | Batch_idx: 40 |  Loss: (0.2859) | Acc: (90.38%) (4743/5248)\n",
            "Epoch: 46 | Batch_idx: 50 |  Loss: (0.2820) | Acc: (90.55%) (5911/6528)\n",
            "Epoch: 46 | Batch_idx: 60 |  Loss: (0.2779) | Acc: (90.80%) (7090/7808)\n",
            "Epoch: 46 | Batch_idx: 70 |  Loss: (0.2762) | Acc: (90.74%) (8246/9088)\n",
            "Epoch: 46 | Batch_idx: 80 |  Loss: (0.2762) | Acc: (90.75%) (9409/10368)\n",
            "Epoch: 46 | Batch_idx: 90 |  Loss: (0.2780) | Acc: (90.79%) (10575/11648)\n",
            "Epoch: 46 | Batch_idx: 100 |  Loss: (0.2811) | Acc: (90.64%) (11718/12928)\n",
            "Epoch: 46 | Batch_idx: 110 |  Loss: (0.2801) | Acc: (90.67%) (12883/14208)\n",
            "Epoch: 46 | Batch_idx: 120 |  Loss: (0.2822) | Acc: (90.62%) (14035/15488)\n",
            "Epoch: 46 | Batch_idx: 130 |  Loss: (0.2860) | Acc: (90.57%) (15187/16768)\n",
            "Epoch: 46 | Batch_idx: 140 |  Loss: (0.2845) | Acc: (90.62%) (16356/18048)\n",
            "Epoch: 46 | Batch_idx: 150 |  Loss: (0.2836) | Acc: (90.63%) (17517/19328)\n",
            "Epoch: 46 | Batch_idx: 160 |  Loss: (0.2836) | Acc: (90.68%) (18687/20608)\n",
            "Epoch: 46 | Batch_idx: 170 |  Loss: (0.2852) | Acc: (90.55%) (19819/21888)\n",
            "Epoch: 46 | Batch_idx: 180 |  Loss: (0.2882) | Acc: (90.41%) (20947/23168)\n",
            "Epoch: 46 | Batch_idx: 190 |  Loss: (0.2871) | Acc: (90.43%) (22109/24448)\n",
            "Epoch: 46 | Batch_idx: 200 |  Loss: (0.2881) | Acc: (90.42%) (23263/25728)\n",
            "Epoch: 46 | Batch_idx: 210 |  Loss: (0.2893) | Acc: (90.38%) (24409/27008)\n",
            "Epoch: 46 | Batch_idx: 220 |  Loss: (0.2868) | Acc: (90.46%) (25589/28288)\n",
            "Epoch: 46 | Batch_idx: 230 |  Loss: (0.2853) | Acc: (90.47%) (26749/29568)\n",
            "Epoch: 46 | Batch_idx: 240 |  Loss: (0.2865) | Acc: (90.41%) (27890/30848)\n",
            "Epoch: 46 | Batch_idx: 250 |  Loss: (0.2866) | Acc: (90.41%) (29048/32128)\n",
            "Epoch: 46 | Batch_idx: 260 |  Loss: (0.2872) | Acc: (90.42%) (30208/33408)\n",
            "Epoch: 46 | Batch_idx: 270 |  Loss: (0.2868) | Acc: (90.45%) (31376/34688)\n",
            "Epoch: 46 | Batch_idx: 280 |  Loss: (0.2892) | Acc: (90.38%) (32507/35968)\n",
            "Epoch: 46 | Batch_idx: 290 |  Loss: (0.2899) | Acc: (90.35%) (33653/37248)\n",
            "Epoch: 46 | Batch_idx: 300 |  Loss: (0.2894) | Acc: (90.36%) (34814/38528)\n",
            "Epoch: 46 | Batch_idx: 310 |  Loss: (0.2893) | Acc: (90.36%) (35971/39808)\n",
            "Epoch: 46 | Batch_idx: 320 |  Loss: (0.2886) | Acc: (90.39%) (37139/41088)\n",
            "Epoch: 46 | Batch_idx: 330 |  Loss: (0.2880) | Acc: (90.40%) (38301/42368)\n",
            "Epoch: 46 | Batch_idx: 340 |  Loss: (0.2879) | Acc: (90.38%) (39451/43648)\n",
            "Epoch: 46 | Batch_idx: 350 |  Loss: (0.2882) | Acc: (90.40%) (40615/44928)\n",
            "Epoch: 46 | Batch_idx: 360 |  Loss: (0.2884) | Acc: (90.39%) (41767/46208)\n",
            "Epoch: 46 | Batch_idx: 370 |  Loss: (0.2892) | Acc: (90.38%) (42918/47488)\n",
            "Epoch: 46 | Batch_idx: 380 |  Loss: (0.2890) | Acc: (90.38%) (44076/48768)\n",
            "Epoch: 46 | Batch_idx: 390 |  Loss: (0.2898) | Acc: (90.36%) (45180/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3897) | Acc: (87.41%) (8741/10000)\n",
            "Epoch: 47 | Batch_idx: 0 |  Loss: (0.3141) | Acc: (89.84%) (115/128)\n",
            "Epoch: 47 | Batch_idx: 10 |  Loss: (0.2701) | Acc: (90.84%) (1279/1408)\n",
            "Epoch: 47 | Batch_idx: 20 |  Loss: (0.2732) | Acc: (90.89%) (2443/2688)\n",
            "Epoch: 47 | Batch_idx: 30 |  Loss: (0.2816) | Acc: (90.88%) (3606/3968)\n",
            "Epoch: 47 | Batch_idx: 40 |  Loss: (0.2841) | Acc: (90.82%) (4766/5248)\n",
            "Epoch: 47 | Batch_idx: 50 |  Loss: (0.2866) | Acc: (90.75%) (5924/6528)\n",
            "Epoch: 47 | Batch_idx: 60 |  Loss: (0.2863) | Acc: (90.75%) (7086/7808)\n",
            "Epoch: 47 | Batch_idx: 70 |  Loss: (0.2850) | Acc: (90.78%) (8250/9088)\n",
            "Epoch: 47 | Batch_idx: 80 |  Loss: (0.2822) | Acc: (90.86%) (9420/10368)\n",
            "Epoch: 47 | Batch_idx: 90 |  Loss: (0.2815) | Acc: (90.76%) (10572/11648)\n",
            "Epoch: 47 | Batch_idx: 100 |  Loss: (0.2806) | Acc: (90.71%) (11727/12928)\n",
            "Epoch: 47 | Batch_idx: 110 |  Loss: (0.2807) | Acc: (90.72%) (12890/14208)\n",
            "Epoch: 47 | Batch_idx: 120 |  Loss: (0.2809) | Acc: (90.68%) (14045/15488)\n",
            "Epoch: 47 | Batch_idx: 130 |  Loss: (0.2833) | Acc: (90.63%) (15197/16768)\n",
            "Epoch: 47 | Batch_idx: 140 |  Loss: (0.2836) | Acc: (90.58%) (16347/18048)\n",
            "Epoch: 47 | Batch_idx: 150 |  Loss: (0.2887) | Acc: (90.45%) (17482/19328)\n",
            "Epoch: 47 | Batch_idx: 160 |  Loss: (0.2885) | Acc: (90.43%) (18635/20608)\n",
            "Epoch: 47 | Batch_idx: 170 |  Loss: (0.2875) | Acc: (90.47%) (19801/21888)\n",
            "Epoch: 47 | Batch_idx: 180 |  Loss: (0.2886) | Acc: (90.40%) (20944/23168)\n",
            "Epoch: 47 | Batch_idx: 190 |  Loss: (0.2917) | Acc: (90.29%) (22074/24448)\n",
            "Epoch: 47 | Batch_idx: 200 |  Loss: (0.2896) | Acc: (90.38%) (23253/25728)\n",
            "Epoch: 47 | Batch_idx: 210 |  Loss: (0.2872) | Acc: (90.44%) (24426/27008)\n",
            "Epoch: 47 | Batch_idx: 220 |  Loss: (0.2881) | Acc: (90.41%) (25576/28288)\n",
            "Epoch: 47 | Batch_idx: 230 |  Loss: (0.2877) | Acc: (90.43%) (26739/29568)\n",
            "Epoch: 47 | Batch_idx: 240 |  Loss: (0.2886) | Acc: (90.44%) (27899/30848)\n",
            "Epoch: 47 | Batch_idx: 250 |  Loss: (0.2884) | Acc: (90.45%) (29061/32128)\n",
            "Epoch: 47 | Batch_idx: 260 |  Loss: (0.2891) | Acc: (90.43%) (30210/33408)\n",
            "Epoch: 47 | Batch_idx: 270 |  Loss: (0.2889) | Acc: (90.39%) (31355/34688)\n",
            "Epoch: 47 | Batch_idx: 280 |  Loss: (0.2884) | Acc: (90.42%) (32521/35968)\n",
            "Epoch: 47 | Batch_idx: 290 |  Loss: (0.2894) | Acc: (90.40%) (33674/37248)\n",
            "Epoch: 47 | Batch_idx: 300 |  Loss: (0.2894) | Acc: (90.43%) (34841/38528)\n",
            "Epoch: 47 | Batch_idx: 310 |  Loss: (0.2895) | Acc: (90.43%) (35999/39808)\n",
            "Epoch: 47 | Batch_idx: 320 |  Loss: (0.2887) | Acc: (90.46%) (37170/41088)\n",
            "Epoch: 47 | Batch_idx: 330 |  Loss: (0.2882) | Acc: (90.47%) (38331/42368)\n",
            "Epoch: 47 | Batch_idx: 340 |  Loss: (0.2882) | Acc: (90.47%) (39488/43648)\n",
            "Epoch: 47 | Batch_idx: 350 |  Loss: (0.2890) | Acc: (90.44%) (40633/44928)\n",
            "Epoch: 47 | Batch_idx: 360 |  Loss: (0.2900) | Acc: (90.40%) (41770/46208)\n",
            "Epoch: 47 | Batch_idx: 370 |  Loss: (0.2900) | Acc: (90.40%) (42927/47488)\n",
            "Epoch: 47 | Batch_idx: 380 |  Loss: (0.2899) | Acc: (90.41%) (44089/48768)\n",
            "Epoch: 47 | Batch_idx: 390 |  Loss: (0.2901) | Acc: (90.39%) (45194/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4013) | Acc: (87.34%) (8734/10000)\n",
            "Epoch: 48 | Batch_idx: 0 |  Loss: (0.2855) | Acc: (85.16%) (109/128)\n",
            "Epoch: 48 | Batch_idx: 10 |  Loss: (0.2566) | Acc: (91.19%) (1284/1408)\n",
            "Epoch: 48 | Batch_idx: 20 |  Loss: (0.2521) | Acc: (91.37%) (2456/2688)\n",
            "Epoch: 48 | Batch_idx: 30 |  Loss: (0.2630) | Acc: (90.88%) (3606/3968)\n",
            "Epoch: 48 | Batch_idx: 40 |  Loss: (0.2818) | Acc: (90.30%) (4739/5248)\n",
            "Epoch: 48 | Batch_idx: 50 |  Loss: (0.2802) | Acc: (90.47%) (5906/6528)\n",
            "Epoch: 48 | Batch_idx: 60 |  Loss: (0.2758) | Acc: (90.61%) (7075/7808)\n",
            "Epoch: 48 | Batch_idx: 70 |  Loss: (0.2779) | Acc: (90.60%) (8234/9088)\n",
            "Epoch: 48 | Batch_idx: 80 |  Loss: (0.2748) | Acc: (90.70%) (9404/10368)\n",
            "Epoch: 48 | Batch_idx: 90 |  Loss: (0.2739) | Acc: (90.75%) (10571/11648)\n",
            "Epoch: 48 | Batch_idx: 100 |  Loss: (0.2730) | Acc: (90.78%) (11736/12928)\n",
            "Epoch: 48 | Batch_idx: 110 |  Loss: (0.2711) | Acc: (90.82%) (12903/14208)\n",
            "Epoch: 48 | Batch_idx: 120 |  Loss: (0.2728) | Acc: (90.73%) (14053/15488)\n",
            "Epoch: 48 | Batch_idx: 130 |  Loss: (0.2748) | Acc: (90.72%) (15212/16768)\n",
            "Epoch: 48 | Batch_idx: 140 |  Loss: (0.2742) | Acc: (90.71%) (16372/18048)\n",
            "Epoch: 48 | Batch_idx: 150 |  Loss: (0.2743) | Acc: (90.72%) (17535/19328)\n",
            "Epoch: 48 | Batch_idx: 160 |  Loss: (0.2769) | Acc: (90.64%) (18679/20608)\n",
            "Epoch: 48 | Batch_idx: 170 |  Loss: (0.2777) | Acc: (90.66%) (19843/21888)\n",
            "Epoch: 48 | Batch_idx: 180 |  Loss: (0.2773) | Acc: (90.67%) (21006/23168)\n",
            "Epoch: 48 | Batch_idx: 190 |  Loss: (0.2783) | Acc: (90.65%) (22161/24448)\n",
            "Epoch: 48 | Batch_idx: 200 |  Loss: (0.2781) | Acc: (90.64%) (23321/25728)\n",
            "Epoch: 48 | Batch_idx: 210 |  Loss: (0.2777) | Acc: (90.65%) (24483/27008)\n",
            "Epoch: 48 | Batch_idx: 220 |  Loss: (0.2786) | Acc: (90.62%) (25634/28288)\n",
            "Epoch: 48 | Batch_idx: 230 |  Loss: (0.2770) | Acc: (90.65%) (26804/29568)\n",
            "Epoch: 48 | Batch_idx: 240 |  Loss: (0.2780) | Acc: (90.65%) (27963/30848)\n",
            "Epoch: 48 | Batch_idx: 250 |  Loss: (0.2783) | Acc: (90.64%) (29121/32128)\n",
            "Epoch: 48 | Batch_idx: 260 |  Loss: (0.2797) | Acc: (90.59%) (30263/33408)\n",
            "Epoch: 48 | Batch_idx: 270 |  Loss: (0.2795) | Acc: (90.58%) (31422/34688)\n",
            "Epoch: 48 | Batch_idx: 280 |  Loss: (0.2795) | Acc: (90.59%) (32585/35968)\n",
            "Epoch: 48 | Batch_idx: 290 |  Loss: (0.2807) | Acc: (90.56%) (33731/37248)\n",
            "Epoch: 48 | Batch_idx: 300 |  Loss: (0.2809) | Acc: (90.54%) (34885/38528)\n",
            "Epoch: 48 | Batch_idx: 310 |  Loss: (0.2810) | Acc: (90.54%) (36043/39808)\n",
            "Epoch: 48 | Batch_idx: 320 |  Loss: (0.2810) | Acc: (90.55%) (37205/41088)\n",
            "Epoch: 48 | Batch_idx: 330 |  Loss: (0.2815) | Acc: (90.52%) (38350/42368)\n",
            "Epoch: 48 | Batch_idx: 340 |  Loss: (0.2829) | Acc: (90.47%) (39488/43648)\n",
            "Epoch: 48 | Batch_idx: 350 |  Loss: (0.2845) | Acc: (90.43%) (40629/44928)\n",
            "Epoch: 48 | Batch_idx: 360 |  Loss: (0.2855) | Acc: (90.39%) (41769/46208)\n",
            "Epoch: 48 | Batch_idx: 370 |  Loss: (0.2854) | Acc: (90.43%) (42942/47488)\n",
            "Epoch: 48 | Batch_idx: 380 |  Loss: (0.2845) | Acc: (90.45%) (44111/48768)\n",
            "Epoch: 48 | Batch_idx: 390 |  Loss: (0.2854) | Acc: (90.43%) (45216/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4107) | Acc: (86.93%) (8693/10000)\n",
            "Epoch: 49 | Batch_idx: 0 |  Loss: (0.1704) | Acc: (95.31%) (122/128)\n",
            "Epoch: 49 | Batch_idx: 10 |  Loss: (0.2477) | Acc: (91.19%) (1284/1408)\n",
            "Epoch: 49 | Batch_idx: 20 |  Loss: (0.2717) | Acc: (91.00%) (2446/2688)\n",
            "Epoch: 49 | Batch_idx: 30 |  Loss: (0.2747) | Acc: (91.03%) (3612/3968)\n",
            "Epoch: 49 | Batch_idx: 40 |  Loss: (0.2704) | Acc: (91.35%) (4794/5248)\n",
            "Epoch: 49 | Batch_idx: 50 |  Loss: (0.2620) | Acc: (91.59%) (5979/6528)\n",
            "Epoch: 49 | Batch_idx: 60 |  Loss: (0.2636) | Acc: (91.39%) (7136/7808)\n",
            "Epoch: 49 | Batch_idx: 70 |  Loss: (0.2619) | Acc: (91.48%) (8314/9088)\n",
            "Epoch: 49 | Batch_idx: 80 |  Loss: (0.2700) | Acc: (91.25%) (9461/10368)\n",
            "Epoch: 49 | Batch_idx: 90 |  Loss: (0.2714) | Acc: (91.29%) (10633/11648)\n",
            "Epoch: 49 | Batch_idx: 100 |  Loss: (0.2703) | Acc: (91.24%) (11795/12928)\n",
            "Epoch: 49 | Batch_idx: 110 |  Loss: (0.2695) | Acc: (91.24%) (12963/14208)\n",
            "Epoch: 49 | Batch_idx: 120 |  Loss: (0.2705) | Acc: (91.15%) (14118/15488)\n",
            "Epoch: 49 | Batch_idx: 130 |  Loss: (0.2730) | Acc: (91.04%) (15266/16768)\n",
            "Epoch: 49 | Batch_idx: 140 |  Loss: (0.2745) | Acc: (91.04%) (16430/18048)\n",
            "Epoch: 49 | Batch_idx: 150 |  Loss: (0.2737) | Acc: (91.02%) (17593/19328)\n",
            "Epoch: 49 | Batch_idx: 160 |  Loss: (0.2738) | Acc: (91.06%) (18766/20608)\n",
            "Epoch: 49 | Batch_idx: 170 |  Loss: (0.2724) | Acc: (91.09%) (19937/21888)\n",
            "Epoch: 49 | Batch_idx: 180 |  Loss: (0.2738) | Acc: (90.98%) (21078/23168)\n",
            "Epoch: 49 | Batch_idx: 190 |  Loss: (0.2721) | Acc: (91.03%) (22254/24448)\n",
            "Epoch: 49 | Batch_idx: 200 |  Loss: (0.2722) | Acc: (90.99%) (23411/25728)\n",
            "Epoch: 49 | Batch_idx: 210 |  Loss: (0.2745) | Acc: (90.90%) (24549/27008)\n",
            "Epoch: 49 | Batch_idx: 220 |  Loss: (0.2744) | Acc: (90.89%) (25712/28288)\n",
            "Epoch: 49 | Batch_idx: 230 |  Loss: (0.2754) | Acc: (90.84%) (26860/29568)\n",
            "Epoch: 49 | Batch_idx: 240 |  Loss: (0.2772) | Acc: (90.77%) (28000/30848)\n",
            "Epoch: 49 | Batch_idx: 250 |  Loss: (0.2765) | Acc: (90.81%) (29177/32128)\n",
            "Epoch: 49 | Batch_idx: 260 |  Loss: (0.2769) | Acc: (90.80%) (30334/33408)\n",
            "Epoch: 49 | Batch_idx: 270 |  Loss: (0.2772) | Acc: (90.80%) (31495/34688)\n",
            "Epoch: 49 | Batch_idx: 280 |  Loss: (0.2773) | Acc: (90.80%) (32658/35968)\n",
            "Epoch: 49 | Batch_idx: 290 |  Loss: (0.2778) | Acc: (90.77%) (33811/37248)\n",
            "Epoch: 49 | Batch_idx: 300 |  Loss: (0.2783) | Acc: (90.75%) (34963/38528)\n",
            "Epoch: 49 | Batch_idx: 310 |  Loss: (0.2775) | Acc: (90.78%) (36138/39808)\n",
            "Epoch: 49 | Batch_idx: 320 |  Loss: (0.2782) | Acc: (90.78%) (37298/41088)\n",
            "Epoch: 49 | Batch_idx: 330 |  Loss: (0.2781) | Acc: (90.78%) (38462/42368)\n",
            "Epoch: 49 | Batch_idx: 340 |  Loss: (0.2790) | Acc: (90.77%) (39618/43648)\n",
            "Epoch: 49 | Batch_idx: 350 |  Loss: (0.2791) | Acc: (90.77%) (40781/44928)\n",
            "Epoch: 49 | Batch_idx: 360 |  Loss: (0.2793) | Acc: (90.77%) (41941/46208)\n",
            "Epoch: 49 | Batch_idx: 370 |  Loss: (0.2804) | Acc: (90.72%) (43083/47488)\n",
            "Epoch: 49 | Batch_idx: 380 |  Loss: (0.2801) | Acc: (90.72%) (44241/48768)\n",
            "Epoch: 49 | Batch_idx: 390 |  Loss: (0.2799) | Acc: (90.70%) (45348/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3974) | Acc: (88.15%) (8815/10000)\n",
            "Epoch: 50 | Batch_idx: 0 |  Loss: (0.2526) | Acc: (93.75%) (120/128)\n",
            "Epoch: 50 | Batch_idx: 10 |  Loss: (0.2512) | Acc: (92.33%) (1300/1408)\n",
            "Epoch: 50 | Batch_idx: 20 |  Loss: (0.2684) | Acc: (91.52%) (2460/2688)\n",
            "Epoch: 50 | Batch_idx: 30 |  Loss: (0.2725) | Acc: (91.13%) (3616/3968)\n",
            "Epoch: 50 | Batch_idx: 40 |  Loss: (0.2731) | Acc: (90.78%) (4764/5248)\n",
            "Epoch: 50 | Batch_idx: 50 |  Loss: (0.2790) | Acc: (90.53%) (5910/6528)\n",
            "Epoch: 50 | Batch_idx: 60 |  Loss: (0.2748) | Acc: (90.74%) (7085/7808)\n",
            "Epoch: 50 | Batch_idx: 70 |  Loss: (0.2734) | Acc: (90.83%) (8255/9088)\n",
            "Epoch: 50 | Batch_idx: 80 |  Loss: (0.2775) | Acc: (90.66%) (9400/10368)\n",
            "Epoch: 50 | Batch_idx: 90 |  Loss: (0.2786) | Acc: (90.55%) (10547/11648)\n",
            "Epoch: 50 | Batch_idx: 100 |  Loss: (0.2777) | Acc: (90.62%) (11715/12928)\n",
            "Epoch: 50 | Batch_idx: 110 |  Loss: (0.2773) | Acc: (90.62%) (12875/14208)\n",
            "Epoch: 50 | Batch_idx: 120 |  Loss: (0.2760) | Acc: (90.68%) (14044/15488)\n",
            "Epoch: 50 | Batch_idx: 130 |  Loss: (0.2745) | Acc: (90.78%) (15222/16768)\n",
            "Epoch: 50 | Batch_idx: 140 |  Loss: (0.2738) | Acc: (90.83%) (16393/18048)\n",
            "Epoch: 50 | Batch_idx: 150 |  Loss: (0.2745) | Acc: (90.84%) (17557/19328)\n",
            "Epoch: 50 | Batch_idx: 160 |  Loss: (0.2762) | Acc: (90.85%) (18723/20608)\n",
            "Epoch: 50 | Batch_idx: 170 |  Loss: (0.2788) | Acc: (90.80%) (19874/21888)\n",
            "Epoch: 50 | Batch_idx: 180 |  Loss: (0.2784) | Acc: (90.79%) (21035/23168)\n",
            "Epoch: 50 | Batch_idx: 190 |  Loss: (0.2796) | Acc: (90.76%) (22189/24448)\n",
            "Epoch: 50 | Batch_idx: 200 |  Loss: (0.2809) | Acc: (90.76%) (23352/25728)\n",
            "Epoch: 50 | Batch_idx: 210 |  Loss: (0.2788) | Acc: (90.84%) (24533/27008)\n",
            "Epoch: 50 | Batch_idx: 220 |  Loss: (0.2787) | Acc: (90.88%) (25709/28288)\n",
            "Epoch: 50 | Batch_idx: 230 |  Loss: (0.2781) | Acc: (90.88%) (26871/29568)\n",
            "Epoch: 50 | Batch_idx: 240 |  Loss: (0.2782) | Acc: (90.84%) (28022/30848)\n",
            "Epoch: 50 | Batch_idx: 250 |  Loss: (0.2800) | Acc: (90.79%) (29170/32128)\n",
            "Epoch: 50 | Batch_idx: 260 |  Loss: (0.2792) | Acc: (90.83%) (30343/33408)\n",
            "Epoch: 50 | Batch_idx: 270 |  Loss: (0.2791) | Acc: (90.82%) (31503/34688)\n",
            "Epoch: 50 | Batch_idx: 280 |  Loss: (0.2808) | Acc: (90.78%) (32652/35968)\n",
            "Epoch: 50 | Batch_idx: 290 |  Loss: (0.2823) | Acc: (90.73%) (33794/37248)\n",
            "Epoch: 50 | Batch_idx: 300 |  Loss: (0.2832) | Acc: (90.69%) (34942/38528)\n",
            "Epoch: 50 | Batch_idx: 310 |  Loss: (0.2828) | Acc: (90.69%) (36103/39808)\n",
            "Epoch: 50 | Batch_idx: 320 |  Loss: (0.2844) | Acc: (90.64%) (37242/41088)\n",
            "Epoch: 50 | Batch_idx: 330 |  Loss: (0.2851) | Acc: (90.60%) (38387/42368)\n",
            "Epoch: 50 | Batch_idx: 340 |  Loss: (0.2849) | Acc: (90.62%) (39552/43648)\n",
            "Epoch: 50 | Batch_idx: 350 |  Loss: (0.2855) | Acc: (90.59%) (40699/44928)\n",
            "Epoch: 50 | Batch_idx: 360 |  Loss: (0.2856) | Acc: (90.58%) (41856/46208)\n",
            "Epoch: 50 | Batch_idx: 370 |  Loss: (0.2851) | Acc: (90.62%) (43032/47488)\n",
            "Epoch: 50 | Batch_idx: 380 |  Loss: (0.2851) | Acc: (90.61%) (44188/48768)\n",
            "Epoch: 50 | Batch_idx: 390 |  Loss: (0.2848) | Acc: (90.64%) (45318/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4025) | Acc: (87.58%) (8758/10000)\n",
            "Epoch: 51 | Batch_idx: 0 |  Loss: (0.1588) | Acc: (94.53%) (121/128)\n",
            "Epoch: 51 | Batch_idx: 10 |  Loss: (0.2259) | Acc: (92.33%) (1300/1408)\n",
            "Epoch: 51 | Batch_idx: 20 |  Loss: (0.2365) | Acc: (92.04%) (2474/2688)\n",
            "Epoch: 51 | Batch_idx: 30 |  Loss: (0.2322) | Acc: (92.04%) (3652/3968)\n",
            "Epoch: 51 | Batch_idx: 40 |  Loss: (0.2394) | Acc: (91.67%) (4811/5248)\n",
            "Epoch: 51 | Batch_idx: 50 |  Loss: (0.2406) | Acc: (91.65%) (5983/6528)\n",
            "Epoch: 51 | Batch_idx: 60 |  Loss: (0.2507) | Acc: (91.39%) (7136/7808)\n",
            "Epoch: 51 | Batch_idx: 70 |  Loss: (0.2587) | Acc: (91.19%) (8287/9088)\n",
            "Epoch: 51 | Batch_idx: 80 |  Loss: (0.2580) | Acc: (91.19%) (9455/10368)\n",
            "Epoch: 51 | Batch_idx: 90 |  Loss: (0.2613) | Acc: (91.09%) (10610/11648)\n",
            "Epoch: 51 | Batch_idx: 100 |  Loss: (0.2624) | Acc: (91.05%) (11771/12928)\n",
            "Epoch: 51 | Batch_idx: 110 |  Loss: (0.2660) | Acc: (91.02%) (12932/14208)\n",
            "Epoch: 51 | Batch_idx: 120 |  Loss: (0.2656) | Acc: (91.02%) (14097/15488)\n",
            "Epoch: 51 | Batch_idx: 130 |  Loss: (0.2666) | Acc: (90.95%) (15251/16768)\n",
            "Epoch: 51 | Batch_idx: 140 |  Loss: (0.2683) | Acc: (90.90%) (16405/18048)\n",
            "Epoch: 51 | Batch_idx: 150 |  Loss: (0.2726) | Acc: (90.77%) (17544/19328)\n",
            "Epoch: 51 | Batch_idx: 160 |  Loss: (0.2733) | Acc: (90.69%) (18690/20608)\n",
            "Epoch: 51 | Batch_idx: 170 |  Loss: (0.2715) | Acc: (90.74%) (19862/21888)\n",
            "Epoch: 51 | Batch_idx: 180 |  Loss: (0.2723) | Acc: (90.74%) (21023/23168)\n",
            "Epoch: 51 | Batch_idx: 190 |  Loss: (0.2718) | Acc: (90.75%) (22186/24448)\n",
            "Epoch: 51 | Batch_idx: 200 |  Loss: (0.2718) | Acc: (90.79%) (23359/25728)\n",
            "Epoch: 51 | Batch_idx: 210 |  Loss: (0.2736) | Acc: (90.74%) (24506/27008)\n",
            "Epoch: 51 | Batch_idx: 220 |  Loss: (0.2748) | Acc: (90.72%) (25663/28288)\n",
            "Epoch: 51 | Batch_idx: 230 |  Loss: (0.2752) | Acc: (90.69%) (26816/29568)\n",
            "Epoch: 51 | Batch_idx: 240 |  Loss: (0.2762) | Acc: (90.68%) (27972/30848)\n",
            "Epoch: 51 | Batch_idx: 250 |  Loss: (0.2779) | Acc: (90.60%) (29109/32128)\n",
            "Epoch: 51 | Batch_idx: 260 |  Loss: (0.2790) | Acc: (90.58%) (30260/33408)\n",
            "Epoch: 51 | Batch_idx: 270 |  Loss: (0.2787) | Acc: (90.58%) (31420/34688)\n",
            "Epoch: 51 | Batch_idx: 280 |  Loss: (0.2778) | Acc: (90.61%) (32592/35968)\n",
            "Epoch: 51 | Batch_idx: 290 |  Loss: (0.2773) | Acc: (90.62%) (33756/37248)\n",
            "Epoch: 51 | Batch_idx: 300 |  Loss: (0.2778) | Acc: (90.60%) (34905/38528)\n",
            "Epoch: 51 | Batch_idx: 310 |  Loss: (0.2770) | Acc: (90.60%) (36067/39808)\n",
            "Epoch: 51 | Batch_idx: 320 |  Loss: (0.2780) | Acc: (90.58%) (37217/41088)\n",
            "Epoch: 51 | Batch_idx: 330 |  Loss: (0.2780) | Acc: (90.59%) (38383/42368)\n",
            "Epoch: 51 | Batch_idx: 340 |  Loss: (0.2777) | Acc: (90.59%) (39539/43648)\n",
            "Epoch: 51 | Batch_idx: 350 |  Loss: (0.2783) | Acc: (90.56%) (40688/44928)\n",
            "Epoch: 51 | Batch_idx: 360 |  Loss: (0.2787) | Acc: (90.55%) (41841/46208)\n",
            "Epoch: 51 | Batch_idx: 370 |  Loss: (0.2779) | Acc: (90.61%) (43028/47488)\n",
            "Epoch: 51 | Batch_idx: 380 |  Loss: (0.2783) | Acc: (90.59%) (44180/48768)\n",
            "Epoch: 51 | Batch_idx: 390 |  Loss: (0.2795) | Acc: (90.56%) (45282/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4061) | Acc: (86.97%) (8697/10000)\n",
            "Epoch: 52 | Batch_idx: 0 |  Loss: (0.2950) | Acc: (87.50%) (112/128)\n",
            "Epoch: 52 | Batch_idx: 10 |  Loss: (0.2481) | Acc: (91.55%) (1289/1408)\n",
            "Epoch: 52 | Batch_idx: 20 |  Loss: (0.2654) | Acc: (91.18%) (2451/2688)\n",
            "Epoch: 52 | Batch_idx: 30 |  Loss: (0.2686) | Acc: (90.83%) (3604/3968)\n",
            "Epoch: 52 | Batch_idx: 40 |  Loss: (0.2744) | Acc: (90.45%) (4747/5248)\n",
            "Epoch: 52 | Batch_idx: 50 |  Loss: (0.2674) | Acc: (90.61%) (5915/6528)\n",
            "Epoch: 52 | Batch_idx: 60 |  Loss: (0.2647) | Acc: (90.79%) (7089/7808)\n",
            "Epoch: 52 | Batch_idx: 70 |  Loss: (0.2673) | Acc: (90.81%) (8253/9088)\n",
            "Epoch: 52 | Batch_idx: 80 |  Loss: (0.2640) | Acc: (90.96%) (9431/10368)\n",
            "Epoch: 52 | Batch_idx: 90 |  Loss: (0.2631) | Acc: (90.98%) (10597/11648)\n",
            "Epoch: 52 | Batch_idx: 100 |  Loss: (0.2682) | Acc: (90.79%) (11737/12928)\n",
            "Epoch: 52 | Batch_idx: 110 |  Loss: (0.2708) | Acc: (90.72%) (12889/14208)\n",
            "Epoch: 52 | Batch_idx: 120 |  Loss: (0.2682) | Acc: (90.84%) (14070/15488)\n",
            "Epoch: 52 | Batch_idx: 130 |  Loss: (0.2691) | Acc: (90.79%) (15224/16768)\n",
            "Epoch: 52 | Batch_idx: 140 |  Loss: (0.2684) | Acc: (90.84%) (16394/18048)\n",
            "Epoch: 52 | Batch_idx: 150 |  Loss: (0.2666) | Acc: (90.94%) (17577/19328)\n",
            "Epoch: 52 | Batch_idx: 160 |  Loss: (0.2659) | Acc: (90.96%) (18746/20608)\n",
            "Epoch: 52 | Batch_idx: 170 |  Loss: (0.2694) | Acc: (90.94%) (19904/21888)\n",
            "Epoch: 52 | Batch_idx: 180 |  Loss: (0.2715) | Acc: (90.88%) (21054/23168)\n",
            "Epoch: 52 | Batch_idx: 190 |  Loss: (0.2715) | Acc: (90.83%) (22205/24448)\n",
            "Epoch: 52 | Batch_idx: 200 |  Loss: (0.2723) | Acc: (90.83%) (23368/25728)\n",
            "Epoch: 52 | Batch_idx: 210 |  Loss: (0.2728) | Acc: (90.82%) (24528/27008)\n",
            "Epoch: 52 | Batch_idx: 220 |  Loss: (0.2734) | Acc: (90.82%) (25691/28288)\n",
            "Epoch: 52 | Batch_idx: 230 |  Loss: (0.2753) | Acc: (90.77%) (26840/29568)\n",
            "Epoch: 52 | Batch_idx: 240 |  Loss: (0.2750) | Acc: (90.81%) (28013/30848)\n",
            "Epoch: 52 | Batch_idx: 250 |  Loss: (0.2744) | Acc: (90.84%) (29184/32128)\n",
            "Epoch: 52 | Batch_idx: 260 |  Loss: (0.2756) | Acc: (90.78%) (30329/33408)\n",
            "Epoch: 52 | Batch_idx: 270 |  Loss: (0.2764) | Acc: (90.75%) (31481/34688)\n",
            "Epoch: 52 | Batch_idx: 280 |  Loss: (0.2754) | Acc: (90.82%) (32667/35968)\n",
            "Epoch: 52 | Batch_idx: 290 |  Loss: (0.2758) | Acc: (90.82%) (33828/37248)\n",
            "Epoch: 52 | Batch_idx: 300 |  Loss: (0.2765) | Acc: (90.79%) (34980/38528)\n",
            "Epoch: 52 | Batch_idx: 310 |  Loss: (0.2771) | Acc: (90.78%) (36138/39808)\n",
            "Epoch: 52 | Batch_idx: 320 |  Loss: (0.2764) | Acc: (90.81%) (37312/41088)\n",
            "Epoch: 52 | Batch_idx: 330 |  Loss: (0.2767) | Acc: (90.80%) (38472/42368)\n",
            "Epoch: 52 | Batch_idx: 340 |  Loss: (0.2764) | Acc: (90.82%) (39639/43648)\n",
            "Epoch: 52 | Batch_idx: 350 |  Loss: (0.2780) | Acc: (90.77%) (40780/44928)\n",
            "Epoch: 52 | Batch_idx: 360 |  Loss: (0.2777) | Acc: (90.78%) (41946/46208)\n",
            "Epoch: 52 | Batch_idx: 370 |  Loss: (0.2774) | Acc: (90.78%) (43110/47488)\n",
            "Epoch: 52 | Batch_idx: 380 |  Loss: (0.2765) | Acc: (90.80%) (44279/48768)\n",
            "Epoch: 52 | Batch_idx: 390 |  Loss: (0.2769) | Acc: (90.79%) (45395/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3927) | Acc: (87.38%) (8738/10000)\n",
            "Epoch: 53 | Batch_idx: 0 |  Loss: (0.1691) | Acc: (91.41%) (117/128)\n",
            "Epoch: 53 | Batch_idx: 10 |  Loss: (0.2290) | Acc: (92.05%) (1296/1408)\n",
            "Epoch: 53 | Batch_idx: 20 |  Loss: (0.2478) | Acc: (91.74%) (2466/2688)\n",
            "Epoch: 53 | Batch_idx: 30 |  Loss: (0.2520) | Acc: (91.61%) (3635/3968)\n",
            "Epoch: 53 | Batch_idx: 40 |  Loss: (0.2496) | Acc: (91.63%) (4809/5248)\n",
            "Epoch: 53 | Batch_idx: 50 |  Loss: (0.2535) | Acc: (91.45%) (5970/6528)\n",
            "Epoch: 53 | Batch_idx: 60 |  Loss: (0.2518) | Acc: (91.55%) (7148/7808)\n",
            "Epoch: 53 | Batch_idx: 70 |  Loss: (0.2505) | Acc: (91.63%) (8327/9088)\n",
            "Epoch: 53 | Batch_idx: 80 |  Loss: (0.2560) | Acc: (91.44%) (9481/10368)\n",
            "Epoch: 53 | Batch_idx: 90 |  Loss: (0.2545) | Acc: (91.54%) (10662/11648)\n",
            "Epoch: 53 | Batch_idx: 100 |  Loss: (0.2551) | Acc: (91.55%) (11836/12928)\n",
            "Epoch: 53 | Batch_idx: 110 |  Loss: (0.2538) | Acc: (91.54%) (13006/14208)\n",
            "Epoch: 53 | Batch_idx: 120 |  Loss: (0.2583) | Acc: (91.46%) (14165/15488)\n",
            "Epoch: 53 | Batch_idx: 130 |  Loss: (0.2614) | Acc: (91.30%) (15309/16768)\n",
            "Epoch: 53 | Batch_idx: 140 |  Loss: (0.2615) | Acc: (91.30%) (16478/18048)\n",
            "Epoch: 53 | Batch_idx: 150 |  Loss: (0.2618) | Acc: (91.29%) (17645/19328)\n",
            "Epoch: 53 | Batch_idx: 160 |  Loss: (0.2628) | Acc: (91.26%) (18807/20608)\n",
            "Epoch: 53 | Batch_idx: 170 |  Loss: (0.2633) | Acc: (91.26%) (19976/21888)\n",
            "Epoch: 53 | Batch_idx: 180 |  Loss: (0.2648) | Acc: (91.22%) (21133/23168)\n",
            "Epoch: 53 | Batch_idx: 190 |  Loss: (0.2684) | Acc: (91.12%) (22278/24448)\n",
            "Epoch: 53 | Batch_idx: 200 |  Loss: (0.2679) | Acc: (91.15%) (23452/25728)\n",
            "Epoch: 53 | Batch_idx: 210 |  Loss: (0.2676) | Acc: (91.15%) (24618/27008)\n",
            "Epoch: 53 | Batch_idx: 220 |  Loss: (0.2678) | Acc: (91.12%) (25775/28288)\n",
            "Epoch: 53 | Batch_idx: 230 |  Loss: (0.2684) | Acc: (91.04%) (26920/29568)\n",
            "Epoch: 53 | Batch_idx: 240 |  Loss: (0.2686) | Acc: (91.02%) (28078/30848)\n",
            "Epoch: 53 | Batch_idx: 250 |  Loss: (0.2678) | Acc: (91.03%) (29246/32128)\n",
            "Epoch: 53 | Batch_idx: 260 |  Loss: (0.2684) | Acc: (91.00%) (30402/33408)\n",
            "Epoch: 53 | Batch_idx: 270 |  Loss: (0.2704) | Acc: (90.94%) (31544/34688)\n",
            "Epoch: 53 | Batch_idx: 280 |  Loss: (0.2720) | Acc: (90.86%) (32679/35968)\n",
            "Epoch: 53 | Batch_idx: 290 |  Loss: (0.2725) | Acc: (90.82%) (33829/37248)\n",
            "Epoch: 53 | Batch_idx: 300 |  Loss: (0.2712) | Acc: (90.88%) (35015/38528)\n",
            "Epoch: 53 | Batch_idx: 310 |  Loss: (0.2707) | Acc: (90.91%) (36190/39808)\n",
            "Epoch: 53 | Batch_idx: 320 |  Loss: (0.2706) | Acc: (90.92%) (37358/41088)\n",
            "Epoch: 53 | Batch_idx: 330 |  Loss: (0.2709) | Acc: (90.90%) (38514/42368)\n",
            "Epoch: 53 | Batch_idx: 340 |  Loss: (0.2712) | Acc: (90.91%) (39681/43648)\n",
            "Epoch: 53 | Batch_idx: 350 |  Loss: (0.2725) | Acc: (90.87%) (40828/44928)\n",
            "Epoch: 53 | Batch_idx: 360 |  Loss: (0.2728) | Acc: (90.86%) (41986/46208)\n",
            "Epoch: 53 | Batch_idx: 370 |  Loss: (0.2731) | Acc: (90.86%) (43147/47488)\n",
            "Epoch: 53 | Batch_idx: 380 |  Loss: (0.2729) | Acc: (90.88%) (44319/48768)\n",
            "Epoch: 53 | Batch_idx: 390 |  Loss: (0.2730) | Acc: (90.86%) (45429/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4299) | Acc: (86.79%) (8679/10000)\n",
            "Epoch: 54 | Batch_idx: 0 |  Loss: (0.2041) | Acc: (91.41%) (117/128)\n",
            "Epoch: 54 | Batch_idx: 10 |  Loss: (0.2557) | Acc: (91.76%) (1292/1408)\n",
            "Epoch: 54 | Batch_idx: 20 |  Loss: (0.2628) | Acc: (91.15%) (2450/2688)\n",
            "Epoch: 54 | Batch_idx: 30 |  Loss: (0.2586) | Acc: (91.15%) (3617/3968)\n",
            "Epoch: 54 | Batch_idx: 40 |  Loss: (0.2593) | Acc: (91.22%) (4787/5248)\n",
            "Epoch: 54 | Batch_idx: 50 |  Loss: (0.2592) | Acc: (91.34%) (5963/6528)\n",
            "Epoch: 54 | Batch_idx: 60 |  Loss: (0.2628) | Acc: (91.25%) (7125/7808)\n",
            "Epoch: 54 | Batch_idx: 70 |  Loss: (0.2680) | Acc: (91.01%) (8271/9088)\n",
            "Epoch: 54 | Batch_idx: 80 |  Loss: (0.2706) | Acc: (90.99%) (9434/10368)\n",
            "Epoch: 54 | Batch_idx: 90 |  Loss: (0.2696) | Acc: (90.99%) (10598/11648)\n",
            "Epoch: 54 | Batch_idx: 100 |  Loss: (0.2683) | Acc: (90.96%) (11759/12928)\n",
            "Epoch: 54 | Batch_idx: 110 |  Loss: (0.2684) | Acc: (90.93%) (12919/14208)\n",
            "Epoch: 54 | Batch_idx: 120 |  Loss: (0.2738) | Acc: (90.78%) (14060/15488)\n",
            "Epoch: 54 | Batch_idx: 130 |  Loss: (0.2764) | Acc: (90.68%) (15206/16768)\n",
            "Epoch: 54 | Batch_idx: 140 |  Loss: (0.2752) | Acc: (90.69%) (16367/18048)\n",
            "Epoch: 54 | Batch_idx: 150 |  Loss: (0.2731) | Acc: (90.78%) (17546/19328)\n",
            "Epoch: 54 | Batch_idx: 160 |  Loss: (0.2742) | Acc: (90.81%) (18714/20608)\n",
            "Epoch: 54 | Batch_idx: 170 |  Loss: (0.2766) | Acc: (90.76%) (19865/21888)\n",
            "Epoch: 54 | Batch_idx: 180 |  Loss: (0.2755) | Acc: (90.75%) (21025/23168)\n",
            "Epoch: 54 | Batch_idx: 190 |  Loss: (0.2742) | Acc: (90.73%) (22181/24448)\n",
            "Epoch: 54 | Batch_idx: 200 |  Loss: (0.2720) | Acc: (90.78%) (23356/25728)\n",
            "Epoch: 54 | Batch_idx: 210 |  Loss: (0.2710) | Acc: (90.84%) (24535/27008)\n",
            "Epoch: 54 | Batch_idx: 220 |  Loss: (0.2714) | Acc: (90.84%) (25698/28288)\n",
            "Epoch: 54 | Batch_idx: 230 |  Loss: (0.2725) | Acc: (90.87%) (26869/29568)\n",
            "Epoch: 54 | Batch_idx: 240 |  Loss: (0.2738) | Acc: (90.83%) (28019/30848)\n",
            "Epoch: 54 | Batch_idx: 250 |  Loss: (0.2759) | Acc: (90.77%) (29161/32128)\n",
            "Epoch: 54 | Batch_idx: 260 |  Loss: (0.2762) | Acc: (90.74%) (30313/33408)\n",
            "Epoch: 54 | Batch_idx: 270 |  Loss: (0.2770) | Acc: (90.71%) (31465/34688)\n",
            "Epoch: 54 | Batch_idx: 280 |  Loss: (0.2759) | Acc: (90.72%) (32630/35968)\n",
            "Epoch: 54 | Batch_idx: 290 |  Loss: (0.2779) | Acc: (90.67%) (33772/37248)\n",
            "Epoch: 54 | Batch_idx: 300 |  Loss: (0.2773) | Acc: (90.68%) (34939/38528)\n",
            "Epoch: 54 | Batch_idx: 310 |  Loss: (0.2774) | Acc: (90.68%) (36096/39808)\n",
            "Epoch: 54 | Batch_idx: 320 |  Loss: (0.2776) | Acc: (90.69%) (37264/41088)\n",
            "Epoch: 54 | Batch_idx: 330 |  Loss: (0.2779) | Acc: (90.67%) (38415/42368)\n",
            "Epoch: 54 | Batch_idx: 340 |  Loss: (0.2800) | Acc: (90.58%) (39537/43648)\n",
            "Epoch: 54 | Batch_idx: 350 |  Loss: (0.2796) | Acc: (90.60%) (40706/44928)\n",
            "Epoch: 54 | Batch_idx: 360 |  Loss: (0.2796) | Acc: (90.61%) (41867/46208)\n",
            "Epoch: 54 | Batch_idx: 370 |  Loss: (0.2792) | Acc: (90.63%) (43039/47488)\n",
            "Epoch: 54 | Batch_idx: 380 |  Loss: (0.2804) | Acc: (90.61%) (44190/48768)\n",
            "Epoch: 54 | Batch_idx: 390 |  Loss: (0.2798) | Acc: (90.61%) (45304/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4449) | Acc: (86.30%) (8630/10000)\n",
            "Epoch: 55 | Batch_idx: 0 |  Loss: (0.2535) | Acc: (89.84%) (115/128)\n",
            "Epoch: 55 | Batch_idx: 10 |  Loss: (0.2955) | Acc: (90.70%) (1277/1408)\n",
            "Epoch: 55 | Batch_idx: 20 |  Loss: (0.2719) | Acc: (91.03%) (2447/2688)\n",
            "Epoch: 55 | Batch_idx: 30 |  Loss: (0.2654) | Acc: (91.20%) (3619/3968)\n",
            "Epoch: 55 | Batch_idx: 40 |  Loss: (0.2712) | Acc: (90.99%) (4775/5248)\n",
            "Epoch: 55 | Batch_idx: 50 |  Loss: (0.2655) | Acc: (91.07%) (5945/6528)\n",
            "Epoch: 55 | Batch_idx: 60 |  Loss: (0.2602) | Acc: (91.19%) (7120/7808)\n",
            "Epoch: 55 | Batch_idx: 70 |  Loss: (0.2598) | Acc: (91.11%) (8280/9088)\n",
            "Epoch: 55 | Batch_idx: 80 |  Loss: (0.2637) | Acc: (90.98%) (9433/10368)\n",
            "Epoch: 55 | Batch_idx: 90 |  Loss: (0.2623) | Acc: (90.98%) (10597/11648)\n",
            "Epoch: 55 | Batch_idx: 100 |  Loss: (0.2644) | Acc: (90.93%) (11755/12928)\n",
            "Epoch: 55 | Batch_idx: 110 |  Loss: (0.2597) | Acc: (91.08%) (12941/14208)\n",
            "Epoch: 55 | Batch_idx: 120 |  Loss: (0.2588) | Acc: (91.10%) (14110/15488)\n",
            "Epoch: 55 | Batch_idx: 130 |  Loss: (0.2627) | Acc: (91.02%) (15263/16768)\n",
            "Epoch: 55 | Batch_idx: 140 |  Loss: (0.2636) | Acc: (91.01%) (16426/18048)\n",
            "Epoch: 55 | Batch_idx: 150 |  Loss: (0.2627) | Acc: (91.03%) (17595/19328)\n",
            "Epoch: 55 | Batch_idx: 160 |  Loss: (0.2643) | Acc: (90.98%) (18749/20608)\n",
            "Epoch: 55 | Batch_idx: 170 |  Loss: (0.2631) | Acc: (91.07%) (19933/21888)\n",
            "Epoch: 55 | Batch_idx: 180 |  Loss: (0.2627) | Acc: (91.09%) (21103/23168)\n",
            "Epoch: 55 | Batch_idx: 190 |  Loss: (0.2639) | Acc: (91.02%) (22253/24448)\n",
            "Epoch: 55 | Batch_idx: 200 |  Loss: (0.2625) | Acc: (91.05%) (23425/25728)\n",
            "Epoch: 55 | Batch_idx: 210 |  Loss: (0.2607) | Acc: (91.10%) (24604/27008)\n",
            "Epoch: 55 | Batch_idx: 220 |  Loss: (0.2628) | Acc: (91.02%) (25748/28288)\n",
            "Epoch: 55 | Batch_idx: 230 |  Loss: (0.2628) | Acc: (91.02%) (26912/29568)\n",
            "Epoch: 55 | Batch_idx: 240 |  Loss: (0.2645) | Acc: (90.97%) (28061/30848)\n",
            "Epoch: 55 | Batch_idx: 250 |  Loss: (0.2655) | Acc: (90.94%) (29217/32128)\n",
            "Epoch: 55 | Batch_idx: 260 |  Loss: (0.2667) | Acc: (90.92%) (30374/33408)\n",
            "Epoch: 55 | Batch_idx: 270 |  Loss: (0.2666) | Acc: (90.95%) (31550/34688)\n",
            "Epoch: 55 | Batch_idx: 280 |  Loss: (0.2658) | Acc: (90.98%) (32723/35968)\n",
            "Epoch: 55 | Batch_idx: 290 |  Loss: (0.2666) | Acc: (90.96%) (33882/37248)\n",
            "Epoch: 55 | Batch_idx: 300 |  Loss: (0.2666) | Acc: (91.01%) (35063/38528)\n",
            "Epoch: 55 | Batch_idx: 310 |  Loss: (0.2667) | Acc: (91.03%) (36236/39808)\n",
            "Epoch: 55 | Batch_idx: 320 |  Loss: (0.2669) | Acc: (91.03%) (37402/41088)\n",
            "Epoch: 55 | Batch_idx: 330 |  Loss: (0.2674) | Acc: (90.99%) (38552/42368)\n",
            "Epoch: 55 | Batch_idx: 340 |  Loss: (0.2688) | Acc: (90.95%) (39700/43648)\n",
            "Epoch: 55 | Batch_idx: 350 |  Loss: (0.2701) | Acc: (90.93%) (40855/44928)\n",
            "Epoch: 55 | Batch_idx: 360 |  Loss: (0.2697) | Acc: (90.93%) (42017/46208)\n",
            "Epoch: 55 | Batch_idx: 370 |  Loss: (0.2703) | Acc: (90.92%) (43176/47488)\n",
            "Epoch: 55 | Batch_idx: 380 |  Loss: (0.2702) | Acc: (90.93%) (44346/48768)\n",
            "Epoch: 55 | Batch_idx: 390 |  Loss: (0.2704) | Acc: (90.95%) (45476/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4675) | Acc: (85.74%) (8574/10000)\n",
            "Epoch: 56 | Batch_idx: 0 |  Loss: (0.1766) | Acc: (93.75%) (120/128)\n",
            "Epoch: 56 | Batch_idx: 10 |  Loss: (0.2199) | Acc: (92.68%) (1305/1408)\n",
            "Epoch: 56 | Batch_idx: 20 |  Loss: (0.2612) | Acc: (91.41%) (2457/2688)\n",
            "Epoch: 56 | Batch_idx: 30 |  Loss: (0.2637) | Acc: (91.46%) (3629/3968)\n",
            "Epoch: 56 | Batch_idx: 40 |  Loss: (0.2602) | Acc: (91.48%) (4801/5248)\n",
            "Epoch: 56 | Batch_idx: 50 |  Loss: (0.2540) | Acc: (91.64%) (5982/6528)\n",
            "Epoch: 56 | Batch_idx: 60 |  Loss: (0.2667) | Acc: (91.16%) (7118/7808)\n",
            "Epoch: 56 | Batch_idx: 70 |  Loss: (0.2665) | Acc: (91.12%) (8281/9088)\n",
            "Epoch: 56 | Batch_idx: 80 |  Loss: (0.2625) | Acc: (91.24%) (9460/10368)\n",
            "Epoch: 56 | Batch_idx: 90 |  Loss: (0.2601) | Acc: (91.26%) (10630/11648)\n",
            "Epoch: 56 | Batch_idx: 100 |  Loss: (0.2614) | Acc: (91.22%) (11793/12928)\n",
            "Epoch: 56 | Batch_idx: 110 |  Loss: (0.2625) | Acc: (91.18%) (12955/14208)\n",
            "Epoch: 56 | Batch_idx: 120 |  Loss: (0.2623) | Acc: (91.20%) (14125/15488)\n",
            "Epoch: 56 | Batch_idx: 130 |  Loss: (0.2621) | Acc: (91.17%) (15287/16768)\n",
            "Epoch: 56 | Batch_idx: 140 |  Loss: (0.2660) | Acc: (91.07%) (16436/18048)\n",
            "Epoch: 56 | Batch_idx: 150 |  Loss: (0.2669) | Acc: (90.99%) (17586/19328)\n",
            "Epoch: 56 | Batch_idx: 160 |  Loss: (0.2677) | Acc: (90.96%) (18746/20608)\n",
            "Epoch: 56 | Batch_idx: 170 |  Loss: (0.2667) | Acc: (91.03%) (19924/21888)\n",
            "Epoch: 56 | Batch_idx: 180 |  Loss: (0.2668) | Acc: (91.05%) (21094/23168)\n",
            "Epoch: 56 | Batch_idx: 190 |  Loss: (0.2665) | Acc: (91.06%) (22262/24448)\n",
            "Epoch: 56 | Batch_idx: 200 |  Loss: (0.2664) | Acc: (91.05%) (23426/25728)\n",
            "Epoch: 56 | Batch_idx: 210 |  Loss: (0.2701) | Acc: (90.98%) (24573/27008)\n",
            "Epoch: 56 | Batch_idx: 220 |  Loss: (0.2715) | Acc: (90.94%) (25726/28288)\n",
            "Epoch: 56 | Batch_idx: 230 |  Loss: (0.2695) | Acc: (91.00%) (26906/29568)\n",
            "Epoch: 56 | Batch_idx: 240 |  Loss: (0.2696) | Acc: (91.05%) (28086/30848)\n",
            "Epoch: 56 | Batch_idx: 250 |  Loss: (0.2690) | Acc: (91.04%) (29248/32128)\n",
            "Epoch: 56 | Batch_idx: 260 |  Loss: (0.2696) | Acc: (91.03%) (30410/33408)\n",
            "Epoch: 56 | Batch_idx: 270 |  Loss: (0.2703) | Acc: (91.01%) (31570/34688)\n",
            "Epoch: 56 | Batch_idx: 280 |  Loss: (0.2699) | Acc: (91.00%) (32732/35968)\n",
            "Epoch: 56 | Batch_idx: 290 |  Loss: (0.2704) | Acc: (90.98%) (33887/37248)\n",
            "Epoch: 56 | Batch_idx: 300 |  Loss: (0.2700) | Acc: (91.00%) (35059/38528)\n",
            "Epoch: 56 | Batch_idx: 310 |  Loss: (0.2711) | Acc: (90.95%) (36207/39808)\n",
            "Epoch: 56 | Batch_idx: 320 |  Loss: (0.2707) | Acc: (90.99%) (37384/41088)\n",
            "Epoch: 56 | Batch_idx: 330 |  Loss: (0.2702) | Acc: (91.01%) (38558/42368)\n",
            "Epoch: 56 | Batch_idx: 340 |  Loss: (0.2704) | Acc: (90.99%) (39715/43648)\n",
            "Epoch: 56 | Batch_idx: 350 |  Loss: (0.2710) | Acc: (90.98%) (40876/44928)\n",
            "Epoch: 56 | Batch_idx: 360 |  Loss: (0.2710) | Acc: (90.99%) (42045/46208)\n",
            "Epoch: 56 | Batch_idx: 370 |  Loss: (0.2704) | Acc: (91.01%) (43218/47488)\n",
            "Epoch: 56 | Batch_idx: 380 |  Loss: (0.2700) | Acc: (91.04%) (44399/48768)\n",
            "Epoch: 56 | Batch_idx: 390 |  Loss: (0.2702) | Acc: (91.04%) (45521/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4295) | Acc: (86.49%) (8649/10000)\n",
            "Epoch: 57 | Batch_idx: 0 |  Loss: (0.3020) | Acc: (88.28%) (113/128)\n",
            "Epoch: 57 | Batch_idx: 10 |  Loss: (0.2759) | Acc: (90.91%) (1280/1408)\n",
            "Epoch: 57 | Batch_idx: 20 |  Loss: (0.2514) | Acc: (91.63%) (2463/2688)\n",
            "Epoch: 57 | Batch_idx: 30 |  Loss: (0.2438) | Acc: (92.09%) (3654/3968)\n",
            "Epoch: 57 | Batch_idx: 40 |  Loss: (0.2464) | Acc: (91.81%) (4818/5248)\n",
            "Epoch: 57 | Batch_idx: 50 |  Loss: (0.2511) | Acc: (91.70%) (5986/6528)\n",
            "Epoch: 57 | Batch_idx: 60 |  Loss: (0.2589) | Acc: (91.48%) (7143/7808)\n",
            "Epoch: 57 | Batch_idx: 70 |  Loss: (0.2603) | Acc: (91.42%) (8308/9088)\n",
            "Epoch: 57 | Batch_idx: 80 |  Loss: (0.2592) | Acc: (91.43%) (9479/10368)\n",
            "Epoch: 57 | Batch_idx: 90 |  Loss: (0.2587) | Acc: (91.44%) (10651/11648)\n",
            "Epoch: 57 | Batch_idx: 100 |  Loss: (0.2573) | Acc: (91.47%) (11825/12928)\n",
            "Epoch: 57 | Batch_idx: 110 |  Loss: (0.2540) | Acc: (91.66%) (13023/14208)\n",
            "Epoch: 57 | Batch_idx: 120 |  Loss: (0.2550) | Acc: (91.55%) (14180/15488)\n",
            "Epoch: 57 | Batch_idx: 130 |  Loss: (0.2561) | Acc: (91.56%) (15353/16768)\n",
            "Epoch: 57 | Batch_idx: 140 |  Loss: (0.2580) | Acc: (91.54%) (16522/18048)\n",
            "Epoch: 57 | Batch_idx: 150 |  Loss: (0.2574) | Acc: (91.59%) (17702/19328)\n",
            "Epoch: 57 | Batch_idx: 160 |  Loss: (0.2563) | Acc: (91.54%) (18865/20608)\n",
            "Epoch: 57 | Batch_idx: 170 |  Loss: (0.2571) | Acc: (91.51%) (20030/21888)\n",
            "Epoch: 57 | Batch_idx: 180 |  Loss: (0.2585) | Acc: (91.47%) (21191/23168)\n",
            "Epoch: 57 | Batch_idx: 190 |  Loss: (0.2587) | Acc: (91.48%) (22364/24448)\n",
            "Epoch: 57 | Batch_idx: 200 |  Loss: (0.2592) | Acc: (91.43%) (23522/25728)\n",
            "Epoch: 57 | Batch_idx: 210 |  Loss: (0.2600) | Acc: (91.38%) (24681/27008)\n",
            "Epoch: 57 | Batch_idx: 220 |  Loss: (0.2609) | Acc: (91.31%) (25831/28288)\n",
            "Epoch: 57 | Batch_idx: 230 |  Loss: (0.2606) | Acc: (91.30%) (26995/29568)\n",
            "Epoch: 57 | Batch_idx: 240 |  Loss: (0.2609) | Acc: (91.27%) (28155/30848)\n",
            "Epoch: 57 | Batch_idx: 250 |  Loss: (0.2607) | Acc: (91.26%) (29319/32128)\n",
            "Epoch: 57 | Batch_idx: 260 |  Loss: (0.2599) | Acc: (91.29%) (30499/33408)\n",
            "Epoch: 57 | Batch_idx: 270 |  Loss: (0.2595) | Acc: (91.28%) (31663/34688)\n",
            "Epoch: 57 | Batch_idx: 280 |  Loss: (0.2600) | Acc: (91.29%) (32835/35968)\n",
            "Epoch: 57 | Batch_idx: 290 |  Loss: (0.2609) | Acc: (91.24%) (33984/37248)\n",
            "Epoch: 57 | Batch_idx: 300 |  Loss: (0.2624) | Acc: (91.19%) (35134/38528)\n",
            "Epoch: 57 | Batch_idx: 310 |  Loss: (0.2617) | Acc: (91.21%) (36308/39808)\n",
            "Epoch: 57 | Batch_idx: 320 |  Loss: (0.2612) | Acc: (91.25%) (37491/41088)\n",
            "Epoch: 57 | Batch_idx: 330 |  Loss: (0.2619) | Acc: (91.20%) (38640/42368)\n",
            "Epoch: 57 | Batch_idx: 340 |  Loss: (0.2623) | Acc: (91.20%) (39809/43648)\n",
            "Epoch: 57 | Batch_idx: 350 |  Loss: (0.2623) | Acc: (91.21%) (40978/44928)\n",
            "Epoch: 57 | Batch_idx: 360 |  Loss: (0.2632) | Acc: (91.19%) (42138/46208)\n",
            "Epoch: 57 | Batch_idx: 370 |  Loss: (0.2641) | Acc: (91.17%) (43295/47488)\n",
            "Epoch: 57 | Batch_idx: 380 |  Loss: (0.2643) | Acc: (91.16%) (44458/48768)\n",
            "Epoch: 57 | Batch_idx: 390 |  Loss: (0.2652) | Acc: (91.14%) (45568/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4082) | Acc: (87.33%) (8733/10000)\n",
            "Epoch: 58 | Batch_idx: 0 |  Loss: (0.2056) | Acc: (92.97%) (119/128)\n",
            "Epoch: 58 | Batch_idx: 10 |  Loss: (0.2603) | Acc: (90.77%) (1278/1408)\n",
            "Epoch: 58 | Batch_idx: 20 |  Loss: (0.2580) | Acc: (91.15%) (2450/2688)\n",
            "Epoch: 58 | Batch_idx: 30 |  Loss: (0.2627) | Acc: (90.95%) (3609/3968)\n",
            "Epoch: 58 | Batch_idx: 40 |  Loss: (0.2579) | Acc: (91.25%) (4789/5248)\n",
            "Epoch: 58 | Batch_idx: 50 |  Loss: (0.2526) | Acc: (91.53%) (5975/6528)\n",
            "Epoch: 58 | Batch_idx: 60 |  Loss: (0.2568) | Acc: (91.43%) (7139/7808)\n",
            "Epoch: 58 | Batch_idx: 70 |  Loss: (0.2547) | Acc: (91.46%) (8312/9088)\n",
            "Epoch: 58 | Batch_idx: 80 |  Loss: (0.2538) | Acc: (91.47%) (9484/10368)\n",
            "Epoch: 58 | Batch_idx: 90 |  Loss: (0.2523) | Acc: (91.54%) (10662/11648)\n",
            "Epoch: 58 | Batch_idx: 100 |  Loss: (0.2570) | Acc: (91.42%) (11819/12928)\n",
            "Epoch: 58 | Batch_idx: 110 |  Loss: (0.2614) | Acc: (91.20%) (12958/14208)\n",
            "Epoch: 58 | Batch_idx: 120 |  Loss: (0.2614) | Acc: (91.24%) (14131/15488)\n",
            "Epoch: 58 | Batch_idx: 130 |  Loss: (0.2598) | Acc: (91.35%) (15317/16768)\n",
            "Epoch: 58 | Batch_idx: 140 |  Loss: (0.2611) | Acc: (91.32%) (16482/18048)\n",
            "Epoch: 58 | Batch_idx: 150 |  Loss: (0.2629) | Acc: (91.28%) (17642/19328)\n",
            "Epoch: 58 | Batch_idx: 160 |  Loss: (0.2628) | Acc: (91.28%) (18812/20608)\n",
            "Epoch: 58 | Batch_idx: 170 |  Loss: (0.2626) | Acc: (91.31%) (19987/21888)\n",
            "Epoch: 58 | Batch_idx: 180 |  Loss: (0.2627) | Acc: (91.32%) (21156/23168)\n",
            "Epoch: 58 | Batch_idx: 190 |  Loss: (0.2636) | Acc: (91.29%) (22318/24448)\n",
            "Epoch: 58 | Batch_idx: 200 |  Loss: (0.2632) | Acc: (91.29%) (23488/25728)\n",
            "Epoch: 58 | Batch_idx: 210 |  Loss: (0.2644) | Acc: (91.25%) (24646/27008)\n",
            "Epoch: 58 | Batch_idx: 220 |  Loss: (0.2639) | Acc: (91.26%) (25817/28288)\n",
            "Epoch: 58 | Batch_idx: 230 |  Loss: (0.2649) | Acc: (91.24%) (26979/29568)\n",
            "Epoch: 58 | Batch_idx: 240 |  Loss: (0.2647) | Acc: (91.27%) (28156/30848)\n",
            "Epoch: 58 | Batch_idx: 250 |  Loss: (0.2651) | Acc: (91.29%) (29330/32128)\n",
            "Epoch: 58 | Batch_idx: 260 |  Loss: (0.2662) | Acc: (91.28%) (30496/33408)\n",
            "Epoch: 58 | Batch_idx: 270 |  Loss: (0.2657) | Acc: (91.29%) (31665/34688)\n",
            "Epoch: 58 | Batch_idx: 280 |  Loss: (0.2650) | Acc: (91.29%) (32835/35968)\n",
            "Epoch: 58 | Batch_idx: 290 |  Loss: (0.2656) | Acc: (91.30%) (34007/37248)\n",
            "Epoch: 58 | Batch_idx: 300 |  Loss: (0.2660) | Acc: (91.28%) (35167/38528)\n",
            "Epoch: 58 | Batch_idx: 310 |  Loss: (0.2668) | Acc: (91.27%) (36334/39808)\n",
            "Epoch: 58 | Batch_idx: 320 |  Loss: (0.2683) | Acc: (91.20%) (37474/41088)\n",
            "Epoch: 58 | Batch_idx: 330 |  Loss: (0.2671) | Acc: (91.25%) (38660/42368)\n",
            "Epoch: 58 | Batch_idx: 340 |  Loss: (0.2687) | Acc: (91.21%) (39812/43648)\n",
            "Epoch: 58 | Batch_idx: 350 |  Loss: (0.2691) | Acc: (91.19%) (40969/44928)\n",
            "Epoch: 58 | Batch_idx: 360 |  Loss: (0.2705) | Acc: (91.16%) (42125/46208)\n",
            "Epoch: 58 | Batch_idx: 370 |  Loss: (0.2708) | Acc: (91.15%) (43284/47488)\n",
            "Epoch: 58 | Batch_idx: 380 |  Loss: (0.2703) | Acc: (91.16%) (44459/48768)\n",
            "Epoch: 58 | Batch_idx: 390 |  Loss: (0.2703) | Acc: (91.15%) (45577/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4450) | Acc: (86.34%) (8634/10000)\n",
            "Epoch: 59 | Batch_idx: 0 |  Loss: (0.2496) | Acc: (90.62%) (116/128)\n",
            "Epoch: 59 | Batch_idx: 10 |  Loss: (0.2295) | Acc: (92.19%) (1298/1408)\n",
            "Epoch: 59 | Batch_idx: 20 |  Loss: (0.2293) | Acc: (92.71%) (2492/2688)\n",
            "Epoch: 59 | Batch_idx: 30 |  Loss: (0.2298) | Acc: (92.69%) (3678/3968)\n",
            "Epoch: 59 | Batch_idx: 40 |  Loss: (0.2459) | Acc: (92.02%) (4829/5248)\n",
            "Epoch: 59 | Batch_idx: 50 |  Loss: (0.2532) | Acc: (91.71%) (5987/6528)\n",
            "Epoch: 59 | Batch_idx: 60 |  Loss: (0.2544) | Acc: (91.68%) (7158/7808)\n",
            "Epoch: 59 | Batch_idx: 70 |  Loss: (0.2518) | Acc: (91.73%) (8336/9088)\n",
            "Epoch: 59 | Batch_idx: 80 |  Loss: (0.2562) | Acc: (91.62%) (9499/10368)\n",
            "Epoch: 59 | Batch_idx: 90 |  Loss: (0.2535) | Acc: (91.67%) (10678/11648)\n",
            "Epoch: 59 | Batch_idx: 100 |  Loss: (0.2547) | Acc: (91.63%) (11846/12928)\n",
            "Epoch: 59 | Batch_idx: 110 |  Loss: (0.2572) | Acc: (91.53%) (13005/14208)\n",
            "Epoch: 59 | Batch_idx: 120 |  Loss: (0.2560) | Acc: (91.54%) (14177/15488)\n",
            "Epoch: 59 | Batch_idx: 130 |  Loss: (0.2542) | Acc: (91.60%) (15360/16768)\n",
            "Epoch: 59 | Batch_idx: 140 |  Loss: (0.2546) | Acc: (91.54%) (16521/18048)\n",
            "Epoch: 59 | Batch_idx: 150 |  Loss: (0.2579) | Acc: (91.38%) (17661/19328)\n",
            "Epoch: 59 | Batch_idx: 160 |  Loss: (0.2582) | Acc: (91.39%) (18833/20608)\n",
            "Epoch: 59 | Batch_idx: 170 |  Loss: (0.2599) | Acc: (91.34%) (19992/21888)\n",
            "Epoch: 59 | Batch_idx: 180 |  Loss: (0.2603) | Acc: (91.37%) (21169/23168)\n",
            "Epoch: 59 | Batch_idx: 190 |  Loss: (0.2612) | Acc: (91.35%) (22333/24448)\n",
            "Epoch: 59 | Batch_idx: 200 |  Loss: (0.2609) | Acc: (91.33%) (23497/25728)\n",
            "Epoch: 59 | Batch_idx: 210 |  Loss: (0.2618) | Acc: (91.29%) (24655/27008)\n",
            "Epoch: 59 | Batch_idx: 220 |  Loss: (0.2619) | Acc: (91.27%) (25819/28288)\n",
            "Epoch: 59 | Batch_idx: 230 |  Loss: (0.2639) | Acc: (91.23%) (26976/29568)\n",
            "Epoch: 59 | Batch_idx: 240 |  Loss: (0.2627) | Acc: (91.26%) (28151/30848)\n",
            "Epoch: 59 | Batch_idx: 250 |  Loss: (0.2621) | Acc: (91.27%) (29322/32128)\n",
            "Epoch: 59 | Batch_idx: 260 |  Loss: (0.2620) | Acc: (91.30%) (30500/33408)\n",
            "Epoch: 59 | Batch_idx: 270 |  Loss: (0.2626) | Acc: (91.25%) (31652/34688)\n",
            "Epoch: 59 | Batch_idx: 280 |  Loss: (0.2634) | Acc: (91.26%) (32823/35968)\n",
            "Epoch: 59 | Batch_idx: 290 |  Loss: (0.2641) | Acc: (91.23%) (33980/37248)\n",
            "Epoch: 59 | Batch_idx: 300 |  Loss: (0.2639) | Acc: (91.22%) (35144/38528)\n",
            "Epoch: 59 | Batch_idx: 310 |  Loss: (0.2645) | Acc: (91.20%) (36303/39808)\n",
            "Epoch: 59 | Batch_idx: 320 |  Loss: (0.2648) | Acc: (91.19%) (37467/41088)\n",
            "Epoch: 59 | Batch_idx: 330 |  Loss: (0.2648) | Acc: (91.18%) (38632/42368)\n",
            "Epoch: 59 | Batch_idx: 340 |  Loss: (0.2648) | Acc: (91.19%) (39801/43648)\n",
            "Epoch: 59 | Batch_idx: 350 |  Loss: (0.2649) | Acc: (91.19%) (40972/44928)\n",
            "Epoch: 59 | Batch_idx: 360 |  Loss: (0.2661) | Acc: (91.16%) (42122/46208)\n",
            "Epoch: 59 | Batch_idx: 370 |  Loss: (0.2668) | Acc: (91.12%) (43269/47488)\n",
            "Epoch: 59 | Batch_idx: 380 |  Loss: (0.2677) | Acc: (91.08%) (44419/48768)\n",
            "Epoch: 59 | Batch_idx: 390 |  Loss: (0.2684) | Acc: (91.04%) (45522/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4098) | Acc: (87.05%) (8705/10000)\n",
            "Epoch: 60 | Batch_idx: 0 |  Loss: (0.2617) | Acc: (92.97%) (119/128)\n",
            "Epoch: 60 | Batch_idx: 10 |  Loss: (0.2516) | Acc: (91.90%) (1294/1408)\n",
            "Epoch: 60 | Batch_idx: 20 |  Loss: (0.2283) | Acc: (92.41%) (2484/2688)\n",
            "Epoch: 60 | Batch_idx: 30 |  Loss: (0.2396) | Acc: (91.86%) (3645/3968)\n",
            "Epoch: 60 | Batch_idx: 40 |  Loss: (0.2289) | Acc: (92.23%) (4840/5248)\n",
            "Epoch: 60 | Batch_idx: 50 |  Loss: (0.2226) | Acc: (92.45%) (6035/6528)\n",
            "Epoch: 60 | Batch_idx: 60 |  Loss: (0.2238) | Acc: (92.35%) (7211/7808)\n",
            "Epoch: 60 | Batch_idx: 70 |  Loss: (0.2319) | Acc: (92.07%) (8367/9088)\n",
            "Epoch: 60 | Batch_idx: 80 |  Loss: (0.2357) | Acc: (91.92%) (9530/10368)\n",
            "Epoch: 60 | Batch_idx: 90 |  Loss: (0.2371) | Acc: (91.81%) (10694/11648)\n",
            "Epoch: 60 | Batch_idx: 100 |  Loss: (0.2440) | Acc: (91.62%) (11845/12928)\n",
            "Epoch: 60 | Batch_idx: 110 |  Loss: (0.2443) | Acc: (91.64%) (13020/14208)\n",
            "Epoch: 60 | Batch_idx: 120 |  Loss: (0.2462) | Acc: (91.57%) (14182/15488)\n",
            "Epoch: 60 | Batch_idx: 130 |  Loss: (0.2459) | Acc: (91.58%) (15356/16768)\n",
            "Epoch: 60 | Batch_idx: 140 |  Loss: (0.2443) | Acc: (91.62%) (16536/18048)\n",
            "Epoch: 60 | Batch_idx: 150 |  Loss: (0.2456) | Acc: (91.60%) (17704/19328)\n",
            "Epoch: 60 | Batch_idx: 160 |  Loss: (0.2468) | Acc: (91.60%) (18876/20608)\n",
            "Epoch: 60 | Batch_idx: 170 |  Loss: (0.2492) | Acc: (91.53%) (20034/21888)\n",
            "Epoch: 60 | Batch_idx: 180 |  Loss: (0.2529) | Acc: (91.44%) (21184/23168)\n",
            "Epoch: 60 | Batch_idx: 190 |  Loss: (0.2548) | Acc: (91.35%) (22334/24448)\n",
            "Epoch: 60 | Batch_idx: 200 |  Loss: (0.2562) | Acc: (91.31%) (23492/25728)\n",
            "Epoch: 60 | Batch_idx: 210 |  Loss: (0.2559) | Acc: (91.33%) (24666/27008)\n",
            "Epoch: 60 | Batch_idx: 220 |  Loss: (0.2579) | Acc: (91.28%) (25820/28288)\n",
            "Epoch: 60 | Batch_idx: 230 |  Loss: (0.2574) | Acc: (91.27%) (26988/29568)\n",
            "Epoch: 60 | Batch_idx: 240 |  Loss: (0.2571) | Acc: (91.30%) (28164/30848)\n",
            "Epoch: 60 | Batch_idx: 250 |  Loss: (0.2587) | Acc: (91.26%) (29321/32128)\n",
            "Epoch: 60 | Batch_idx: 260 |  Loss: (0.2587) | Acc: (91.26%) (30488/33408)\n",
            "Epoch: 60 | Batch_idx: 270 |  Loss: (0.2593) | Acc: (91.26%) (31658/34688)\n",
            "Epoch: 60 | Batch_idx: 280 |  Loss: (0.2596) | Acc: (91.24%) (32819/35968)\n",
            "Epoch: 60 | Batch_idx: 290 |  Loss: (0.2598) | Acc: (91.25%) (33990/37248)\n",
            "Epoch: 60 | Batch_idx: 300 |  Loss: (0.2605) | Acc: (91.24%) (35153/38528)\n",
            "Epoch: 60 | Batch_idx: 310 |  Loss: (0.2624) | Acc: (91.21%) (36309/39808)\n",
            "Epoch: 60 | Batch_idx: 320 |  Loss: (0.2625) | Acc: (91.20%) (37471/41088)\n",
            "Epoch: 60 | Batch_idx: 330 |  Loss: (0.2628) | Acc: (91.21%) (38642/42368)\n",
            "Epoch: 60 | Batch_idx: 340 |  Loss: (0.2636) | Acc: (91.16%) (39791/43648)\n",
            "Epoch: 60 | Batch_idx: 350 |  Loss: (0.2634) | Acc: (91.18%) (40966/44928)\n",
            "Epoch: 60 | Batch_idx: 360 |  Loss: (0.2629) | Acc: (91.19%) (42135/46208)\n",
            "Epoch: 60 | Batch_idx: 370 |  Loss: (0.2634) | Acc: (91.18%) (43300/47488)\n",
            "Epoch: 60 | Batch_idx: 380 |  Loss: (0.2647) | Acc: (91.14%) (44449/48768)\n",
            "Epoch: 60 | Batch_idx: 390 |  Loss: (0.2651) | Acc: (91.13%) (45566/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3815) | Acc: (87.57%) (8757/10000)\n",
            "Epoch: 61 | Batch_idx: 0 |  Loss: (0.2355) | Acc: (90.62%) (116/128)\n",
            "Epoch: 61 | Batch_idx: 10 |  Loss: (0.2373) | Acc: (92.54%) (1303/1408)\n",
            "Epoch: 61 | Batch_idx: 20 |  Loss: (0.2366) | Acc: (92.15%) (2477/2688)\n",
            "Epoch: 61 | Batch_idx: 30 |  Loss: (0.2240) | Acc: (92.57%) (3673/3968)\n",
            "Epoch: 61 | Batch_idx: 40 |  Loss: (0.2248) | Acc: (92.78%) (4869/5248)\n",
            "Epoch: 61 | Batch_idx: 50 |  Loss: (0.2395) | Acc: (92.25%) (6022/6528)\n",
            "Epoch: 61 | Batch_idx: 60 |  Loss: (0.2400) | Acc: (92.25%) (7203/7808)\n",
            "Epoch: 61 | Batch_idx: 70 |  Loss: (0.2424) | Acc: (92.13%) (8373/9088)\n",
            "Epoch: 61 | Batch_idx: 80 |  Loss: (0.2416) | Acc: (92.12%) (9551/10368)\n",
            "Epoch: 61 | Batch_idx: 90 |  Loss: (0.2436) | Acc: (92.12%) (10730/11648)\n",
            "Epoch: 61 | Batch_idx: 100 |  Loss: (0.2503) | Acc: (91.83%) (11872/12928)\n",
            "Epoch: 61 | Batch_idx: 110 |  Loss: (0.2531) | Acc: (91.72%) (13031/14208)\n",
            "Epoch: 61 | Batch_idx: 120 |  Loss: (0.2546) | Acc: (91.65%) (14195/15488)\n",
            "Epoch: 61 | Batch_idx: 130 |  Loss: (0.2566) | Acc: (91.60%) (15360/16768)\n",
            "Epoch: 61 | Batch_idx: 140 |  Loss: (0.2552) | Acc: (91.63%) (16538/18048)\n",
            "Epoch: 61 | Batch_idx: 150 |  Loss: (0.2597) | Acc: (91.47%) (17679/19328)\n",
            "Epoch: 61 | Batch_idx: 160 |  Loss: (0.2635) | Acc: (91.29%) (18814/20608)\n",
            "Epoch: 61 | Batch_idx: 170 |  Loss: (0.2632) | Acc: (91.24%) (19971/21888)\n",
            "Epoch: 61 | Batch_idx: 180 |  Loss: (0.2606) | Acc: (91.32%) (21156/23168)\n",
            "Epoch: 61 | Batch_idx: 190 |  Loss: (0.2610) | Acc: (91.30%) (22320/24448)\n",
            "Epoch: 61 | Batch_idx: 200 |  Loss: (0.2625) | Acc: (91.27%) (23482/25728)\n",
            "Epoch: 61 | Batch_idx: 210 |  Loss: (0.2629) | Acc: (91.23%) (24640/27008)\n",
            "Epoch: 61 | Batch_idx: 220 |  Loss: (0.2628) | Acc: (91.20%) (25799/28288)\n",
            "Epoch: 61 | Batch_idx: 230 |  Loss: (0.2623) | Acc: (91.25%) (26981/29568)\n",
            "Epoch: 61 | Batch_idx: 240 |  Loss: (0.2614) | Acc: (91.27%) (28156/30848)\n",
            "Epoch: 61 | Batch_idx: 250 |  Loss: (0.2604) | Acc: (91.30%) (29332/32128)\n",
            "Epoch: 61 | Batch_idx: 260 |  Loss: (0.2601) | Acc: (91.33%) (30511/33408)\n",
            "Epoch: 61 | Batch_idx: 270 |  Loss: (0.2608) | Acc: (91.28%) (31662/34688)\n",
            "Epoch: 61 | Batch_idx: 280 |  Loss: (0.2615) | Acc: (91.24%) (32818/35968)\n",
            "Epoch: 61 | Batch_idx: 290 |  Loss: (0.2615) | Acc: (91.23%) (33980/37248)\n",
            "Epoch: 61 | Batch_idx: 300 |  Loss: (0.2617) | Acc: (91.20%) (35138/38528)\n",
            "Epoch: 61 | Batch_idx: 310 |  Loss: (0.2624) | Acc: (91.17%) (36293/39808)\n",
            "Epoch: 61 | Batch_idx: 320 |  Loss: (0.2620) | Acc: (91.17%) (37461/41088)\n",
            "Epoch: 61 | Batch_idx: 330 |  Loss: (0.2616) | Acc: (91.17%) (38628/42368)\n",
            "Epoch: 61 | Batch_idx: 340 |  Loss: (0.2623) | Acc: (91.17%) (39795/43648)\n",
            "Epoch: 61 | Batch_idx: 350 |  Loss: (0.2631) | Acc: (91.14%) (40948/44928)\n",
            "Epoch: 61 | Batch_idx: 360 |  Loss: (0.2629) | Acc: (91.17%) (42126/46208)\n",
            "Epoch: 61 | Batch_idx: 370 |  Loss: (0.2640) | Acc: (91.14%) (43279/47488)\n",
            "Epoch: 61 | Batch_idx: 380 |  Loss: (0.2639) | Acc: (91.13%) (44440/48768)\n",
            "Epoch: 61 | Batch_idx: 390 |  Loss: (0.2641) | Acc: (91.12%) (45559/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4055) | Acc: (86.88%) (8688/10000)\n",
            "Epoch: 62 | Batch_idx: 0 |  Loss: (0.2435) | Acc: (90.62%) (116/128)\n",
            "Epoch: 62 | Batch_idx: 10 |  Loss: (0.2414) | Acc: (92.12%) (1297/1408)\n",
            "Epoch: 62 | Batch_idx: 20 |  Loss: (0.2189) | Acc: (92.67%) (2491/2688)\n",
            "Epoch: 62 | Batch_idx: 30 |  Loss: (0.2382) | Acc: (91.96%) (3649/3968)\n",
            "Epoch: 62 | Batch_idx: 40 |  Loss: (0.2335) | Acc: (92.23%) (4840/5248)\n",
            "Epoch: 62 | Batch_idx: 50 |  Loss: (0.2365) | Acc: (92.10%) (6012/6528)\n",
            "Epoch: 62 | Batch_idx: 60 |  Loss: (0.2352) | Acc: (92.14%) (7194/7808)\n",
            "Epoch: 62 | Batch_idx: 70 |  Loss: (0.2368) | Acc: (92.08%) (8368/9088)\n",
            "Epoch: 62 | Batch_idx: 80 |  Loss: (0.2402) | Acc: (91.92%) (9530/10368)\n",
            "Epoch: 62 | Batch_idx: 90 |  Loss: (0.2419) | Acc: (91.82%) (10695/11648)\n",
            "Epoch: 62 | Batch_idx: 100 |  Loss: (0.2393) | Acc: (91.93%) (11885/12928)\n",
            "Epoch: 62 | Batch_idx: 110 |  Loss: (0.2385) | Acc: (91.93%) (13061/14208)\n",
            "Epoch: 62 | Batch_idx: 120 |  Loss: (0.2416) | Acc: (91.80%) (14218/15488)\n",
            "Epoch: 62 | Batch_idx: 130 |  Loss: (0.2414) | Acc: (91.73%) (15381/16768)\n",
            "Epoch: 62 | Batch_idx: 140 |  Loss: (0.2430) | Acc: (91.69%) (16549/18048)\n",
            "Epoch: 62 | Batch_idx: 150 |  Loss: (0.2428) | Acc: (91.72%) (17728/19328)\n",
            "Epoch: 62 | Batch_idx: 160 |  Loss: (0.2457) | Acc: (91.61%) (18879/20608)\n",
            "Epoch: 62 | Batch_idx: 170 |  Loss: (0.2456) | Acc: (91.62%) (20053/21888)\n",
            "Epoch: 62 | Batch_idx: 180 |  Loss: (0.2448) | Acc: (91.65%) (21233/23168)\n",
            "Epoch: 62 | Batch_idx: 190 |  Loss: (0.2448) | Acc: (91.65%) (22407/24448)\n",
            "Epoch: 62 | Batch_idx: 200 |  Loss: (0.2458) | Acc: (91.64%) (23577/25728)\n",
            "Epoch: 62 | Batch_idx: 210 |  Loss: (0.2461) | Acc: (91.63%) (24747/27008)\n",
            "Epoch: 62 | Batch_idx: 220 |  Loss: (0.2458) | Acc: (91.66%) (25928/28288)\n",
            "Epoch: 62 | Batch_idx: 230 |  Loss: (0.2467) | Acc: (91.68%) (27109/29568)\n",
            "Epoch: 62 | Batch_idx: 240 |  Loss: (0.2459) | Acc: (91.72%) (28295/30848)\n",
            "Epoch: 62 | Batch_idx: 250 |  Loss: (0.2469) | Acc: (91.68%) (29455/32128)\n",
            "Epoch: 62 | Batch_idx: 260 |  Loss: (0.2484) | Acc: (91.61%) (30604/33408)\n",
            "Epoch: 62 | Batch_idx: 270 |  Loss: (0.2499) | Acc: (91.58%) (31767/34688)\n",
            "Epoch: 62 | Batch_idx: 280 |  Loss: (0.2512) | Acc: (91.53%) (32923/35968)\n",
            "Epoch: 62 | Batch_idx: 290 |  Loss: (0.2523) | Acc: (91.52%) (34091/37248)\n",
            "Epoch: 62 | Batch_idx: 300 |  Loss: (0.2523) | Acc: (91.51%) (35258/38528)\n",
            "Epoch: 62 | Batch_idx: 310 |  Loss: (0.2521) | Acc: (91.50%) (36426/39808)\n",
            "Epoch: 62 | Batch_idx: 320 |  Loss: (0.2515) | Acc: (91.53%) (37609/41088)\n",
            "Epoch: 62 | Batch_idx: 330 |  Loss: (0.2517) | Acc: (91.51%) (38773/42368)\n",
            "Epoch: 62 | Batch_idx: 340 |  Loss: (0.2522) | Acc: (91.50%) (39938/43648)\n",
            "Epoch: 62 | Batch_idx: 350 |  Loss: (0.2522) | Acc: (91.50%) (41108/44928)\n",
            "Epoch: 62 | Batch_idx: 360 |  Loss: (0.2537) | Acc: (91.46%) (42262/46208)\n",
            "Epoch: 62 | Batch_idx: 370 |  Loss: (0.2552) | Acc: (91.42%) (43412/47488)\n",
            "Epoch: 62 | Batch_idx: 380 |  Loss: (0.2563) | Acc: (91.38%) (44566/48768)\n",
            "Epoch: 62 | Batch_idx: 390 |  Loss: (0.2561) | Acc: (91.39%) (45696/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4202) | Acc: (87.05%) (8705/10000)\n",
            "Epoch: 63 | Batch_idx: 0 |  Loss: (0.2527) | Acc: (92.97%) (119/128)\n",
            "Epoch: 63 | Batch_idx: 10 |  Loss: (0.2487) | Acc: (91.26%) (1285/1408)\n",
            "Epoch: 63 | Batch_idx: 20 |  Loss: (0.2459) | Acc: (91.93%) (2471/2688)\n",
            "Epoch: 63 | Batch_idx: 30 |  Loss: (0.2334) | Acc: (92.11%) (3655/3968)\n",
            "Epoch: 63 | Batch_idx: 40 |  Loss: (0.2362) | Acc: (92.15%) (4836/5248)\n",
            "Epoch: 63 | Batch_idx: 50 |  Loss: (0.2443) | Acc: (91.76%) (5990/6528)\n",
            "Epoch: 63 | Batch_idx: 60 |  Loss: (0.2511) | Acc: (91.57%) (7150/7808)\n",
            "Epoch: 63 | Batch_idx: 70 |  Loss: (0.2490) | Acc: (91.64%) (8328/9088)\n",
            "Epoch: 63 | Batch_idx: 80 |  Loss: (0.2474) | Acc: (91.67%) (9504/10368)\n",
            "Epoch: 63 | Batch_idx: 90 |  Loss: (0.2503) | Acc: (91.57%) (10666/11648)\n",
            "Epoch: 63 | Batch_idx: 100 |  Loss: (0.2510) | Acc: (91.61%) (11843/12928)\n",
            "Epoch: 63 | Batch_idx: 110 |  Loss: (0.2504) | Acc: (91.56%) (13009/14208)\n",
            "Epoch: 63 | Batch_idx: 120 |  Loss: (0.2485) | Acc: (91.59%) (14186/15488)\n",
            "Epoch: 63 | Batch_idx: 130 |  Loss: (0.2497) | Acc: (91.60%) (15359/16768)\n",
            "Epoch: 63 | Batch_idx: 140 |  Loss: (0.2471) | Acc: (91.58%) (16528/18048)\n",
            "Epoch: 63 | Batch_idx: 150 |  Loss: (0.2493) | Acc: (91.45%) (17676/19328)\n",
            "Epoch: 63 | Batch_idx: 160 |  Loss: (0.2516) | Acc: (91.42%) (18839/20608)\n",
            "Epoch: 63 | Batch_idx: 170 |  Loss: (0.2535) | Acc: (91.35%) (19995/21888)\n",
            "Epoch: 63 | Batch_idx: 180 |  Loss: (0.2542) | Acc: (91.32%) (21158/23168)\n",
            "Epoch: 63 | Batch_idx: 190 |  Loss: (0.2549) | Acc: (91.31%) (22324/24448)\n",
            "Epoch: 63 | Batch_idx: 200 |  Loss: (0.2559) | Acc: (91.31%) (23493/25728)\n",
            "Epoch: 63 | Batch_idx: 210 |  Loss: (0.2564) | Acc: (91.31%) (24660/27008)\n",
            "Epoch: 63 | Batch_idx: 220 |  Loss: (0.2556) | Acc: (91.37%) (25848/28288)\n",
            "Epoch: 63 | Batch_idx: 230 |  Loss: (0.2568) | Acc: (91.33%) (27004/29568)\n",
            "Epoch: 63 | Batch_idx: 240 |  Loss: (0.2573) | Acc: (91.31%) (28166/30848)\n",
            "Epoch: 63 | Batch_idx: 250 |  Loss: (0.2579) | Acc: (91.30%) (29332/32128)\n",
            "Epoch: 63 | Batch_idx: 260 |  Loss: (0.2575) | Acc: (91.34%) (30514/33408)\n",
            "Epoch: 63 | Batch_idx: 270 |  Loss: (0.2576) | Acc: (91.37%) (31693/34688)\n",
            "Epoch: 63 | Batch_idx: 280 |  Loss: (0.2567) | Acc: (91.39%) (32871/35968)\n",
            "Epoch: 63 | Batch_idx: 290 |  Loss: (0.2564) | Acc: (91.40%) (34046/37248)\n",
            "Epoch: 63 | Batch_idx: 300 |  Loss: (0.2563) | Acc: (91.40%) (35213/38528)\n",
            "Epoch: 63 | Batch_idx: 310 |  Loss: (0.2562) | Acc: (91.44%) (36399/39808)\n",
            "Epoch: 63 | Batch_idx: 320 |  Loss: (0.2562) | Acc: (91.46%) (37578/41088)\n",
            "Epoch: 63 | Batch_idx: 330 |  Loss: (0.2557) | Acc: (91.45%) (38745/42368)\n",
            "Epoch: 63 | Batch_idx: 340 |  Loss: (0.2552) | Acc: (91.46%) (39922/43648)\n",
            "Epoch: 63 | Batch_idx: 350 |  Loss: (0.2559) | Acc: (91.44%) (41080/44928)\n",
            "Epoch: 63 | Batch_idx: 360 |  Loss: (0.2560) | Acc: (91.43%) (42250/46208)\n",
            "Epoch: 63 | Batch_idx: 370 |  Loss: (0.2573) | Acc: (91.36%) (43387/47488)\n",
            "Epoch: 63 | Batch_idx: 380 |  Loss: (0.2577) | Acc: (91.36%) (44554/48768)\n",
            "Epoch: 63 | Batch_idx: 390 |  Loss: (0.2581) | Acc: (91.34%) (45669/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4513) | Acc: (85.31%) (8531/10000)\n",
            "Epoch: 64 | Batch_idx: 0 |  Loss: (0.2711) | Acc: (91.41%) (117/128)\n",
            "Epoch: 64 | Batch_idx: 10 |  Loss: (0.2801) | Acc: (90.48%) (1274/1408)\n",
            "Epoch: 64 | Batch_idx: 20 |  Loss: (0.2707) | Acc: (91.11%) (2449/2688)\n",
            "Epoch: 64 | Batch_idx: 30 |  Loss: (0.2726) | Acc: (90.70%) (3599/3968)\n",
            "Epoch: 64 | Batch_idx: 40 |  Loss: (0.2677) | Acc: (90.85%) (4768/5248)\n",
            "Epoch: 64 | Batch_idx: 50 |  Loss: (0.2577) | Acc: (91.30%) (5960/6528)\n",
            "Epoch: 64 | Batch_idx: 60 |  Loss: (0.2575) | Acc: (91.50%) (7144/7808)\n",
            "Epoch: 64 | Batch_idx: 70 |  Loss: (0.2557) | Acc: (91.53%) (8318/9088)\n",
            "Epoch: 64 | Batch_idx: 80 |  Loss: (0.2593) | Acc: (91.46%) (9483/10368)\n",
            "Epoch: 64 | Batch_idx: 90 |  Loss: (0.2552) | Acc: (91.64%) (10674/11648)\n",
            "Epoch: 64 | Batch_idx: 100 |  Loss: (0.2542) | Acc: (91.55%) (11836/12928)\n",
            "Epoch: 64 | Batch_idx: 110 |  Loss: (0.2528) | Acc: (91.62%) (13017/14208)\n",
            "Epoch: 64 | Batch_idx: 120 |  Loss: (0.2501) | Acc: (91.79%) (14217/15488)\n",
            "Epoch: 64 | Batch_idx: 130 |  Loss: (0.2497) | Acc: (91.75%) (15385/16768)\n",
            "Epoch: 64 | Batch_idx: 140 |  Loss: (0.2518) | Acc: (91.67%) (16545/18048)\n",
            "Epoch: 64 | Batch_idx: 150 |  Loss: (0.2513) | Acc: (91.66%) (17717/19328)\n",
            "Epoch: 64 | Batch_idx: 160 |  Loss: (0.2518) | Acc: (91.66%) (18890/20608)\n",
            "Epoch: 64 | Batch_idx: 170 |  Loss: (0.2522) | Acc: (91.67%) (20064/21888)\n",
            "Epoch: 64 | Batch_idx: 180 |  Loss: (0.2529) | Acc: (91.63%) (21229/23168)\n",
            "Epoch: 64 | Batch_idx: 190 |  Loss: (0.2520) | Acc: (91.64%) (22404/24448)\n",
            "Epoch: 64 | Batch_idx: 200 |  Loss: (0.2523) | Acc: (91.62%) (23572/25728)\n",
            "Epoch: 64 | Batch_idx: 210 |  Loss: (0.2542) | Acc: (91.57%) (24732/27008)\n",
            "Epoch: 64 | Batch_idx: 220 |  Loss: (0.2549) | Acc: (91.57%) (25902/28288)\n",
            "Epoch: 64 | Batch_idx: 230 |  Loss: (0.2561) | Acc: (91.56%) (27072/29568)\n",
            "Epoch: 64 | Batch_idx: 240 |  Loss: (0.2539) | Acc: (91.61%) (28260/30848)\n",
            "Epoch: 64 | Batch_idx: 250 |  Loss: (0.2544) | Acc: (91.60%) (29430/32128)\n",
            "Epoch: 64 | Batch_idx: 260 |  Loss: (0.2552) | Acc: (91.59%) (30598/33408)\n",
            "Epoch: 64 | Batch_idx: 270 |  Loss: (0.2568) | Acc: (91.52%) (31748/34688)\n",
            "Epoch: 64 | Batch_idx: 280 |  Loss: (0.2566) | Acc: (91.56%) (32933/35968)\n",
            "Epoch: 64 | Batch_idx: 290 |  Loss: (0.2573) | Acc: (91.52%) (34088/37248)\n",
            "Epoch: 64 | Batch_idx: 300 |  Loss: (0.2583) | Acc: (91.46%) (35238/38528)\n",
            "Epoch: 64 | Batch_idx: 310 |  Loss: (0.2580) | Acc: (91.47%) (36412/39808)\n",
            "Epoch: 64 | Batch_idx: 320 |  Loss: (0.2592) | Acc: (91.41%) (37559/41088)\n",
            "Epoch: 64 | Batch_idx: 330 |  Loss: (0.2585) | Acc: (91.41%) (38730/42368)\n",
            "Epoch: 64 | Batch_idx: 340 |  Loss: (0.2582) | Acc: (91.43%) (39908/43648)\n",
            "Epoch: 64 | Batch_idx: 350 |  Loss: (0.2591) | Acc: (91.40%) (41062/44928)\n",
            "Epoch: 64 | Batch_idx: 360 |  Loss: (0.2592) | Acc: (91.39%) (42231/46208)\n",
            "Epoch: 64 | Batch_idx: 370 |  Loss: (0.2588) | Acc: (91.41%) (43407/47488)\n",
            "Epoch: 64 | Batch_idx: 380 |  Loss: (0.2583) | Acc: (91.42%) (44584/48768)\n",
            "Epoch: 64 | Batch_idx: 390 |  Loss: (0.2585) | Acc: (91.40%) (45701/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4301) | Acc: (87.32%) (8732/10000)\n",
            "Epoch: 65 | Batch_idx: 0 |  Loss: (0.2133) | Acc: (90.62%) (116/128)\n",
            "Epoch: 65 | Batch_idx: 10 |  Loss: (0.2728) | Acc: (90.41%) (1273/1408)\n",
            "Epoch: 65 | Batch_idx: 20 |  Loss: (0.2612) | Acc: (91.59%) (2462/2688)\n",
            "Epoch: 65 | Batch_idx: 30 |  Loss: (0.2552) | Acc: (91.66%) (3637/3968)\n",
            "Epoch: 65 | Batch_idx: 40 |  Loss: (0.2494) | Acc: (91.71%) (4813/5248)\n",
            "Epoch: 65 | Batch_idx: 50 |  Loss: (0.2454) | Acc: (91.85%) (5996/6528)\n",
            "Epoch: 65 | Batch_idx: 60 |  Loss: (0.2509) | Acc: (91.71%) (7161/7808)\n",
            "Epoch: 65 | Batch_idx: 70 |  Loss: (0.2518) | Acc: (91.68%) (8332/9088)\n",
            "Epoch: 65 | Batch_idx: 80 |  Loss: (0.2536) | Acc: (91.69%) (9506/10368)\n",
            "Epoch: 65 | Batch_idx: 90 |  Loss: (0.2547) | Acc: (91.65%) (10675/11648)\n",
            "Epoch: 65 | Batch_idx: 100 |  Loss: (0.2556) | Acc: (91.58%) (11839/12928)\n",
            "Epoch: 65 | Batch_idx: 110 |  Loss: (0.2550) | Acc: (91.62%) (13017/14208)\n",
            "Epoch: 65 | Batch_idx: 120 |  Loss: (0.2580) | Acc: (91.52%) (14174/15488)\n",
            "Epoch: 65 | Batch_idx: 130 |  Loss: (0.2568) | Acc: (91.53%) (15347/16768)\n",
            "Epoch: 65 | Batch_idx: 140 |  Loss: (0.2582) | Acc: (91.49%) (16512/18048)\n",
            "Epoch: 65 | Batch_idx: 150 |  Loss: (0.2608) | Acc: (91.42%) (17669/19328)\n",
            "Epoch: 65 | Batch_idx: 160 |  Loss: (0.2587) | Acc: (91.45%) (18846/20608)\n",
            "Epoch: 65 | Batch_idx: 170 |  Loss: (0.2581) | Acc: (91.39%) (20003/21888)\n",
            "Epoch: 65 | Batch_idx: 180 |  Loss: (0.2586) | Acc: (91.36%) (21167/23168)\n",
            "Epoch: 65 | Batch_idx: 190 |  Loss: (0.2570) | Acc: (91.37%) (22339/24448)\n",
            "Epoch: 65 | Batch_idx: 200 |  Loss: (0.2609) | Acc: (91.28%) (23484/25728)\n",
            "Epoch: 65 | Batch_idx: 210 |  Loss: (0.2616) | Acc: (91.24%) (24641/27008)\n",
            "Epoch: 65 | Batch_idx: 220 |  Loss: (0.2616) | Acc: (91.23%) (25806/28288)\n",
            "Epoch: 65 | Batch_idx: 230 |  Loss: (0.2617) | Acc: (91.17%) (26958/29568)\n",
            "Epoch: 65 | Batch_idx: 240 |  Loss: (0.2623) | Acc: (91.10%) (28104/30848)\n",
            "Epoch: 65 | Batch_idx: 250 |  Loss: (0.2642) | Acc: (91.04%) (29250/32128)\n",
            "Epoch: 65 | Batch_idx: 260 |  Loss: (0.2633) | Acc: (91.08%) (30429/33408)\n",
            "Epoch: 65 | Batch_idx: 270 |  Loss: (0.2620) | Acc: (91.12%) (31606/34688)\n",
            "Epoch: 65 | Batch_idx: 280 |  Loss: (0.2617) | Acc: (91.14%) (32781/35968)\n",
            "Epoch: 65 | Batch_idx: 290 |  Loss: (0.2616) | Acc: (91.15%) (33950/37248)\n",
            "Epoch: 65 | Batch_idx: 300 |  Loss: (0.2620) | Acc: (91.14%) (35115/38528)\n",
            "Epoch: 65 | Batch_idx: 310 |  Loss: (0.2618) | Acc: (91.15%) (36285/39808)\n",
            "Epoch: 65 | Batch_idx: 320 |  Loss: (0.2622) | Acc: (91.13%) (37443/41088)\n",
            "Epoch: 65 | Batch_idx: 330 |  Loss: (0.2627) | Acc: (91.13%) (38610/42368)\n",
            "Epoch: 65 | Batch_idx: 340 |  Loss: (0.2625) | Acc: (91.11%) (39767/43648)\n",
            "Epoch: 65 | Batch_idx: 350 |  Loss: (0.2627) | Acc: (91.13%) (40941/44928)\n",
            "Epoch: 65 | Batch_idx: 360 |  Loss: (0.2630) | Acc: (91.12%) (42107/46208)\n",
            "Epoch: 65 | Batch_idx: 370 |  Loss: (0.2634) | Acc: (91.14%) (43279/47488)\n",
            "Epoch: 65 | Batch_idx: 380 |  Loss: (0.2620) | Acc: (91.18%) (44467/48768)\n",
            "Epoch: 65 | Batch_idx: 390 |  Loss: (0.2620) | Acc: (91.18%) (45591/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4490) | Acc: (86.35%) (8635/10000)\n",
            "Epoch: 66 | Batch_idx: 0 |  Loss: (0.2837) | Acc: (89.06%) (114/128)\n",
            "Epoch: 66 | Batch_idx: 10 |  Loss: (0.2593) | Acc: (91.76%) (1292/1408)\n",
            "Epoch: 66 | Batch_idx: 20 |  Loss: (0.2530) | Acc: (91.52%) (2460/2688)\n",
            "Epoch: 66 | Batch_idx: 30 |  Loss: (0.2558) | Acc: (91.71%) (3639/3968)\n",
            "Epoch: 66 | Batch_idx: 40 |  Loss: (0.2599) | Acc: (91.54%) (4804/5248)\n",
            "Epoch: 66 | Batch_idx: 50 |  Loss: (0.2542) | Acc: (91.61%) (5980/6528)\n",
            "Epoch: 66 | Batch_idx: 60 |  Loss: (0.2525) | Acc: (91.53%) (7147/7808)\n",
            "Epoch: 66 | Batch_idx: 70 |  Loss: (0.2454) | Acc: (91.73%) (8336/9088)\n",
            "Epoch: 66 | Batch_idx: 80 |  Loss: (0.2461) | Acc: (91.74%) (9512/10368)\n",
            "Epoch: 66 | Batch_idx: 90 |  Loss: (0.2450) | Acc: (91.78%) (10691/11648)\n",
            "Epoch: 66 | Batch_idx: 100 |  Loss: (0.2462) | Acc: (91.68%) (11852/12928)\n",
            "Epoch: 66 | Batch_idx: 110 |  Loss: (0.2471) | Acc: (91.58%) (13011/14208)\n",
            "Epoch: 66 | Batch_idx: 120 |  Loss: (0.2470) | Acc: (91.59%) (14185/15488)\n",
            "Epoch: 66 | Batch_idx: 130 |  Loss: (0.2473) | Acc: (91.57%) (15354/16768)\n",
            "Epoch: 66 | Batch_idx: 140 |  Loss: (0.2465) | Acc: (91.69%) (16549/18048)\n",
            "Epoch: 66 | Batch_idx: 150 |  Loss: (0.2466) | Acc: (91.73%) (17730/19328)\n",
            "Epoch: 66 | Batch_idx: 160 |  Loss: (0.2490) | Acc: (91.64%) (18885/20608)\n",
            "Epoch: 66 | Batch_idx: 170 |  Loss: (0.2486) | Acc: (91.62%) (20053/21888)\n",
            "Epoch: 66 | Batch_idx: 180 |  Loss: (0.2504) | Acc: (91.53%) (21206/23168)\n",
            "Epoch: 66 | Batch_idx: 190 |  Loss: (0.2507) | Acc: (91.58%) (22389/24448)\n",
            "Epoch: 66 | Batch_idx: 200 |  Loss: (0.2510) | Acc: (91.58%) (23562/25728)\n",
            "Epoch: 66 | Batch_idx: 210 |  Loss: (0.2505) | Acc: (91.59%) (24737/27008)\n",
            "Epoch: 66 | Batch_idx: 220 |  Loss: (0.2518) | Acc: (91.54%) (25895/28288)\n",
            "Epoch: 66 | Batch_idx: 230 |  Loss: (0.2528) | Acc: (91.52%) (27062/29568)\n",
            "Epoch: 66 | Batch_idx: 240 |  Loss: (0.2529) | Acc: (91.53%) (28236/30848)\n",
            "Epoch: 66 | Batch_idx: 250 |  Loss: (0.2535) | Acc: (91.55%) (29412/32128)\n",
            "Epoch: 66 | Batch_idx: 260 |  Loss: (0.2544) | Acc: (91.52%) (30576/33408)\n",
            "Epoch: 66 | Batch_idx: 270 |  Loss: (0.2546) | Acc: (91.50%) (31741/34688)\n",
            "Epoch: 66 | Batch_idx: 280 |  Loss: (0.2546) | Acc: (91.50%) (32910/35968)\n",
            "Epoch: 66 | Batch_idx: 290 |  Loss: (0.2533) | Acc: (91.55%) (34100/37248)\n",
            "Epoch: 66 | Batch_idx: 300 |  Loss: (0.2546) | Acc: (91.48%) (35246/38528)\n",
            "Epoch: 66 | Batch_idx: 310 |  Loss: (0.2547) | Acc: (91.46%) (36410/39808)\n",
            "Epoch: 66 | Batch_idx: 320 |  Loss: (0.2551) | Acc: (91.44%) (37569/41088)\n",
            "Epoch: 66 | Batch_idx: 330 |  Loss: (0.2556) | Acc: (91.40%) (38726/42368)\n",
            "Epoch: 66 | Batch_idx: 340 |  Loss: (0.2565) | Acc: (91.39%) (39892/43648)\n",
            "Epoch: 66 | Batch_idx: 350 |  Loss: (0.2572) | Acc: (91.36%) (41045/44928)\n",
            "Epoch: 66 | Batch_idx: 360 |  Loss: (0.2575) | Acc: (91.34%) (42208/46208)\n",
            "Epoch: 66 | Batch_idx: 370 |  Loss: (0.2585) | Acc: (91.32%) (43364/47488)\n",
            "Epoch: 66 | Batch_idx: 380 |  Loss: (0.2590) | Acc: (91.32%) (44534/48768)\n",
            "Epoch: 66 | Batch_idx: 390 |  Loss: (0.2596) | Acc: (91.31%) (45657/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3994) | Acc: (87.58%) (8758/10000)\n",
            "Epoch: 67 | Batch_idx: 0 |  Loss: (0.2166) | Acc: (92.97%) (119/128)\n",
            "Epoch: 67 | Batch_idx: 10 |  Loss: (0.2377) | Acc: (91.69%) (1291/1408)\n",
            "Epoch: 67 | Batch_idx: 20 |  Loss: (0.2530) | Acc: (91.44%) (2458/2688)\n",
            "Epoch: 67 | Batch_idx: 30 |  Loss: (0.2468) | Acc: (91.73%) (3640/3968)\n",
            "Epoch: 67 | Batch_idx: 40 |  Loss: (0.2539) | Acc: (91.65%) (4810/5248)\n",
            "Epoch: 67 | Batch_idx: 50 |  Loss: (0.2512) | Acc: (91.62%) (5981/6528)\n",
            "Epoch: 67 | Batch_idx: 60 |  Loss: (0.2498) | Acc: (91.55%) (7148/7808)\n",
            "Epoch: 67 | Batch_idx: 70 |  Loss: (0.2510) | Acc: (91.58%) (8323/9088)\n",
            "Epoch: 67 | Batch_idx: 80 |  Loss: (0.2556) | Acc: (91.51%) (9488/10368)\n",
            "Epoch: 67 | Batch_idx: 90 |  Loss: (0.2559) | Acc: (91.54%) (10662/11648)\n",
            "Epoch: 67 | Batch_idx: 100 |  Loss: (0.2547) | Acc: (91.55%) (11835/12928)\n",
            "Epoch: 67 | Batch_idx: 110 |  Loss: (0.2557) | Acc: (91.53%) (13004/14208)\n",
            "Epoch: 67 | Batch_idx: 120 |  Loss: (0.2556) | Acc: (91.50%) (14171/15488)\n",
            "Epoch: 67 | Batch_idx: 130 |  Loss: (0.2550) | Acc: (91.50%) (15342/16768)\n",
            "Epoch: 67 | Batch_idx: 140 |  Loss: (0.2535) | Acc: (91.58%) (16528/18048)\n",
            "Epoch: 67 | Batch_idx: 150 |  Loss: (0.2546) | Acc: (91.55%) (17695/19328)\n",
            "Epoch: 67 | Batch_idx: 160 |  Loss: (0.2551) | Acc: (91.53%) (18863/20608)\n",
            "Epoch: 67 | Batch_idx: 170 |  Loss: (0.2549) | Acc: (91.53%) (20034/21888)\n",
            "Epoch: 67 | Batch_idx: 180 |  Loss: (0.2555) | Acc: (91.54%) (21207/23168)\n",
            "Epoch: 67 | Batch_idx: 190 |  Loss: (0.2549) | Acc: (91.55%) (22382/24448)\n",
            "Epoch: 67 | Batch_idx: 200 |  Loss: (0.2546) | Acc: (91.55%) (23555/25728)\n",
            "Epoch: 67 | Batch_idx: 210 |  Loss: (0.2554) | Acc: (91.52%) (24719/27008)\n",
            "Epoch: 67 | Batch_idx: 220 |  Loss: (0.2563) | Acc: (91.47%) (25875/28288)\n",
            "Epoch: 67 | Batch_idx: 230 |  Loss: (0.2580) | Acc: (91.43%) (27035/29568)\n",
            "Epoch: 67 | Batch_idx: 240 |  Loss: (0.2593) | Acc: (91.41%) (28197/30848)\n",
            "Epoch: 67 | Batch_idx: 250 |  Loss: (0.2578) | Acc: (91.45%) (29380/32128)\n",
            "Epoch: 67 | Batch_idx: 260 |  Loss: (0.2572) | Acc: (91.50%) (30568/33408)\n",
            "Epoch: 67 | Batch_idx: 270 |  Loss: (0.2577) | Acc: (91.48%) (31732/34688)\n",
            "Epoch: 67 | Batch_idx: 280 |  Loss: (0.2571) | Acc: (91.50%) (32912/35968)\n",
            "Epoch: 67 | Batch_idx: 290 |  Loss: (0.2566) | Acc: (91.51%) (34086/37248)\n",
            "Epoch: 67 | Batch_idx: 300 |  Loss: (0.2586) | Acc: (91.45%) (35232/38528)\n",
            "Epoch: 67 | Batch_idx: 310 |  Loss: (0.2588) | Acc: (91.43%) (36396/39808)\n",
            "Epoch: 67 | Batch_idx: 320 |  Loss: (0.2590) | Acc: (91.42%) (37562/41088)\n",
            "Epoch: 67 | Batch_idx: 330 |  Loss: (0.2589) | Acc: (91.42%) (38733/42368)\n",
            "Epoch: 67 | Batch_idx: 340 |  Loss: (0.2592) | Acc: (91.41%) (39899/43648)\n",
            "Epoch: 67 | Batch_idx: 350 |  Loss: (0.2595) | Acc: (91.38%) (41057/44928)\n",
            "Epoch: 67 | Batch_idx: 360 |  Loss: (0.2588) | Acc: (91.41%) (42238/46208)\n",
            "Epoch: 67 | Batch_idx: 370 |  Loss: (0.2595) | Acc: (91.39%) (43399/47488)\n",
            "Epoch: 67 | Batch_idx: 380 |  Loss: (0.2595) | Acc: (91.39%) (44569/48768)\n",
            "Epoch: 67 | Batch_idx: 390 |  Loss: (0.2596) | Acc: (91.38%) (45692/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4371) | Acc: (85.79%) (8579/10000)\n",
            "Epoch: 68 | Batch_idx: 0 |  Loss: (0.2989) | Acc: (89.84%) (115/128)\n",
            "Epoch: 68 | Batch_idx: 10 |  Loss: (0.2468) | Acc: (91.12%) (1283/1408)\n",
            "Epoch: 68 | Batch_idx: 20 |  Loss: (0.2406) | Acc: (91.63%) (2463/2688)\n",
            "Epoch: 68 | Batch_idx: 30 |  Loss: (0.2467) | Acc: (91.20%) (3619/3968)\n",
            "Epoch: 68 | Batch_idx: 40 |  Loss: (0.2457) | Acc: (91.33%) (4793/5248)\n",
            "Epoch: 68 | Batch_idx: 50 |  Loss: (0.2517) | Acc: (91.21%) (5954/6528)\n",
            "Epoch: 68 | Batch_idx: 60 |  Loss: (0.2590) | Acc: (90.91%) (7098/7808)\n",
            "Epoch: 68 | Batch_idx: 70 |  Loss: (0.2502) | Acc: (91.25%) (8293/9088)\n",
            "Epoch: 68 | Batch_idx: 80 |  Loss: (0.2518) | Acc: (91.23%) (9459/10368)\n",
            "Epoch: 68 | Batch_idx: 90 |  Loss: (0.2523) | Acc: (91.27%) (10631/11648)\n",
            "Epoch: 68 | Batch_idx: 100 |  Loss: (0.2564) | Acc: (91.22%) (11793/12928)\n",
            "Epoch: 68 | Batch_idx: 110 |  Loss: (0.2555) | Acc: (91.33%) (12976/14208)\n",
            "Epoch: 68 | Batch_idx: 120 |  Loss: (0.2538) | Acc: (91.34%) (14147/15488)\n",
            "Epoch: 68 | Batch_idx: 130 |  Loss: (0.2513) | Acc: (91.36%) (15320/16768)\n",
            "Epoch: 68 | Batch_idx: 140 |  Loss: (0.2536) | Acc: (91.36%) (16488/18048)\n",
            "Epoch: 68 | Batch_idx: 150 |  Loss: (0.2546) | Acc: (91.34%) (17654/19328)\n",
            "Epoch: 68 | Batch_idx: 160 |  Loss: (0.2531) | Acc: (91.44%) (18843/20608)\n",
            "Epoch: 68 | Batch_idx: 170 |  Loss: (0.2545) | Acc: (91.36%) (19997/21888)\n",
            "Epoch: 68 | Batch_idx: 180 |  Loss: (0.2557) | Acc: (91.35%) (21164/23168)\n",
            "Epoch: 68 | Batch_idx: 190 |  Loss: (0.2577) | Acc: (91.35%) (22333/24448)\n",
            "Epoch: 68 | Batch_idx: 200 |  Loss: (0.2595) | Acc: (91.29%) (23486/25728)\n",
            "Epoch: 68 | Batch_idx: 210 |  Loss: (0.2591) | Acc: (91.32%) (24664/27008)\n",
            "Epoch: 68 | Batch_idx: 220 |  Loss: (0.2596) | Acc: (91.30%) (25826/28288)\n",
            "Epoch: 68 | Batch_idx: 230 |  Loss: (0.2602) | Acc: (91.25%) (26982/29568)\n",
            "Epoch: 68 | Batch_idx: 240 |  Loss: (0.2591) | Acc: (91.30%) (28164/30848)\n",
            "Epoch: 68 | Batch_idx: 250 |  Loss: (0.2594) | Acc: (91.28%) (29325/32128)\n",
            "Epoch: 68 | Batch_idx: 260 |  Loss: (0.2604) | Acc: (91.23%) (30478/33408)\n",
            "Epoch: 68 | Batch_idx: 270 |  Loss: (0.2609) | Acc: (91.17%) (31626/34688)\n",
            "Epoch: 68 | Batch_idx: 280 |  Loss: (0.2604) | Acc: (91.18%) (32795/35968)\n",
            "Epoch: 68 | Batch_idx: 290 |  Loss: (0.2594) | Acc: (91.22%) (33979/37248)\n",
            "Epoch: 68 | Batch_idx: 300 |  Loss: (0.2613) | Acc: (91.18%) (35130/38528)\n",
            "Epoch: 68 | Batch_idx: 310 |  Loss: (0.2615) | Acc: (91.19%) (36302/39808)\n",
            "Epoch: 68 | Batch_idx: 320 |  Loss: (0.2611) | Acc: (91.21%) (37477/41088)\n",
            "Epoch: 68 | Batch_idx: 330 |  Loss: (0.2603) | Acc: (91.24%) (38656/42368)\n",
            "Epoch: 68 | Batch_idx: 340 |  Loss: (0.2606) | Acc: (91.22%) (39816/43648)\n",
            "Epoch: 68 | Batch_idx: 350 |  Loss: (0.2616) | Acc: (91.21%) (40981/44928)\n",
            "Epoch: 68 | Batch_idx: 360 |  Loss: (0.2607) | Acc: (91.25%) (42165/46208)\n",
            "Epoch: 68 | Batch_idx: 370 |  Loss: (0.2604) | Acc: (91.27%) (43340/47488)\n",
            "Epoch: 68 | Batch_idx: 380 |  Loss: (0.2607) | Acc: (91.29%) (44518/48768)\n",
            "Epoch: 68 | Batch_idx: 390 |  Loss: (0.2601) | Acc: (91.31%) (45653/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4613) | Acc: (86.49%) (8649/10000)\n",
            "Epoch: 69 | Batch_idx: 0 |  Loss: (0.2979) | Acc: (90.62%) (116/128)\n",
            "Epoch: 69 | Batch_idx: 10 |  Loss: (0.2325) | Acc: (92.83%) (1307/1408)\n",
            "Epoch: 69 | Batch_idx: 20 |  Loss: (0.2273) | Acc: (92.63%) (2490/2688)\n",
            "Epoch: 69 | Batch_idx: 30 |  Loss: (0.2280) | Acc: (92.36%) (3665/3968)\n",
            "Epoch: 69 | Batch_idx: 40 |  Loss: (0.2271) | Acc: (92.38%) (4848/5248)\n",
            "Epoch: 69 | Batch_idx: 50 |  Loss: (0.2273) | Acc: (92.43%) (6034/6528)\n",
            "Epoch: 69 | Batch_idx: 60 |  Loss: (0.2244) | Acc: (92.55%) (7226/7808)\n",
            "Epoch: 69 | Batch_idx: 70 |  Loss: (0.2290) | Acc: (92.44%) (8401/9088)\n",
            "Epoch: 69 | Batch_idx: 80 |  Loss: (0.2355) | Acc: (92.33%) (9573/10368)\n",
            "Epoch: 69 | Batch_idx: 90 |  Loss: (0.2372) | Acc: (92.19%) (10738/11648)\n",
            "Epoch: 69 | Batch_idx: 100 |  Loss: (0.2390) | Acc: (92.09%) (11906/12928)\n",
            "Epoch: 69 | Batch_idx: 110 |  Loss: (0.2369) | Acc: (92.15%) (13093/14208)\n",
            "Epoch: 69 | Batch_idx: 120 |  Loss: (0.2367) | Acc: (92.17%) (14275/15488)\n",
            "Epoch: 69 | Batch_idx: 130 |  Loss: (0.2379) | Acc: (92.17%) (15455/16768)\n",
            "Epoch: 69 | Batch_idx: 140 |  Loss: (0.2391) | Acc: (92.10%) (16623/18048)\n",
            "Epoch: 69 | Batch_idx: 150 |  Loss: (0.2413) | Acc: (92.04%) (17790/19328)\n",
            "Epoch: 69 | Batch_idx: 160 |  Loss: (0.2418) | Acc: (91.98%) (18955/20608)\n",
            "Epoch: 69 | Batch_idx: 170 |  Loss: (0.2408) | Acc: (91.95%) (20126/21888)\n",
            "Epoch: 69 | Batch_idx: 180 |  Loss: (0.2432) | Acc: (91.91%) (21293/23168)\n",
            "Epoch: 69 | Batch_idx: 190 |  Loss: (0.2443) | Acc: (91.87%) (22461/24448)\n",
            "Epoch: 69 | Batch_idx: 200 |  Loss: (0.2435) | Acc: (91.87%) (23637/25728)\n",
            "Epoch: 69 | Batch_idx: 210 |  Loss: (0.2454) | Acc: (91.78%) (24787/27008)\n",
            "Epoch: 69 | Batch_idx: 220 |  Loss: (0.2465) | Acc: (91.72%) (25947/28288)\n",
            "Epoch: 69 | Batch_idx: 230 |  Loss: (0.2477) | Acc: (91.68%) (27107/29568)\n",
            "Epoch: 69 | Batch_idx: 240 |  Loss: (0.2471) | Acc: (91.66%) (28276/30848)\n",
            "Epoch: 69 | Batch_idx: 250 |  Loss: (0.2464) | Acc: (91.68%) (29455/32128)\n",
            "Epoch: 69 | Batch_idx: 260 |  Loss: (0.2493) | Acc: (91.61%) (30604/33408)\n",
            "Epoch: 69 | Batch_idx: 270 |  Loss: (0.2499) | Acc: (91.60%) (31773/34688)\n",
            "Epoch: 69 | Batch_idx: 280 |  Loss: (0.2508) | Acc: (91.56%) (32931/35968)\n",
            "Epoch: 69 | Batch_idx: 290 |  Loss: (0.2515) | Acc: (91.54%) (34096/37248)\n",
            "Epoch: 69 | Batch_idx: 300 |  Loss: (0.2515) | Acc: (91.54%) (35270/38528)\n",
            "Epoch: 69 | Batch_idx: 310 |  Loss: (0.2513) | Acc: (91.56%) (36448/39808)\n",
            "Epoch: 69 | Batch_idx: 320 |  Loss: (0.2524) | Acc: (91.55%) (37617/41088)\n",
            "Epoch: 69 | Batch_idx: 330 |  Loss: (0.2543) | Acc: (91.47%) (38753/42368)\n",
            "Epoch: 69 | Batch_idx: 340 |  Loss: (0.2538) | Acc: (91.48%) (39929/43648)\n",
            "Epoch: 69 | Batch_idx: 350 |  Loss: (0.2543) | Acc: (91.47%) (41097/44928)\n",
            "Epoch: 69 | Batch_idx: 360 |  Loss: (0.2546) | Acc: (91.49%) (42275/46208)\n",
            "Epoch: 69 | Batch_idx: 370 |  Loss: (0.2545) | Acc: (91.49%) (43446/47488)\n",
            "Epoch: 69 | Batch_idx: 380 |  Loss: (0.2543) | Acc: (91.48%) (44612/48768)\n",
            "Epoch: 69 | Batch_idx: 390 |  Loss: (0.2552) | Acc: (91.46%) (45732/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4464) | Acc: (85.54%) (8554/10000)\n",
            "Epoch: 70 | Batch_idx: 0 |  Loss: (0.2734) | Acc: (89.84%) (115/128)\n",
            "Epoch: 70 | Batch_idx: 10 |  Loss: (0.2600) | Acc: (90.91%) (1280/1408)\n",
            "Epoch: 70 | Batch_idx: 20 |  Loss: (0.2463) | Acc: (91.89%) (2470/2688)\n",
            "Epoch: 70 | Batch_idx: 30 |  Loss: (0.2461) | Acc: (91.91%) (3647/3968)\n",
            "Epoch: 70 | Batch_idx: 40 |  Loss: (0.2384) | Acc: (92.32%) (4845/5248)\n",
            "Epoch: 70 | Batch_idx: 50 |  Loss: (0.2346) | Acc: (92.40%) (6032/6528)\n",
            "Epoch: 70 | Batch_idx: 60 |  Loss: (0.2339) | Acc: (92.24%) (7202/7808)\n",
            "Epoch: 70 | Batch_idx: 70 |  Loss: (0.2391) | Acc: (92.09%) (8369/9088)\n",
            "Epoch: 70 | Batch_idx: 80 |  Loss: (0.2420) | Acc: (91.99%) (9538/10368)\n",
            "Epoch: 70 | Batch_idx: 90 |  Loss: (0.2464) | Acc: (91.78%) (10690/11648)\n",
            "Epoch: 70 | Batch_idx: 100 |  Loss: (0.2432) | Acc: (91.91%) (11882/12928)\n",
            "Epoch: 70 | Batch_idx: 110 |  Loss: (0.2419) | Acc: (91.89%) (13056/14208)\n",
            "Epoch: 70 | Batch_idx: 120 |  Loss: (0.2400) | Acc: (91.96%) (14242/15488)\n",
            "Epoch: 70 | Batch_idx: 130 |  Loss: (0.2428) | Acc: (91.87%) (15405/16768)\n",
            "Epoch: 70 | Batch_idx: 140 |  Loss: (0.2448) | Acc: (91.81%) (16570/18048)\n",
            "Epoch: 70 | Batch_idx: 150 |  Loss: (0.2458) | Acc: (91.83%) (17749/19328)\n",
            "Epoch: 70 | Batch_idx: 160 |  Loss: (0.2454) | Acc: (91.86%) (18931/20608)\n",
            "Epoch: 70 | Batch_idx: 170 |  Loss: (0.2455) | Acc: (91.85%) (20104/21888)\n",
            "Epoch: 70 | Batch_idx: 180 |  Loss: (0.2439) | Acc: (91.87%) (21285/23168)\n",
            "Epoch: 70 | Batch_idx: 190 |  Loss: (0.2465) | Acc: (91.79%) (22442/24448)\n",
            "Epoch: 70 | Batch_idx: 200 |  Loss: (0.2472) | Acc: (91.79%) (23615/25728)\n",
            "Epoch: 70 | Batch_idx: 210 |  Loss: (0.2483) | Acc: (91.76%) (24782/27008)\n",
            "Epoch: 70 | Batch_idx: 220 |  Loss: (0.2484) | Acc: (91.72%) (25945/28288)\n",
            "Epoch: 70 | Batch_idx: 230 |  Loss: (0.2488) | Acc: (91.68%) (27107/29568)\n",
            "Epoch: 70 | Batch_idx: 240 |  Loss: (0.2485) | Acc: (91.69%) (28284/30848)\n",
            "Epoch: 70 | Batch_idx: 250 |  Loss: (0.2488) | Acc: (91.71%) (29463/32128)\n",
            "Epoch: 70 | Batch_idx: 260 |  Loss: (0.2496) | Acc: (91.70%) (30634/33408)\n",
            "Epoch: 70 | Batch_idx: 270 |  Loss: (0.2506) | Acc: (91.64%) (31787/34688)\n",
            "Epoch: 70 | Batch_idx: 280 |  Loss: (0.2519) | Acc: (91.61%) (32952/35968)\n",
            "Epoch: 70 | Batch_idx: 290 |  Loss: (0.2520) | Acc: (91.60%) (34121/37248)\n",
            "Epoch: 70 | Batch_idx: 300 |  Loss: (0.2525) | Acc: (91.60%) (35292/38528)\n",
            "Epoch: 70 | Batch_idx: 310 |  Loss: (0.2520) | Acc: (91.61%) (36469/39808)\n",
            "Epoch: 70 | Batch_idx: 320 |  Loss: (0.2520) | Acc: (91.61%) (37642/41088)\n",
            "Epoch: 70 | Batch_idx: 330 |  Loss: (0.2526) | Acc: (91.60%) (38810/42368)\n",
            "Epoch: 70 | Batch_idx: 340 |  Loss: (0.2532) | Acc: (91.60%) (39982/43648)\n",
            "Epoch: 70 | Batch_idx: 350 |  Loss: (0.2523) | Acc: (91.62%) (41165/44928)\n",
            "Epoch: 70 | Batch_idx: 360 |  Loss: (0.2528) | Acc: (91.60%) (42328/46208)\n",
            "Epoch: 70 | Batch_idx: 370 |  Loss: (0.2522) | Acc: (91.59%) (43495/47488)\n",
            "Epoch: 70 | Batch_idx: 380 |  Loss: (0.2540) | Acc: (91.56%) (44654/48768)\n",
            "Epoch: 70 | Batch_idx: 390 |  Loss: (0.2551) | Acc: (91.53%) (45766/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4237) | Acc: (86.02%) (8602/10000)\n",
            "Epoch: 71 | Batch_idx: 0 |  Loss: (0.2079) | Acc: (92.97%) (119/128)\n",
            "Epoch: 71 | Batch_idx: 10 |  Loss: (0.2293) | Acc: (91.55%) (1289/1408)\n",
            "Epoch: 71 | Batch_idx: 20 |  Loss: (0.2324) | Acc: (92.37%) (2483/2688)\n",
            "Epoch: 71 | Batch_idx: 30 |  Loss: (0.2360) | Acc: (92.01%) (3651/3968)\n",
            "Epoch: 71 | Batch_idx: 40 |  Loss: (0.2378) | Acc: (91.90%) (4823/5248)\n",
            "Epoch: 71 | Batch_idx: 50 |  Loss: (0.2313) | Acc: (92.20%) (6019/6528)\n",
            "Epoch: 71 | Batch_idx: 60 |  Loss: (0.2315) | Acc: (92.25%) (7203/7808)\n",
            "Epoch: 71 | Batch_idx: 70 |  Loss: (0.2332) | Acc: (92.18%) (8377/9088)\n",
            "Epoch: 71 | Batch_idx: 80 |  Loss: (0.2333) | Acc: (92.10%) (9549/10368)\n",
            "Epoch: 71 | Batch_idx: 90 |  Loss: (0.2323) | Acc: (92.15%) (10734/11648)\n",
            "Epoch: 71 | Batch_idx: 100 |  Loss: (0.2324) | Acc: (92.18%) (11917/12928)\n",
            "Epoch: 71 | Batch_idx: 110 |  Loss: (0.2350) | Acc: (92.05%) (13078/14208)\n",
            "Epoch: 71 | Batch_idx: 120 |  Loss: (0.2376) | Acc: (92.03%) (14254/15488)\n",
            "Epoch: 71 | Batch_idx: 130 |  Loss: (0.2380) | Acc: (92.03%) (15432/16768)\n",
            "Epoch: 71 | Batch_idx: 140 |  Loss: (0.2378) | Acc: (91.97%) (16598/18048)\n",
            "Epoch: 71 | Batch_idx: 150 |  Loss: (0.2380) | Acc: (91.99%) (17779/19328)\n",
            "Epoch: 71 | Batch_idx: 160 |  Loss: (0.2392) | Acc: (91.94%) (18946/20608)\n",
            "Epoch: 71 | Batch_idx: 170 |  Loss: (0.2419) | Acc: (91.80%) (20094/21888)\n",
            "Epoch: 71 | Batch_idx: 180 |  Loss: (0.2432) | Acc: (91.75%) (21256/23168)\n",
            "Epoch: 71 | Batch_idx: 190 |  Loss: (0.2434) | Acc: (91.76%) (22434/24448)\n",
            "Epoch: 71 | Batch_idx: 200 |  Loss: (0.2457) | Acc: (91.68%) (23587/25728)\n",
            "Epoch: 71 | Batch_idx: 210 |  Loss: (0.2446) | Acc: (91.74%) (24778/27008)\n",
            "Epoch: 71 | Batch_idx: 220 |  Loss: (0.2457) | Acc: (91.72%) (25946/28288)\n",
            "Epoch: 71 | Batch_idx: 230 |  Loss: (0.2457) | Acc: (91.73%) (27123/29568)\n",
            "Epoch: 71 | Batch_idx: 240 |  Loss: (0.2447) | Acc: (91.75%) (28303/30848)\n",
            "Epoch: 71 | Batch_idx: 250 |  Loss: (0.2449) | Acc: (91.77%) (29483/32128)\n",
            "Epoch: 71 | Batch_idx: 260 |  Loss: (0.2465) | Acc: (91.74%) (30647/33408)\n",
            "Epoch: 71 | Batch_idx: 270 |  Loss: (0.2480) | Acc: (91.67%) (31800/34688)\n",
            "Epoch: 71 | Batch_idx: 280 |  Loss: (0.2488) | Acc: (91.65%) (32966/35968)\n",
            "Epoch: 71 | Batch_idx: 290 |  Loss: (0.2485) | Acc: (91.66%) (34141/37248)\n",
            "Epoch: 71 | Batch_idx: 300 |  Loss: (0.2480) | Acc: (91.69%) (35326/38528)\n",
            "Epoch: 71 | Batch_idx: 310 |  Loss: (0.2487) | Acc: (91.67%) (36493/39808)\n",
            "Epoch: 71 | Batch_idx: 320 |  Loss: (0.2486) | Acc: (91.67%) (37664/41088)\n",
            "Epoch: 71 | Batch_idx: 330 |  Loss: (0.2490) | Acc: (91.64%) (38827/42368)\n",
            "Epoch: 71 | Batch_idx: 340 |  Loss: (0.2490) | Acc: (91.63%) (39993/43648)\n",
            "Epoch: 71 | Batch_idx: 350 |  Loss: (0.2489) | Acc: (91.63%) (41169/44928)\n",
            "Epoch: 71 | Batch_idx: 360 |  Loss: (0.2500) | Acc: (91.62%) (42337/46208)\n",
            "Epoch: 71 | Batch_idx: 370 |  Loss: (0.2505) | Acc: (91.60%) (43497/47488)\n",
            "Epoch: 71 | Batch_idx: 380 |  Loss: (0.2506) | Acc: (91.59%) (44668/48768)\n",
            "Epoch: 71 | Batch_idx: 390 |  Loss: (0.2510) | Acc: (91.59%) (45797/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4080) | Acc: (87.68%) (8768/10000)\n",
            "Epoch: 72 | Batch_idx: 0 |  Loss: (0.2205) | Acc: (92.97%) (119/128)\n",
            "Epoch: 72 | Batch_idx: 10 |  Loss: (0.2167) | Acc: (92.19%) (1298/1408)\n",
            "Epoch: 72 | Batch_idx: 20 |  Loss: (0.2202) | Acc: (92.11%) (2476/2688)\n",
            "Epoch: 72 | Batch_idx: 30 |  Loss: (0.2175) | Acc: (92.49%) (3670/3968)\n",
            "Epoch: 72 | Batch_idx: 40 |  Loss: (0.2237) | Acc: (92.26%) (4842/5248)\n",
            "Epoch: 72 | Batch_idx: 50 |  Loss: (0.2292) | Acc: (92.08%) (6011/6528)\n",
            "Epoch: 72 | Batch_idx: 60 |  Loss: (0.2258) | Acc: (92.14%) (7194/7808)\n",
            "Epoch: 72 | Batch_idx: 70 |  Loss: (0.2228) | Acc: (92.28%) (8386/9088)\n",
            "Epoch: 72 | Batch_idx: 80 |  Loss: (0.2269) | Acc: (92.25%) (9564/10368)\n",
            "Epoch: 72 | Batch_idx: 90 |  Loss: (0.2305) | Acc: (92.12%) (10730/11648)\n",
            "Epoch: 72 | Batch_idx: 100 |  Loss: (0.2315) | Acc: (92.18%) (11917/12928)\n",
            "Epoch: 72 | Batch_idx: 110 |  Loss: (0.2314) | Acc: (92.16%) (13094/14208)\n",
            "Epoch: 72 | Batch_idx: 120 |  Loss: (0.2320) | Acc: (92.17%) (14276/15488)\n",
            "Epoch: 72 | Batch_idx: 130 |  Loss: (0.2329) | Acc: (92.23%) (15465/16768)\n",
            "Epoch: 72 | Batch_idx: 140 |  Loss: (0.2324) | Acc: (92.28%) (16655/18048)\n",
            "Epoch: 72 | Batch_idx: 150 |  Loss: (0.2338) | Acc: (92.28%) (17836/19328)\n",
            "Epoch: 72 | Batch_idx: 160 |  Loss: (0.2352) | Acc: (92.24%) (19008/20608)\n",
            "Epoch: 72 | Batch_idx: 170 |  Loss: (0.2359) | Acc: (92.20%) (20180/21888)\n",
            "Epoch: 72 | Batch_idx: 180 |  Loss: (0.2368) | Acc: (92.15%) (21349/23168)\n",
            "Epoch: 72 | Batch_idx: 190 |  Loss: (0.2356) | Acc: (92.18%) (22537/24448)\n",
            "Epoch: 72 | Batch_idx: 200 |  Loss: (0.2340) | Acc: (92.21%) (23724/25728)\n",
            "Epoch: 72 | Batch_idx: 210 |  Loss: (0.2350) | Acc: (92.17%) (24892/27008)\n",
            "Epoch: 72 | Batch_idx: 220 |  Loss: (0.2349) | Acc: (92.17%) (26072/28288)\n",
            "Epoch: 72 | Batch_idx: 230 |  Loss: (0.2348) | Acc: (92.17%) (27253/29568)\n",
            "Epoch: 72 | Batch_idx: 240 |  Loss: (0.2359) | Acc: (92.14%) (28422/30848)\n",
            "Epoch: 72 | Batch_idx: 250 |  Loss: (0.2370) | Acc: (92.08%) (29584/32128)\n",
            "Epoch: 72 | Batch_idx: 260 |  Loss: (0.2386) | Acc: (92.03%) (30745/33408)\n",
            "Epoch: 72 | Batch_idx: 270 |  Loss: (0.2410) | Acc: (91.98%) (31906/34688)\n",
            "Epoch: 72 | Batch_idx: 280 |  Loss: (0.2407) | Acc: (92.00%) (33092/35968)\n",
            "Epoch: 72 | Batch_idx: 290 |  Loss: (0.2398) | Acc: (92.01%) (34272/37248)\n",
            "Epoch: 72 | Batch_idx: 300 |  Loss: (0.2404) | Acc: (92.00%) (35447/38528)\n",
            "Epoch: 72 | Batch_idx: 310 |  Loss: (0.2408) | Acc: (91.97%) (36613/39808)\n",
            "Epoch: 72 | Batch_idx: 320 |  Loss: (0.2409) | Acc: (92.00%) (37799/41088)\n",
            "Epoch: 72 | Batch_idx: 330 |  Loss: (0.2411) | Acc: (91.97%) (38964/42368)\n",
            "Epoch: 72 | Batch_idx: 340 |  Loss: (0.2430) | Acc: (91.91%) (40118/43648)\n",
            "Epoch: 72 | Batch_idx: 350 |  Loss: (0.2441) | Acc: (91.90%) (41288/44928)\n",
            "Epoch: 72 | Batch_idx: 360 |  Loss: (0.2437) | Acc: (91.89%) (42461/46208)\n",
            "Epoch: 72 | Batch_idx: 370 |  Loss: (0.2436) | Acc: (91.86%) (43623/47488)\n",
            "Epoch: 72 | Batch_idx: 380 |  Loss: (0.2441) | Acc: (91.83%) (44783/48768)\n",
            "Epoch: 72 | Batch_idx: 390 |  Loss: (0.2443) | Acc: (91.80%) (45899/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4312) | Acc: (86.53%) (8653/10000)\n",
            "Epoch: 73 | Batch_idx: 0 |  Loss: (0.1864) | Acc: (94.53%) (121/128)\n",
            "Epoch: 73 | Batch_idx: 10 |  Loss: (0.2463) | Acc: (92.05%) (1296/1408)\n",
            "Epoch: 73 | Batch_idx: 20 |  Loss: (0.2426) | Acc: (92.34%) (2482/2688)\n",
            "Epoch: 73 | Batch_idx: 30 |  Loss: (0.2417) | Acc: (92.16%) (3657/3968)\n",
            "Epoch: 73 | Batch_idx: 40 |  Loss: (0.2315) | Acc: (92.32%) (4845/5248)\n",
            "Epoch: 73 | Batch_idx: 50 |  Loss: (0.2320) | Acc: (92.20%) (6019/6528)\n",
            "Epoch: 73 | Batch_idx: 60 |  Loss: (0.2340) | Acc: (92.12%) (7193/7808)\n",
            "Epoch: 73 | Batch_idx: 70 |  Loss: (0.2361) | Acc: (91.97%) (8358/9088)\n",
            "Epoch: 73 | Batch_idx: 80 |  Loss: (0.2422) | Acc: (91.80%) (9518/10368)\n",
            "Epoch: 73 | Batch_idx: 90 |  Loss: (0.2447) | Acc: (91.67%) (10678/11648)\n",
            "Epoch: 73 | Batch_idx: 100 |  Loss: (0.2466) | Acc: (91.60%) (11842/12928)\n",
            "Epoch: 73 | Batch_idx: 110 |  Loss: (0.2472) | Acc: (91.48%) (12998/14208)\n",
            "Epoch: 73 | Batch_idx: 120 |  Loss: (0.2470) | Acc: (91.51%) (14173/15488)\n",
            "Epoch: 73 | Batch_idx: 130 |  Loss: (0.2475) | Acc: (91.48%) (15340/16768)\n",
            "Epoch: 73 | Batch_idx: 140 |  Loss: (0.2479) | Acc: (91.51%) (16516/18048)\n",
            "Epoch: 73 | Batch_idx: 150 |  Loss: (0.2492) | Acc: (91.46%) (17678/19328)\n",
            "Epoch: 73 | Batch_idx: 160 |  Loss: (0.2480) | Acc: (91.50%) (18857/20608)\n",
            "Epoch: 73 | Batch_idx: 170 |  Loss: (0.2466) | Acc: (91.57%) (20042/21888)\n",
            "Epoch: 73 | Batch_idx: 180 |  Loss: (0.2463) | Acc: (91.60%) (21223/23168)\n",
            "Epoch: 73 | Batch_idx: 190 |  Loss: (0.2471) | Acc: (91.57%) (22387/24448)\n",
            "Epoch: 73 | Batch_idx: 200 |  Loss: (0.2462) | Acc: (91.61%) (23570/25728)\n",
            "Epoch: 73 | Batch_idx: 210 |  Loss: (0.2459) | Acc: (91.65%) (24753/27008)\n",
            "Epoch: 73 | Batch_idx: 220 |  Loss: (0.2469) | Acc: (91.59%) (25909/28288)\n",
            "Epoch: 73 | Batch_idx: 230 |  Loss: (0.2439) | Acc: (91.68%) (27108/29568)\n",
            "Epoch: 73 | Batch_idx: 240 |  Loss: (0.2447) | Acc: (91.67%) (28279/30848)\n",
            "Epoch: 73 | Batch_idx: 250 |  Loss: (0.2467) | Acc: (91.61%) (29432/32128)\n",
            "Epoch: 73 | Batch_idx: 260 |  Loss: (0.2460) | Acc: (91.68%) (30628/33408)\n",
            "Epoch: 73 | Batch_idx: 270 |  Loss: (0.2459) | Acc: (91.69%) (31805/34688)\n",
            "Epoch: 73 | Batch_idx: 280 |  Loss: (0.2470) | Acc: (91.69%) (32979/35968)\n",
            "Epoch: 73 | Batch_idx: 290 |  Loss: (0.2467) | Acc: (91.70%) (34158/37248)\n",
            "Epoch: 73 | Batch_idx: 300 |  Loss: (0.2466) | Acc: (91.72%) (35336/38528)\n",
            "Epoch: 73 | Batch_idx: 310 |  Loss: (0.2461) | Acc: (91.73%) (36516/39808)\n",
            "Epoch: 73 | Batch_idx: 320 |  Loss: (0.2459) | Acc: (91.73%) (37691/41088)\n",
            "Epoch: 73 | Batch_idx: 330 |  Loss: (0.2458) | Acc: (91.73%) (38865/42368)\n",
            "Epoch: 73 | Batch_idx: 340 |  Loss: (0.2469) | Acc: (91.69%) (40020/43648)\n",
            "Epoch: 73 | Batch_idx: 350 |  Loss: (0.2469) | Acc: (91.68%) (41192/44928)\n",
            "Epoch: 73 | Batch_idx: 360 |  Loss: (0.2468) | Acc: (91.70%) (42371/46208)\n",
            "Epoch: 73 | Batch_idx: 370 |  Loss: (0.2468) | Acc: (91.71%) (43552/47488)\n",
            "Epoch: 73 | Batch_idx: 380 |  Loss: (0.2463) | Acc: (91.74%) (44742/48768)\n",
            "Epoch: 73 | Batch_idx: 390 |  Loss: (0.2472) | Acc: (91.73%) (45863/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4029) | Acc: (87.66%) (8766/10000)\n",
            "Epoch: 74 | Batch_idx: 0 |  Loss: (0.2039) | Acc: (94.53%) (121/128)\n",
            "Epoch: 74 | Batch_idx: 10 |  Loss: (0.2313) | Acc: (92.33%) (1300/1408)\n",
            "Epoch: 74 | Batch_idx: 20 |  Loss: (0.2448) | Acc: (92.00%) (2473/2688)\n",
            "Epoch: 74 | Batch_idx: 30 |  Loss: (0.2441) | Acc: (91.94%) (3648/3968)\n",
            "Epoch: 74 | Batch_idx: 40 |  Loss: (0.2412) | Acc: (91.98%) (4827/5248)\n",
            "Epoch: 74 | Batch_idx: 50 |  Loss: (0.2482) | Acc: (91.71%) (5987/6528)\n",
            "Epoch: 74 | Batch_idx: 60 |  Loss: (0.2445) | Acc: (91.80%) (7168/7808)\n",
            "Epoch: 74 | Batch_idx: 70 |  Loss: (0.2403) | Acc: (92.02%) (8363/9088)\n",
            "Epoch: 74 | Batch_idx: 80 |  Loss: (0.2403) | Acc: (92.02%) (9541/10368)\n",
            "Epoch: 74 | Batch_idx: 90 |  Loss: (0.2407) | Acc: (92.00%) (10716/11648)\n",
            "Epoch: 74 | Batch_idx: 100 |  Loss: (0.2398) | Acc: (91.99%) (11893/12928)\n",
            "Epoch: 74 | Batch_idx: 110 |  Loss: (0.2391) | Acc: (91.98%) (13069/14208)\n",
            "Epoch: 74 | Batch_idx: 120 |  Loss: (0.2400) | Acc: (91.94%) (14240/15488)\n",
            "Epoch: 74 | Batch_idx: 130 |  Loss: (0.2384) | Acc: (92.04%) (15434/16768)\n",
            "Epoch: 74 | Batch_idx: 140 |  Loss: (0.2385) | Acc: (92.03%) (16609/18048)\n",
            "Epoch: 74 | Batch_idx: 150 |  Loss: (0.2370) | Acc: (92.06%) (17793/19328)\n",
            "Epoch: 74 | Batch_idx: 160 |  Loss: (0.2397) | Acc: (91.96%) (18952/20608)\n",
            "Epoch: 74 | Batch_idx: 170 |  Loss: (0.2441) | Acc: (91.84%) (20101/21888)\n",
            "Epoch: 74 | Batch_idx: 180 |  Loss: (0.2450) | Acc: (91.83%) (21276/23168)\n",
            "Epoch: 74 | Batch_idx: 190 |  Loss: (0.2450) | Acc: (91.85%) (22455/24448)\n",
            "Epoch: 74 | Batch_idx: 200 |  Loss: (0.2466) | Acc: (91.74%) (23604/25728)\n",
            "Epoch: 74 | Batch_idx: 210 |  Loss: (0.2485) | Acc: (91.70%) (24767/27008)\n",
            "Epoch: 74 | Batch_idx: 220 |  Loss: (0.2483) | Acc: (91.72%) (25946/28288)\n",
            "Epoch: 74 | Batch_idx: 230 |  Loss: (0.2491) | Acc: (91.71%) (27118/29568)\n",
            "Epoch: 74 | Batch_idx: 240 |  Loss: (0.2485) | Acc: (91.75%) (28303/30848)\n",
            "Epoch: 74 | Batch_idx: 250 |  Loss: (0.2488) | Acc: (91.77%) (29485/32128)\n",
            "Epoch: 74 | Batch_idx: 260 |  Loss: (0.2488) | Acc: (91.77%) (30659/33408)\n",
            "Epoch: 74 | Batch_idx: 270 |  Loss: (0.2498) | Acc: (91.74%) (31824/34688)\n",
            "Epoch: 74 | Batch_idx: 280 |  Loss: (0.2499) | Acc: (91.75%) (32999/35968)\n",
            "Epoch: 74 | Batch_idx: 290 |  Loss: (0.2504) | Acc: (91.75%) (34175/37248)\n",
            "Epoch: 74 | Batch_idx: 300 |  Loss: (0.2496) | Acc: (91.77%) (35357/38528)\n",
            "Epoch: 74 | Batch_idx: 310 |  Loss: (0.2505) | Acc: (91.73%) (36516/39808)\n",
            "Epoch: 74 | Batch_idx: 320 |  Loss: (0.2514) | Acc: (91.69%) (37674/41088)\n",
            "Epoch: 74 | Batch_idx: 330 |  Loss: (0.2521) | Acc: (91.64%) (38828/42368)\n",
            "Epoch: 74 | Batch_idx: 340 |  Loss: (0.2513) | Acc: (91.66%) (40008/43648)\n",
            "Epoch: 74 | Batch_idx: 350 |  Loss: (0.2507) | Acc: (91.66%) (41183/44928)\n",
            "Epoch: 74 | Batch_idx: 360 |  Loss: (0.2499) | Acc: (91.70%) (42372/46208)\n",
            "Epoch: 74 | Batch_idx: 370 |  Loss: (0.2510) | Acc: (91.67%) (43532/47488)\n",
            "Epoch: 74 | Batch_idx: 380 |  Loss: (0.2515) | Acc: (91.65%) (44695/48768)\n",
            "Epoch: 74 | Batch_idx: 390 |  Loss: (0.2514) | Acc: (91.66%) (45828/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3811) | Acc: (88.18%) (8818/10000)\n",
            "Epoch: 75 | Batch_idx: 0 |  Loss: (0.2695) | Acc: (92.97%) (119/128)\n",
            "Epoch: 75 | Batch_idx: 10 |  Loss: (0.2267) | Acc: (93.39%) (1315/1408)\n",
            "Epoch: 75 | Batch_idx: 20 |  Loss: (0.2448) | Acc: (92.00%) (2473/2688)\n",
            "Epoch: 75 | Batch_idx: 30 |  Loss: (0.2480) | Acc: (91.78%) (3642/3968)\n",
            "Epoch: 75 | Batch_idx: 40 |  Loss: (0.2504) | Acc: (91.81%) (4818/5248)\n",
            "Epoch: 75 | Batch_idx: 50 |  Loss: (0.2435) | Acc: (92.06%) (6010/6528)\n",
            "Epoch: 75 | Batch_idx: 60 |  Loss: (0.2460) | Acc: (91.97%) (7181/7808)\n",
            "Epoch: 75 | Batch_idx: 70 |  Loss: (0.2429) | Acc: (92.02%) (8363/9088)\n",
            "Epoch: 75 | Batch_idx: 80 |  Loss: (0.2405) | Acc: (92.07%) (9546/10368)\n",
            "Epoch: 75 | Batch_idx: 90 |  Loss: (0.2411) | Acc: (92.05%) (10722/11648)\n",
            "Epoch: 75 | Batch_idx: 100 |  Loss: (0.2420) | Acc: (92.03%) (11898/12928)\n",
            "Epoch: 75 | Batch_idx: 110 |  Loss: (0.2419) | Acc: (92.00%) (13071/14208)\n",
            "Epoch: 75 | Batch_idx: 120 |  Loss: (0.2408) | Acc: (92.05%) (14257/15488)\n",
            "Epoch: 75 | Batch_idx: 130 |  Loss: (0.2392) | Acc: (92.06%) (15436/16768)\n",
            "Epoch: 75 | Batch_idx: 140 |  Loss: (0.2396) | Acc: (91.99%) (16603/18048)\n",
            "Epoch: 75 | Batch_idx: 150 |  Loss: (0.2404) | Acc: (92.01%) (17784/19328)\n",
            "Epoch: 75 | Batch_idx: 160 |  Loss: (0.2413) | Acc: (91.94%) (18948/20608)\n",
            "Epoch: 75 | Batch_idx: 170 |  Loss: (0.2438) | Acc: (91.91%) (20118/21888)\n",
            "Epoch: 75 | Batch_idx: 180 |  Loss: (0.2428) | Acc: (91.95%) (21302/23168)\n",
            "Epoch: 75 | Batch_idx: 190 |  Loss: (0.2431) | Acc: (91.94%) (22477/24448)\n",
            "Epoch: 75 | Batch_idx: 200 |  Loss: (0.2435) | Acc: (91.93%) (23652/25728)\n",
            "Epoch: 75 | Batch_idx: 210 |  Loss: (0.2433) | Acc: (91.97%) (24839/27008)\n",
            "Epoch: 75 | Batch_idx: 220 |  Loss: (0.2439) | Acc: (91.95%) (26012/28288)\n",
            "Epoch: 75 | Batch_idx: 230 |  Loss: (0.2434) | Acc: (91.97%) (27193/29568)\n",
            "Epoch: 75 | Batch_idx: 240 |  Loss: (0.2442) | Acc: (91.94%) (28361/30848)\n",
            "Epoch: 75 | Batch_idx: 250 |  Loss: (0.2459) | Acc: (91.87%) (29516/32128)\n",
            "Epoch: 75 | Batch_idx: 260 |  Loss: (0.2446) | Acc: (91.91%) (30706/33408)\n",
            "Epoch: 75 | Batch_idx: 270 |  Loss: (0.2450) | Acc: (91.89%) (31874/34688)\n",
            "Epoch: 75 | Batch_idx: 280 |  Loss: (0.2450) | Acc: (91.87%) (33044/35968)\n",
            "Epoch: 75 | Batch_idx: 290 |  Loss: (0.2450) | Acc: (91.88%) (34222/37248)\n",
            "Epoch: 75 | Batch_idx: 300 |  Loss: (0.2452) | Acc: (91.86%) (35392/38528)\n",
            "Epoch: 75 | Batch_idx: 310 |  Loss: (0.2447) | Acc: (91.87%) (36570/39808)\n",
            "Epoch: 75 | Batch_idx: 320 |  Loss: (0.2472) | Acc: (91.84%) (37734/41088)\n",
            "Epoch: 75 | Batch_idx: 330 |  Loss: (0.2482) | Acc: (91.80%) (38893/42368)\n",
            "Epoch: 75 | Batch_idx: 340 |  Loss: (0.2487) | Acc: (91.77%) (40054/43648)\n",
            "Epoch: 75 | Batch_idx: 350 |  Loss: (0.2486) | Acc: (91.78%) (41233/44928)\n",
            "Epoch: 75 | Batch_idx: 360 |  Loss: (0.2494) | Acc: (91.73%) (42385/46208)\n",
            "Epoch: 75 | Batch_idx: 370 |  Loss: (0.2498) | Acc: (91.72%) (43556/47488)\n",
            "Epoch: 75 | Batch_idx: 380 |  Loss: (0.2500) | Acc: (91.70%) (44721/48768)\n",
            "Epoch: 75 | Batch_idx: 390 |  Loss: (0.2506) | Acc: (91.69%) (45843/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4126) | Acc: (87.36%) (8736/10000)\n",
            "Epoch: 76 | Batch_idx: 0 |  Loss: (0.1457) | Acc: (96.09%) (123/128)\n",
            "Epoch: 76 | Batch_idx: 10 |  Loss: (0.2458) | Acc: (91.55%) (1289/1408)\n",
            "Epoch: 76 | Batch_idx: 20 |  Loss: (0.2486) | Acc: (91.44%) (2458/2688)\n",
            "Epoch: 76 | Batch_idx: 30 |  Loss: (0.2489) | Acc: (91.28%) (3622/3968)\n",
            "Epoch: 76 | Batch_idx: 40 |  Loss: (0.2398) | Acc: (91.60%) (4807/5248)\n",
            "Epoch: 76 | Batch_idx: 50 |  Loss: (0.2348) | Acc: (91.68%) (5985/6528)\n",
            "Epoch: 76 | Batch_idx: 60 |  Loss: (0.2315) | Acc: (91.97%) (7181/7808)\n",
            "Epoch: 76 | Batch_idx: 70 |  Loss: (0.2356) | Acc: (91.89%) (8351/9088)\n",
            "Epoch: 76 | Batch_idx: 80 |  Loss: (0.2359) | Acc: (91.94%) (9532/10368)\n",
            "Epoch: 76 | Batch_idx: 90 |  Loss: (0.2355) | Acc: (91.90%) (10704/11648)\n",
            "Epoch: 76 | Batch_idx: 100 |  Loss: (0.2363) | Acc: (91.92%) (11883/12928)\n",
            "Epoch: 76 | Batch_idx: 110 |  Loss: (0.2372) | Acc: (91.91%) (13058/14208)\n",
            "Epoch: 76 | Batch_idx: 120 |  Loss: (0.2411) | Acc: (91.86%) (14227/15488)\n",
            "Epoch: 76 | Batch_idx: 130 |  Loss: (0.2395) | Acc: (91.89%) (15408/16768)\n",
            "Epoch: 76 | Batch_idx: 140 |  Loss: (0.2397) | Acc: (91.90%) (16586/18048)\n",
            "Epoch: 76 | Batch_idx: 150 |  Loss: (0.2405) | Acc: (91.87%) (17756/19328)\n",
            "Epoch: 76 | Batch_idx: 160 |  Loss: (0.2422) | Acc: (91.84%) (18926/20608)\n",
            "Epoch: 76 | Batch_idx: 170 |  Loss: (0.2432) | Acc: (91.83%) (20100/21888)\n",
            "Epoch: 76 | Batch_idx: 180 |  Loss: (0.2434) | Acc: (91.79%) (21265/23168)\n",
            "Epoch: 76 | Batch_idx: 190 |  Loss: (0.2432) | Acc: (91.81%) (22446/24448)\n",
            "Epoch: 76 | Batch_idx: 200 |  Loss: (0.2424) | Acc: (91.84%) (23629/25728)\n",
            "Epoch: 76 | Batch_idx: 210 |  Loss: (0.2412) | Acc: (91.85%) (24808/27008)\n",
            "Epoch: 76 | Batch_idx: 220 |  Loss: (0.2407) | Acc: (91.89%) (25994/28288)\n",
            "Epoch: 76 | Batch_idx: 230 |  Loss: (0.2406) | Acc: (91.89%) (27169/29568)\n",
            "Epoch: 76 | Batch_idx: 240 |  Loss: (0.2417) | Acc: (91.84%) (28332/30848)\n",
            "Epoch: 76 | Batch_idx: 250 |  Loss: (0.2423) | Acc: (91.84%) (29505/32128)\n",
            "Epoch: 76 | Batch_idx: 260 |  Loss: (0.2431) | Acc: (91.80%) (30670/33408)\n",
            "Epoch: 76 | Batch_idx: 270 |  Loss: (0.2417) | Acc: (91.87%) (31867/34688)\n",
            "Epoch: 76 | Batch_idx: 280 |  Loss: (0.2426) | Acc: (91.88%) (33047/35968)\n",
            "Epoch: 76 | Batch_idx: 290 |  Loss: (0.2433) | Acc: (91.84%) (34207/37248)\n",
            "Epoch: 76 | Batch_idx: 300 |  Loss: (0.2443) | Acc: (91.82%) (35376/38528)\n",
            "Epoch: 76 | Batch_idx: 310 |  Loss: (0.2461) | Acc: (91.75%) (36522/39808)\n",
            "Epoch: 76 | Batch_idx: 320 |  Loss: (0.2469) | Acc: (91.72%) (37687/41088)\n",
            "Epoch: 76 | Batch_idx: 330 |  Loss: (0.2469) | Acc: (91.72%) (38862/42368)\n",
            "Epoch: 76 | Batch_idx: 340 |  Loss: (0.2471) | Acc: (91.73%) (40039/43648)\n",
            "Epoch: 76 | Batch_idx: 350 |  Loss: (0.2460) | Acc: (91.76%) (41227/44928)\n",
            "Epoch: 76 | Batch_idx: 360 |  Loss: (0.2451) | Acc: (91.79%) (42414/46208)\n",
            "Epoch: 76 | Batch_idx: 370 |  Loss: (0.2450) | Acc: (91.81%) (43597/47488)\n",
            "Epoch: 76 | Batch_idx: 380 |  Loss: (0.2449) | Acc: (91.82%) (44778/48768)\n",
            "Epoch: 76 | Batch_idx: 390 |  Loss: (0.2448) | Acc: (91.85%) (45924/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4590) | Acc: (86.46%) (8646/10000)\n",
            "Epoch: 77 | Batch_idx: 0 |  Loss: (0.2903) | Acc: (91.41%) (117/128)\n",
            "Epoch: 77 | Batch_idx: 10 |  Loss: (0.2189) | Acc: (92.90%) (1308/1408)\n",
            "Epoch: 77 | Batch_idx: 20 |  Loss: (0.2135) | Acc: (92.67%) (2491/2688)\n",
            "Epoch: 77 | Batch_idx: 30 |  Loss: (0.2193) | Acc: (92.44%) (3668/3968)\n",
            "Epoch: 77 | Batch_idx: 40 |  Loss: (0.2221) | Acc: (92.26%) (4842/5248)\n",
            "Epoch: 77 | Batch_idx: 50 |  Loss: (0.2212) | Acc: (92.37%) (6030/6528)\n",
            "Epoch: 77 | Batch_idx: 60 |  Loss: (0.2243) | Acc: (92.30%) (7207/7808)\n",
            "Epoch: 77 | Batch_idx: 70 |  Loss: (0.2276) | Acc: (92.32%) (8390/9088)\n",
            "Epoch: 77 | Batch_idx: 80 |  Loss: (0.2312) | Acc: (92.19%) (9558/10368)\n",
            "Epoch: 77 | Batch_idx: 90 |  Loss: (0.2343) | Acc: (92.06%) (10723/11648)\n",
            "Epoch: 77 | Batch_idx: 100 |  Loss: (0.2354) | Acc: (91.99%) (11893/12928)\n",
            "Epoch: 77 | Batch_idx: 110 |  Loss: (0.2349) | Acc: (92.02%) (13074/14208)\n",
            "Epoch: 77 | Batch_idx: 120 |  Loss: (0.2376) | Acc: (91.94%) (14239/15488)\n",
            "Epoch: 77 | Batch_idx: 130 |  Loss: (0.2377) | Acc: (91.97%) (15421/16768)\n",
            "Epoch: 77 | Batch_idx: 140 |  Loss: (0.2378) | Acc: (91.93%) (16591/18048)\n",
            "Epoch: 77 | Batch_idx: 150 |  Loss: (0.2369) | Acc: (91.98%) (17778/19328)\n",
            "Epoch: 77 | Batch_idx: 160 |  Loss: (0.2375) | Acc: (91.96%) (18952/20608)\n",
            "Epoch: 77 | Batch_idx: 170 |  Loss: (0.2397) | Acc: (91.90%) (20116/21888)\n",
            "Epoch: 77 | Batch_idx: 180 |  Loss: (0.2405) | Acc: (91.92%) (21296/23168)\n",
            "Epoch: 77 | Batch_idx: 190 |  Loss: (0.2423) | Acc: (91.87%) (22461/24448)\n",
            "Epoch: 77 | Batch_idx: 200 |  Loss: (0.2440) | Acc: (91.81%) (23622/25728)\n",
            "Epoch: 77 | Batch_idx: 210 |  Loss: (0.2429) | Acc: (91.85%) (24806/27008)\n",
            "Epoch: 77 | Batch_idx: 220 |  Loss: (0.2450) | Acc: (91.81%) (25970/28288)\n",
            "Epoch: 77 | Batch_idx: 230 |  Loss: (0.2449) | Acc: (91.81%) (27145/29568)\n",
            "Epoch: 77 | Batch_idx: 240 |  Loss: (0.2424) | Acc: (91.91%) (28352/30848)\n",
            "Epoch: 77 | Batch_idx: 250 |  Loss: (0.2412) | Acc: (91.94%) (29539/32128)\n",
            "Epoch: 77 | Batch_idx: 260 |  Loss: (0.2403) | Acc: (91.97%) (30724/33408)\n",
            "Epoch: 77 | Batch_idx: 270 |  Loss: (0.2419) | Acc: (91.95%) (31895/34688)\n",
            "Epoch: 77 | Batch_idx: 280 |  Loss: (0.2422) | Acc: (91.92%) (33061/35968)\n",
            "Epoch: 77 | Batch_idx: 290 |  Loss: (0.2418) | Acc: (91.94%) (34246/37248)\n",
            "Epoch: 77 | Batch_idx: 300 |  Loss: (0.2421) | Acc: (91.93%) (35418/38528)\n",
            "Epoch: 77 | Batch_idx: 310 |  Loss: (0.2425) | Acc: (91.92%) (36591/39808)\n",
            "Epoch: 77 | Batch_idx: 320 |  Loss: (0.2429) | Acc: (91.90%) (37761/41088)\n",
            "Epoch: 77 | Batch_idx: 330 |  Loss: (0.2436) | Acc: (91.88%) (38927/42368)\n",
            "Epoch: 77 | Batch_idx: 340 |  Loss: (0.2433) | Acc: (91.88%) (40103/43648)\n",
            "Epoch: 77 | Batch_idx: 350 |  Loss: (0.2426) | Acc: (91.91%) (41292/44928)\n",
            "Epoch: 77 | Batch_idx: 360 |  Loss: (0.2422) | Acc: (91.91%) (42469/46208)\n",
            "Epoch: 77 | Batch_idx: 370 |  Loss: (0.2420) | Acc: (91.89%) (43636/47488)\n",
            "Epoch: 77 | Batch_idx: 380 |  Loss: (0.2418) | Acc: (91.89%) (44811/48768)\n",
            "Epoch: 77 | Batch_idx: 390 |  Loss: (0.2423) | Acc: (91.88%) (45938/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4473) | Acc: (86.98%) (8698/10000)\n",
            "Epoch: 78 | Batch_idx: 0 |  Loss: (0.3385) | Acc: (91.41%) (117/128)\n",
            "Epoch: 78 | Batch_idx: 10 |  Loss: (0.2428) | Acc: (93.04%) (1310/1408)\n",
            "Epoch: 78 | Batch_idx: 20 |  Loss: (0.2224) | Acc: (93.56%) (2515/2688)\n",
            "Epoch: 78 | Batch_idx: 30 |  Loss: (0.2206) | Acc: (93.12%) (3695/3968)\n",
            "Epoch: 78 | Batch_idx: 40 |  Loss: (0.2257) | Acc: (92.74%) (4867/5248)\n",
            "Epoch: 78 | Batch_idx: 50 |  Loss: (0.2314) | Acc: (92.33%) (6027/6528)\n",
            "Epoch: 78 | Batch_idx: 60 |  Loss: (0.2396) | Acc: (92.19%) (7198/7808)\n",
            "Epoch: 78 | Batch_idx: 70 |  Loss: (0.2430) | Acc: (92.00%) (8361/9088)\n",
            "Epoch: 78 | Batch_idx: 80 |  Loss: (0.2443) | Acc: (91.98%) (9536/10368)\n",
            "Epoch: 78 | Batch_idx: 90 |  Loss: (0.2461) | Acc: (91.88%) (10702/11648)\n",
            "Epoch: 78 | Batch_idx: 100 |  Loss: (0.2441) | Acc: (91.87%) (11877/12928)\n",
            "Epoch: 78 | Batch_idx: 110 |  Loss: (0.2435) | Acc: (91.92%) (13060/14208)\n",
            "Epoch: 78 | Batch_idx: 120 |  Loss: (0.2435) | Acc: (91.87%) (14229/15488)\n",
            "Epoch: 78 | Batch_idx: 130 |  Loss: (0.2402) | Acc: (91.99%) (15425/16768)\n",
            "Epoch: 78 | Batch_idx: 140 |  Loss: (0.2402) | Acc: (92.04%) (16612/18048)\n",
            "Epoch: 78 | Batch_idx: 150 |  Loss: (0.2421) | Acc: (92.00%) (17782/19328)\n",
            "Epoch: 78 | Batch_idx: 160 |  Loss: (0.2425) | Acc: (92.03%) (18965/20608)\n",
            "Epoch: 78 | Batch_idx: 170 |  Loss: (0.2437) | Acc: (91.94%) (20123/21888)\n",
            "Epoch: 78 | Batch_idx: 180 |  Loss: (0.2440) | Acc: (91.92%) (21297/23168)\n",
            "Epoch: 78 | Batch_idx: 190 |  Loss: (0.2447) | Acc: (91.88%) (22463/24448)\n",
            "Epoch: 78 | Batch_idx: 200 |  Loss: (0.2469) | Acc: (91.81%) (23622/25728)\n",
            "Epoch: 78 | Batch_idx: 210 |  Loss: (0.2474) | Acc: (91.80%) (24792/27008)\n",
            "Epoch: 78 | Batch_idx: 220 |  Loss: (0.2475) | Acc: (91.78%) (25964/28288)\n",
            "Epoch: 78 | Batch_idx: 230 |  Loss: (0.2466) | Acc: (91.81%) (27147/29568)\n",
            "Epoch: 78 | Batch_idx: 240 |  Loss: (0.2446) | Acc: (91.89%) (28346/30848)\n",
            "Epoch: 78 | Batch_idx: 250 |  Loss: (0.2425) | Acc: (91.94%) (29538/32128)\n",
            "Epoch: 78 | Batch_idx: 260 |  Loss: (0.2434) | Acc: (91.88%) (30696/33408)\n",
            "Epoch: 78 | Batch_idx: 270 |  Loss: (0.2431) | Acc: (91.89%) (31874/34688)\n",
            "Epoch: 78 | Batch_idx: 280 |  Loss: (0.2438) | Acc: (91.86%) (33041/35968)\n",
            "Epoch: 78 | Batch_idx: 290 |  Loss: (0.2443) | Acc: (91.87%) (34218/37248)\n",
            "Epoch: 78 | Batch_idx: 300 |  Loss: (0.2454) | Acc: (91.84%) (35384/38528)\n",
            "Epoch: 78 | Batch_idx: 310 |  Loss: (0.2464) | Acc: (91.83%) (36557/39808)\n",
            "Epoch: 78 | Batch_idx: 320 |  Loss: (0.2463) | Acc: (91.84%) (37735/41088)\n",
            "Epoch: 78 | Batch_idx: 330 |  Loss: (0.2459) | Acc: (91.85%) (38916/42368)\n",
            "Epoch: 78 | Batch_idx: 340 |  Loss: (0.2459) | Acc: (91.85%) (40089/43648)\n",
            "Epoch: 78 | Batch_idx: 350 |  Loss: (0.2467) | Acc: (91.82%) (41253/44928)\n",
            "Epoch: 78 | Batch_idx: 360 |  Loss: (0.2460) | Acc: (91.85%) (42442/46208)\n",
            "Epoch: 78 | Batch_idx: 370 |  Loss: (0.2468) | Acc: (91.84%) (43612/47488)\n",
            "Epoch: 78 | Batch_idx: 380 |  Loss: (0.2467) | Acc: (91.83%) (44784/48768)\n",
            "Epoch: 78 | Batch_idx: 390 |  Loss: (0.2468) | Acc: (91.82%) (45908/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4076) | Acc: (87.50%) (8750/10000)\n",
            "Epoch: 79 | Batch_idx: 0 |  Loss: (0.1475) | Acc: (94.53%) (121/128)\n",
            "Epoch: 79 | Batch_idx: 10 |  Loss: (0.2272) | Acc: (92.19%) (1298/1408)\n",
            "Epoch: 79 | Batch_idx: 20 |  Loss: (0.2233) | Acc: (92.82%) (2495/2688)\n",
            "Epoch: 79 | Batch_idx: 30 |  Loss: (0.2201) | Acc: (92.69%) (3678/3968)\n",
            "Epoch: 79 | Batch_idx: 40 |  Loss: (0.2190) | Acc: (92.64%) (4862/5248)\n",
            "Epoch: 79 | Batch_idx: 50 |  Loss: (0.2142) | Acc: (92.97%) (6069/6528)\n",
            "Epoch: 79 | Batch_idx: 60 |  Loss: (0.2187) | Acc: (92.89%) (7253/7808)\n",
            "Epoch: 79 | Batch_idx: 70 |  Loss: (0.2165) | Acc: (92.94%) (8446/9088)\n",
            "Epoch: 79 | Batch_idx: 80 |  Loss: (0.2178) | Acc: (92.92%) (9634/10368)\n",
            "Epoch: 79 | Batch_idx: 90 |  Loss: (0.2211) | Acc: (92.72%) (10800/11648)\n",
            "Epoch: 79 | Batch_idx: 100 |  Loss: (0.2244) | Acc: (92.69%) (11983/12928)\n",
            "Epoch: 79 | Batch_idx: 110 |  Loss: (0.2260) | Acc: (92.74%) (13176/14208)\n",
            "Epoch: 79 | Batch_idx: 120 |  Loss: (0.2263) | Acc: (92.67%) (14353/15488)\n",
            "Epoch: 79 | Batch_idx: 130 |  Loss: (0.2285) | Acc: (92.57%) (15522/16768)\n",
            "Epoch: 79 | Batch_idx: 140 |  Loss: (0.2307) | Acc: (92.48%) (16691/18048)\n",
            "Epoch: 79 | Batch_idx: 150 |  Loss: (0.2328) | Acc: (92.40%) (17859/19328)\n",
            "Epoch: 79 | Batch_idx: 160 |  Loss: (0.2343) | Acc: (92.36%) (19033/20608)\n",
            "Epoch: 79 | Batch_idx: 170 |  Loss: (0.2328) | Acc: (92.38%) (20220/21888)\n",
            "Epoch: 79 | Batch_idx: 180 |  Loss: (0.2317) | Acc: (92.39%) (21405/23168)\n",
            "Epoch: 79 | Batch_idx: 190 |  Loss: (0.2303) | Acc: (92.40%) (22589/24448)\n",
            "Epoch: 79 | Batch_idx: 200 |  Loss: (0.2306) | Acc: (92.41%) (23775/25728)\n",
            "Epoch: 79 | Batch_idx: 210 |  Loss: (0.2300) | Acc: (92.39%) (24953/27008)\n",
            "Epoch: 79 | Batch_idx: 220 |  Loss: (0.2303) | Acc: (92.40%) (26137/28288)\n",
            "Epoch: 79 | Batch_idx: 230 |  Loss: (0.2311) | Acc: (92.38%) (27316/29568)\n",
            "Epoch: 79 | Batch_idx: 240 |  Loss: (0.2314) | Acc: (92.39%) (28501/30848)\n",
            "Epoch: 79 | Batch_idx: 250 |  Loss: (0.2331) | Acc: (92.32%) (29661/32128)\n",
            "Epoch: 79 | Batch_idx: 260 |  Loss: (0.2340) | Acc: (92.25%) (30818/33408)\n",
            "Epoch: 79 | Batch_idx: 270 |  Loss: (0.2356) | Acc: (92.22%) (31991/34688)\n",
            "Epoch: 79 | Batch_idx: 280 |  Loss: (0.2368) | Acc: (92.18%) (33154/35968)\n",
            "Epoch: 79 | Batch_idx: 290 |  Loss: (0.2368) | Acc: (92.17%) (34333/37248)\n",
            "Epoch: 79 | Batch_idx: 300 |  Loss: (0.2386) | Acc: (92.10%) (35484/38528)\n",
            "Epoch: 79 | Batch_idx: 310 |  Loss: (0.2400) | Acc: (92.06%) (36648/39808)\n",
            "Epoch: 79 | Batch_idx: 320 |  Loss: (0.2416) | Acc: (92.01%) (37804/41088)\n",
            "Epoch: 79 | Batch_idx: 330 |  Loss: (0.2413) | Acc: (92.00%) (38977/42368)\n",
            "Epoch: 79 | Batch_idx: 340 |  Loss: (0.2422) | Acc: (91.97%) (40142/43648)\n",
            "Epoch: 79 | Batch_idx: 350 |  Loss: (0.2436) | Acc: (91.91%) (41292/44928)\n",
            "Epoch: 79 | Batch_idx: 360 |  Loss: (0.2437) | Acc: (91.89%) (42462/46208)\n",
            "Epoch: 79 | Batch_idx: 370 |  Loss: (0.2436) | Acc: (91.88%) (43634/47488)\n",
            "Epoch: 79 | Batch_idx: 380 |  Loss: (0.2439) | Acc: (91.88%) (44810/48768)\n",
            "Epoch: 79 | Batch_idx: 390 |  Loss: (0.2444) | Acc: (91.87%) (45937/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.4260) | Acc: (86.50%) (8650/10000)\n",
            "Epoch: 80 | Batch_idx: 0 |  Loss: (0.1344) | Acc: (96.88%) (124/128)\n",
            "Epoch: 80 | Batch_idx: 10 |  Loss: (0.2406) | Acc: (92.26%) (1299/1408)\n",
            "Epoch: 80 | Batch_idx: 20 |  Loss: (0.2277) | Acc: (92.15%) (2477/2688)\n",
            "Epoch: 80 | Batch_idx: 30 |  Loss: (0.2219) | Acc: (92.04%) (3652/3968)\n",
            "Epoch: 80 | Batch_idx: 40 |  Loss: (0.2068) | Acc: (92.74%) (4867/5248)\n",
            "Epoch: 80 | Batch_idx: 50 |  Loss: (0.1980) | Acc: (93.08%) (6076/6528)\n",
            "Epoch: 80 | Batch_idx: 60 |  Loss: (0.1979) | Acc: (93.10%) (7269/7808)\n",
            "Epoch: 80 | Batch_idx: 70 |  Loss: (0.1915) | Acc: (93.32%) (8481/9088)\n",
            "Epoch: 80 | Batch_idx: 80 |  Loss: (0.1856) | Acc: (93.54%) (9698/10368)\n",
            "Epoch: 80 | Batch_idx: 90 |  Loss: (0.1827) | Acc: (93.65%) (10908/11648)\n",
            "Epoch: 80 | Batch_idx: 100 |  Loss: (0.1796) | Acc: (93.76%) (12121/12928)\n",
            "Epoch: 80 | Batch_idx: 110 |  Loss: (0.1776) | Acc: (93.88%) (13339/14208)\n",
            "Epoch: 80 | Batch_idx: 120 |  Loss: (0.1764) | Acc: (93.96%) (14552/15488)\n",
            "Epoch: 80 | Batch_idx: 130 |  Loss: (0.1765) | Acc: (93.96%) (15756/16768)\n",
            "Epoch: 80 | Batch_idx: 140 |  Loss: (0.1762) | Acc: (94.00%) (16966/18048)\n",
            "Epoch: 80 | Batch_idx: 150 |  Loss: (0.1740) | Acc: (94.07%) (18181/19328)\n",
            "Epoch: 80 | Batch_idx: 160 |  Loss: (0.1731) | Acc: (94.12%) (19396/20608)\n",
            "Epoch: 80 | Batch_idx: 170 |  Loss: (0.1724) | Acc: (94.12%) (20602/21888)\n",
            "Epoch: 80 | Batch_idx: 180 |  Loss: (0.1706) | Acc: (94.16%) (21814/23168)\n",
            "Epoch: 80 | Batch_idx: 190 |  Loss: (0.1684) | Acc: (94.24%) (23041/24448)\n",
            "Epoch: 80 | Batch_idx: 200 |  Loss: (0.1678) | Acc: (94.26%) (24251/25728)\n",
            "Epoch: 80 | Batch_idx: 210 |  Loss: (0.1659) | Acc: (94.30%) (25469/27008)\n",
            "Epoch: 80 | Batch_idx: 220 |  Loss: (0.1638) | Acc: (94.38%) (26697/28288)\n",
            "Epoch: 80 | Batch_idx: 230 |  Loss: (0.1628) | Acc: (94.39%) (27910/29568)\n",
            "Epoch: 80 | Batch_idx: 240 |  Loss: (0.1620) | Acc: (94.43%) (29131/30848)\n",
            "Epoch: 80 | Batch_idx: 250 |  Loss: (0.1610) | Acc: (94.48%) (30354/32128)\n",
            "Epoch: 80 | Batch_idx: 260 |  Loss: (0.1603) | Acc: (94.52%) (31576/33408)\n",
            "Epoch: 80 | Batch_idx: 270 |  Loss: (0.1601) | Acc: (94.53%) (32792/34688)\n",
            "Epoch: 80 | Batch_idx: 280 |  Loss: (0.1589) | Acc: (94.57%) (34015/35968)\n",
            "Epoch: 80 | Batch_idx: 290 |  Loss: (0.1579) | Acc: (94.62%) (35244/37248)\n",
            "Epoch: 80 | Batch_idx: 300 |  Loss: (0.1576) | Acc: (94.64%) (36462/38528)\n",
            "Epoch: 80 | Batch_idx: 310 |  Loss: (0.1560) | Acc: (94.69%) (37695/39808)\n",
            "Epoch: 80 | Batch_idx: 320 |  Loss: (0.1548) | Acc: (94.73%) (38921/41088)\n",
            "Epoch: 80 | Batch_idx: 330 |  Loss: (0.1540) | Acc: (94.75%) (40144/42368)\n",
            "Epoch: 80 | Batch_idx: 340 |  Loss: (0.1533) | Acc: (94.77%) (41367/43648)\n",
            "Epoch: 80 | Batch_idx: 350 |  Loss: (0.1518) | Acc: (94.83%) (42603/44928)\n",
            "Epoch: 80 | Batch_idx: 360 |  Loss: (0.1508) | Acc: (94.86%) (43833/46208)\n",
            "Epoch: 80 | Batch_idx: 370 |  Loss: (0.1500) | Acc: (94.88%) (45055/47488)\n",
            "Epoch: 80 | Batch_idx: 380 |  Loss: (0.1499) | Acc: (94.88%) (46269/48768)\n",
            "Epoch: 80 | Batch_idx: 390 |  Loss: (0.1491) | Acc: (94.90%) (47448/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3122) | Acc: (90.52%) (9052/10000)\n",
            "Epoch: 81 | Batch_idx: 0 |  Loss: (0.0534) | Acc: (98.44%) (126/128)\n",
            "Epoch: 81 | Batch_idx: 10 |  Loss: (0.1312) | Acc: (95.74%) (1348/1408)\n",
            "Epoch: 81 | Batch_idx: 20 |  Loss: (0.1114) | Acc: (96.13%) (2584/2688)\n",
            "Epoch: 81 | Batch_idx: 30 |  Loss: (0.1199) | Acc: (95.89%) (3805/3968)\n",
            "Epoch: 81 | Batch_idx: 40 |  Loss: (0.1184) | Acc: (95.88%) (5032/5248)\n",
            "Epoch: 81 | Batch_idx: 50 |  Loss: (0.1174) | Acc: (95.94%) (6263/6528)\n",
            "Epoch: 81 | Batch_idx: 60 |  Loss: (0.1194) | Acc: (95.85%) (7484/7808)\n",
            "Epoch: 81 | Batch_idx: 70 |  Loss: (0.1156) | Acc: (95.94%) (8719/9088)\n",
            "Epoch: 81 | Batch_idx: 80 |  Loss: (0.1174) | Acc: (95.88%) (9941/10368)\n",
            "Epoch: 81 | Batch_idx: 90 |  Loss: (0.1161) | Acc: (95.90%) (11170/11648)\n",
            "Epoch: 81 | Batch_idx: 100 |  Loss: (0.1175) | Acc: (95.86%) (12393/12928)\n",
            "Epoch: 81 | Batch_idx: 110 |  Loss: (0.1167) | Acc: (95.92%) (13629/14208)\n",
            "Epoch: 81 | Batch_idx: 120 |  Loss: (0.1157) | Acc: (95.96%) (14863/15488)\n",
            "Epoch: 81 | Batch_idx: 130 |  Loss: (0.1161) | Acc: (95.99%) (16095/16768)\n",
            "Epoch: 81 | Batch_idx: 140 |  Loss: (0.1144) | Acc: (96.07%) (17338/18048)\n",
            "Epoch: 81 | Batch_idx: 150 |  Loss: (0.1156) | Acc: (96.04%) (18563/19328)\n",
            "Epoch: 81 | Batch_idx: 160 |  Loss: (0.1151) | Acc: (96.05%) (19793/20608)\n",
            "Epoch: 81 | Batch_idx: 170 |  Loss: (0.1150) | Acc: (96.06%) (21026/21888)\n",
            "Epoch: 81 | Batch_idx: 180 |  Loss: (0.1160) | Acc: (96.03%) (22248/23168)\n",
            "Epoch: 81 | Batch_idx: 190 |  Loss: (0.1173) | Acc: (96.01%) (23473/24448)\n",
            "Epoch: 81 | Batch_idx: 200 |  Loss: (0.1164) | Acc: (96.06%) (24714/25728)\n",
            "Epoch: 81 | Batch_idx: 210 |  Loss: (0.1156) | Acc: (96.11%) (25958/27008)\n",
            "Epoch: 81 | Batch_idx: 220 |  Loss: (0.1159) | Acc: (96.08%) (27179/28288)\n",
            "Epoch: 81 | Batch_idx: 230 |  Loss: (0.1173) | Acc: (96.05%) (28399/29568)\n",
            "Epoch: 81 | Batch_idx: 240 |  Loss: (0.1173) | Acc: (96.05%) (29630/30848)\n",
            "Epoch: 81 | Batch_idx: 250 |  Loss: (0.1168) | Acc: (96.07%) (30866/32128)\n",
            "Epoch: 81 | Batch_idx: 260 |  Loss: (0.1171) | Acc: (96.06%) (32093/33408)\n",
            "Epoch: 81 | Batch_idx: 270 |  Loss: (0.1170) | Acc: (96.06%) (33322/34688)\n",
            "Epoch: 81 | Batch_idx: 280 |  Loss: (0.1164) | Acc: (96.05%) (34549/35968)\n",
            "Epoch: 81 | Batch_idx: 290 |  Loss: (0.1165) | Acc: (96.06%) (35779/37248)\n",
            "Epoch: 81 | Batch_idx: 300 |  Loss: (0.1161) | Acc: (96.07%) (37014/38528)\n",
            "Epoch: 81 | Batch_idx: 310 |  Loss: (0.1156) | Acc: (96.08%) (38249/39808)\n",
            "Epoch: 81 | Batch_idx: 320 |  Loss: (0.1151) | Acc: (96.11%) (39488/41088)\n",
            "Epoch: 81 | Batch_idx: 330 |  Loss: (0.1151) | Acc: (96.11%) (40718/42368)\n",
            "Epoch: 81 | Batch_idx: 340 |  Loss: (0.1141) | Acc: (96.14%) (41964/43648)\n",
            "Epoch: 81 | Batch_idx: 350 |  Loss: (0.1150) | Acc: (96.12%) (43183/44928)\n",
            "Epoch: 81 | Batch_idx: 360 |  Loss: (0.1139) | Acc: (96.14%) (44423/46208)\n",
            "Epoch: 81 | Batch_idx: 370 |  Loss: (0.1138) | Acc: (96.14%) (45655/47488)\n",
            "Epoch: 81 | Batch_idx: 380 |  Loss: (0.1139) | Acc: (96.12%) (46876/48768)\n",
            "Epoch: 81 | Batch_idx: 390 |  Loss: (0.1137) | Acc: (96.14%) (48068/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3017) | Acc: (91.05%) (9105/10000)\n",
            "Epoch: 82 | Batch_idx: 0 |  Loss: (0.0741) | Acc: (97.66%) (125/128)\n",
            "Epoch: 82 | Batch_idx: 10 |  Loss: (0.0985) | Acc: (97.16%) (1368/1408)\n",
            "Epoch: 82 | Batch_idx: 20 |  Loss: (0.1012) | Acc: (96.73%) (2600/2688)\n",
            "Epoch: 82 | Batch_idx: 30 |  Loss: (0.1089) | Acc: (96.55%) (3831/3968)\n",
            "Epoch: 82 | Batch_idx: 40 |  Loss: (0.1080) | Acc: (96.42%) (5060/5248)\n",
            "Epoch: 82 | Batch_idx: 50 |  Loss: (0.1066) | Acc: (96.45%) (6296/6528)\n",
            "Epoch: 82 | Batch_idx: 60 |  Loss: (0.1056) | Acc: (96.45%) (7531/7808)\n",
            "Epoch: 82 | Batch_idx: 70 |  Loss: (0.1047) | Acc: (96.46%) (8766/9088)\n",
            "Epoch: 82 | Batch_idx: 80 |  Loss: (0.1021) | Acc: (96.57%) (10012/10368)\n",
            "Epoch: 82 | Batch_idx: 90 |  Loss: (0.1012) | Acc: (96.58%) (11250/11648)\n",
            "Epoch: 82 | Batch_idx: 100 |  Loss: (0.1035) | Acc: (96.53%) (12479/12928)\n",
            "Epoch: 82 | Batch_idx: 110 |  Loss: (0.1018) | Acc: (96.56%) (13719/14208)\n",
            "Epoch: 82 | Batch_idx: 120 |  Loss: (0.1025) | Acc: (96.55%) (14953/15488)\n",
            "Epoch: 82 | Batch_idx: 130 |  Loss: (0.1035) | Acc: (96.49%) (16180/16768)\n",
            "Epoch: 82 | Batch_idx: 140 |  Loss: (0.1038) | Acc: (96.46%) (17410/18048)\n",
            "Epoch: 82 | Batch_idx: 150 |  Loss: (0.1028) | Acc: (96.52%) (18655/19328)\n",
            "Epoch: 82 | Batch_idx: 160 |  Loss: (0.1019) | Acc: (96.53%) (19893/20608)\n",
            "Epoch: 82 | Batch_idx: 170 |  Loss: (0.1021) | Acc: (96.50%) (21121/21888)\n",
            "Epoch: 82 | Batch_idx: 180 |  Loss: (0.1025) | Acc: (96.47%) (22351/23168)\n",
            "Epoch: 82 | Batch_idx: 190 |  Loss: (0.1030) | Acc: (96.43%) (23575/24448)\n",
            "Epoch: 82 | Batch_idx: 200 |  Loss: (0.1023) | Acc: (96.47%) (24819/25728)\n",
            "Epoch: 82 | Batch_idx: 210 |  Loss: (0.1023) | Acc: (96.46%) (26053/27008)\n",
            "Epoch: 82 | Batch_idx: 220 |  Loss: (0.1014) | Acc: (96.48%) (27293/28288)\n",
            "Epoch: 82 | Batch_idx: 230 |  Loss: (0.1010) | Acc: (96.49%) (28529/29568)\n",
            "Epoch: 82 | Batch_idx: 240 |  Loss: (0.1013) | Acc: (96.48%) (29761/30848)\n",
            "Epoch: 82 | Batch_idx: 250 |  Loss: (0.1012) | Acc: (96.48%) (30996/32128)\n",
            "Epoch: 82 | Batch_idx: 260 |  Loss: (0.1012) | Acc: (96.48%) (32233/33408)\n",
            "Epoch: 82 | Batch_idx: 270 |  Loss: (0.1017) | Acc: (96.46%) (33461/34688)\n",
            "Epoch: 82 | Batch_idx: 280 |  Loss: (0.1014) | Acc: (96.48%) (34703/35968)\n",
            "Epoch: 82 | Batch_idx: 290 |  Loss: (0.1014) | Acc: (96.51%) (35947/37248)\n",
            "Epoch: 82 | Batch_idx: 300 |  Loss: (0.1015) | Acc: (96.49%) (37174/38528)\n",
            "Epoch: 82 | Batch_idx: 310 |  Loss: (0.1008) | Acc: (96.51%) (38418/39808)\n",
            "Epoch: 82 | Batch_idx: 320 |  Loss: (0.1004) | Acc: (96.52%) (39658/41088)\n",
            "Epoch: 82 | Batch_idx: 330 |  Loss: (0.1009) | Acc: (96.52%) (40895/42368)\n",
            "Epoch: 82 | Batch_idx: 340 |  Loss: (0.1012) | Acc: (96.50%) (42120/43648)\n",
            "Epoch: 82 | Batch_idx: 350 |  Loss: (0.1007) | Acc: (96.52%) (43364/44928)\n",
            "Epoch: 82 | Batch_idx: 360 |  Loss: (0.1010) | Acc: (96.52%) (44598/46208)\n",
            "Epoch: 82 | Batch_idx: 370 |  Loss: (0.1006) | Acc: (96.53%) (45839/47488)\n",
            "Epoch: 82 | Batch_idx: 380 |  Loss: (0.1003) | Acc: (96.55%) (47085/48768)\n",
            "Epoch: 82 | Batch_idx: 390 |  Loss: (0.1001) | Acc: (96.55%) (48275/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3045) | Acc: (91.33%) (9133/10000)\n",
            "Epoch: 83 | Batch_idx: 0 |  Loss: (0.1335) | Acc: (96.09%) (123/128)\n",
            "Epoch: 83 | Batch_idx: 10 |  Loss: (0.0982) | Acc: (96.52%) (1359/1408)\n",
            "Epoch: 83 | Batch_idx: 20 |  Loss: (0.0999) | Acc: (96.32%) (2589/2688)\n",
            "Epoch: 83 | Batch_idx: 30 |  Loss: (0.0986) | Acc: (96.50%) (3829/3968)\n",
            "Epoch: 83 | Batch_idx: 40 |  Loss: (0.0927) | Acc: (96.72%) (5076/5248)\n",
            "Epoch: 83 | Batch_idx: 50 |  Loss: (0.0914) | Acc: (96.78%) (6318/6528)\n",
            "Epoch: 83 | Batch_idx: 60 |  Loss: (0.0924) | Acc: (96.81%) (7559/7808)\n",
            "Epoch: 83 | Batch_idx: 70 |  Loss: (0.0922) | Acc: (96.76%) (8794/9088)\n",
            "Epoch: 83 | Batch_idx: 80 |  Loss: (0.0930) | Acc: (96.80%) (10036/10368)\n",
            "Epoch: 83 | Batch_idx: 90 |  Loss: (0.0925) | Acc: (96.78%) (11273/11648)\n",
            "Epoch: 83 | Batch_idx: 100 |  Loss: (0.0947) | Acc: (96.70%) (12501/12928)\n",
            "Epoch: 83 | Batch_idx: 110 |  Loss: (0.0935) | Acc: (96.72%) (13742/14208)\n",
            "Epoch: 83 | Batch_idx: 120 |  Loss: (0.0925) | Acc: (96.77%) (14987/15488)\n",
            "Epoch: 83 | Batch_idx: 130 |  Loss: (0.0922) | Acc: (96.79%) (16229/16768)\n",
            "Epoch: 83 | Batch_idx: 140 |  Loss: (0.0928) | Acc: (96.78%) (17466/18048)\n",
            "Epoch: 83 | Batch_idx: 150 |  Loss: (0.0932) | Acc: (96.76%) (18702/19328)\n",
            "Epoch: 83 | Batch_idx: 160 |  Loss: (0.0932) | Acc: (96.77%) (19943/20608)\n",
            "Epoch: 83 | Batch_idx: 170 |  Loss: (0.0940) | Acc: (96.74%) (21175/21888)\n",
            "Epoch: 83 | Batch_idx: 180 |  Loss: (0.0941) | Acc: (96.75%) (22414/23168)\n",
            "Epoch: 83 | Batch_idx: 190 |  Loss: (0.0939) | Acc: (96.74%) (23652/24448)\n",
            "Epoch: 83 | Batch_idx: 200 |  Loss: (0.0940) | Acc: (96.75%) (24893/25728)\n",
            "Epoch: 83 | Batch_idx: 210 |  Loss: (0.0938) | Acc: (96.76%) (26134/27008)\n",
            "Epoch: 83 | Batch_idx: 220 |  Loss: (0.0929) | Acc: (96.80%) (27383/28288)\n",
            "Epoch: 83 | Batch_idx: 230 |  Loss: (0.0923) | Acc: (96.82%) (28627/29568)\n",
            "Epoch: 83 | Batch_idx: 240 |  Loss: (0.0919) | Acc: (96.82%) (29867/30848)\n",
            "Epoch: 83 | Batch_idx: 250 |  Loss: (0.0924) | Acc: (96.81%) (31103/32128)\n",
            "Epoch: 83 | Batch_idx: 260 |  Loss: (0.0918) | Acc: (96.83%) (32349/33408)\n",
            "Epoch: 83 | Batch_idx: 270 |  Loss: (0.0911) | Acc: (96.86%) (33598/34688)\n",
            "Epoch: 83 | Batch_idx: 280 |  Loss: (0.0911) | Acc: (96.86%) (34839/35968)\n",
            "Epoch: 83 | Batch_idx: 290 |  Loss: (0.0913) | Acc: (96.85%) (36075/37248)\n",
            "Epoch: 83 | Batch_idx: 300 |  Loss: (0.0907) | Acc: (96.88%) (37327/38528)\n",
            "Epoch: 83 | Batch_idx: 310 |  Loss: (0.0909) | Acc: (96.88%) (38564/39808)\n",
            "Epoch: 83 | Batch_idx: 320 |  Loss: (0.0904) | Acc: (96.88%) (39806/41088)\n",
            "Epoch: 83 | Batch_idx: 330 |  Loss: (0.0906) | Acc: (96.88%) (41047/42368)\n",
            "Epoch: 83 | Batch_idx: 340 |  Loss: (0.0907) | Acc: (96.86%) (42278/43648)\n",
            "Epoch: 83 | Batch_idx: 350 |  Loss: (0.0913) | Acc: (96.85%) (43513/44928)\n",
            "Epoch: 83 | Batch_idx: 360 |  Loss: (0.0911) | Acc: (96.86%) (44757/46208)\n",
            "Epoch: 83 | Batch_idx: 370 |  Loss: (0.0913) | Acc: (96.86%) (45995/47488)\n",
            "Epoch: 83 | Batch_idx: 380 |  Loss: (0.0911) | Acc: (96.88%) (47244/48768)\n",
            "Epoch: 83 | Batch_idx: 390 |  Loss: (0.0909) | Acc: (96.87%) (48436/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3021) | Acc: (91.17%) (9117/10000)\n",
            "Epoch: 84 | Batch_idx: 0 |  Loss: (0.0799) | Acc: (96.09%) (123/128)\n",
            "Epoch: 84 | Batch_idx: 10 |  Loss: (0.0807) | Acc: (97.37%) (1371/1408)\n",
            "Epoch: 84 | Batch_idx: 20 |  Loss: (0.0769) | Acc: (97.40%) (2618/2688)\n",
            "Epoch: 84 | Batch_idx: 30 |  Loss: (0.0851) | Acc: (97.20%) (3857/3968)\n",
            "Epoch: 84 | Batch_idx: 40 |  Loss: (0.0858) | Acc: (97.08%) (5095/5248)\n",
            "Epoch: 84 | Batch_idx: 50 |  Loss: (0.0847) | Acc: (97.12%) (6340/6528)\n",
            "Epoch: 84 | Batch_idx: 60 |  Loss: (0.0844) | Acc: (97.05%) (7578/7808)\n",
            "Epoch: 84 | Batch_idx: 70 |  Loss: (0.0839) | Acc: (97.07%) (8822/9088)\n",
            "Epoch: 84 | Batch_idx: 80 |  Loss: (0.0823) | Acc: (97.13%) (10070/10368)\n",
            "Epoch: 84 | Batch_idx: 90 |  Loss: (0.0816) | Acc: (97.12%) (11313/11648)\n",
            "Epoch: 84 | Batch_idx: 100 |  Loss: (0.0821) | Acc: (97.11%) (12555/12928)\n",
            "Epoch: 84 | Batch_idx: 110 |  Loss: (0.0832) | Acc: (97.10%) (13796/14208)\n",
            "Epoch: 84 | Batch_idx: 120 |  Loss: (0.0827) | Acc: (97.08%) (15035/15488)\n",
            "Epoch: 84 | Batch_idx: 130 |  Loss: (0.0829) | Acc: (97.05%) (16274/16768)\n",
            "Epoch: 84 | Batch_idx: 140 |  Loss: (0.0830) | Acc: (97.06%) (17517/18048)\n",
            "Epoch: 84 | Batch_idx: 150 |  Loss: (0.0839) | Acc: (97.09%) (18765/19328)\n",
            "Epoch: 84 | Batch_idx: 160 |  Loss: (0.0836) | Acc: (97.08%) (20006/20608)\n",
            "Epoch: 84 | Batch_idx: 170 |  Loss: (0.0834) | Acc: (97.09%) (21250/21888)\n",
            "Epoch: 84 | Batch_idx: 180 |  Loss: (0.0829) | Acc: (97.10%) (22497/23168)\n",
            "Epoch: 84 | Batch_idx: 190 |  Loss: (0.0839) | Acc: (97.09%) (23736/24448)\n",
            "Epoch: 84 | Batch_idx: 200 |  Loss: (0.0857) | Acc: (97.04%) (24967/25728)\n",
            "Epoch: 84 | Batch_idx: 210 |  Loss: (0.0855) | Acc: (97.06%) (26215/27008)\n",
            "Epoch: 84 | Batch_idx: 220 |  Loss: (0.0854) | Acc: (97.08%) (27461/28288)\n",
            "Epoch: 84 | Batch_idx: 230 |  Loss: (0.0847) | Acc: (97.11%) (28713/29568)\n",
            "Epoch: 84 | Batch_idx: 240 |  Loss: (0.0844) | Acc: (97.11%) (29957/30848)\n",
            "Epoch: 84 | Batch_idx: 250 |  Loss: (0.0842) | Acc: (97.10%) (31196/32128)\n",
            "Epoch: 84 | Batch_idx: 260 |  Loss: (0.0840) | Acc: (97.10%) (32439/33408)\n",
            "Epoch: 84 | Batch_idx: 270 |  Loss: (0.0848) | Acc: (97.09%) (33678/34688)\n",
            "Epoch: 84 | Batch_idx: 280 |  Loss: (0.0848) | Acc: (97.09%) (34921/35968)\n",
            "Epoch: 84 | Batch_idx: 290 |  Loss: (0.0848) | Acc: (97.08%) (36159/37248)\n",
            "Epoch: 84 | Batch_idx: 300 |  Loss: (0.0854) | Acc: (97.04%) (37386/38528)\n",
            "Epoch: 84 | Batch_idx: 310 |  Loss: (0.0848) | Acc: (97.06%) (38639/39808)\n",
            "Epoch: 84 | Batch_idx: 320 |  Loss: (0.0842) | Acc: (97.10%) (39895/41088)\n",
            "Epoch: 84 | Batch_idx: 330 |  Loss: (0.0842) | Acc: (97.10%) (41140/42368)\n",
            "Epoch: 84 | Batch_idx: 340 |  Loss: (0.0845) | Acc: (97.09%) (42379/43648)\n",
            "Epoch: 84 | Batch_idx: 350 |  Loss: (0.0841) | Acc: (97.12%) (43633/44928)\n",
            "Epoch: 84 | Batch_idx: 360 |  Loss: (0.0840) | Acc: (97.12%) (44877/46208)\n",
            "Epoch: 84 | Batch_idx: 370 |  Loss: (0.0838) | Acc: (97.13%) (46126/47488)\n",
            "Epoch: 84 | Batch_idx: 380 |  Loss: (0.0836) | Acc: (97.14%) (47375/48768)\n",
            "Epoch: 84 | Batch_idx: 390 |  Loss: (0.0840) | Acc: (97.13%) (48564/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3063) | Acc: (91.40%) (9140/10000)\n",
            "Epoch: 85 | Batch_idx: 0 |  Loss: (0.0163) | Acc: (100.00%) (128/128)\n",
            "Epoch: 85 | Batch_idx: 10 |  Loss: (0.0752) | Acc: (97.80%) (1377/1408)\n",
            "Epoch: 85 | Batch_idx: 20 |  Loss: (0.0718) | Acc: (97.66%) (2625/2688)\n",
            "Epoch: 85 | Batch_idx: 30 |  Loss: (0.0716) | Acc: (97.68%) (3876/3968)\n",
            "Epoch: 85 | Batch_idx: 40 |  Loss: (0.0715) | Acc: (97.68%) (5126/5248)\n",
            "Epoch: 85 | Batch_idx: 50 |  Loss: (0.0693) | Acc: (97.72%) (6379/6528)\n",
            "Epoch: 85 | Batch_idx: 60 |  Loss: (0.0711) | Acc: (97.63%) (7623/7808)\n",
            "Epoch: 85 | Batch_idx: 70 |  Loss: (0.0700) | Acc: (97.65%) (8874/9088)\n",
            "Epoch: 85 | Batch_idx: 80 |  Loss: (0.0710) | Acc: (97.58%) (10117/10368)\n",
            "Epoch: 85 | Batch_idx: 90 |  Loss: (0.0742) | Acc: (97.45%) (11351/11648)\n",
            "Epoch: 85 | Batch_idx: 100 |  Loss: (0.0762) | Acc: (97.39%) (12590/12928)\n",
            "Epoch: 85 | Batch_idx: 110 |  Loss: (0.0746) | Acc: (97.46%) (13847/14208)\n",
            "Epoch: 85 | Batch_idx: 120 |  Loss: (0.0756) | Acc: (97.46%) (15095/15488)\n",
            "Epoch: 85 | Batch_idx: 130 |  Loss: (0.0751) | Acc: (97.50%) (16348/16768)\n",
            "Epoch: 85 | Batch_idx: 140 |  Loss: (0.0757) | Acc: (97.45%) (17587/18048)\n",
            "Epoch: 85 | Batch_idx: 150 |  Loss: (0.0760) | Acc: (97.43%) (18832/19328)\n",
            "Epoch: 85 | Batch_idx: 160 |  Loss: (0.0757) | Acc: (97.43%) (20079/20608)\n",
            "Epoch: 85 | Batch_idx: 170 |  Loss: (0.0759) | Acc: (97.40%) (21318/21888)\n",
            "Epoch: 85 | Batch_idx: 180 |  Loss: (0.0761) | Acc: (97.41%) (22568/23168)\n",
            "Epoch: 85 | Batch_idx: 190 |  Loss: (0.0758) | Acc: (97.41%) (23815/24448)\n",
            "Epoch: 85 | Batch_idx: 200 |  Loss: (0.0768) | Acc: (97.38%) (25053/25728)\n",
            "Epoch: 85 | Batch_idx: 210 |  Loss: (0.0769) | Acc: (97.38%) (26301/27008)\n",
            "Epoch: 85 | Batch_idx: 220 |  Loss: (0.0768) | Acc: (97.38%) (27547/28288)\n",
            "Epoch: 85 | Batch_idx: 230 |  Loss: (0.0774) | Acc: (97.36%) (28786/29568)\n",
            "Epoch: 85 | Batch_idx: 240 |  Loss: (0.0774) | Acc: (97.35%) (30029/30848)\n",
            "Epoch: 85 | Batch_idx: 250 |  Loss: (0.0785) | Acc: (97.31%) (31263/32128)\n",
            "Epoch: 85 | Batch_idx: 260 |  Loss: (0.0783) | Acc: (97.30%) (32506/33408)\n",
            "Epoch: 85 | Batch_idx: 270 |  Loss: (0.0779) | Acc: (97.31%) (33756/34688)\n",
            "Epoch: 85 | Batch_idx: 280 |  Loss: (0.0782) | Acc: (97.31%) (35002/35968)\n",
            "Epoch: 85 | Batch_idx: 290 |  Loss: (0.0792) | Acc: (97.27%) (36232/37248)\n",
            "Epoch: 85 | Batch_idx: 300 |  Loss: (0.0792) | Acc: (97.26%) (37473/38528)\n",
            "Epoch: 85 | Batch_idx: 310 |  Loss: (0.0794) | Acc: (97.25%) (38715/39808)\n",
            "Epoch: 85 | Batch_idx: 320 |  Loss: (0.0793) | Acc: (97.25%) (39960/41088)\n",
            "Epoch: 85 | Batch_idx: 330 |  Loss: (0.0795) | Acc: (97.25%) (41204/42368)\n",
            "Epoch: 85 | Batch_idx: 340 |  Loss: (0.0796) | Acc: (97.26%) (42452/43648)\n",
            "Epoch: 85 | Batch_idx: 350 |  Loss: (0.0795) | Acc: (97.27%) (43703/44928)\n",
            "Epoch: 85 | Batch_idx: 360 |  Loss: (0.0792) | Acc: (97.29%) (44955/46208)\n",
            "Epoch: 85 | Batch_idx: 370 |  Loss: (0.0789) | Acc: (97.31%) (46211/47488)\n",
            "Epoch: 85 | Batch_idx: 380 |  Loss: (0.0790) | Acc: (97.31%) (47455/48768)\n",
            "Epoch: 85 | Batch_idx: 390 |  Loss: (0.0792) | Acc: (97.30%) (48651/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3089) | Acc: (91.34%) (9134/10000)\n",
            "Epoch: 86 | Batch_idx: 0 |  Loss: (0.0647) | Acc: (98.44%) (126/128)\n",
            "Epoch: 86 | Batch_idx: 10 |  Loss: (0.0701) | Acc: (97.37%) (1371/1408)\n",
            "Epoch: 86 | Batch_idx: 20 |  Loss: (0.0763) | Acc: (97.17%) (2612/2688)\n",
            "Epoch: 86 | Batch_idx: 30 |  Loss: (0.0810) | Acc: (97.00%) (3849/3968)\n",
            "Epoch: 86 | Batch_idx: 40 |  Loss: (0.0844) | Acc: (96.89%) (5085/5248)\n",
            "Epoch: 86 | Batch_idx: 50 |  Loss: (0.0813) | Acc: (97.03%) (6334/6528)\n",
            "Epoch: 86 | Batch_idx: 60 |  Loss: (0.0800) | Acc: (97.14%) (7585/7808)\n",
            "Epoch: 86 | Batch_idx: 70 |  Loss: (0.0803) | Acc: (97.14%) (8828/9088)\n",
            "Epoch: 86 | Batch_idx: 80 |  Loss: (0.0783) | Acc: (97.17%) (10075/10368)\n",
            "Epoch: 86 | Batch_idx: 90 |  Loss: (0.0767) | Acc: (97.24%) (11327/11648)\n",
            "Epoch: 86 | Batch_idx: 100 |  Loss: (0.0760) | Acc: (97.29%) (12578/12928)\n",
            "Epoch: 86 | Batch_idx: 110 |  Loss: (0.0769) | Acc: (97.30%) (13825/14208)\n",
            "Epoch: 86 | Batch_idx: 120 |  Loss: (0.0756) | Acc: (97.33%) (15075/15488)\n",
            "Epoch: 86 | Batch_idx: 130 |  Loss: (0.0750) | Acc: (97.33%) (16321/16768)\n",
            "Epoch: 86 | Batch_idx: 140 |  Loss: (0.0747) | Acc: (97.33%) (17567/18048)\n",
            "Epoch: 86 | Batch_idx: 150 |  Loss: (0.0744) | Acc: (97.33%) (18812/19328)\n",
            "Epoch: 86 | Batch_idx: 160 |  Loss: (0.0747) | Acc: (97.32%) (20056/20608)\n",
            "Epoch: 86 | Batch_idx: 170 |  Loss: (0.0745) | Acc: (97.31%) (21300/21888)\n",
            "Epoch: 86 | Batch_idx: 180 |  Loss: (0.0745) | Acc: (97.32%) (22546/23168)\n",
            "Epoch: 86 | Batch_idx: 190 |  Loss: (0.0750) | Acc: (97.30%) (23789/24448)\n",
            "Epoch: 86 | Batch_idx: 200 |  Loss: (0.0755) | Acc: (97.30%) (25034/25728)\n",
            "Epoch: 86 | Batch_idx: 210 |  Loss: (0.0764) | Acc: (97.29%) (26276/27008)\n",
            "Epoch: 86 | Batch_idx: 220 |  Loss: (0.0770) | Acc: (97.29%) (27520/28288)\n",
            "Epoch: 86 | Batch_idx: 230 |  Loss: (0.0761) | Acc: (97.31%) (28774/29568)\n",
            "Epoch: 86 | Batch_idx: 240 |  Loss: (0.0761) | Acc: (97.31%) (30019/30848)\n",
            "Epoch: 86 | Batch_idx: 250 |  Loss: (0.0762) | Acc: (97.32%) (31266/32128)\n",
            "Epoch: 86 | Batch_idx: 260 |  Loss: (0.0763) | Acc: (97.31%) (32509/33408)\n",
            "Epoch: 86 | Batch_idx: 270 |  Loss: (0.0773) | Acc: (97.29%) (33747/34688)\n",
            "Epoch: 86 | Batch_idx: 280 |  Loss: (0.0768) | Acc: (97.29%) (34993/35968)\n",
            "Epoch: 86 | Batch_idx: 290 |  Loss: (0.0767) | Acc: (97.29%) (36239/37248)\n",
            "Epoch: 86 | Batch_idx: 300 |  Loss: (0.0766) | Acc: (97.31%) (37492/38528)\n",
            "Epoch: 86 | Batch_idx: 310 |  Loss: (0.0767) | Acc: (97.29%) (38730/39808)\n",
            "Epoch: 86 | Batch_idx: 320 |  Loss: (0.0773) | Acc: (97.28%) (39969/41088)\n",
            "Epoch: 86 | Batch_idx: 330 |  Loss: (0.0779) | Acc: (97.27%) (41211/42368)\n",
            "Epoch: 86 | Batch_idx: 340 |  Loss: (0.0775) | Acc: (97.27%) (42455/43648)\n",
            "Epoch: 86 | Batch_idx: 350 |  Loss: (0.0776) | Acc: (97.26%) (43699/44928)\n",
            "Epoch: 86 | Batch_idx: 360 |  Loss: (0.0774) | Acc: (97.27%) (44946/46208)\n",
            "Epoch: 86 | Batch_idx: 370 |  Loss: (0.0774) | Acc: (97.27%) (46190/47488)\n",
            "Epoch: 86 | Batch_idx: 380 |  Loss: (0.0770) | Acc: (97.28%) (47443/48768)\n",
            "Epoch: 86 | Batch_idx: 390 |  Loss: (0.0770) | Acc: (97.28%) (48641/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3115) | Acc: (91.58%) (9158/10000)\n",
            "Epoch: 87 | Batch_idx: 0 |  Loss: (0.0615) | Acc: (98.44%) (126/128)\n",
            "Epoch: 87 | Batch_idx: 10 |  Loss: (0.0540) | Acc: (98.30%) (1384/1408)\n",
            "Epoch: 87 | Batch_idx: 20 |  Loss: (0.0607) | Acc: (98.18%) (2639/2688)\n",
            "Epoch: 87 | Batch_idx: 30 |  Loss: (0.0663) | Acc: (97.93%) (3886/3968)\n",
            "Epoch: 87 | Batch_idx: 40 |  Loss: (0.0661) | Acc: (97.79%) (5132/5248)\n",
            "Epoch: 87 | Batch_idx: 50 |  Loss: (0.0666) | Acc: (97.79%) (6384/6528)\n",
            "Epoch: 87 | Batch_idx: 60 |  Loss: (0.0695) | Acc: (97.68%) (7627/7808)\n",
            "Epoch: 87 | Batch_idx: 70 |  Loss: (0.0720) | Acc: (97.52%) (8863/9088)\n",
            "Epoch: 87 | Batch_idx: 80 |  Loss: (0.0734) | Acc: (97.48%) (10107/10368)\n",
            "Epoch: 87 | Batch_idx: 90 |  Loss: (0.0734) | Acc: (97.42%) (11347/11648)\n",
            "Epoch: 87 | Batch_idx: 100 |  Loss: (0.0753) | Acc: (97.42%) (12594/12928)\n",
            "Epoch: 87 | Batch_idx: 110 |  Loss: (0.0750) | Acc: (97.40%) (13839/14208)\n",
            "Epoch: 87 | Batch_idx: 120 |  Loss: (0.0734) | Acc: (97.46%) (15094/15488)\n",
            "Epoch: 87 | Batch_idx: 130 |  Loss: (0.0716) | Acc: (97.53%) (16354/16768)\n",
            "Epoch: 87 | Batch_idx: 140 |  Loss: (0.0719) | Acc: (97.51%) (17599/18048)\n",
            "Epoch: 87 | Batch_idx: 150 |  Loss: (0.0721) | Acc: (97.51%) (18846/19328)\n",
            "Epoch: 87 | Batch_idx: 160 |  Loss: (0.0730) | Acc: (97.49%) (20091/20608)\n",
            "Epoch: 87 | Batch_idx: 170 |  Loss: (0.0730) | Acc: (97.49%) (21339/21888)\n",
            "Epoch: 87 | Batch_idx: 180 |  Loss: (0.0721) | Acc: (97.51%) (22591/23168)\n",
            "Epoch: 87 | Batch_idx: 190 |  Loss: (0.0726) | Acc: (97.50%) (23838/24448)\n",
            "Epoch: 87 | Batch_idx: 200 |  Loss: (0.0716) | Acc: (97.54%) (25095/25728)\n",
            "Epoch: 87 | Batch_idx: 210 |  Loss: (0.0711) | Acc: (97.55%) (26347/27008)\n",
            "Epoch: 87 | Batch_idx: 220 |  Loss: (0.0711) | Acc: (97.57%) (27600/28288)\n",
            "Epoch: 87 | Batch_idx: 230 |  Loss: (0.0713) | Acc: (97.57%) (28849/29568)\n",
            "Epoch: 87 | Batch_idx: 240 |  Loss: (0.0701) | Acc: (97.61%) (30112/30848)\n",
            "Epoch: 87 | Batch_idx: 250 |  Loss: (0.0702) | Acc: (97.60%) (31357/32128)\n",
            "Epoch: 87 | Batch_idx: 260 |  Loss: (0.0704) | Acc: (97.59%) (32603/33408)\n",
            "Epoch: 87 | Batch_idx: 270 |  Loss: (0.0708) | Acc: (97.57%) (33846/34688)\n",
            "Epoch: 87 | Batch_idx: 280 |  Loss: (0.0706) | Acc: (97.58%) (35097/35968)\n",
            "Epoch: 87 | Batch_idx: 290 |  Loss: (0.0704) | Acc: (97.58%) (36345/37248)\n",
            "Epoch: 87 | Batch_idx: 300 |  Loss: (0.0708) | Acc: (97.56%) (37587/38528)\n",
            "Epoch: 87 | Batch_idx: 310 |  Loss: (0.0705) | Acc: (97.58%) (38843/39808)\n",
            "Epoch: 87 | Batch_idx: 320 |  Loss: (0.0701) | Acc: (97.59%) (40096/41088)\n",
            "Epoch: 87 | Batch_idx: 330 |  Loss: (0.0694) | Acc: (97.61%) (41354/42368)\n",
            "Epoch: 87 | Batch_idx: 340 |  Loss: (0.0688) | Acc: (97.63%) (42612/43648)\n",
            "Epoch: 87 | Batch_idx: 350 |  Loss: (0.0690) | Acc: (97.62%) (43860/44928)\n",
            "Epoch: 87 | Batch_idx: 360 |  Loss: (0.0696) | Acc: (97.61%) (45102/46208)\n",
            "Epoch: 87 | Batch_idx: 370 |  Loss: (0.0704) | Acc: (97.58%) (46340/47488)\n",
            "Epoch: 87 | Batch_idx: 380 |  Loss: (0.0700) | Acc: (97.59%) (47594/48768)\n",
            "Epoch: 87 | Batch_idx: 390 |  Loss: (0.0701) | Acc: (97.58%) (48792/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3147) | Acc: (91.35%) (9135/10000)\n",
            "Epoch: 88 | Batch_idx: 0 |  Loss: (0.0477) | Acc: (98.44%) (126/128)\n",
            "Epoch: 88 | Batch_idx: 10 |  Loss: (0.0730) | Acc: (97.94%) (1379/1408)\n",
            "Epoch: 88 | Batch_idx: 20 |  Loss: (0.0765) | Acc: (97.84%) (2630/2688)\n",
            "Epoch: 88 | Batch_idx: 30 |  Loss: (0.0802) | Acc: (97.66%) (3875/3968)\n",
            "Epoch: 88 | Batch_idx: 40 |  Loss: (0.0748) | Acc: (97.69%) (5127/5248)\n",
            "Epoch: 88 | Batch_idx: 50 |  Loss: (0.0735) | Acc: (97.76%) (6382/6528)\n",
            "Epoch: 88 | Batch_idx: 60 |  Loss: (0.0734) | Acc: (97.66%) (7625/7808)\n",
            "Epoch: 88 | Batch_idx: 70 |  Loss: (0.0712) | Acc: (97.74%) (8883/9088)\n",
            "Epoch: 88 | Batch_idx: 80 |  Loss: (0.0742) | Acc: (97.67%) (10126/10368)\n",
            "Epoch: 88 | Batch_idx: 90 |  Loss: (0.0741) | Acc: (97.64%) (11373/11648)\n",
            "Epoch: 88 | Batch_idx: 100 |  Loss: (0.0750) | Acc: (97.56%) (12613/12928)\n",
            "Epoch: 88 | Batch_idx: 110 |  Loss: (0.0754) | Acc: (97.55%) (13860/14208)\n",
            "Epoch: 88 | Batch_idx: 120 |  Loss: (0.0754) | Acc: (97.51%) (15102/15488)\n",
            "Epoch: 88 | Batch_idx: 130 |  Loss: (0.0742) | Acc: (97.54%) (16355/16768)\n",
            "Epoch: 88 | Batch_idx: 140 |  Loss: (0.0743) | Acc: (97.53%) (17602/18048)\n",
            "Epoch: 88 | Batch_idx: 150 |  Loss: (0.0726) | Acc: (97.57%) (18859/19328)\n",
            "Epoch: 88 | Batch_idx: 160 |  Loss: (0.0723) | Acc: (97.56%) (20106/20608)\n",
            "Epoch: 88 | Batch_idx: 170 |  Loss: (0.0724) | Acc: (97.56%) (21353/21888)\n",
            "Epoch: 88 | Batch_idx: 180 |  Loss: (0.0719) | Acc: (97.58%) (22607/23168)\n",
            "Epoch: 88 | Batch_idx: 190 |  Loss: (0.0719) | Acc: (97.59%) (23858/24448)\n",
            "Epoch: 88 | Batch_idx: 200 |  Loss: (0.0717) | Acc: (97.58%) (25106/25728)\n",
            "Epoch: 88 | Batch_idx: 210 |  Loss: (0.0716) | Acc: (97.58%) (26355/27008)\n",
            "Epoch: 88 | Batch_idx: 220 |  Loss: (0.0711) | Acc: (97.62%) (27615/28288)\n",
            "Epoch: 88 | Batch_idx: 230 |  Loss: (0.0716) | Acc: (97.61%) (28860/29568)\n",
            "Epoch: 88 | Batch_idx: 240 |  Loss: (0.0718) | Acc: (97.59%) (30105/30848)\n",
            "Epoch: 88 | Batch_idx: 250 |  Loss: (0.0718) | Acc: (97.60%) (31357/32128)\n",
            "Epoch: 88 | Batch_idx: 260 |  Loss: (0.0711) | Acc: (97.61%) (32608/33408)\n",
            "Epoch: 88 | Batch_idx: 270 |  Loss: (0.0708) | Acc: (97.61%) (33858/34688)\n",
            "Epoch: 88 | Batch_idx: 280 |  Loss: (0.0707) | Acc: (97.62%) (35111/35968)\n",
            "Epoch: 88 | Batch_idx: 290 |  Loss: (0.0708) | Acc: (97.62%) (36360/37248)\n",
            "Epoch: 88 | Batch_idx: 300 |  Loss: (0.0699) | Acc: (97.64%) (37617/38528)\n",
            "Epoch: 88 | Batch_idx: 310 |  Loss: (0.0693) | Acc: (97.65%) (38873/39808)\n",
            "Epoch: 88 | Batch_idx: 320 |  Loss: (0.0694) | Acc: (97.64%) (40119/41088)\n",
            "Epoch: 88 | Batch_idx: 330 |  Loss: (0.0698) | Acc: (97.62%) (41359/42368)\n",
            "Epoch: 88 | Batch_idx: 340 |  Loss: (0.0697) | Acc: (97.62%) (42607/43648)\n",
            "Epoch: 88 | Batch_idx: 350 |  Loss: (0.0697) | Acc: (97.60%) (43851/44928)\n",
            "Epoch: 88 | Batch_idx: 360 |  Loss: (0.0697) | Acc: (97.59%) (45096/46208)\n",
            "Epoch: 88 | Batch_idx: 370 |  Loss: (0.0693) | Acc: (97.60%) (46349/47488)\n",
            "Epoch: 88 | Batch_idx: 380 |  Loss: (0.0687) | Acc: (97.61%) (47602/48768)\n",
            "Epoch: 88 | Batch_idx: 390 |  Loss: (0.0685) | Acc: (97.61%) (48807/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3164) | Acc: (91.55%) (9155/10000)\n",
            "Epoch: 89 | Batch_idx: 0 |  Loss: (0.0392) | Acc: (99.22%) (127/128)\n",
            "Epoch: 89 | Batch_idx: 10 |  Loss: (0.0555) | Acc: (98.01%) (1380/1408)\n",
            "Epoch: 89 | Batch_idx: 20 |  Loss: (0.0615) | Acc: (97.84%) (2630/2688)\n",
            "Epoch: 89 | Batch_idx: 30 |  Loss: (0.0635) | Acc: (97.76%) (3879/3968)\n",
            "Epoch: 89 | Batch_idx: 40 |  Loss: (0.0638) | Acc: (97.77%) (5131/5248)\n",
            "Epoch: 89 | Batch_idx: 50 |  Loss: (0.0659) | Acc: (97.75%) (6381/6528)\n",
            "Epoch: 89 | Batch_idx: 60 |  Loss: (0.0667) | Acc: (97.68%) (7627/7808)\n",
            "Epoch: 89 | Batch_idx: 70 |  Loss: (0.0644) | Acc: (97.78%) (8886/9088)\n",
            "Epoch: 89 | Batch_idx: 80 |  Loss: (0.0664) | Acc: (97.69%) (10128/10368)\n",
            "Epoch: 89 | Batch_idx: 90 |  Loss: (0.0671) | Acc: (97.69%) (11379/11648)\n",
            "Epoch: 89 | Batch_idx: 100 |  Loss: (0.0682) | Acc: (97.70%) (12631/12928)\n",
            "Epoch: 89 | Batch_idx: 110 |  Loss: (0.0694) | Acc: (97.69%) (13880/14208)\n",
            "Epoch: 89 | Batch_idx: 120 |  Loss: (0.0683) | Acc: (97.75%) (15140/15488)\n",
            "Epoch: 89 | Batch_idx: 130 |  Loss: (0.0691) | Acc: (97.73%) (16388/16768)\n",
            "Epoch: 89 | Batch_idx: 140 |  Loss: (0.0687) | Acc: (97.76%) (17644/18048)\n",
            "Epoch: 89 | Batch_idx: 150 |  Loss: (0.0699) | Acc: (97.71%) (18885/19328)\n",
            "Epoch: 89 | Batch_idx: 160 |  Loss: (0.0690) | Acc: (97.71%) (20137/20608)\n",
            "Epoch: 89 | Batch_idx: 170 |  Loss: (0.0687) | Acc: (97.72%) (21390/21888)\n",
            "Epoch: 89 | Batch_idx: 180 |  Loss: (0.0684) | Acc: (97.73%) (22641/23168)\n",
            "Epoch: 89 | Batch_idx: 190 |  Loss: (0.0680) | Acc: (97.73%) (23893/24448)\n",
            "Epoch: 89 | Batch_idx: 200 |  Loss: (0.0679) | Acc: (97.73%) (25145/25728)\n",
            "Epoch: 89 | Batch_idx: 210 |  Loss: (0.0680) | Acc: (97.75%) (26400/27008)\n",
            "Epoch: 89 | Batch_idx: 220 |  Loss: (0.0678) | Acc: (97.73%) (27645/28288)\n",
            "Epoch: 89 | Batch_idx: 230 |  Loss: (0.0676) | Acc: (97.74%) (28900/29568)\n",
            "Epoch: 89 | Batch_idx: 240 |  Loss: (0.0681) | Acc: (97.71%) (30142/30848)\n",
            "Epoch: 89 | Batch_idx: 250 |  Loss: (0.0674) | Acc: (97.72%) (31397/32128)\n",
            "Epoch: 89 | Batch_idx: 260 |  Loss: (0.0679) | Acc: (97.71%) (32644/33408)\n",
            "Epoch: 89 | Batch_idx: 270 |  Loss: (0.0673) | Acc: (97.74%) (33905/34688)\n",
            "Epoch: 89 | Batch_idx: 280 |  Loss: (0.0673) | Acc: (97.73%) (35153/35968)\n",
            "Epoch: 89 | Batch_idx: 290 |  Loss: (0.0672) | Acc: (97.73%) (36403/37248)\n",
            "Epoch: 89 | Batch_idx: 300 |  Loss: (0.0672) | Acc: (97.73%) (37653/38528)\n",
            "Epoch: 89 | Batch_idx: 310 |  Loss: (0.0670) | Acc: (97.74%) (38908/39808)\n",
            "Epoch: 89 | Batch_idx: 320 |  Loss: (0.0671) | Acc: (97.75%) (40162/41088)\n",
            "Epoch: 89 | Batch_idx: 330 |  Loss: (0.0668) | Acc: (97.74%) (41410/42368)\n",
            "Epoch: 89 | Batch_idx: 340 |  Loss: (0.0666) | Acc: (97.74%) (42662/43648)\n",
            "Epoch: 89 | Batch_idx: 350 |  Loss: (0.0664) | Acc: (97.75%) (43915/44928)\n",
            "Epoch: 89 | Batch_idx: 360 |  Loss: (0.0667) | Acc: (97.74%) (45164/46208)\n",
            "Epoch: 89 | Batch_idx: 370 |  Loss: (0.0667) | Acc: (97.74%) (46416/47488)\n",
            "Epoch: 89 | Batch_idx: 380 |  Loss: (0.0666) | Acc: (97.75%) (47669/48768)\n",
            "Epoch: 89 | Batch_idx: 390 |  Loss: (0.0664) | Acc: (97.76%) (48878/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3164) | Acc: (91.58%) (9158/10000)\n",
            "Epoch: 90 | Batch_idx: 0 |  Loss: (0.0695) | Acc: (97.66%) (125/128)\n",
            "Epoch: 90 | Batch_idx: 10 |  Loss: (0.0656) | Acc: (97.73%) (1376/1408)\n",
            "Epoch: 90 | Batch_idx: 20 |  Loss: (0.0637) | Acc: (97.73%) (2627/2688)\n",
            "Epoch: 90 | Batch_idx: 30 |  Loss: (0.0643) | Acc: (97.83%) (3882/3968)\n",
            "Epoch: 90 | Batch_idx: 40 |  Loss: (0.0616) | Acc: (97.87%) (5136/5248)\n",
            "Epoch: 90 | Batch_idx: 50 |  Loss: (0.0598) | Acc: (97.90%) (6391/6528)\n",
            "Epoch: 90 | Batch_idx: 60 |  Loss: (0.0603) | Acc: (97.93%) (7646/7808)\n",
            "Epoch: 90 | Batch_idx: 70 |  Loss: (0.0592) | Acc: (97.98%) (8904/9088)\n",
            "Epoch: 90 | Batch_idx: 80 |  Loss: (0.0575) | Acc: (98.05%) (10166/10368)\n",
            "Epoch: 90 | Batch_idx: 90 |  Loss: (0.0596) | Acc: (97.94%) (11408/11648)\n",
            "Epoch: 90 | Batch_idx: 100 |  Loss: (0.0595) | Acc: (97.93%) (12661/12928)\n",
            "Epoch: 90 | Batch_idx: 110 |  Loss: (0.0582) | Acc: (97.96%) (13918/14208)\n",
            "Epoch: 90 | Batch_idx: 120 |  Loss: (0.0585) | Acc: (97.97%) (15174/15488)\n",
            "Epoch: 90 | Batch_idx: 130 |  Loss: (0.0586) | Acc: (97.95%) (16424/16768)\n",
            "Epoch: 90 | Batch_idx: 140 |  Loss: (0.0595) | Acc: (97.93%) (17674/18048)\n",
            "Epoch: 90 | Batch_idx: 150 |  Loss: (0.0599) | Acc: (97.91%) (18925/19328)\n",
            "Epoch: 90 | Batch_idx: 160 |  Loss: (0.0610) | Acc: (97.89%) (20173/20608)\n",
            "Epoch: 90 | Batch_idx: 170 |  Loss: (0.0612) | Acc: (97.87%) (21421/21888)\n",
            "Epoch: 90 | Batch_idx: 180 |  Loss: (0.0626) | Acc: (97.83%) (22666/23168)\n",
            "Epoch: 90 | Batch_idx: 190 |  Loss: (0.0635) | Acc: (97.78%) (23905/24448)\n",
            "Epoch: 90 | Batch_idx: 200 |  Loss: (0.0630) | Acc: (97.80%) (25162/25728)\n",
            "Epoch: 90 | Batch_idx: 210 |  Loss: (0.0623) | Acc: (97.84%) (26424/27008)\n",
            "Epoch: 90 | Batch_idx: 220 |  Loss: (0.0620) | Acc: (97.84%) (27678/28288)\n",
            "Epoch: 90 | Batch_idx: 230 |  Loss: (0.0618) | Acc: (97.86%) (28934/29568)\n",
            "Epoch: 90 | Batch_idx: 240 |  Loss: (0.0611) | Acc: (97.88%) (30193/30848)\n",
            "Epoch: 90 | Batch_idx: 250 |  Loss: (0.0617) | Acc: (97.85%) (31437/32128)\n",
            "Epoch: 90 | Batch_idx: 260 |  Loss: (0.0624) | Acc: (97.85%) (32689/33408)\n",
            "Epoch: 90 | Batch_idx: 270 |  Loss: (0.0618) | Acc: (97.86%) (33947/34688)\n",
            "Epoch: 90 | Batch_idx: 280 |  Loss: (0.0619) | Acc: (97.86%) (35200/35968)\n",
            "Epoch: 90 | Batch_idx: 290 |  Loss: (0.0616) | Acc: (97.87%) (36456/37248)\n",
            "Epoch: 90 | Batch_idx: 300 |  Loss: (0.0617) | Acc: (97.87%) (37706/38528)\n",
            "Epoch: 90 | Batch_idx: 310 |  Loss: (0.0616) | Acc: (97.86%) (38957/39808)\n",
            "Epoch: 90 | Batch_idx: 320 |  Loss: (0.0619) | Acc: (97.84%) (40200/41088)\n",
            "Epoch: 90 | Batch_idx: 330 |  Loss: (0.0623) | Acc: (97.84%) (41451/42368)\n",
            "Epoch: 90 | Batch_idx: 340 |  Loss: (0.0620) | Acc: (97.86%) (42712/43648)\n",
            "Epoch: 90 | Batch_idx: 350 |  Loss: (0.0618) | Acc: (97.86%) (43967/44928)\n",
            "Epoch: 90 | Batch_idx: 360 |  Loss: (0.0616) | Acc: (97.87%) (45223/46208)\n",
            "Epoch: 90 | Batch_idx: 370 |  Loss: (0.0618) | Acc: (97.88%) (46479/47488)\n",
            "Epoch: 90 | Batch_idx: 380 |  Loss: (0.0618) | Acc: (97.88%) (47735/48768)\n",
            "Epoch: 90 | Batch_idx: 390 |  Loss: (0.0615) | Acc: (97.88%) (48940/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3274) | Acc: (91.46%) (9146/10000)\n",
            "Epoch: 91 | Batch_idx: 0 |  Loss: (0.0426) | Acc: (98.44%) (126/128)\n",
            "Epoch: 91 | Batch_idx: 10 |  Loss: (0.0530) | Acc: (98.22%) (1383/1408)\n",
            "Epoch: 91 | Batch_idx: 20 |  Loss: (0.0582) | Acc: (98.07%) (2636/2688)\n",
            "Epoch: 91 | Batch_idx: 30 |  Loss: (0.0615) | Acc: (97.96%) (3887/3968)\n",
            "Epoch: 91 | Batch_idx: 40 |  Loss: (0.0586) | Acc: (98.02%) (5144/5248)\n",
            "Epoch: 91 | Batch_idx: 50 |  Loss: (0.0573) | Acc: (98.04%) (6400/6528)\n",
            "Epoch: 91 | Batch_idx: 60 |  Loss: (0.0588) | Acc: (97.91%) (7645/7808)\n",
            "Epoch: 91 | Batch_idx: 70 |  Loss: (0.0606) | Acc: (97.88%) (8895/9088)\n",
            "Epoch: 91 | Batch_idx: 80 |  Loss: (0.0611) | Acc: (97.85%) (10145/10368)\n",
            "Epoch: 91 | Batch_idx: 90 |  Loss: (0.0616) | Acc: (97.79%) (11391/11648)\n",
            "Epoch: 91 | Batch_idx: 100 |  Loss: (0.0612) | Acc: (97.83%) (12648/12928)\n",
            "Epoch: 91 | Batch_idx: 110 |  Loss: (0.0617) | Acc: (97.84%) (13901/14208)\n",
            "Epoch: 91 | Batch_idx: 120 |  Loss: (0.0617) | Acc: (97.88%) (15159/15488)\n",
            "Epoch: 91 | Batch_idx: 130 |  Loss: (0.0614) | Acc: (97.89%) (16414/16768)\n",
            "Epoch: 91 | Batch_idx: 140 |  Loss: (0.0617) | Acc: (97.86%) (17662/18048)\n",
            "Epoch: 91 | Batch_idx: 150 |  Loss: (0.0618) | Acc: (97.87%) (18916/19328)\n",
            "Epoch: 91 | Batch_idx: 160 |  Loss: (0.0620) | Acc: (97.89%) (20173/20608)\n",
            "Epoch: 91 | Batch_idx: 170 |  Loss: (0.0612) | Acc: (97.90%) (21429/21888)\n",
            "Epoch: 91 | Batch_idx: 180 |  Loss: (0.0613) | Acc: (97.92%) (22686/23168)\n",
            "Epoch: 91 | Batch_idx: 190 |  Loss: (0.0615) | Acc: (97.93%) (23941/24448)\n",
            "Epoch: 91 | Batch_idx: 200 |  Loss: (0.0620) | Acc: (97.91%) (25191/25728)\n",
            "Epoch: 91 | Batch_idx: 210 |  Loss: (0.0615) | Acc: (97.92%) (26447/27008)\n",
            "Epoch: 91 | Batch_idx: 220 |  Loss: (0.0614) | Acc: (97.92%) (27700/28288)\n",
            "Epoch: 91 | Batch_idx: 230 |  Loss: (0.0624) | Acc: (97.91%) (28949/29568)\n",
            "Epoch: 91 | Batch_idx: 240 |  Loss: (0.0623) | Acc: (97.90%) (30200/30848)\n",
            "Epoch: 91 | Batch_idx: 250 |  Loss: (0.0627) | Acc: (97.88%) (31448/32128)\n",
            "Epoch: 91 | Batch_idx: 260 |  Loss: (0.0626) | Acc: (97.89%) (32702/33408)\n",
            "Epoch: 91 | Batch_idx: 270 |  Loss: (0.0624) | Acc: (97.91%) (33962/34688)\n",
            "Epoch: 91 | Batch_idx: 280 |  Loss: (0.0628) | Acc: (97.92%) (35219/35968)\n",
            "Epoch: 91 | Batch_idx: 290 |  Loss: (0.0624) | Acc: (97.92%) (36473/37248)\n",
            "Epoch: 91 | Batch_idx: 300 |  Loss: (0.0624) | Acc: (97.93%) (37729/38528)\n",
            "Epoch: 91 | Batch_idx: 310 |  Loss: (0.0625) | Acc: (97.93%) (38984/39808)\n",
            "Epoch: 91 | Batch_idx: 320 |  Loss: (0.0618) | Acc: (97.96%) (40251/41088)\n",
            "Epoch: 91 | Batch_idx: 330 |  Loss: (0.0616) | Acc: (97.97%) (41506/42368)\n",
            "Epoch: 91 | Batch_idx: 340 |  Loss: (0.0616) | Acc: (97.96%) (42759/43648)\n",
            "Epoch: 91 | Batch_idx: 350 |  Loss: (0.0614) | Acc: (97.96%) (44010/44928)\n",
            "Epoch: 91 | Batch_idx: 360 |  Loss: (0.0610) | Acc: (97.97%) (45272/46208)\n",
            "Epoch: 91 | Batch_idx: 370 |  Loss: (0.0613) | Acc: (97.97%) (46523/47488)\n",
            "Epoch: 91 | Batch_idx: 380 |  Loss: (0.0610) | Acc: (97.98%) (47784/48768)\n",
            "Epoch: 91 | Batch_idx: 390 |  Loss: (0.0609) | Acc: (98.00%) (48999/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3200) | Acc: (91.53%) (9153/10000)\n",
            "Epoch: 92 | Batch_idx: 0 |  Loss: (0.0154) | Acc: (99.22%) (127/128)\n",
            "Epoch: 92 | Batch_idx: 10 |  Loss: (0.0765) | Acc: (97.23%) (1369/1408)\n",
            "Epoch: 92 | Batch_idx: 20 |  Loss: (0.0702) | Acc: (97.62%) (2624/2688)\n",
            "Epoch: 92 | Batch_idx: 30 |  Loss: (0.0656) | Acc: (97.76%) (3879/3968)\n",
            "Epoch: 92 | Batch_idx: 40 |  Loss: (0.0649) | Acc: (97.85%) (5135/5248)\n",
            "Epoch: 92 | Batch_idx: 50 |  Loss: (0.0649) | Acc: (97.89%) (6390/6528)\n",
            "Epoch: 92 | Batch_idx: 60 |  Loss: (0.0641) | Acc: (97.87%) (7642/7808)\n",
            "Epoch: 92 | Batch_idx: 70 |  Loss: (0.0628) | Acc: (97.84%) (8892/9088)\n",
            "Epoch: 92 | Batch_idx: 80 |  Loss: (0.0635) | Acc: (97.81%) (10141/10368)\n",
            "Epoch: 92 | Batch_idx: 90 |  Loss: (0.0626) | Acc: (97.90%) (11403/11648)\n",
            "Epoch: 92 | Batch_idx: 100 |  Loss: (0.0627) | Acc: (97.93%) (12661/12928)\n",
            "Epoch: 92 | Batch_idx: 110 |  Loss: (0.0624) | Acc: (97.92%) (13913/14208)\n",
            "Epoch: 92 | Batch_idx: 120 |  Loss: (0.0610) | Acc: (97.97%) (15174/15488)\n",
            "Epoch: 92 | Batch_idx: 130 |  Loss: (0.0605) | Acc: (97.95%) (16425/16768)\n",
            "Epoch: 92 | Batch_idx: 140 |  Loss: (0.0591) | Acc: (98.01%) (17688/18048)\n",
            "Epoch: 92 | Batch_idx: 150 |  Loss: (0.0609) | Acc: (97.94%) (18930/19328)\n",
            "Epoch: 92 | Batch_idx: 160 |  Loss: (0.0604) | Acc: (97.97%) (20189/20608)\n",
            "Epoch: 92 | Batch_idx: 170 |  Loss: (0.0594) | Acc: (98.00%) (21451/21888)\n",
            "Epoch: 92 | Batch_idx: 180 |  Loss: (0.0590) | Acc: (98.02%) (22710/23168)\n",
            "Epoch: 92 | Batch_idx: 190 |  Loss: (0.0597) | Acc: (98.01%) (23961/24448)\n",
            "Epoch: 92 | Batch_idx: 200 |  Loss: (0.0598) | Acc: (97.99%) (25211/25728)\n",
            "Epoch: 92 | Batch_idx: 210 |  Loss: (0.0590) | Acc: (98.02%) (26474/27008)\n",
            "Epoch: 92 | Batch_idx: 220 |  Loss: (0.0593) | Acc: (98.01%) (27726/28288)\n",
            "Epoch: 92 | Batch_idx: 230 |  Loss: (0.0590) | Acc: (98.01%) (28980/29568)\n",
            "Epoch: 92 | Batch_idx: 240 |  Loss: (0.0587) | Acc: (98.03%) (30239/30848)\n",
            "Epoch: 92 | Batch_idx: 250 |  Loss: (0.0588) | Acc: (98.02%) (31493/32128)\n",
            "Epoch: 92 | Batch_idx: 260 |  Loss: (0.0588) | Acc: (98.01%) (32743/33408)\n",
            "Epoch: 92 | Batch_idx: 270 |  Loss: (0.0590) | Acc: (98.01%) (33996/34688)\n",
            "Epoch: 92 | Batch_idx: 280 |  Loss: (0.0586) | Acc: (98.01%) (35253/35968)\n",
            "Epoch: 92 | Batch_idx: 290 |  Loss: (0.0591) | Acc: (97.99%) (36501/37248)\n",
            "Epoch: 92 | Batch_idx: 300 |  Loss: (0.0588) | Acc: (98.00%) (37758/38528)\n",
            "Epoch: 92 | Batch_idx: 310 |  Loss: (0.0592) | Acc: (98.00%) (39013/39808)\n",
            "Epoch: 92 | Batch_idx: 320 |  Loss: (0.0591) | Acc: (98.02%) (40273/41088)\n",
            "Epoch: 92 | Batch_idx: 330 |  Loss: (0.0593) | Acc: (98.00%) (41522/42368)\n",
            "Epoch: 92 | Batch_idx: 340 |  Loss: (0.0588) | Acc: (98.02%) (42783/43648)\n",
            "Epoch: 92 | Batch_idx: 350 |  Loss: (0.0583) | Acc: (98.03%) (44045/44928)\n",
            "Epoch: 92 | Batch_idx: 360 |  Loss: (0.0578) | Acc: (98.06%) (45310/46208)\n",
            "Epoch: 92 | Batch_idx: 370 |  Loss: (0.0575) | Acc: (98.07%) (46571/47488)\n",
            "Epoch: 92 | Batch_idx: 380 |  Loss: (0.0575) | Acc: (98.07%) (47825/48768)\n",
            "Epoch: 92 | Batch_idx: 390 |  Loss: (0.0575) | Acc: (98.07%) (49034/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3256) | Acc: (91.36%) (9136/10000)\n",
            "Epoch: 93 | Batch_idx: 0 |  Loss: (0.0842) | Acc: (96.88%) (124/128)\n",
            "Epoch: 93 | Batch_idx: 10 |  Loss: (0.0771) | Acc: (97.80%) (1377/1408)\n",
            "Epoch: 93 | Batch_idx: 20 |  Loss: (0.0625) | Acc: (98.18%) (2639/2688)\n",
            "Epoch: 93 | Batch_idx: 30 |  Loss: (0.0690) | Acc: (97.93%) (3886/3968)\n",
            "Epoch: 93 | Batch_idx: 40 |  Loss: (0.0626) | Acc: (98.19%) (5153/5248)\n",
            "Epoch: 93 | Batch_idx: 50 |  Loss: (0.0632) | Acc: (98.15%) (6407/6528)\n",
            "Epoch: 93 | Batch_idx: 60 |  Loss: (0.0632) | Acc: (98.07%) (7657/7808)\n",
            "Epoch: 93 | Batch_idx: 70 |  Loss: (0.0611) | Acc: (98.13%) (8918/9088)\n",
            "Epoch: 93 | Batch_idx: 80 |  Loss: (0.0608) | Acc: (98.06%) (10167/10368)\n",
            "Epoch: 93 | Batch_idx: 90 |  Loss: (0.0613) | Acc: (98.03%) (11419/11648)\n",
            "Epoch: 93 | Batch_idx: 100 |  Loss: (0.0618) | Acc: (98.00%) (12670/12928)\n",
            "Epoch: 93 | Batch_idx: 110 |  Loss: (0.0630) | Acc: (97.94%) (13915/14208)\n",
            "Epoch: 93 | Batch_idx: 120 |  Loss: (0.0623) | Acc: (97.91%) (15165/15488)\n",
            "Epoch: 93 | Batch_idx: 130 |  Loss: (0.0609) | Acc: (97.94%) (16422/16768)\n",
            "Epoch: 93 | Batch_idx: 140 |  Loss: (0.0605) | Acc: (97.96%) (17679/18048)\n",
            "Epoch: 93 | Batch_idx: 150 |  Loss: (0.0599) | Acc: (97.98%) (18938/19328)\n",
            "Epoch: 93 | Batch_idx: 160 |  Loss: (0.0603) | Acc: (97.96%) (20188/20608)\n",
            "Epoch: 93 | Batch_idx: 170 |  Loss: (0.0602) | Acc: (97.97%) (21444/21888)\n",
            "Epoch: 93 | Batch_idx: 180 |  Loss: (0.0586) | Acc: (98.03%) (22711/23168)\n",
            "Epoch: 93 | Batch_idx: 190 |  Loss: (0.0586) | Acc: (98.02%) (23965/24448)\n",
            "Epoch: 93 | Batch_idx: 200 |  Loss: (0.0578) | Acc: (98.05%) (25227/25728)\n",
            "Epoch: 93 | Batch_idx: 210 |  Loss: (0.0575) | Acc: (98.05%) (26482/27008)\n",
            "Epoch: 93 | Batch_idx: 220 |  Loss: (0.0575) | Acc: (98.05%) (27735/28288)\n",
            "Epoch: 93 | Batch_idx: 230 |  Loss: (0.0573) | Acc: (98.07%) (28997/29568)\n",
            "Epoch: 93 | Batch_idx: 240 |  Loss: (0.0577) | Acc: (98.05%) (30247/30848)\n",
            "Epoch: 93 | Batch_idx: 250 |  Loss: (0.0570) | Acc: (98.07%) (31508/32128)\n",
            "Epoch: 93 | Batch_idx: 260 |  Loss: (0.0585) | Acc: (98.02%) (32745/33408)\n",
            "Epoch: 93 | Batch_idx: 270 |  Loss: (0.0582) | Acc: (98.04%) (34008/34688)\n",
            "Epoch: 93 | Batch_idx: 280 |  Loss: (0.0578) | Acc: (98.05%) (35268/35968)\n",
            "Epoch: 93 | Batch_idx: 290 |  Loss: (0.0582) | Acc: (98.03%) (36515/37248)\n",
            "Epoch: 93 | Batch_idx: 300 |  Loss: (0.0583) | Acc: (98.03%) (37769/38528)\n",
            "Epoch: 93 | Batch_idx: 310 |  Loss: (0.0581) | Acc: (98.02%) (39020/39808)\n",
            "Epoch: 93 | Batch_idx: 320 |  Loss: (0.0579) | Acc: (98.03%) (40279/41088)\n",
            "Epoch: 93 | Batch_idx: 330 |  Loss: (0.0580) | Acc: (98.02%) (41531/42368)\n",
            "Epoch: 93 | Batch_idx: 340 |  Loss: (0.0579) | Acc: (98.02%) (42783/43648)\n",
            "Epoch: 93 | Batch_idx: 350 |  Loss: (0.0579) | Acc: (98.01%) (44036/44928)\n",
            "Epoch: 93 | Batch_idx: 360 |  Loss: (0.0577) | Acc: (98.01%) (45290/46208)\n",
            "Epoch: 93 | Batch_idx: 370 |  Loss: (0.0574) | Acc: (98.03%) (46551/47488)\n",
            "Epoch: 93 | Batch_idx: 380 |  Loss: (0.0568) | Acc: (98.04%) (47811/48768)\n",
            "Epoch: 93 | Batch_idx: 390 |  Loss: (0.0569) | Acc: (98.03%) (49015/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3280) | Acc: (91.37%) (9137/10000)\n",
            "Epoch: 94 | Batch_idx: 0 |  Loss: (0.0189) | Acc: (99.22%) (127/128)\n",
            "Epoch: 94 | Batch_idx: 10 |  Loss: (0.0576) | Acc: (97.87%) (1378/1408)\n",
            "Epoch: 94 | Batch_idx: 20 |  Loss: (0.0568) | Acc: (98.10%) (2637/2688)\n",
            "Epoch: 94 | Batch_idx: 30 |  Loss: (0.0515) | Acc: (98.36%) (3903/3968)\n",
            "Epoch: 94 | Batch_idx: 40 |  Loss: (0.0514) | Acc: (98.30%) (5159/5248)\n",
            "Epoch: 94 | Batch_idx: 50 |  Loss: (0.0512) | Acc: (98.31%) (6418/6528)\n",
            "Epoch: 94 | Batch_idx: 60 |  Loss: (0.0487) | Acc: (98.37%) (7681/7808)\n",
            "Epoch: 94 | Batch_idx: 70 |  Loss: (0.0494) | Acc: (98.34%) (8937/9088)\n",
            "Epoch: 94 | Batch_idx: 80 |  Loss: (0.0493) | Acc: (98.33%) (10195/10368)\n",
            "Epoch: 94 | Batch_idx: 90 |  Loss: (0.0490) | Acc: (98.35%) (11456/11648)\n",
            "Epoch: 94 | Batch_idx: 100 |  Loss: (0.0488) | Acc: (98.34%) (12714/12928)\n",
            "Epoch: 94 | Batch_idx: 110 |  Loss: (0.0489) | Acc: (98.32%) (13969/14208)\n",
            "Epoch: 94 | Batch_idx: 120 |  Loss: (0.0480) | Acc: (98.35%) (15232/15488)\n",
            "Epoch: 94 | Batch_idx: 130 |  Loss: (0.0488) | Acc: (98.32%) (16487/16768)\n",
            "Epoch: 94 | Batch_idx: 140 |  Loss: (0.0495) | Acc: (98.30%) (17741/18048)\n",
            "Epoch: 94 | Batch_idx: 150 |  Loss: (0.0498) | Acc: (98.28%) (18995/19328)\n",
            "Epoch: 94 | Batch_idx: 160 |  Loss: (0.0503) | Acc: (98.25%) (20247/20608)\n",
            "Epoch: 94 | Batch_idx: 170 |  Loss: (0.0509) | Acc: (98.24%) (21502/21888)\n",
            "Epoch: 94 | Batch_idx: 180 |  Loss: (0.0513) | Acc: (98.22%) (22755/23168)\n",
            "Epoch: 94 | Batch_idx: 190 |  Loss: (0.0512) | Acc: (98.22%) (24014/24448)\n",
            "Epoch: 94 | Batch_idx: 200 |  Loss: (0.0512) | Acc: (98.24%) (25275/25728)\n",
            "Epoch: 94 | Batch_idx: 210 |  Loss: (0.0513) | Acc: (98.24%) (26532/27008)\n",
            "Epoch: 94 | Batch_idx: 220 |  Loss: (0.0516) | Acc: (98.23%) (27787/28288)\n",
            "Epoch: 94 | Batch_idx: 230 |  Loss: (0.0512) | Acc: (98.23%) (29045/29568)\n",
            "Epoch: 94 | Batch_idx: 240 |  Loss: (0.0512) | Acc: (98.22%) (30300/30848)\n",
            "Epoch: 94 | Batch_idx: 250 |  Loss: (0.0510) | Acc: (98.23%) (31558/32128)\n",
            "Epoch: 94 | Batch_idx: 260 |  Loss: (0.0507) | Acc: (98.24%) (32820/33408)\n",
            "Epoch: 94 | Batch_idx: 270 |  Loss: (0.0510) | Acc: (98.22%) (34070/34688)\n",
            "Epoch: 94 | Batch_idx: 280 |  Loss: (0.0516) | Acc: (98.20%) (35320/35968)\n",
            "Epoch: 94 | Batch_idx: 290 |  Loss: (0.0513) | Acc: (98.21%) (36581/37248)\n",
            "Epoch: 94 | Batch_idx: 300 |  Loss: (0.0510) | Acc: (98.22%) (37841/38528)\n",
            "Epoch: 94 | Batch_idx: 310 |  Loss: (0.0514) | Acc: (98.19%) (39089/39808)\n",
            "Epoch: 94 | Batch_idx: 320 |  Loss: (0.0510) | Acc: (98.22%) (40357/41088)\n",
            "Epoch: 94 | Batch_idx: 330 |  Loss: (0.0512) | Acc: (98.22%) (41612/42368)\n",
            "Epoch: 94 | Batch_idx: 340 |  Loss: (0.0516) | Acc: (98.19%) (42856/43648)\n",
            "Epoch: 94 | Batch_idx: 350 |  Loss: (0.0519) | Acc: (98.18%) (44112/44928)\n",
            "Epoch: 94 | Batch_idx: 360 |  Loss: (0.0515) | Acc: (98.19%) (45371/46208)\n",
            "Epoch: 94 | Batch_idx: 370 |  Loss: (0.0520) | Acc: (98.17%) (46621/47488)\n",
            "Epoch: 94 | Batch_idx: 380 |  Loss: (0.0519) | Acc: (98.18%) (47879/48768)\n",
            "Epoch: 94 | Batch_idx: 390 |  Loss: (0.0518) | Acc: (98.19%) (49095/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3332) | Acc: (91.38%) (9138/10000)\n",
            "Epoch: 95 | Batch_idx: 0 |  Loss: (0.0406) | Acc: (98.44%) (126/128)\n",
            "Epoch: 95 | Batch_idx: 10 |  Loss: (0.0563) | Acc: (97.94%) (1379/1408)\n",
            "Epoch: 95 | Batch_idx: 20 |  Loss: (0.0558) | Acc: (97.99%) (2634/2688)\n",
            "Epoch: 95 | Batch_idx: 30 |  Loss: (0.0580) | Acc: (98.03%) (3890/3968)\n",
            "Epoch: 95 | Batch_idx: 40 |  Loss: (0.0541) | Acc: (98.17%) (5152/5248)\n",
            "Epoch: 95 | Batch_idx: 50 |  Loss: (0.0526) | Acc: (98.24%) (6413/6528)\n",
            "Epoch: 95 | Batch_idx: 60 |  Loss: (0.0518) | Acc: (98.17%) (7665/7808)\n",
            "Epoch: 95 | Batch_idx: 70 |  Loss: (0.0511) | Acc: (98.17%) (8922/9088)\n",
            "Epoch: 95 | Batch_idx: 80 |  Loss: (0.0502) | Acc: (98.20%) (10181/10368)\n",
            "Epoch: 95 | Batch_idx: 90 |  Loss: (0.0507) | Acc: (98.20%) (11438/11648)\n",
            "Epoch: 95 | Batch_idx: 100 |  Loss: (0.0517) | Acc: (98.17%) (12692/12928)\n",
            "Epoch: 95 | Batch_idx: 110 |  Loss: (0.0518) | Acc: (98.16%) (13946/14208)\n",
            "Epoch: 95 | Batch_idx: 120 |  Loss: (0.0524) | Acc: (98.15%) (15201/15488)\n",
            "Epoch: 95 | Batch_idx: 130 |  Loss: (0.0527) | Acc: (98.13%) (16454/16768)\n",
            "Epoch: 95 | Batch_idx: 140 |  Loss: (0.0532) | Acc: (98.12%) (17709/18048)\n",
            "Epoch: 95 | Batch_idx: 150 |  Loss: (0.0529) | Acc: (98.14%) (18969/19328)\n",
            "Epoch: 95 | Batch_idx: 160 |  Loss: (0.0537) | Acc: (98.12%) (20221/20608)\n",
            "Epoch: 95 | Batch_idx: 170 |  Loss: (0.0539) | Acc: (98.11%) (21475/21888)\n",
            "Epoch: 95 | Batch_idx: 180 |  Loss: (0.0536) | Acc: (98.11%) (22730/23168)\n",
            "Epoch: 95 | Batch_idx: 190 |  Loss: (0.0532) | Acc: (98.14%) (23993/24448)\n",
            "Epoch: 95 | Batch_idx: 200 |  Loss: (0.0530) | Acc: (98.15%) (25251/25728)\n",
            "Epoch: 95 | Batch_idx: 210 |  Loss: (0.0526) | Acc: (98.15%) (26509/27008)\n",
            "Epoch: 95 | Batch_idx: 220 |  Loss: (0.0532) | Acc: (98.12%) (27755/28288)\n",
            "Epoch: 95 | Batch_idx: 230 |  Loss: (0.0531) | Acc: (98.12%) (29011/29568)\n",
            "Epoch: 95 | Batch_idx: 240 |  Loss: (0.0530) | Acc: (98.12%) (30269/30848)\n",
            "Epoch: 95 | Batch_idx: 250 |  Loss: (0.0538) | Acc: (98.09%) (31514/32128)\n",
            "Epoch: 95 | Batch_idx: 260 |  Loss: (0.0538) | Acc: (98.11%) (32775/33408)\n",
            "Epoch: 95 | Batch_idx: 270 |  Loss: (0.0534) | Acc: (98.12%) (34035/34688)\n",
            "Epoch: 95 | Batch_idx: 280 |  Loss: (0.0533) | Acc: (98.12%) (35291/35968)\n",
            "Epoch: 95 | Batch_idx: 290 |  Loss: (0.0532) | Acc: (98.12%) (36548/37248)\n",
            "Epoch: 95 | Batch_idx: 300 |  Loss: (0.0534) | Acc: (98.13%) (37806/38528)\n",
            "Epoch: 95 | Batch_idx: 310 |  Loss: (0.0537) | Acc: (98.12%) (39059/39808)\n",
            "Epoch: 95 | Batch_idx: 320 |  Loss: (0.0539) | Acc: (98.11%) (40310/41088)\n",
            "Epoch: 95 | Batch_idx: 330 |  Loss: (0.0545) | Acc: (98.08%) (41556/42368)\n",
            "Epoch: 95 | Batch_idx: 340 |  Loss: (0.0543) | Acc: (98.10%) (42818/43648)\n",
            "Epoch: 95 | Batch_idx: 350 |  Loss: (0.0539) | Acc: (98.11%) (44080/44928)\n",
            "Epoch: 95 | Batch_idx: 360 |  Loss: (0.0543) | Acc: (98.11%) (45334/46208)\n",
            "Epoch: 95 | Batch_idx: 370 |  Loss: (0.0547) | Acc: (98.10%) (46584/47488)\n",
            "Epoch: 95 | Batch_idx: 380 |  Loss: (0.0543) | Acc: (98.11%) (47845/48768)\n",
            "Epoch: 95 | Batch_idx: 390 |  Loss: (0.0541) | Acc: (98.12%) (49060/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3151) | Acc: (91.62%) (9162/10000)\n",
            "Epoch: 96 | Batch_idx: 0 |  Loss: (0.0756) | Acc: (96.09%) (123/128)\n",
            "Epoch: 96 | Batch_idx: 10 |  Loss: (0.0503) | Acc: (98.51%) (1387/1408)\n",
            "Epoch: 96 | Batch_idx: 20 |  Loss: (0.0520) | Acc: (98.29%) (2642/2688)\n",
            "Epoch: 96 | Batch_idx: 30 |  Loss: (0.0541) | Acc: (98.03%) (3890/3968)\n",
            "Epoch: 96 | Batch_idx: 40 |  Loss: (0.0490) | Acc: (98.27%) (5157/5248)\n",
            "Epoch: 96 | Batch_idx: 50 |  Loss: (0.0499) | Acc: (98.33%) (6419/6528)\n",
            "Epoch: 96 | Batch_idx: 60 |  Loss: (0.0500) | Acc: (98.36%) (7680/7808)\n",
            "Epoch: 96 | Batch_idx: 70 |  Loss: (0.0507) | Acc: (98.34%) (8937/9088)\n",
            "Epoch: 96 | Batch_idx: 80 |  Loss: (0.0504) | Acc: (98.28%) (10190/10368)\n",
            "Epoch: 96 | Batch_idx: 90 |  Loss: (0.0514) | Acc: (98.25%) (11444/11648)\n",
            "Epoch: 96 | Batch_idx: 100 |  Loss: (0.0514) | Acc: (98.24%) (12700/12928)\n",
            "Epoch: 96 | Batch_idx: 110 |  Loss: (0.0509) | Acc: (98.24%) (13958/14208)\n",
            "Epoch: 96 | Batch_idx: 120 |  Loss: (0.0520) | Acc: (98.21%) (15210/15488)\n",
            "Epoch: 96 | Batch_idx: 130 |  Loss: (0.0517) | Acc: (98.20%) (16467/16768)\n",
            "Epoch: 96 | Batch_idx: 140 |  Loss: (0.0512) | Acc: (98.20%) (17724/18048)\n",
            "Epoch: 96 | Batch_idx: 150 |  Loss: (0.0500) | Acc: (98.25%) (18990/19328)\n",
            "Epoch: 96 | Batch_idx: 160 |  Loss: (0.0496) | Acc: (98.28%) (20254/20608)\n",
            "Epoch: 96 | Batch_idx: 170 |  Loss: (0.0497) | Acc: (98.27%) (21509/21888)\n",
            "Epoch: 96 | Batch_idx: 180 |  Loss: (0.0498) | Acc: (98.26%) (22766/23168)\n",
            "Epoch: 96 | Batch_idx: 190 |  Loss: (0.0501) | Acc: (98.26%) (24023/24448)\n",
            "Epoch: 96 | Batch_idx: 200 |  Loss: (0.0503) | Acc: (98.27%) (25282/25728)\n",
            "Epoch: 96 | Batch_idx: 210 |  Loss: (0.0503) | Acc: (98.27%) (26541/27008)\n",
            "Epoch: 96 | Batch_idx: 220 |  Loss: (0.0497) | Acc: (98.30%) (27807/28288)\n",
            "Epoch: 96 | Batch_idx: 230 |  Loss: (0.0497) | Acc: (98.30%) (29064/29568)\n",
            "Epoch: 96 | Batch_idx: 240 |  Loss: (0.0493) | Acc: (98.30%) (30324/30848)\n",
            "Epoch: 96 | Batch_idx: 250 |  Loss: (0.0493) | Acc: (98.29%) (31579/32128)\n",
            "Epoch: 96 | Batch_idx: 260 |  Loss: (0.0493) | Acc: (98.28%) (32835/33408)\n",
            "Epoch: 96 | Batch_idx: 270 |  Loss: (0.0491) | Acc: (98.29%) (34096/34688)\n",
            "Epoch: 96 | Batch_idx: 280 |  Loss: (0.0490) | Acc: (98.31%) (35359/35968)\n",
            "Epoch: 96 | Batch_idx: 290 |  Loss: (0.0495) | Acc: (98.29%) (36611/37248)\n",
            "Epoch: 96 | Batch_idx: 300 |  Loss: (0.0497) | Acc: (98.28%) (37867/38528)\n",
            "Epoch: 96 | Batch_idx: 310 |  Loss: (0.0503) | Acc: (98.28%) (39122/39808)\n",
            "Epoch: 96 | Batch_idx: 320 |  Loss: (0.0503) | Acc: (98.28%) (40380/41088)\n",
            "Epoch: 96 | Batch_idx: 330 |  Loss: (0.0503) | Acc: (98.28%) (41638/42368)\n",
            "Epoch: 96 | Batch_idx: 340 |  Loss: (0.0503) | Acc: (98.27%) (42893/43648)\n",
            "Epoch: 96 | Batch_idx: 350 |  Loss: (0.0505) | Acc: (98.27%) (44149/44928)\n",
            "Epoch: 96 | Batch_idx: 360 |  Loss: (0.0508) | Acc: (98.26%) (45402/46208)\n",
            "Epoch: 96 | Batch_idx: 370 |  Loss: (0.0507) | Acc: (98.25%) (46659/47488)\n",
            "Epoch: 96 | Batch_idx: 380 |  Loss: (0.0507) | Acc: (98.26%) (47919/48768)\n",
            "Epoch: 96 | Batch_idx: 390 |  Loss: (0.0510) | Acc: (98.26%) (49129/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3363) | Acc: (91.55%) (9155/10000)\n",
            "Epoch: 97 | Batch_idx: 0 |  Loss: (0.0335) | Acc: (99.22%) (127/128)\n",
            "Epoch: 97 | Batch_idx: 10 |  Loss: (0.0453) | Acc: (98.44%) (1386/1408)\n",
            "Epoch: 97 | Batch_idx: 20 |  Loss: (0.0449) | Acc: (98.33%) (2643/2688)\n",
            "Epoch: 97 | Batch_idx: 30 |  Loss: (0.0490) | Acc: (98.21%) (3897/3968)\n",
            "Epoch: 97 | Batch_idx: 40 |  Loss: (0.0448) | Acc: (98.42%) (5165/5248)\n",
            "Epoch: 97 | Batch_idx: 50 |  Loss: (0.0430) | Acc: (98.44%) (6426/6528)\n",
            "Epoch: 97 | Batch_idx: 60 |  Loss: (0.0439) | Acc: (98.44%) (7686/7808)\n",
            "Epoch: 97 | Batch_idx: 70 |  Loss: (0.0446) | Acc: (98.45%) (8947/9088)\n",
            "Epoch: 97 | Batch_idx: 80 |  Loss: (0.0435) | Acc: (98.51%) (10214/10368)\n",
            "Epoch: 97 | Batch_idx: 90 |  Loss: (0.0426) | Acc: (98.57%) (11481/11648)\n",
            "Epoch: 97 | Batch_idx: 100 |  Loss: (0.0428) | Acc: (98.55%) (12741/12928)\n",
            "Epoch: 97 | Batch_idx: 110 |  Loss: (0.0415) | Acc: (98.60%) (14009/14208)\n",
            "Epoch: 97 | Batch_idx: 120 |  Loss: (0.0416) | Acc: (98.61%) (15273/15488)\n",
            "Epoch: 97 | Batch_idx: 130 |  Loss: (0.0422) | Acc: (98.59%) (16532/16768)\n",
            "Epoch: 97 | Batch_idx: 140 |  Loss: (0.0422) | Acc: (98.57%) (17790/18048)\n",
            "Epoch: 97 | Batch_idx: 150 |  Loss: (0.0422) | Acc: (98.58%) (19053/19328)\n",
            "Epoch: 97 | Batch_idx: 160 |  Loss: (0.0431) | Acc: (98.52%) (20302/20608)\n",
            "Epoch: 97 | Batch_idx: 170 |  Loss: (0.0430) | Acc: (98.52%) (21564/21888)\n",
            "Epoch: 97 | Batch_idx: 180 |  Loss: (0.0431) | Acc: (98.51%) (22823/23168)\n",
            "Epoch: 97 | Batch_idx: 190 |  Loss: (0.0425) | Acc: (98.53%) (24088/24448)\n",
            "Epoch: 97 | Batch_idx: 200 |  Loss: (0.0423) | Acc: (98.56%) (25357/25728)\n",
            "Epoch: 97 | Batch_idx: 210 |  Loss: (0.0425) | Acc: (98.54%) (26614/27008)\n",
            "Epoch: 97 | Batch_idx: 220 |  Loss: (0.0430) | Acc: (98.54%) (27874/28288)\n",
            "Epoch: 97 | Batch_idx: 230 |  Loss: (0.0432) | Acc: (98.53%) (29134/29568)\n",
            "Epoch: 97 | Batch_idx: 240 |  Loss: (0.0427) | Acc: (98.54%) (30399/30848)\n",
            "Epoch: 97 | Batch_idx: 250 |  Loss: (0.0432) | Acc: (98.54%) (31659/32128)\n",
            "Epoch: 97 | Batch_idx: 260 |  Loss: (0.0430) | Acc: (98.54%) (32921/33408)\n",
            "Epoch: 97 | Batch_idx: 270 |  Loss: (0.0434) | Acc: (98.53%) (34177/34688)\n",
            "Epoch: 97 | Batch_idx: 280 |  Loss: (0.0438) | Acc: (98.52%) (35434/35968)\n",
            "Epoch: 97 | Batch_idx: 290 |  Loss: (0.0443) | Acc: (98.50%) (36688/37248)\n",
            "Epoch: 97 | Batch_idx: 300 |  Loss: (0.0446) | Acc: (98.48%) (37943/38528)\n",
            "Epoch: 97 | Batch_idx: 310 |  Loss: (0.0451) | Acc: (98.47%) (39197/39808)\n",
            "Epoch: 97 | Batch_idx: 320 |  Loss: (0.0451) | Acc: (98.46%) (40457/41088)\n",
            "Epoch: 97 | Batch_idx: 330 |  Loss: (0.0452) | Acc: (98.46%) (41714/42368)\n",
            "Epoch: 97 | Batch_idx: 340 |  Loss: (0.0453) | Acc: (98.45%) (42970/43648)\n",
            "Epoch: 97 | Batch_idx: 350 |  Loss: (0.0452) | Acc: (98.44%) (44229/44928)\n",
            "Epoch: 97 | Batch_idx: 360 |  Loss: (0.0454) | Acc: (98.44%) (45488/46208)\n",
            "Epoch: 97 | Batch_idx: 370 |  Loss: (0.0457) | Acc: (98.44%) (46745/47488)\n",
            "Epoch: 97 | Batch_idx: 380 |  Loss: (0.0458) | Acc: (98.43%) (48001/48768)\n",
            "Epoch: 97 | Batch_idx: 390 |  Loss: (0.0455) | Acc: (98.44%) (49219/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3389) | Acc: (91.39%) (9139/10000)\n",
            "Epoch: 98 | Batch_idx: 0 |  Loss: (0.0772) | Acc: (98.44%) (126/128)\n",
            "Epoch: 98 | Batch_idx: 10 |  Loss: (0.0359) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 98 | Batch_idx: 20 |  Loss: (0.0362) | Acc: (99.03%) (2662/2688)\n",
            "Epoch: 98 | Batch_idx: 30 |  Loss: (0.0400) | Acc: (98.69%) (3916/3968)\n",
            "Epoch: 98 | Batch_idx: 40 |  Loss: (0.0414) | Acc: (98.69%) (5179/5248)\n",
            "Epoch: 98 | Batch_idx: 50 |  Loss: (0.0431) | Acc: (98.64%) (6439/6528)\n",
            "Epoch: 98 | Batch_idx: 60 |  Loss: (0.0432) | Acc: (98.57%) (7696/7808)\n",
            "Epoch: 98 | Batch_idx: 70 |  Loss: (0.0415) | Acc: (98.59%) (8960/9088)\n",
            "Epoch: 98 | Batch_idx: 80 |  Loss: (0.0414) | Acc: (98.56%) (10219/10368)\n",
            "Epoch: 98 | Batch_idx: 90 |  Loss: (0.0418) | Acc: (98.56%) (11480/11648)\n",
            "Epoch: 98 | Batch_idx: 100 |  Loss: (0.0421) | Acc: (98.53%) (12738/12928)\n",
            "Epoch: 98 | Batch_idx: 110 |  Loss: (0.0431) | Acc: (98.48%) (13992/14208)\n",
            "Epoch: 98 | Batch_idx: 120 |  Loss: (0.0440) | Acc: (98.42%) (15243/15488)\n",
            "Epoch: 98 | Batch_idx: 130 |  Loss: (0.0448) | Acc: (98.40%) (16499/16768)\n",
            "Epoch: 98 | Batch_idx: 140 |  Loss: (0.0458) | Acc: (98.37%) (17753/18048)\n",
            "Epoch: 98 | Batch_idx: 150 |  Loss: (0.0454) | Acc: (98.38%) (19015/19328)\n",
            "Epoch: 98 | Batch_idx: 160 |  Loss: (0.0458) | Acc: (98.39%) (20276/20608)\n",
            "Epoch: 98 | Batch_idx: 170 |  Loss: (0.0468) | Acc: (98.36%) (21528/21888)\n",
            "Epoch: 98 | Batch_idx: 180 |  Loss: (0.0467) | Acc: (98.38%) (22792/23168)\n",
            "Epoch: 98 | Batch_idx: 190 |  Loss: (0.0472) | Acc: (98.36%) (24048/24448)\n",
            "Epoch: 98 | Batch_idx: 200 |  Loss: (0.0474) | Acc: (98.36%) (25307/25728)\n",
            "Epoch: 98 | Batch_idx: 210 |  Loss: (0.0473) | Acc: (98.37%) (26569/27008)\n",
            "Epoch: 98 | Batch_idx: 220 |  Loss: (0.0467) | Acc: (98.39%) (27833/28288)\n",
            "Epoch: 98 | Batch_idx: 230 |  Loss: (0.0466) | Acc: (98.39%) (29092/29568)\n",
            "Epoch: 98 | Batch_idx: 240 |  Loss: (0.0466) | Acc: (98.40%) (30354/30848)\n",
            "Epoch: 98 | Batch_idx: 250 |  Loss: (0.0466) | Acc: (98.41%) (31616/32128)\n",
            "Epoch: 98 | Batch_idx: 260 |  Loss: (0.0467) | Acc: (98.41%) (32876/33408)\n",
            "Epoch: 98 | Batch_idx: 270 |  Loss: (0.0469) | Acc: (98.40%) (34132/34688)\n",
            "Epoch: 98 | Batch_idx: 280 |  Loss: (0.0476) | Acc: (98.39%) (35390/35968)\n",
            "Epoch: 98 | Batch_idx: 290 |  Loss: (0.0477) | Acc: (98.39%) (36647/37248)\n",
            "Epoch: 98 | Batch_idx: 300 |  Loss: (0.0482) | Acc: (98.38%) (37903/38528)\n",
            "Epoch: 98 | Batch_idx: 310 |  Loss: (0.0481) | Acc: (98.38%) (39165/39808)\n",
            "Epoch: 98 | Batch_idx: 320 |  Loss: (0.0482) | Acc: (98.38%) (40424/41088)\n",
            "Epoch: 98 | Batch_idx: 330 |  Loss: (0.0483) | Acc: (98.38%) (41680/42368)\n",
            "Epoch: 98 | Batch_idx: 340 |  Loss: (0.0486) | Acc: (98.36%) (42934/43648)\n",
            "Epoch: 98 | Batch_idx: 350 |  Loss: (0.0485) | Acc: (98.36%) (44193/44928)\n",
            "Epoch: 98 | Batch_idx: 360 |  Loss: (0.0484) | Acc: (98.37%) (45453/46208)\n",
            "Epoch: 98 | Batch_idx: 370 |  Loss: (0.0484) | Acc: (98.36%) (46707/47488)\n",
            "Epoch: 98 | Batch_idx: 380 |  Loss: (0.0489) | Acc: (98.35%) (47962/48768)\n",
            "Epoch: 98 | Batch_idx: 390 |  Loss: (0.0487) | Acc: (98.34%) (49171/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3239) | Acc: (91.54%) (9154/10000)\n",
            "Epoch: 99 | Batch_idx: 0 |  Loss: (0.0470) | Acc: (99.22%) (127/128)\n",
            "Epoch: 99 | Batch_idx: 10 |  Loss: (0.0486) | Acc: (98.22%) (1383/1408)\n",
            "Epoch: 99 | Batch_idx: 20 |  Loss: (0.0426) | Acc: (98.47%) (2647/2688)\n",
            "Epoch: 99 | Batch_idx: 30 |  Loss: (0.0440) | Acc: (98.41%) (3905/3968)\n",
            "Epoch: 99 | Batch_idx: 40 |  Loss: (0.0426) | Acc: (98.42%) (5165/5248)\n",
            "Epoch: 99 | Batch_idx: 50 |  Loss: (0.0439) | Acc: (98.45%) (6427/6528)\n",
            "Epoch: 99 | Batch_idx: 60 |  Loss: (0.0449) | Acc: (98.45%) (7687/7808)\n",
            "Epoch: 99 | Batch_idx: 70 |  Loss: (0.0450) | Acc: (98.43%) (8945/9088)\n",
            "Epoch: 99 | Batch_idx: 80 |  Loss: (0.0445) | Acc: (98.49%) (10211/10368)\n",
            "Epoch: 99 | Batch_idx: 90 |  Loss: (0.0471) | Acc: (98.38%) (11459/11648)\n",
            "Epoch: 99 | Batch_idx: 100 |  Loss: (0.0478) | Acc: (98.38%) (12718/12928)\n",
            "Epoch: 99 | Batch_idx: 110 |  Loss: (0.0466) | Acc: (98.42%) (13983/14208)\n",
            "Epoch: 99 | Batch_idx: 120 |  Loss: (0.0463) | Acc: (98.39%) (15239/15488)\n",
            "Epoch: 99 | Batch_idx: 130 |  Loss: (0.0476) | Acc: (98.37%) (16495/16768)\n",
            "Epoch: 99 | Batch_idx: 140 |  Loss: (0.0469) | Acc: (98.39%) (17758/18048)\n",
            "Epoch: 99 | Batch_idx: 150 |  Loss: (0.0478) | Acc: (98.37%) (19013/19328)\n",
            "Epoch: 99 | Batch_idx: 160 |  Loss: (0.0469) | Acc: (98.41%) (20281/20608)\n",
            "Epoch: 99 | Batch_idx: 170 |  Loss: (0.0477) | Acc: (98.39%) (21535/21888)\n",
            "Epoch: 99 | Batch_idx: 180 |  Loss: (0.0474) | Acc: (98.39%) (22796/23168)\n",
            "Epoch: 99 | Batch_idx: 190 |  Loss: (0.0471) | Acc: (98.40%) (24058/24448)\n",
            "Epoch: 99 | Batch_idx: 200 |  Loss: (0.0468) | Acc: (98.41%) (25319/25728)\n",
            "Epoch: 99 | Batch_idx: 210 |  Loss: (0.0464) | Acc: (98.43%) (26583/27008)\n",
            "Epoch: 99 | Batch_idx: 220 |  Loss: (0.0463) | Acc: (98.43%) (27843/28288)\n",
            "Epoch: 99 | Batch_idx: 230 |  Loss: (0.0467) | Acc: (98.42%) (29100/29568)\n",
            "Epoch: 99 | Batch_idx: 240 |  Loss: (0.0466) | Acc: (98.43%) (30363/30848)\n",
            "Epoch: 99 | Batch_idx: 250 |  Loss: (0.0465) | Acc: (98.42%) (31620/32128)\n",
            "Epoch: 99 | Batch_idx: 260 |  Loss: (0.0465) | Acc: (98.42%) (32881/33408)\n",
            "Epoch: 99 | Batch_idx: 270 |  Loss: (0.0463) | Acc: (98.43%) (34144/34688)\n",
            "Epoch: 99 | Batch_idx: 280 |  Loss: (0.0463) | Acc: (98.42%) (35401/35968)\n",
            "Epoch: 99 | Batch_idx: 290 |  Loss: (0.0462) | Acc: (98.43%) (36663/37248)\n",
            "Epoch: 99 | Batch_idx: 300 |  Loss: (0.0463) | Acc: (98.42%) (37921/38528)\n",
            "Epoch: 99 | Batch_idx: 310 |  Loss: (0.0460) | Acc: (98.43%) (39183/39808)\n",
            "Epoch: 99 | Batch_idx: 320 |  Loss: (0.0467) | Acc: (98.41%) (40434/41088)\n",
            "Epoch: 99 | Batch_idx: 330 |  Loss: (0.0476) | Acc: (98.38%) (41682/42368)\n",
            "Epoch: 99 | Batch_idx: 340 |  Loss: (0.0472) | Acc: (98.39%) (42947/43648)\n",
            "Epoch: 99 | Batch_idx: 350 |  Loss: (0.0477) | Acc: (98.37%) (44197/44928)\n",
            "Epoch: 99 | Batch_idx: 360 |  Loss: (0.0475) | Acc: (98.38%) (45459/46208)\n",
            "Epoch: 99 | Batch_idx: 370 |  Loss: (0.0475) | Acc: (98.39%) (46722/47488)\n",
            "Epoch: 99 | Batch_idx: 380 |  Loss: (0.0476) | Acc: (98.38%) (47976/48768)\n",
            "Epoch: 99 | Batch_idx: 390 |  Loss: (0.0478) | Acc: (98.37%) (49186/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3362) | Acc: (91.40%) (9140/10000)\n",
            "Epoch: 100 | Batch_idx: 0 |  Loss: (0.1188) | Acc: (96.09%) (123/128)\n",
            "Epoch: 100 | Batch_idx: 10 |  Loss: (0.0600) | Acc: (98.01%) (1380/1408)\n",
            "Epoch: 100 | Batch_idx: 20 |  Loss: (0.0465) | Acc: (98.55%) (2649/2688)\n",
            "Epoch: 100 | Batch_idx: 30 |  Loss: (0.0498) | Acc: (98.11%) (3893/3968)\n",
            "Epoch: 100 | Batch_idx: 40 |  Loss: (0.0504) | Acc: (98.11%) (5149/5248)\n",
            "Epoch: 100 | Batch_idx: 50 |  Loss: (0.0496) | Acc: (98.13%) (6406/6528)\n",
            "Epoch: 100 | Batch_idx: 60 |  Loss: (0.0525) | Acc: (98.09%) (7659/7808)\n",
            "Epoch: 100 | Batch_idx: 70 |  Loss: (0.0502) | Acc: (98.17%) (8922/9088)\n",
            "Epoch: 100 | Batch_idx: 80 |  Loss: (0.0496) | Acc: (98.20%) (10181/10368)\n",
            "Epoch: 100 | Batch_idx: 90 |  Loss: (0.0494) | Acc: (98.21%) (11439/11648)\n",
            "Epoch: 100 | Batch_idx: 100 |  Loss: (0.0482) | Acc: (98.21%) (12697/12928)\n",
            "Epoch: 100 | Batch_idx: 110 |  Loss: (0.0479) | Acc: (98.26%) (13961/14208)\n",
            "Epoch: 100 | Batch_idx: 120 |  Loss: (0.0478) | Acc: (98.27%) (15220/15488)\n",
            "Epoch: 100 | Batch_idx: 130 |  Loss: (0.0460) | Acc: (98.34%) (16490/16768)\n",
            "Epoch: 100 | Batch_idx: 140 |  Loss: (0.0458) | Acc: (98.32%) (17744/18048)\n",
            "Epoch: 100 | Batch_idx: 150 |  Loss: (0.0466) | Acc: (98.28%) (18996/19328)\n",
            "Epoch: 100 | Batch_idx: 160 |  Loss: (0.0465) | Acc: (98.30%) (20257/20608)\n",
            "Epoch: 100 | Batch_idx: 170 |  Loss: (0.0459) | Acc: (98.32%) (21520/21888)\n",
            "Epoch: 100 | Batch_idx: 180 |  Loss: (0.0457) | Acc: (98.33%) (22782/23168)\n",
            "Epoch: 100 | Batch_idx: 190 |  Loss: (0.0455) | Acc: (98.35%) (24045/24448)\n",
            "Epoch: 100 | Batch_idx: 200 |  Loss: (0.0452) | Acc: (98.36%) (25307/25728)\n",
            "Epoch: 100 | Batch_idx: 210 |  Loss: (0.0454) | Acc: (98.35%) (26562/27008)\n",
            "Epoch: 100 | Batch_idx: 220 |  Loss: (0.0457) | Acc: (98.35%) (27821/28288)\n",
            "Epoch: 100 | Batch_idx: 230 |  Loss: (0.0453) | Acc: (98.36%) (29083/29568)\n",
            "Epoch: 100 | Batch_idx: 240 |  Loss: (0.0452) | Acc: (98.37%) (30344/30848)\n",
            "Epoch: 100 | Batch_idx: 250 |  Loss: (0.0458) | Acc: (98.36%) (31600/32128)\n",
            "Epoch: 100 | Batch_idx: 260 |  Loss: (0.0454) | Acc: (98.37%) (32864/33408)\n",
            "Epoch: 100 | Batch_idx: 270 |  Loss: (0.0455) | Acc: (98.36%) (34120/34688)\n",
            "Epoch: 100 | Batch_idx: 280 |  Loss: (0.0453) | Acc: (98.37%) (35382/35968)\n",
            "Epoch: 100 | Batch_idx: 290 |  Loss: (0.0451) | Acc: (98.37%) (36642/37248)\n",
            "Epoch: 100 | Batch_idx: 300 |  Loss: (0.0456) | Acc: (98.35%) (37893/38528)\n",
            "Epoch: 100 | Batch_idx: 310 |  Loss: (0.0454) | Acc: (98.36%) (39157/39808)\n",
            "Epoch: 100 | Batch_idx: 320 |  Loss: (0.0458) | Acc: (98.35%) (40410/41088)\n",
            "Epoch: 100 | Batch_idx: 330 |  Loss: (0.0457) | Acc: (98.35%) (41667/42368)\n",
            "Epoch: 100 | Batch_idx: 340 |  Loss: (0.0458) | Acc: (98.35%) (42926/43648)\n",
            "Epoch: 100 | Batch_idx: 350 |  Loss: (0.0457) | Acc: (98.36%) (44190/44928)\n",
            "Epoch: 100 | Batch_idx: 360 |  Loss: (0.0459) | Acc: (98.36%) (45448/46208)\n",
            "Epoch: 100 | Batch_idx: 370 |  Loss: (0.0459) | Acc: (98.36%) (46709/47488)\n",
            "Epoch: 100 | Batch_idx: 380 |  Loss: (0.0457) | Acc: (98.36%) (47970/48768)\n",
            "Epoch: 100 | Batch_idx: 390 |  Loss: (0.0458) | Acc: (98.37%) (49184/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3321) | Acc: (91.59%) (9159/10000)\n",
            "Epoch: 101 | Batch_idx: 0 |  Loss: (0.0189) | Acc: (99.22%) (127/128)\n",
            "Epoch: 101 | Batch_idx: 10 |  Loss: (0.0245) | Acc: (99.01%) (1394/1408)\n",
            "Epoch: 101 | Batch_idx: 20 |  Loss: (0.0320) | Acc: (98.74%) (2654/2688)\n",
            "Epoch: 101 | Batch_idx: 30 |  Loss: (0.0381) | Acc: (98.61%) (3913/3968)\n",
            "Epoch: 101 | Batch_idx: 40 |  Loss: (0.0379) | Acc: (98.65%) (5177/5248)\n",
            "Epoch: 101 | Batch_idx: 50 |  Loss: (0.0394) | Acc: (98.62%) (6438/6528)\n",
            "Epoch: 101 | Batch_idx: 60 |  Loss: (0.0394) | Acc: (98.59%) (7698/7808)\n",
            "Epoch: 101 | Batch_idx: 70 |  Loss: (0.0420) | Acc: (98.56%) (8957/9088)\n",
            "Epoch: 101 | Batch_idx: 80 |  Loss: (0.0434) | Acc: (98.49%) (10211/10368)\n",
            "Epoch: 101 | Batch_idx: 90 |  Loss: (0.0430) | Acc: (98.48%) (11471/11648)\n",
            "Epoch: 101 | Batch_idx: 100 |  Loss: (0.0443) | Acc: (98.46%) (12729/12928)\n",
            "Epoch: 101 | Batch_idx: 110 |  Loss: (0.0436) | Acc: (98.51%) (13996/14208)\n",
            "Epoch: 101 | Batch_idx: 120 |  Loss: (0.0441) | Acc: (98.51%) (15258/15488)\n",
            "Epoch: 101 | Batch_idx: 130 |  Loss: (0.0432) | Acc: (98.53%) (16521/16768)\n",
            "Epoch: 101 | Batch_idx: 140 |  Loss: (0.0424) | Acc: (98.55%) (17787/18048)\n",
            "Epoch: 101 | Batch_idx: 150 |  Loss: (0.0428) | Acc: (98.54%) (19045/19328)\n",
            "Epoch: 101 | Batch_idx: 160 |  Loss: (0.0431) | Acc: (98.53%) (20306/20608)\n",
            "Epoch: 101 | Batch_idx: 170 |  Loss: (0.0434) | Acc: (98.52%) (21565/21888)\n",
            "Epoch: 101 | Batch_idx: 180 |  Loss: (0.0434) | Acc: (98.52%) (22825/23168)\n",
            "Epoch: 101 | Batch_idx: 190 |  Loss: (0.0439) | Acc: (98.49%) (24079/24448)\n",
            "Epoch: 101 | Batch_idx: 200 |  Loss: (0.0438) | Acc: (98.51%) (25345/25728)\n",
            "Epoch: 101 | Batch_idx: 210 |  Loss: (0.0437) | Acc: (98.51%) (26605/27008)\n",
            "Epoch: 101 | Batch_idx: 220 |  Loss: (0.0432) | Acc: (98.53%) (27871/28288)\n",
            "Epoch: 101 | Batch_idx: 230 |  Loss: (0.0426) | Acc: (98.55%) (29139/29568)\n",
            "Epoch: 101 | Batch_idx: 240 |  Loss: (0.0438) | Acc: (98.51%) (30388/30848)\n",
            "Epoch: 101 | Batch_idx: 250 |  Loss: (0.0436) | Acc: (98.52%) (31651/32128)\n",
            "Epoch: 101 | Batch_idx: 260 |  Loss: (0.0435) | Acc: (98.50%) (32908/33408)\n",
            "Epoch: 101 | Batch_idx: 270 |  Loss: (0.0435) | Acc: (98.50%) (34169/34688)\n",
            "Epoch: 101 | Batch_idx: 280 |  Loss: (0.0431) | Acc: (98.52%) (35435/35968)\n",
            "Epoch: 101 | Batch_idx: 290 |  Loss: (0.0429) | Acc: (98.53%) (36699/37248)\n",
            "Epoch: 101 | Batch_idx: 300 |  Loss: (0.0428) | Acc: (98.52%) (37957/38528)\n",
            "Epoch: 101 | Batch_idx: 310 |  Loss: (0.0427) | Acc: (98.52%) (39217/39808)\n",
            "Epoch: 101 | Batch_idx: 320 |  Loss: (0.0425) | Acc: (98.53%) (40483/41088)\n",
            "Epoch: 101 | Batch_idx: 330 |  Loss: (0.0426) | Acc: (98.52%) (41740/42368)\n",
            "Epoch: 101 | Batch_idx: 340 |  Loss: (0.0429) | Acc: (98.51%) (42997/43648)\n",
            "Epoch: 101 | Batch_idx: 350 |  Loss: (0.0427) | Acc: (98.51%) (44258/44928)\n",
            "Epoch: 101 | Batch_idx: 360 |  Loss: (0.0431) | Acc: (98.50%) (45513/46208)\n",
            "Epoch: 101 | Batch_idx: 370 |  Loss: (0.0436) | Acc: (98.48%) (46768/47488)\n",
            "Epoch: 101 | Batch_idx: 380 |  Loss: (0.0433) | Acc: (98.49%) (48033/48768)\n",
            "Epoch: 101 | Batch_idx: 390 |  Loss: (0.0434) | Acc: (98.50%) (49248/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3425) | Acc: (91.79%) (9179/10000)\n",
            "Epoch: 102 | Batch_idx: 0 |  Loss: (0.0122) | Acc: (99.22%) (127/128)\n",
            "Epoch: 102 | Batch_idx: 10 |  Loss: (0.0319) | Acc: (99.22%) (1397/1408)\n",
            "Epoch: 102 | Batch_idx: 20 |  Loss: (0.0427) | Acc: (98.74%) (2654/2688)\n",
            "Epoch: 102 | Batch_idx: 30 |  Loss: (0.0454) | Acc: (98.71%) (3917/3968)\n",
            "Epoch: 102 | Batch_idx: 40 |  Loss: (0.0514) | Acc: (98.51%) (5170/5248)\n",
            "Epoch: 102 | Batch_idx: 50 |  Loss: (0.0491) | Acc: (98.58%) (6435/6528)\n",
            "Epoch: 102 | Batch_idx: 60 |  Loss: (0.0520) | Acc: (98.46%) (7688/7808)\n",
            "Epoch: 102 | Batch_idx: 70 |  Loss: (0.0502) | Acc: (98.47%) (8949/9088)\n",
            "Epoch: 102 | Batch_idx: 80 |  Loss: (0.0490) | Acc: (98.48%) (10210/10368)\n",
            "Epoch: 102 | Batch_idx: 90 |  Loss: (0.0479) | Acc: (98.47%) (11470/11648)\n",
            "Epoch: 102 | Batch_idx: 100 |  Loss: (0.0472) | Acc: (98.46%) (12729/12928)\n",
            "Epoch: 102 | Batch_idx: 110 |  Loss: (0.0470) | Acc: (98.47%) (13990/14208)\n",
            "Epoch: 102 | Batch_idx: 120 |  Loss: (0.0474) | Acc: (98.46%) (15249/15488)\n",
            "Epoch: 102 | Batch_idx: 130 |  Loss: (0.0478) | Acc: (98.43%) (16505/16768)\n",
            "Epoch: 102 | Batch_idx: 140 |  Loss: (0.0479) | Acc: (98.44%) (17766/18048)\n",
            "Epoch: 102 | Batch_idx: 150 |  Loss: (0.0479) | Acc: (98.42%) (19023/19328)\n",
            "Epoch: 102 | Batch_idx: 160 |  Loss: (0.0477) | Acc: (98.42%) (20283/20608)\n",
            "Epoch: 102 | Batch_idx: 170 |  Loss: (0.0473) | Acc: (98.43%) (21545/21888)\n",
            "Epoch: 102 | Batch_idx: 180 |  Loss: (0.0475) | Acc: (98.44%) (22807/23168)\n",
            "Epoch: 102 | Batch_idx: 190 |  Loss: (0.0473) | Acc: (98.43%) (24064/24448)\n",
            "Epoch: 102 | Batch_idx: 200 |  Loss: (0.0469) | Acc: (98.45%) (25328/25728)\n",
            "Epoch: 102 | Batch_idx: 210 |  Loss: (0.0463) | Acc: (98.46%) (26591/27008)\n",
            "Epoch: 102 | Batch_idx: 220 |  Loss: (0.0461) | Acc: (98.44%) (27848/28288)\n",
            "Epoch: 102 | Batch_idx: 230 |  Loss: (0.0460) | Acc: (98.45%) (29109/29568)\n",
            "Epoch: 102 | Batch_idx: 240 |  Loss: (0.0458) | Acc: (98.44%) (30367/30848)\n",
            "Epoch: 102 | Batch_idx: 250 |  Loss: (0.0452) | Acc: (98.45%) (31630/32128)\n",
            "Epoch: 102 | Batch_idx: 260 |  Loss: (0.0459) | Acc: (98.43%) (32883/33408)\n",
            "Epoch: 102 | Batch_idx: 270 |  Loss: (0.0455) | Acc: (98.43%) (34144/34688)\n",
            "Epoch: 102 | Batch_idx: 280 |  Loss: (0.0456) | Acc: (98.43%) (35403/35968)\n",
            "Epoch: 102 | Batch_idx: 290 |  Loss: (0.0458) | Acc: (98.43%) (36664/37248)\n",
            "Epoch: 102 | Batch_idx: 300 |  Loss: (0.0453) | Acc: (98.45%) (37929/38528)\n",
            "Epoch: 102 | Batch_idx: 310 |  Loss: (0.0452) | Acc: (98.44%) (39188/39808)\n",
            "Epoch: 102 | Batch_idx: 320 |  Loss: (0.0451) | Acc: (98.45%) (40450/41088)\n",
            "Epoch: 102 | Batch_idx: 330 |  Loss: (0.0450) | Acc: (98.45%) (41712/42368)\n",
            "Epoch: 102 | Batch_idx: 340 |  Loss: (0.0450) | Acc: (98.46%) (42975/43648)\n",
            "Epoch: 102 | Batch_idx: 350 |  Loss: (0.0452) | Acc: (98.44%) (44228/44928)\n",
            "Epoch: 102 | Batch_idx: 360 |  Loss: (0.0456) | Acc: (98.43%) (45482/46208)\n",
            "Epoch: 102 | Batch_idx: 370 |  Loss: (0.0456) | Acc: (98.42%) (46739/47488)\n",
            "Epoch: 102 | Batch_idx: 380 |  Loss: (0.0456) | Acc: (98.43%) (48001/48768)\n",
            "Epoch: 102 | Batch_idx: 390 |  Loss: (0.0459) | Acc: (98.41%) (49207/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3389) | Acc: (91.74%) (9174/10000)\n",
            "Epoch: 103 | Batch_idx: 0 |  Loss: (0.0609) | Acc: (99.22%) (127/128)\n",
            "Epoch: 103 | Batch_idx: 10 |  Loss: (0.0388) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 103 | Batch_idx: 20 |  Loss: (0.0377) | Acc: (98.88%) (2658/2688)\n",
            "Epoch: 103 | Batch_idx: 30 |  Loss: (0.0399) | Acc: (98.74%) (3918/3968)\n",
            "Epoch: 103 | Batch_idx: 40 |  Loss: (0.0395) | Acc: (98.72%) (5181/5248)\n",
            "Epoch: 103 | Batch_idx: 50 |  Loss: (0.0375) | Acc: (98.82%) (6451/6528)\n",
            "Epoch: 103 | Batch_idx: 60 |  Loss: (0.0387) | Acc: (98.80%) (7714/7808)\n",
            "Epoch: 103 | Batch_idx: 70 |  Loss: (0.0410) | Acc: (98.69%) (8969/9088)\n",
            "Epoch: 103 | Batch_idx: 80 |  Loss: (0.0420) | Acc: (98.65%) (10228/10368)\n",
            "Epoch: 103 | Batch_idx: 90 |  Loss: (0.0412) | Acc: (98.69%) (11495/11648)\n",
            "Epoch: 103 | Batch_idx: 100 |  Loss: (0.0414) | Acc: (98.66%) (12755/12928)\n",
            "Epoch: 103 | Batch_idx: 110 |  Loss: (0.0418) | Acc: (98.66%) (14018/14208)\n",
            "Epoch: 103 | Batch_idx: 120 |  Loss: (0.0427) | Acc: (98.65%) (15279/15488)\n",
            "Epoch: 103 | Batch_idx: 130 |  Loss: (0.0419) | Acc: (98.67%) (16545/16768)\n",
            "Epoch: 103 | Batch_idx: 140 |  Loss: (0.0411) | Acc: (98.69%) (17811/18048)\n",
            "Epoch: 103 | Batch_idx: 150 |  Loss: (0.0399) | Acc: (98.72%) (19081/19328)\n",
            "Epoch: 103 | Batch_idx: 160 |  Loss: (0.0397) | Acc: (98.71%) (20342/20608)\n",
            "Epoch: 103 | Batch_idx: 170 |  Loss: (0.0395) | Acc: (98.72%) (21608/21888)\n",
            "Epoch: 103 | Batch_idx: 180 |  Loss: (0.0396) | Acc: (98.71%) (22869/23168)\n",
            "Epoch: 103 | Batch_idx: 190 |  Loss: (0.0397) | Acc: (98.68%) (24126/24448)\n",
            "Epoch: 103 | Batch_idx: 200 |  Loss: (0.0396) | Acc: (98.69%) (25390/25728)\n",
            "Epoch: 103 | Batch_idx: 210 |  Loss: (0.0393) | Acc: (98.69%) (26655/27008)\n",
            "Epoch: 103 | Batch_idx: 220 |  Loss: (0.0391) | Acc: (98.70%) (27919/28288)\n",
            "Epoch: 103 | Batch_idx: 230 |  Loss: (0.0390) | Acc: (98.69%) (29181/29568)\n",
            "Epoch: 103 | Batch_idx: 240 |  Loss: (0.0397) | Acc: (98.66%) (30436/30848)\n",
            "Epoch: 103 | Batch_idx: 250 |  Loss: (0.0392) | Acc: (98.69%) (31706/32128)\n",
            "Epoch: 103 | Batch_idx: 260 |  Loss: (0.0390) | Acc: (98.69%) (32972/33408)\n",
            "Epoch: 103 | Batch_idx: 270 |  Loss: (0.0396) | Acc: (98.68%) (34231/34688)\n",
            "Epoch: 103 | Batch_idx: 280 |  Loss: (0.0400) | Acc: (98.67%) (35488/35968)\n",
            "Epoch: 103 | Batch_idx: 290 |  Loss: (0.0400) | Acc: (98.67%) (36752/37248)\n",
            "Epoch: 103 | Batch_idx: 300 |  Loss: (0.0397) | Acc: (98.67%) (38017/38528)\n",
            "Epoch: 103 | Batch_idx: 310 |  Loss: (0.0404) | Acc: (98.66%) (39276/39808)\n",
            "Epoch: 103 | Batch_idx: 320 |  Loss: (0.0401) | Acc: (98.67%) (40540/41088)\n",
            "Epoch: 103 | Batch_idx: 330 |  Loss: (0.0402) | Acc: (98.67%) (41804/42368)\n",
            "Epoch: 103 | Batch_idx: 340 |  Loss: (0.0404) | Acc: (98.65%) (43060/43648)\n",
            "Epoch: 103 | Batch_idx: 350 |  Loss: (0.0407) | Acc: (98.64%) (44316/44928)\n",
            "Epoch: 103 | Batch_idx: 360 |  Loss: (0.0407) | Acc: (98.63%) (45577/46208)\n",
            "Epoch: 103 | Batch_idx: 370 |  Loss: (0.0410) | Acc: (98.62%) (46833/47488)\n",
            "Epoch: 103 | Batch_idx: 380 |  Loss: (0.0411) | Acc: (98.63%) (48099/48768)\n",
            "Epoch: 103 | Batch_idx: 390 |  Loss: (0.0410) | Acc: (98.63%) (49315/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3463) | Acc: (91.62%) (9162/10000)\n",
            "Epoch: 104 | Batch_idx: 0 |  Loss: (0.0384) | Acc: (98.44%) (126/128)\n",
            "Epoch: 104 | Batch_idx: 10 |  Loss: (0.0325) | Acc: (98.86%) (1392/1408)\n",
            "Epoch: 104 | Batch_idx: 20 |  Loss: (0.0322) | Acc: (98.88%) (2658/2688)\n",
            "Epoch: 104 | Batch_idx: 30 |  Loss: (0.0346) | Acc: (98.74%) (3918/3968)\n",
            "Epoch: 104 | Batch_idx: 40 |  Loss: (0.0362) | Acc: (98.74%) (5182/5248)\n",
            "Epoch: 104 | Batch_idx: 50 |  Loss: (0.0361) | Acc: (98.76%) (6447/6528)\n",
            "Epoch: 104 | Batch_idx: 60 |  Loss: (0.0389) | Acc: (98.64%) (7702/7808)\n",
            "Epoch: 104 | Batch_idx: 70 |  Loss: (0.0384) | Acc: (98.64%) (8964/9088)\n",
            "Epoch: 104 | Batch_idx: 80 |  Loss: (0.0404) | Acc: (98.58%) (10221/10368)\n",
            "Epoch: 104 | Batch_idx: 90 |  Loss: (0.0402) | Acc: (98.59%) (11484/11648)\n",
            "Epoch: 104 | Batch_idx: 100 |  Loss: (0.0399) | Acc: (98.62%) (12750/12928)\n",
            "Epoch: 104 | Batch_idx: 110 |  Loss: (0.0399) | Acc: (98.61%) (14011/14208)\n",
            "Epoch: 104 | Batch_idx: 120 |  Loss: (0.0397) | Acc: (98.61%) (15273/15488)\n",
            "Epoch: 104 | Batch_idx: 130 |  Loss: (0.0394) | Acc: (98.62%) (16536/16768)\n",
            "Epoch: 104 | Batch_idx: 140 |  Loss: (0.0394) | Acc: (98.61%) (17797/18048)\n",
            "Epoch: 104 | Batch_idx: 150 |  Loss: (0.0392) | Acc: (98.63%) (19063/19328)\n",
            "Epoch: 104 | Batch_idx: 160 |  Loss: (0.0404) | Acc: (98.58%) (20316/20608)\n",
            "Epoch: 104 | Batch_idx: 170 |  Loss: (0.0395) | Acc: (98.62%) (21585/21888)\n",
            "Epoch: 104 | Batch_idx: 180 |  Loss: (0.0399) | Acc: (98.59%) (22841/23168)\n",
            "Epoch: 104 | Batch_idx: 190 |  Loss: (0.0405) | Acc: (98.58%) (24101/24448)\n",
            "Epoch: 104 | Batch_idx: 200 |  Loss: (0.0407) | Acc: (98.59%) (25364/25728)\n",
            "Epoch: 104 | Batch_idx: 210 |  Loss: (0.0405) | Acc: (98.61%) (26633/27008)\n",
            "Epoch: 104 | Batch_idx: 220 |  Loss: (0.0398) | Acc: (98.63%) (27900/28288)\n",
            "Epoch: 104 | Batch_idx: 230 |  Loss: (0.0401) | Acc: (98.61%) (29156/29568)\n",
            "Epoch: 104 | Batch_idx: 240 |  Loss: (0.0401) | Acc: (98.60%) (30417/30848)\n",
            "Epoch: 104 | Batch_idx: 250 |  Loss: (0.0401) | Acc: (98.60%) (31679/32128)\n",
            "Epoch: 104 | Batch_idx: 260 |  Loss: (0.0396) | Acc: (98.63%) (32949/33408)\n",
            "Epoch: 104 | Batch_idx: 270 |  Loss: (0.0394) | Acc: (98.63%) (34214/34688)\n",
            "Epoch: 104 | Batch_idx: 280 |  Loss: (0.0393) | Acc: (98.64%) (35479/35968)\n",
            "Epoch: 104 | Batch_idx: 290 |  Loss: (0.0391) | Acc: (98.64%) (36742/37248)\n",
            "Epoch: 104 | Batch_idx: 300 |  Loss: (0.0394) | Acc: (98.63%) (38001/38528)\n",
            "Epoch: 104 | Batch_idx: 310 |  Loss: (0.0398) | Acc: (98.62%) (39259/39808)\n",
            "Epoch: 104 | Batch_idx: 320 |  Loss: (0.0396) | Acc: (98.63%) (40524/41088)\n",
            "Epoch: 104 | Batch_idx: 330 |  Loss: (0.0396) | Acc: (98.64%) (41790/42368)\n",
            "Epoch: 104 | Batch_idx: 340 |  Loss: (0.0392) | Acc: (98.65%) (43057/43648)\n",
            "Epoch: 104 | Batch_idx: 350 |  Loss: (0.0397) | Acc: (98.63%) (44314/44928)\n",
            "Epoch: 104 | Batch_idx: 360 |  Loss: (0.0397) | Acc: (98.62%) (45572/46208)\n",
            "Epoch: 104 | Batch_idx: 370 |  Loss: (0.0395) | Acc: (98.63%) (46838/47488)\n",
            "Epoch: 104 | Batch_idx: 380 |  Loss: (0.0394) | Acc: (98.63%) (48099/48768)\n",
            "Epoch: 104 | Batch_idx: 390 |  Loss: (0.0395) | Acc: (98.62%) (49310/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3504) | Acc: (91.61%) (9161/10000)\n",
            "Epoch: 105 | Batch_idx: 0 |  Loss: (0.0484) | Acc: (99.22%) (127/128)\n",
            "Epoch: 105 | Batch_idx: 10 |  Loss: (0.0380) | Acc: (98.86%) (1392/1408)\n",
            "Epoch: 105 | Batch_idx: 20 |  Loss: (0.0414) | Acc: (98.85%) (2657/2688)\n",
            "Epoch: 105 | Batch_idx: 30 |  Loss: (0.0410) | Acc: (98.77%) (3919/3968)\n",
            "Epoch: 105 | Batch_idx: 40 |  Loss: (0.0409) | Acc: (98.69%) (5179/5248)\n",
            "Epoch: 105 | Batch_idx: 50 |  Loss: (0.0394) | Acc: (98.71%) (6444/6528)\n",
            "Epoch: 105 | Batch_idx: 60 |  Loss: (0.0384) | Acc: (98.72%) (7708/7808)\n",
            "Epoch: 105 | Batch_idx: 70 |  Loss: (0.0396) | Acc: (98.65%) (8965/9088)\n",
            "Epoch: 105 | Batch_idx: 80 |  Loss: (0.0405) | Acc: (98.61%) (10224/10368)\n",
            "Epoch: 105 | Batch_idx: 90 |  Loss: (0.0410) | Acc: (98.57%) (11481/11648)\n",
            "Epoch: 105 | Batch_idx: 100 |  Loss: (0.0406) | Acc: (98.58%) (12744/12928)\n",
            "Epoch: 105 | Batch_idx: 110 |  Loss: (0.0406) | Acc: (98.56%) (14003/14208)\n",
            "Epoch: 105 | Batch_idx: 120 |  Loss: (0.0401) | Acc: (98.57%) (15267/15488)\n",
            "Epoch: 105 | Batch_idx: 130 |  Loss: (0.0401) | Acc: (98.58%) (16530/16768)\n",
            "Epoch: 105 | Batch_idx: 140 |  Loss: (0.0391) | Acc: (98.63%) (17801/18048)\n",
            "Epoch: 105 | Batch_idx: 150 |  Loss: (0.0383) | Acc: (98.66%) (19069/19328)\n",
            "Epoch: 105 | Batch_idx: 160 |  Loss: (0.0381) | Acc: (98.67%) (20334/20608)\n",
            "Epoch: 105 | Batch_idx: 170 |  Loss: (0.0387) | Acc: (98.67%) (21596/21888)\n",
            "Epoch: 105 | Batch_idx: 180 |  Loss: (0.0396) | Acc: (98.61%) (22845/23168)\n",
            "Epoch: 105 | Batch_idx: 190 |  Loss: (0.0388) | Acc: (98.62%) (24111/24448)\n",
            "Epoch: 105 | Batch_idx: 200 |  Loss: (0.0386) | Acc: (98.64%) (25377/25728)\n",
            "Epoch: 105 | Batch_idx: 210 |  Loss: (0.0384) | Acc: (98.65%) (26644/27008)\n",
            "Epoch: 105 | Batch_idx: 220 |  Loss: (0.0386) | Acc: (98.64%) (27903/28288)\n",
            "Epoch: 105 | Batch_idx: 230 |  Loss: (0.0388) | Acc: (98.63%) (29163/29568)\n",
            "Epoch: 105 | Batch_idx: 240 |  Loss: (0.0390) | Acc: (98.62%) (30423/30848)\n",
            "Epoch: 105 | Batch_idx: 250 |  Loss: (0.0390) | Acc: (98.62%) (31685/32128)\n",
            "Epoch: 105 | Batch_idx: 260 |  Loss: (0.0390) | Acc: (98.62%) (32948/33408)\n",
            "Epoch: 105 | Batch_idx: 270 |  Loss: (0.0384) | Acc: (98.65%) (34219/34688)\n",
            "Epoch: 105 | Batch_idx: 280 |  Loss: (0.0383) | Acc: (98.65%) (35483/35968)\n",
            "Epoch: 105 | Batch_idx: 290 |  Loss: (0.0387) | Acc: (98.65%) (36744/37248)\n",
            "Epoch: 105 | Batch_idx: 300 |  Loss: (0.0387) | Acc: (98.64%) (38003/38528)\n",
            "Epoch: 105 | Batch_idx: 310 |  Loss: (0.0384) | Acc: (98.65%) (39270/39808)\n",
            "Epoch: 105 | Batch_idx: 320 |  Loss: (0.0384) | Acc: (98.64%) (40531/41088)\n",
            "Epoch: 105 | Batch_idx: 330 |  Loss: (0.0381) | Acc: (98.66%) (41802/42368)\n",
            "Epoch: 105 | Batch_idx: 340 |  Loss: (0.0383) | Acc: (98.66%) (43065/43648)\n",
            "Epoch: 105 | Batch_idx: 350 |  Loss: (0.0385) | Acc: (98.66%) (44325/44928)\n",
            "Epoch: 105 | Batch_idx: 360 |  Loss: (0.0381) | Acc: (98.68%) (45597/46208)\n",
            "Epoch: 105 | Batch_idx: 370 |  Loss: (0.0380) | Acc: (98.68%) (46859/47488)\n",
            "Epoch: 105 | Batch_idx: 380 |  Loss: (0.0380) | Acc: (98.68%) (48124/48768)\n",
            "Epoch: 105 | Batch_idx: 390 |  Loss: (0.0378) | Acc: (98.68%) (49342/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3536) | Acc: (91.36%) (9136/10000)\n",
            "Epoch: 106 | Batch_idx: 0 |  Loss: (0.1062) | Acc: (95.31%) (122/128)\n",
            "Epoch: 106 | Batch_idx: 10 |  Loss: (0.0517) | Acc: (98.30%) (1384/1408)\n",
            "Epoch: 106 | Batch_idx: 20 |  Loss: (0.0438) | Acc: (98.59%) (2650/2688)\n",
            "Epoch: 106 | Batch_idx: 30 |  Loss: (0.0424) | Acc: (98.69%) (3916/3968)\n",
            "Epoch: 106 | Batch_idx: 40 |  Loss: (0.0416) | Acc: (98.70%) (5180/5248)\n",
            "Epoch: 106 | Batch_idx: 50 |  Loss: (0.0395) | Acc: (98.77%) (6448/6528)\n",
            "Epoch: 106 | Batch_idx: 60 |  Loss: (0.0374) | Acc: (98.86%) (7719/7808)\n",
            "Epoch: 106 | Batch_idx: 70 |  Loss: (0.0373) | Acc: (98.88%) (8986/9088)\n",
            "Epoch: 106 | Batch_idx: 80 |  Loss: (0.0378) | Acc: (98.82%) (10246/10368)\n",
            "Epoch: 106 | Batch_idx: 90 |  Loss: (0.0382) | Acc: (98.82%) (11510/11648)\n",
            "Epoch: 106 | Batch_idx: 100 |  Loss: (0.0375) | Acc: (98.86%) (12780/12928)\n",
            "Epoch: 106 | Batch_idx: 110 |  Loss: (0.0372) | Acc: (98.84%) (14043/14208)\n",
            "Epoch: 106 | Batch_idx: 120 |  Loss: (0.0368) | Acc: (98.83%) (15307/15488)\n",
            "Epoch: 106 | Batch_idx: 130 |  Loss: (0.0376) | Acc: (98.81%) (16568/16768)\n",
            "Epoch: 106 | Batch_idx: 140 |  Loss: (0.0374) | Acc: (98.81%) (17834/18048)\n",
            "Epoch: 106 | Batch_idx: 150 |  Loss: (0.0368) | Acc: (98.83%) (19101/19328)\n",
            "Epoch: 106 | Batch_idx: 160 |  Loss: (0.0370) | Acc: (98.82%) (20364/20608)\n",
            "Epoch: 106 | Batch_idx: 170 |  Loss: (0.0376) | Acc: (98.77%) (21619/21888)\n",
            "Epoch: 106 | Batch_idx: 180 |  Loss: (0.0377) | Acc: (98.76%) (22881/23168)\n",
            "Epoch: 106 | Batch_idx: 190 |  Loss: (0.0371) | Acc: (98.77%) (24147/24448)\n",
            "Epoch: 106 | Batch_idx: 200 |  Loss: (0.0376) | Acc: (98.77%) (25412/25728)\n",
            "Epoch: 106 | Batch_idx: 210 |  Loss: (0.0377) | Acc: (98.78%) (26678/27008)\n",
            "Epoch: 106 | Batch_idx: 220 |  Loss: (0.0380) | Acc: (98.77%) (27941/28288)\n",
            "Epoch: 106 | Batch_idx: 230 |  Loss: (0.0383) | Acc: (98.76%) (29202/29568)\n",
            "Epoch: 106 | Batch_idx: 240 |  Loss: (0.0384) | Acc: (98.75%) (30463/30848)\n",
            "Epoch: 106 | Batch_idx: 250 |  Loss: (0.0387) | Acc: (98.74%) (31723/32128)\n",
            "Epoch: 106 | Batch_idx: 260 |  Loss: (0.0386) | Acc: (98.75%) (32990/33408)\n",
            "Epoch: 106 | Batch_idx: 270 |  Loss: (0.0382) | Acc: (98.75%) (34255/34688)\n",
            "Epoch: 106 | Batch_idx: 280 |  Loss: (0.0380) | Acc: (98.76%) (35522/35968)\n",
            "Epoch: 106 | Batch_idx: 290 |  Loss: (0.0377) | Acc: (98.77%) (36790/37248)\n",
            "Epoch: 106 | Batch_idx: 300 |  Loss: (0.0378) | Acc: (98.77%) (38053/38528)\n",
            "Epoch: 106 | Batch_idx: 310 |  Loss: (0.0379) | Acc: (98.76%) (39314/39808)\n",
            "Epoch: 106 | Batch_idx: 320 |  Loss: (0.0376) | Acc: (98.77%) (40581/41088)\n",
            "Epoch: 106 | Batch_idx: 330 |  Loss: (0.0377) | Acc: (98.76%) (41844/42368)\n",
            "Epoch: 106 | Batch_idx: 340 |  Loss: (0.0375) | Acc: (98.77%) (43110/43648)\n",
            "Epoch: 106 | Batch_idx: 350 |  Loss: (0.0372) | Acc: (98.78%) (44378/44928)\n",
            "Epoch: 106 | Batch_idx: 360 |  Loss: (0.0375) | Acc: (98.77%) (45639/46208)\n",
            "Epoch: 106 | Batch_idx: 370 |  Loss: (0.0377) | Acc: (98.76%) (46901/47488)\n",
            "Epoch: 106 | Batch_idx: 380 |  Loss: (0.0373) | Acc: (98.78%) (48173/48768)\n",
            "Epoch: 106 | Batch_idx: 390 |  Loss: (0.0373) | Acc: (98.79%) (49393/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3581) | Acc: (91.57%) (9157/10000)\n",
            "Epoch: 107 | Batch_idx: 0 |  Loss: (0.0382) | Acc: (98.44%) (126/128)\n",
            "Epoch: 107 | Batch_idx: 10 |  Loss: (0.0538) | Acc: (98.37%) (1385/1408)\n",
            "Epoch: 107 | Batch_idx: 20 |  Loss: (0.0411) | Acc: (98.74%) (2654/2688)\n",
            "Epoch: 107 | Batch_idx: 30 |  Loss: (0.0440) | Acc: (98.61%) (3913/3968)\n",
            "Epoch: 107 | Batch_idx: 40 |  Loss: (0.0430) | Acc: (98.55%) (5172/5248)\n",
            "Epoch: 107 | Batch_idx: 50 |  Loss: (0.0442) | Acc: (98.47%) (6428/6528)\n",
            "Epoch: 107 | Batch_idx: 60 |  Loss: (0.0444) | Acc: (98.48%) (7689/7808)\n",
            "Epoch: 107 | Batch_idx: 70 |  Loss: (0.0424) | Acc: (98.54%) (8955/9088)\n",
            "Epoch: 107 | Batch_idx: 80 |  Loss: (0.0434) | Acc: (98.50%) (10212/10368)\n",
            "Epoch: 107 | Batch_idx: 90 |  Loss: (0.0428) | Acc: (98.51%) (11475/11648)\n",
            "Epoch: 107 | Batch_idx: 100 |  Loss: (0.0435) | Acc: (98.51%) (12735/12928)\n",
            "Epoch: 107 | Batch_idx: 110 |  Loss: (0.0421) | Acc: (98.57%) (14005/14208)\n",
            "Epoch: 107 | Batch_idx: 120 |  Loss: (0.0428) | Acc: (98.55%) (15263/15488)\n",
            "Epoch: 107 | Batch_idx: 130 |  Loss: (0.0430) | Acc: (98.56%) (16526/16768)\n",
            "Epoch: 107 | Batch_idx: 140 |  Loss: (0.0430) | Acc: (98.56%) (17789/18048)\n",
            "Epoch: 107 | Batch_idx: 150 |  Loss: (0.0424) | Acc: (98.58%) (19054/19328)\n",
            "Epoch: 107 | Batch_idx: 160 |  Loss: (0.0429) | Acc: (98.56%) (20311/20608)\n",
            "Epoch: 107 | Batch_idx: 170 |  Loss: (0.0423) | Acc: (98.59%) (21579/21888)\n",
            "Epoch: 107 | Batch_idx: 180 |  Loss: (0.0416) | Acc: (98.61%) (22845/23168)\n",
            "Epoch: 107 | Batch_idx: 190 |  Loss: (0.0420) | Acc: (98.59%) (24103/24448)\n",
            "Epoch: 107 | Batch_idx: 200 |  Loss: (0.0417) | Acc: (98.60%) (25367/25728)\n",
            "Epoch: 107 | Batch_idx: 210 |  Loss: (0.0417) | Acc: (98.58%) (26625/27008)\n",
            "Epoch: 107 | Batch_idx: 220 |  Loss: (0.0409) | Acc: (98.61%) (27894/28288)\n",
            "Epoch: 107 | Batch_idx: 230 |  Loss: (0.0407) | Acc: (98.61%) (29157/29568)\n",
            "Epoch: 107 | Batch_idx: 240 |  Loss: (0.0407) | Acc: (98.63%) (30424/30848)\n",
            "Epoch: 107 | Batch_idx: 250 |  Loss: (0.0407) | Acc: (98.63%) (31687/32128)\n",
            "Epoch: 107 | Batch_idx: 260 |  Loss: (0.0406) | Acc: (98.64%) (32953/33408)\n",
            "Epoch: 107 | Batch_idx: 270 |  Loss: (0.0405) | Acc: (98.65%) (34218/34688)\n",
            "Epoch: 107 | Batch_idx: 280 |  Loss: (0.0402) | Acc: (98.65%) (35482/35968)\n",
            "Epoch: 107 | Batch_idx: 290 |  Loss: (0.0398) | Acc: (98.66%) (36748/37248)\n",
            "Epoch: 107 | Batch_idx: 300 |  Loss: (0.0399) | Acc: (98.66%) (38012/38528)\n",
            "Epoch: 107 | Batch_idx: 310 |  Loss: (0.0399) | Acc: (98.66%) (39274/39808)\n",
            "Epoch: 107 | Batch_idx: 320 |  Loss: (0.0402) | Acc: (98.65%) (40535/41088)\n",
            "Epoch: 107 | Batch_idx: 330 |  Loss: (0.0403) | Acc: (98.65%) (41796/42368)\n",
            "Epoch: 107 | Batch_idx: 340 |  Loss: (0.0402) | Acc: (98.64%) (43055/43648)\n",
            "Epoch: 107 | Batch_idx: 350 |  Loss: (0.0403) | Acc: (98.63%) (44314/44928)\n",
            "Epoch: 107 | Batch_idx: 360 |  Loss: (0.0399) | Acc: (98.64%) (45580/46208)\n",
            "Epoch: 107 | Batch_idx: 370 |  Loss: (0.0401) | Acc: (98.63%) (46838/47488)\n",
            "Epoch: 107 | Batch_idx: 380 |  Loss: (0.0405) | Acc: (98.63%) (48098/48768)\n",
            "Epoch: 107 | Batch_idx: 390 |  Loss: (0.0405) | Acc: (98.62%) (49310/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3518) | Acc: (91.08%) (9108/10000)\n",
            "Epoch: 108 | Batch_idx: 0 |  Loss: (0.1103) | Acc: (97.66%) (125/128)\n",
            "Epoch: 108 | Batch_idx: 10 |  Loss: (0.0511) | Acc: (98.30%) (1384/1408)\n",
            "Epoch: 108 | Batch_idx: 20 |  Loss: (0.0454) | Acc: (98.47%) (2647/2688)\n",
            "Epoch: 108 | Batch_idx: 30 |  Loss: (0.0476) | Acc: (98.41%) (3905/3968)\n",
            "Epoch: 108 | Batch_idx: 40 |  Loss: (0.0455) | Acc: (98.46%) (5167/5248)\n",
            "Epoch: 108 | Batch_idx: 50 |  Loss: (0.0459) | Acc: (98.39%) (6423/6528)\n",
            "Epoch: 108 | Batch_idx: 60 |  Loss: (0.0440) | Acc: (98.49%) (7690/7808)\n",
            "Epoch: 108 | Batch_idx: 70 |  Loss: (0.0420) | Acc: (98.55%) (8956/9088)\n",
            "Epoch: 108 | Batch_idx: 80 |  Loss: (0.0418) | Acc: (98.52%) (10215/10368)\n",
            "Epoch: 108 | Batch_idx: 90 |  Loss: (0.0412) | Acc: (98.54%) (11478/11648)\n",
            "Epoch: 108 | Batch_idx: 100 |  Loss: (0.0404) | Acc: (98.57%) (12743/12928)\n",
            "Epoch: 108 | Batch_idx: 110 |  Loss: (0.0404) | Acc: (98.57%) (14005/14208)\n",
            "Epoch: 108 | Batch_idx: 120 |  Loss: (0.0400) | Acc: (98.59%) (15270/15488)\n",
            "Epoch: 108 | Batch_idx: 130 |  Loss: (0.0399) | Acc: (98.61%) (16535/16768)\n",
            "Epoch: 108 | Batch_idx: 140 |  Loss: (0.0405) | Acc: (98.59%) (17793/18048)\n",
            "Epoch: 108 | Batch_idx: 150 |  Loss: (0.0418) | Acc: (98.56%) (19050/19328)\n",
            "Epoch: 108 | Batch_idx: 160 |  Loss: (0.0408) | Acc: (98.60%) (20320/20608)\n",
            "Epoch: 108 | Batch_idx: 170 |  Loss: (0.0408) | Acc: (98.61%) (21583/21888)\n",
            "Epoch: 108 | Batch_idx: 180 |  Loss: (0.0407) | Acc: (98.62%) (22848/23168)\n",
            "Epoch: 108 | Batch_idx: 190 |  Loss: (0.0405) | Acc: (98.64%) (24116/24448)\n",
            "Epoch: 108 | Batch_idx: 200 |  Loss: (0.0397) | Acc: (98.67%) (25385/25728)\n",
            "Epoch: 108 | Batch_idx: 210 |  Loss: (0.0397) | Acc: (98.68%) (26651/27008)\n",
            "Epoch: 108 | Batch_idx: 220 |  Loss: (0.0396) | Acc: (98.67%) (27912/28288)\n",
            "Epoch: 108 | Batch_idx: 230 |  Loss: (0.0398) | Acc: (98.68%) (29179/29568)\n",
            "Epoch: 108 | Batch_idx: 240 |  Loss: (0.0405) | Acc: (98.65%) (30432/30848)\n",
            "Epoch: 108 | Batch_idx: 250 |  Loss: (0.0406) | Acc: (98.64%) (31692/32128)\n",
            "Epoch: 108 | Batch_idx: 260 |  Loss: (0.0399) | Acc: (98.66%) (32959/33408)\n",
            "Epoch: 108 | Batch_idx: 270 |  Loss: (0.0407) | Acc: (98.64%) (34216/34688)\n",
            "Epoch: 108 | Batch_idx: 280 |  Loss: (0.0404) | Acc: (98.65%) (35481/35968)\n",
            "Epoch: 108 | Batch_idx: 290 |  Loss: (0.0403) | Acc: (98.64%) (36741/37248)\n",
            "Epoch: 108 | Batch_idx: 300 |  Loss: (0.0403) | Acc: (98.64%) (38003/38528)\n",
            "Epoch: 108 | Batch_idx: 310 |  Loss: (0.0401) | Acc: (98.65%) (39271/39808)\n",
            "Epoch: 108 | Batch_idx: 320 |  Loss: (0.0399) | Acc: (98.66%) (40538/41088)\n",
            "Epoch: 108 | Batch_idx: 330 |  Loss: (0.0395) | Acc: (98.68%) (41807/42368)\n",
            "Epoch: 108 | Batch_idx: 340 |  Loss: (0.0394) | Acc: (98.68%) (43072/43648)\n",
            "Epoch: 108 | Batch_idx: 350 |  Loss: (0.0389) | Acc: (98.70%) (44342/44928)\n",
            "Epoch: 108 | Batch_idx: 360 |  Loss: (0.0388) | Acc: (98.69%) (45603/46208)\n",
            "Epoch: 108 | Batch_idx: 370 |  Loss: (0.0385) | Acc: (98.70%) (46871/47488)\n",
            "Epoch: 108 | Batch_idx: 380 |  Loss: (0.0383) | Acc: (98.71%) (48137/48768)\n",
            "Epoch: 108 | Batch_idx: 390 |  Loss: (0.0384) | Acc: (98.70%) (49351/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3628) | Acc: (91.46%) (9146/10000)\n",
            "Epoch: 109 | Batch_idx: 0 |  Loss: (0.0219) | Acc: (99.22%) (127/128)\n",
            "Epoch: 109 | Batch_idx: 10 |  Loss: (0.0302) | Acc: (99.01%) (1394/1408)\n",
            "Epoch: 109 | Batch_idx: 20 |  Loss: (0.0303) | Acc: (98.96%) (2660/2688)\n",
            "Epoch: 109 | Batch_idx: 30 |  Loss: (0.0302) | Acc: (98.87%) (3923/3968)\n",
            "Epoch: 109 | Batch_idx: 40 |  Loss: (0.0359) | Acc: (98.69%) (5179/5248)\n",
            "Epoch: 109 | Batch_idx: 50 |  Loss: (0.0380) | Acc: (98.65%) (6440/6528)\n",
            "Epoch: 109 | Batch_idx: 60 |  Loss: (0.0364) | Acc: (98.73%) (7709/7808)\n",
            "Epoch: 109 | Batch_idx: 70 |  Loss: (0.0373) | Acc: (98.75%) (8974/9088)\n",
            "Epoch: 109 | Batch_idx: 80 |  Loss: (0.0370) | Acc: (98.76%) (10239/10368)\n",
            "Epoch: 109 | Batch_idx: 90 |  Loss: (0.0379) | Acc: (98.72%) (11499/11648)\n",
            "Epoch: 109 | Batch_idx: 100 |  Loss: (0.0371) | Acc: (98.75%) (12767/12928)\n",
            "Epoch: 109 | Batch_idx: 110 |  Loss: (0.0385) | Acc: (98.73%) (14028/14208)\n",
            "Epoch: 109 | Batch_idx: 120 |  Loss: (0.0378) | Acc: (98.73%) (15292/15488)\n",
            "Epoch: 109 | Batch_idx: 130 |  Loss: (0.0383) | Acc: (98.72%) (16553/16768)\n",
            "Epoch: 109 | Batch_idx: 140 |  Loss: (0.0383) | Acc: (98.72%) (17817/18048)\n",
            "Epoch: 109 | Batch_idx: 150 |  Loss: (0.0384) | Acc: (98.74%) (19084/19328)\n",
            "Epoch: 109 | Batch_idx: 160 |  Loss: (0.0386) | Acc: (98.70%) (20341/20608)\n",
            "Epoch: 109 | Batch_idx: 170 |  Loss: (0.0380) | Acc: (98.73%) (21609/21888)\n",
            "Epoch: 109 | Batch_idx: 180 |  Loss: (0.0379) | Acc: (98.75%) (22878/23168)\n",
            "Epoch: 109 | Batch_idx: 190 |  Loss: (0.0372) | Acc: (98.79%) (24151/24448)\n",
            "Epoch: 109 | Batch_idx: 200 |  Loss: (0.0373) | Acc: (98.78%) (25413/25728)\n",
            "Epoch: 109 | Batch_idx: 210 |  Loss: (0.0382) | Acc: (98.74%) (26669/27008)\n",
            "Epoch: 109 | Batch_idx: 220 |  Loss: (0.0378) | Acc: (98.75%) (27934/28288)\n",
            "Epoch: 109 | Batch_idx: 230 |  Loss: (0.0377) | Acc: (98.75%) (29198/29568)\n",
            "Epoch: 109 | Batch_idx: 240 |  Loss: (0.0378) | Acc: (98.74%) (30460/30848)\n",
            "Epoch: 109 | Batch_idx: 250 |  Loss: (0.0378) | Acc: (98.74%) (31723/32128)\n",
            "Epoch: 109 | Batch_idx: 260 |  Loss: (0.0379) | Acc: (98.74%) (32988/33408)\n",
            "Epoch: 109 | Batch_idx: 270 |  Loss: (0.0378) | Acc: (98.74%) (34251/34688)\n",
            "Epoch: 109 | Batch_idx: 280 |  Loss: (0.0381) | Acc: (98.73%) (35510/35968)\n",
            "Epoch: 109 | Batch_idx: 290 |  Loss: (0.0383) | Acc: (98.73%) (36775/37248)\n",
            "Epoch: 109 | Batch_idx: 300 |  Loss: (0.0390) | Acc: (98.71%) (38031/38528)\n",
            "Epoch: 109 | Batch_idx: 310 |  Loss: (0.0391) | Acc: (98.70%) (39292/39808)\n",
            "Epoch: 109 | Batch_idx: 320 |  Loss: (0.0388) | Acc: (98.71%) (40559/41088)\n",
            "Epoch: 109 | Batch_idx: 330 |  Loss: (0.0391) | Acc: (98.70%) (41819/42368)\n",
            "Epoch: 109 | Batch_idx: 340 |  Loss: (0.0391) | Acc: (98.70%) (43080/43648)\n",
            "Epoch: 109 | Batch_idx: 350 |  Loss: (0.0390) | Acc: (98.70%) (44342/44928)\n",
            "Epoch: 109 | Batch_idx: 360 |  Loss: (0.0386) | Acc: (98.71%) (45613/46208)\n",
            "Epoch: 109 | Batch_idx: 370 |  Loss: (0.0387) | Acc: (98.70%) (46873/47488)\n",
            "Epoch: 109 | Batch_idx: 380 |  Loss: (0.0386) | Acc: (98.71%) (48139/48768)\n",
            "Epoch: 109 | Batch_idx: 390 |  Loss: (0.0383) | Acc: (98.72%) (49358/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3469) | Acc: (91.50%) (9150/10000)\n",
            "Epoch: 110 | Batch_idx: 0 |  Loss: (0.0127) | Acc: (100.00%) (128/128)\n",
            "Epoch: 110 | Batch_idx: 10 |  Loss: (0.0316) | Acc: (99.01%) (1394/1408)\n",
            "Epoch: 110 | Batch_idx: 20 |  Loss: (0.0318) | Acc: (98.96%) (2660/2688)\n",
            "Epoch: 110 | Batch_idx: 30 |  Loss: (0.0362) | Acc: (98.71%) (3917/3968)\n",
            "Epoch: 110 | Batch_idx: 40 |  Loss: (0.0348) | Acc: (98.74%) (5182/5248)\n",
            "Epoch: 110 | Batch_idx: 50 |  Loss: (0.0355) | Acc: (98.74%) (6446/6528)\n",
            "Epoch: 110 | Batch_idx: 60 |  Loss: (0.0346) | Acc: (98.78%) (7713/7808)\n",
            "Epoch: 110 | Batch_idx: 70 |  Loss: (0.0343) | Acc: (98.78%) (8977/9088)\n",
            "Epoch: 110 | Batch_idx: 80 |  Loss: (0.0343) | Acc: (98.77%) (10240/10368)\n",
            "Epoch: 110 | Batch_idx: 90 |  Loss: (0.0343) | Acc: (98.78%) (11506/11648)\n",
            "Epoch: 110 | Batch_idx: 100 |  Loss: (0.0334) | Acc: (98.82%) (12775/12928)\n",
            "Epoch: 110 | Batch_idx: 110 |  Loss: (0.0339) | Acc: (98.82%) (14040/14208)\n",
            "Epoch: 110 | Batch_idx: 120 |  Loss: (0.0336) | Acc: (98.82%) (15306/15488)\n",
            "Epoch: 110 | Batch_idx: 130 |  Loss: (0.0332) | Acc: (98.84%) (16573/16768)\n",
            "Epoch: 110 | Batch_idx: 140 |  Loss: (0.0328) | Acc: (98.84%) (17839/18048)\n",
            "Epoch: 110 | Batch_idx: 150 |  Loss: (0.0329) | Acc: (98.83%) (19102/19328)\n",
            "Epoch: 110 | Batch_idx: 160 |  Loss: (0.0328) | Acc: (98.83%) (20367/20608)\n",
            "Epoch: 110 | Batch_idx: 170 |  Loss: (0.0323) | Acc: (98.83%) (21632/21888)\n",
            "Epoch: 110 | Batch_idx: 180 |  Loss: (0.0328) | Acc: (98.81%) (22893/23168)\n",
            "Epoch: 110 | Batch_idx: 190 |  Loss: (0.0331) | Acc: (98.80%) (24155/24448)\n",
            "Epoch: 110 | Batch_idx: 200 |  Loss: (0.0336) | Acc: (98.80%) (25419/25728)\n",
            "Epoch: 110 | Batch_idx: 210 |  Loss: (0.0335) | Acc: (98.80%) (26685/27008)\n",
            "Epoch: 110 | Batch_idx: 220 |  Loss: (0.0339) | Acc: (98.79%) (27946/28288)\n",
            "Epoch: 110 | Batch_idx: 230 |  Loss: (0.0340) | Acc: (98.78%) (29207/29568)\n",
            "Epoch: 110 | Batch_idx: 240 |  Loss: (0.0337) | Acc: (98.78%) (30472/30848)\n",
            "Epoch: 110 | Batch_idx: 250 |  Loss: (0.0341) | Acc: (98.77%) (31734/32128)\n",
            "Epoch: 110 | Batch_idx: 260 |  Loss: (0.0339) | Acc: (98.79%) (33004/33408)\n",
            "Epoch: 110 | Batch_idx: 270 |  Loss: (0.0345) | Acc: (98.79%) (34267/34688)\n",
            "Epoch: 110 | Batch_idx: 280 |  Loss: (0.0346) | Acc: (98.78%) (35529/35968)\n",
            "Epoch: 110 | Batch_idx: 290 |  Loss: (0.0342) | Acc: (98.78%) (36795/37248)\n",
            "Epoch: 110 | Batch_idx: 300 |  Loss: (0.0344) | Acc: (98.79%) (38060/38528)\n",
            "Epoch: 110 | Batch_idx: 310 |  Loss: (0.0343) | Acc: (98.78%) (39323/39808)\n",
            "Epoch: 110 | Batch_idx: 320 |  Loss: (0.0344) | Acc: (98.77%) (40584/41088)\n",
            "Epoch: 110 | Batch_idx: 330 |  Loss: (0.0342) | Acc: (98.78%) (41853/42368)\n",
            "Epoch: 110 | Batch_idx: 340 |  Loss: (0.0345) | Acc: (98.78%) (43115/43648)\n",
            "Epoch: 110 | Batch_idx: 350 |  Loss: (0.0346) | Acc: (98.78%) (44378/44928)\n",
            "Epoch: 110 | Batch_idx: 360 |  Loss: (0.0350) | Acc: (98.75%) (45631/46208)\n",
            "Epoch: 110 | Batch_idx: 370 |  Loss: (0.0351) | Acc: (98.75%) (46894/47488)\n",
            "Epoch: 110 | Batch_idx: 380 |  Loss: (0.0353) | Acc: (98.75%) (48157/48768)\n",
            "Epoch: 110 | Batch_idx: 390 |  Loss: (0.0352) | Acc: (98.75%) (49375/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3653) | Acc: (91.28%) (9128/10000)\n",
            "Epoch: 111 | Batch_idx: 0 |  Loss: (0.0755) | Acc: (96.09%) (123/128)\n",
            "Epoch: 111 | Batch_idx: 10 |  Loss: (0.0440) | Acc: (98.79%) (1391/1408)\n",
            "Epoch: 111 | Batch_idx: 20 |  Loss: (0.0423) | Acc: (98.62%) (2651/2688)\n",
            "Epoch: 111 | Batch_idx: 30 |  Loss: (0.0412) | Acc: (98.59%) (3912/3968)\n",
            "Epoch: 111 | Batch_idx: 40 |  Loss: (0.0395) | Acc: (98.70%) (5180/5248)\n",
            "Epoch: 111 | Batch_idx: 50 |  Loss: (0.0397) | Acc: (98.71%) (6444/6528)\n",
            "Epoch: 111 | Batch_idx: 60 |  Loss: (0.0398) | Acc: (98.69%) (7706/7808)\n",
            "Epoch: 111 | Batch_idx: 70 |  Loss: (0.0390) | Acc: (98.70%) (8970/9088)\n",
            "Epoch: 111 | Batch_idx: 80 |  Loss: (0.0386) | Acc: (98.76%) (10239/10368)\n",
            "Epoch: 111 | Batch_idx: 90 |  Loss: (0.0395) | Acc: (98.75%) (11502/11648)\n",
            "Epoch: 111 | Batch_idx: 100 |  Loss: (0.0380) | Acc: (98.79%) (12772/12928)\n",
            "Epoch: 111 | Batch_idx: 110 |  Loss: (0.0374) | Acc: (98.82%) (14041/14208)\n",
            "Epoch: 111 | Batch_idx: 120 |  Loss: (0.0377) | Acc: (98.80%) (15302/15488)\n",
            "Epoch: 111 | Batch_idx: 130 |  Loss: (0.0372) | Acc: (98.77%) (16562/16768)\n",
            "Epoch: 111 | Batch_idx: 140 |  Loss: (0.0366) | Acc: (98.78%) (17828/18048)\n",
            "Epoch: 111 | Batch_idx: 150 |  Loss: (0.0360) | Acc: (98.82%) (19099/19328)\n",
            "Epoch: 111 | Batch_idx: 160 |  Loss: (0.0364) | Acc: (98.81%) (20363/20608)\n",
            "Epoch: 111 | Batch_idx: 170 |  Loss: (0.0358) | Acc: (98.84%) (21635/21888)\n",
            "Epoch: 111 | Batch_idx: 180 |  Loss: (0.0360) | Acc: (98.81%) (22893/23168)\n",
            "Epoch: 111 | Batch_idx: 190 |  Loss: (0.0362) | Acc: (98.80%) (24155/24448)\n",
            "Epoch: 111 | Batch_idx: 200 |  Loss: (0.0362) | Acc: (98.80%) (25418/25728)\n",
            "Epoch: 111 | Batch_idx: 210 |  Loss: (0.0369) | Acc: (98.79%) (26680/27008)\n",
            "Epoch: 111 | Batch_idx: 220 |  Loss: (0.0364) | Acc: (98.80%) (27948/28288)\n",
            "Epoch: 111 | Batch_idx: 230 |  Loss: (0.0365) | Acc: (98.79%) (29211/29568)\n",
            "Epoch: 111 | Batch_idx: 240 |  Loss: (0.0359) | Acc: (98.81%) (30482/30848)\n",
            "Epoch: 111 | Batch_idx: 250 |  Loss: (0.0356) | Acc: (98.83%) (31752/32128)\n",
            "Epoch: 111 | Batch_idx: 260 |  Loss: (0.0355) | Acc: (98.84%) (33019/33408)\n",
            "Epoch: 111 | Batch_idx: 270 |  Loss: (0.0355) | Acc: (98.83%) (34282/34688)\n",
            "Epoch: 111 | Batch_idx: 280 |  Loss: (0.0354) | Acc: (98.83%) (35547/35968)\n",
            "Epoch: 111 | Batch_idx: 290 |  Loss: (0.0354) | Acc: (98.82%) (36808/37248)\n",
            "Epoch: 111 | Batch_idx: 300 |  Loss: (0.0351) | Acc: (98.84%) (38080/38528)\n",
            "Epoch: 111 | Batch_idx: 310 |  Loss: (0.0349) | Acc: (98.84%) (39345/39808)\n",
            "Epoch: 111 | Batch_idx: 320 |  Loss: (0.0349) | Acc: (98.83%) (40608/41088)\n",
            "Epoch: 111 | Batch_idx: 330 |  Loss: (0.0347) | Acc: (98.84%) (41875/42368)\n",
            "Epoch: 111 | Batch_idx: 340 |  Loss: (0.0346) | Acc: (98.85%) (43144/43648)\n",
            "Epoch: 111 | Batch_idx: 350 |  Loss: (0.0349) | Acc: (98.84%) (44406/44928)\n",
            "Epoch: 111 | Batch_idx: 360 |  Loss: (0.0347) | Acc: (98.85%) (45675/46208)\n",
            "Epoch: 111 | Batch_idx: 370 |  Loss: (0.0344) | Acc: (98.85%) (46944/47488)\n",
            "Epoch: 111 | Batch_idx: 380 |  Loss: (0.0345) | Acc: (98.85%) (48209/48768)\n",
            "Epoch: 111 | Batch_idx: 390 |  Loss: (0.0343) | Acc: (98.86%) (49429/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3591) | Acc: (91.56%) (9156/10000)\n",
            "Epoch: 112 | Batch_idx: 0 |  Loss: (0.0370) | Acc: (99.22%) (127/128)\n",
            "Epoch: 112 | Batch_idx: 10 |  Loss: (0.0248) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 112 | Batch_idx: 20 |  Loss: (0.0268) | Acc: (99.18%) (2666/2688)\n",
            "Epoch: 112 | Batch_idx: 30 |  Loss: (0.0263) | Acc: (99.24%) (3938/3968)\n",
            "Epoch: 112 | Batch_idx: 40 |  Loss: (0.0293) | Acc: (99.05%) (5198/5248)\n",
            "Epoch: 112 | Batch_idx: 50 |  Loss: (0.0290) | Acc: (99.10%) (6469/6528)\n",
            "Epoch: 112 | Batch_idx: 60 |  Loss: (0.0289) | Acc: (99.09%) (7737/7808)\n",
            "Epoch: 112 | Batch_idx: 70 |  Loss: (0.0284) | Acc: (99.05%) (9002/9088)\n",
            "Epoch: 112 | Batch_idx: 80 |  Loss: (0.0291) | Acc: (99.04%) (10268/10368)\n",
            "Epoch: 112 | Batch_idx: 90 |  Loss: (0.0299) | Acc: (99.00%) (11531/11648)\n",
            "Epoch: 112 | Batch_idx: 100 |  Loss: (0.0297) | Acc: (99.00%) (12799/12928)\n",
            "Epoch: 112 | Batch_idx: 110 |  Loss: (0.0298) | Acc: (99.00%) (14066/14208)\n",
            "Epoch: 112 | Batch_idx: 120 |  Loss: (0.0304) | Acc: (98.97%) (15329/15488)\n",
            "Epoch: 112 | Batch_idx: 130 |  Loss: (0.0307) | Acc: (98.98%) (16597/16768)\n",
            "Epoch: 112 | Batch_idx: 140 |  Loss: (0.0308) | Acc: (98.97%) (17863/18048)\n",
            "Epoch: 112 | Batch_idx: 150 |  Loss: (0.0308) | Acc: (98.95%) (19125/19328)\n",
            "Epoch: 112 | Batch_idx: 160 |  Loss: (0.0314) | Acc: (98.94%) (20389/20608)\n",
            "Epoch: 112 | Batch_idx: 170 |  Loss: (0.0318) | Acc: (98.92%) (21652/21888)\n",
            "Epoch: 112 | Batch_idx: 180 |  Loss: (0.0320) | Acc: (98.90%) (22914/23168)\n",
            "Epoch: 112 | Batch_idx: 190 |  Loss: (0.0324) | Acc: (98.91%) (24182/24448)\n",
            "Epoch: 112 | Batch_idx: 200 |  Loss: (0.0326) | Acc: (98.89%) (25443/25728)\n",
            "Epoch: 112 | Batch_idx: 210 |  Loss: (0.0328) | Acc: (98.88%) (26705/27008)\n",
            "Epoch: 112 | Batch_idx: 220 |  Loss: (0.0324) | Acc: (98.90%) (27976/28288)\n",
            "Epoch: 112 | Batch_idx: 230 |  Loss: (0.0326) | Acc: (98.89%) (29239/29568)\n",
            "Epoch: 112 | Batch_idx: 240 |  Loss: (0.0329) | Acc: (98.88%) (30502/30848)\n",
            "Epoch: 112 | Batch_idx: 250 |  Loss: (0.0334) | Acc: (98.86%) (31763/32128)\n",
            "Epoch: 112 | Batch_idx: 260 |  Loss: (0.0335) | Acc: (98.85%) (33025/33408)\n",
            "Epoch: 112 | Batch_idx: 270 |  Loss: (0.0334) | Acc: (98.85%) (34290/34688)\n",
            "Epoch: 112 | Batch_idx: 280 |  Loss: (0.0336) | Acc: (98.84%) (35550/35968)\n",
            "Epoch: 112 | Batch_idx: 290 |  Loss: (0.0340) | Acc: (98.82%) (36810/37248)\n",
            "Epoch: 112 | Batch_idx: 300 |  Loss: (0.0347) | Acc: (98.81%) (38068/38528)\n",
            "Epoch: 112 | Batch_idx: 310 |  Loss: (0.0345) | Acc: (98.80%) (39330/39808)\n",
            "Epoch: 112 | Batch_idx: 320 |  Loss: (0.0345) | Acc: (98.80%) (40594/41088)\n",
            "Epoch: 112 | Batch_idx: 330 |  Loss: (0.0346) | Acc: (98.79%) (41854/42368)\n",
            "Epoch: 112 | Batch_idx: 340 |  Loss: (0.0347) | Acc: (98.79%) (43119/43648)\n",
            "Epoch: 112 | Batch_idx: 350 |  Loss: (0.0347) | Acc: (98.79%) (44384/44928)\n",
            "Epoch: 112 | Batch_idx: 360 |  Loss: (0.0351) | Acc: (98.77%) (45641/46208)\n",
            "Epoch: 112 | Batch_idx: 370 |  Loss: (0.0353) | Acc: (98.77%) (46903/47488)\n",
            "Epoch: 112 | Batch_idx: 380 |  Loss: (0.0350) | Acc: (98.78%) (48174/48768)\n",
            "Epoch: 112 | Batch_idx: 390 |  Loss: (0.0350) | Acc: (98.78%) (49388/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3648) | Acc: (91.43%) (9143/10000)\n",
            "Epoch: 113 | Batch_idx: 0 |  Loss: (0.0481) | Acc: (97.66%) (125/128)\n",
            "Epoch: 113 | Batch_idx: 10 |  Loss: (0.0382) | Acc: (98.72%) (1390/1408)\n",
            "Epoch: 113 | Batch_idx: 20 |  Loss: (0.0337) | Acc: (98.92%) (2659/2688)\n",
            "Epoch: 113 | Batch_idx: 30 |  Loss: (0.0314) | Acc: (98.94%) (3926/3968)\n",
            "Epoch: 113 | Batch_idx: 40 |  Loss: (0.0316) | Acc: (98.89%) (5190/5248)\n",
            "Epoch: 113 | Batch_idx: 50 |  Loss: (0.0329) | Acc: (98.77%) (6448/6528)\n",
            "Epoch: 113 | Batch_idx: 60 |  Loss: (0.0329) | Acc: (98.81%) (7715/7808)\n",
            "Epoch: 113 | Batch_idx: 70 |  Loss: (0.0338) | Acc: (98.80%) (8979/9088)\n",
            "Epoch: 113 | Batch_idx: 80 |  Loss: (0.0347) | Acc: (98.76%) (10239/10368)\n",
            "Epoch: 113 | Batch_idx: 90 |  Loss: (0.0344) | Acc: (98.77%) (11505/11648)\n",
            "Epoch: 113 | Batch_idx: 100 |  Loss: (0.0345) | Acc: (98.76%) (12768/12928)\n",
            "Epoch: 113 | Batch_idx: 110 |  Loss: (0.0349) | Acc: (98.71%) (14025/14208)\n",
            "Epoch: 113 | Batch_idx: 120 |  Loss: (0.0344) | Acc: (98.75%) (15295/15488)\n",
            "Epoch: 113 | Batch_idx: 130 |  Loss: (0.0346) | Acc: (98.75%) (16558/16768)\n",
            "Epoch: 113 | Batch_idx: 140 |  Loss: (0.0349) | Acc: (98.72%) (17817/18048)\n",
            "Epoch: 113 | Batch_idx: 150 |  Loss: (0.0352) | Acc: (98.71%) (19078/19328)\n",
            "Epoch: 113 | Batch_idx: 160 |  Loss: (0.0357) | Acc: (98.70%) (20341/20608)\n",
            "Epoch: 113 | Batch_idx: 170 |  Loss: (0.0358) | Acc: (98.70%) (21604/21888)\n",
            "Epoch: 113 | Batch_idx: 180 |  Loss: (0.0356) | Acc: (98.71%) (22870/23168)\n",
            "Epoch: 113 | Batch_idx: 190 |  Loss: (0.0352) | Acc: (98.72%) (24135/24448)\n",
            "Epoch: 113 | Batch_idx: 200 |  Loss: (0.0351) | Acc: (98.71%) (25397/25728)\n",
            "Epoch: 113 | Batch_idx: 210 |  Loss: (0.0351) | Acc: (98.73%) (26664/27008)\n",
            "Epoch: 113 | Batch_idx: 220 |  Loss: (0.0351) | Acc: (98.73%) (27928/28288)\n",
            "Epoch: 113 | Batch_idx: 230 |  Loss: (0.0351) | Acc: (98.74%) (29196/29568)\n",
            "Epoch: 113 | Batch_idx: 240 |  Loss: (0.0351) | Acc: (98.74%) (30458/30848)\n",
            "Epoch: 113 | Batch_idx: 250 |  Loss: (0.0356) | Acc: (98.74%) (31723/32128)\n",
            "Epoch: 113 | Batch_idx: 260 |  Loss: (0.0356) | Acc: (98.74%) (32988/33408)\n",
            "Epoch: 113 | Batch_idx: 270 |  Loss: (0.0356) | Acc: (98.76%) (34257/34688)\n",
            "Epoch: 113 | Batch_idx: 280 |  Loss: (0.0352) | Acc: (98.77%) (35526/35968)\n",
            "Epoch: 113 | Batch_idx: 290 |  Loss: (0.0349) | Acc: (98.78%) (36792/37248)\n",
            "Epoch: 113 | Batch_idx: 300 |  Loss: (0.0348) | Acc: (98.77%) (38056/38528)\n",
            "Epoch: 113 | Batch_idx: 310 |  Loss: (0.0351) | Acc: (98.77%) (39319/39808)\n",
            "Epoch: 113 | Batch_idx: 320 |  Loss: (0.0349) | Acc: (98.79%) (40589/41088)\n",
            "Epoch: 113 | Batch_idx: 330 |  Loss: (0.0346) | Acc: (98.79%) (41856/42368)\n",
            "Epoch: 113 | Batch_idx: 340 |  Loss: (0.0344) | Acc: (98.80%) (43125/43648)\n",
            "Epoch: 113 | Batch_idx: 350 |  Loss: (0.0342) | Acc: (98.82%) (44397/44928)\n",
            "Epoch: 113 | Batch_idx: 360 |  Loss: (0.0341) | Acc: (98.82%) (45662/46208)\n",
            "Epoch: 113 | Batch_idx: 370 |  Loss: (0.0340) | Acc: (98.82%) (46928/47488)\n",
            "Epoch: 113 | Batch_idx: 380 |  Loss: (0.0339) | Acc: (98.82%) (48191/48768)\n",
            "Epoch: 113 | Batch_idx: 390 |  Loss: (0.0341) | Acc: (98.81%) (49406/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3648) | Acc: (91.44%) (9144/10000)\n",
            "Epoch: 114 | Batch_idx: 0 |  Loss: (0.0164) | Acc: (99.22%) (127/128)\n",
            "Epoch: 114 | Batch_idx: 10 |  Loss: (0.0249) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 114 | Batch_idx: 20 |  Loss: (0.0296) | Acc: (98.81%) (2656/2688)\n",
            "Epoch: 114 | Batch_idx: 30 |  Loss: (0.0295) | Acc: (98.92%) (3925/3968)\n",
            "Epoch: 114 | Batch_idx: 40 |  Loss: (0.0339) | Acc: (98.78%) (5184/5248)\n",
            "Epoch: 114 | Batch_idx: 50 |  Loss: (0.0330) | Acc: (98.79%) (6449/6528)\n",
            "Epoch: 114 | Batch_idx: 60 |  Loss: (0.0338) | Acc: (98.78%) (7713/7808)\n",
            "Epoch: 114 | Batch_idx: 70 |  Loss: (0.0336) | Acc: (98.77%) (8976/9088)\n",
            "Epoch: 114 | Batch_idx: 80 |  Loss: (0.0356) | Acc: (98.76%) (10239/10368)\n",
            "Epoch: 114 | Batch_idx: 90 |  Loss: (0.0364) | Acc: (98.76%) (11503/11648)\n",
            "Epoch: 114 | Batch_idx: 100 |  Loss: (0.0364) | Acc: (98.73%) (12764/12928)\n",
            "Epoch: 114 | Batch_idx: 110 |  Loss: (0.0367) | Acc: (98.73%) (14027/14208)\n",
            "Epoch: 114 | Batch_idx: 120 |  Loss: (0.0368) | Acc: (98.75%) (15294/15488)\n",
            "Epoch: 114 | Batch_idx: 130 |  Loss: (0.0367) | Acc: (98.74%) (16557/16768)\n",
            "Epoch: 114 | Batch_idx: 140 |  Loss: (0.0374) | Acc: (98.71%) (17815/18048)\n",
            "Epoch: 114 | Batch_idx: 150 |  Loss: (0.0383) | Acc: (98.68%) (19072/19328)\n",
            "Epoch: 114 | Batch_idx: 160 |  Loss: (0.0378) | Acc: (98.68%) (20335/20608)\n",
            "Epoch: 114 | Batch_idx: 170 |  Loss: (0.0378) | Acc: (98.70%) (21604/21888)\n",
            "Epoch: 114 | Batch_idx: 180 |  Loss: (0.0373) | Acc: (98.72%) (22872/23168)\n",
            "Epoch: 114 | Batch_idx: 190 |  Loss: (0.0371) | Acc: (98.73%) (24137/24448)\n",
            "Epoch: 114 | Batch_idx: 200 |  Loss: (0.0368) | Acc: (98.73%) (25401/25728)\n",
            "Epoch: 114 | Batch_idx: 210 |  Loss: (0.0368) | Acc: (98.74%) (26667/27008)\n",
            "Epoch: 114 | Batch_idx: 220 |  Loss: (0.0376) | Acc: (98.72%) (27925/28288)\n",
            "Epoch: 114 | Batch_idx: 230 |  Loss: (0.0373) | Acc: (98.73%) (29193/29568)\n",
            "Epoch: 114 | Batch_idx: 240 |  Loss: (0.0370) | Acc: (98.74%) (30459/30848)\n",
            "Epoch: 114 | Batch_idx: 250 |  Loss: (0.0365) | Acc: (98.77%) (31732/32128)\n",
            "Epoch: 114 | Batch_idx: 260 |  Loss: (0.0361) | Acc: (98.78%) (33001/33408)\n",
            "Epoch: 114 | Batch_idx: 270 |  Loss: (0.0368) | Acc: (98.75%) (34254/34688)\n",
            "Epoch: 114 | Batch_idx: 280 |  Loss: (0.0369) | Acc: (98.74%) (35516/35968)\n",
            "Epoch: 114 | Batch_idx: 290 |  Loss: (0.0372) | Acc: (98.74%) (36780/37248)\n",
            "Epoch: 114 | Batch_idx: 300 |  Loss: (0.0377) | Acc: (98.73%) (38038/38528)\n",
            "Epoch: 114 | Batch_idx: 310 |  Loss: (0.0378) | Acc: (98.73%) (39303/39808)\n",
            "Epoch: 114 | Batch_idx: 320 |  Loss: (0.0379) | Acc: (98.72%) (40561/41088)\n",
            "Epoch: 114 | Batch_idx: 330 |  Loss: (0.0375) | Acc: (98.73%) (41828/42368)\n",
            "Epoch: 114 | Batch_idx: 340 |  Loss: (0.0375) | Acc: (98.74%) (43096/43648)\n",
            "Epoch: 114 | Batch_idx: 350 |  Loss: (0.0377) | Acc: (98.73%) (44359/44928)\n",
            "Epoch: 114 | Batch_idx: 360 |  Loss: (0.0371) | Acc: (98.75%) (45631/46208)\n",
            "Epoch: 114 | Batch_idx: 370 |  Loss: (0.0372) | Acc: (98.75%) (46895/47488)\n",
            "Epoch: 114 | Batch_idx: 380 |  Loss: (0.0371) | Acc: (98.76%) (48163/48768)\n",
            "Epoch: 114 | Batch_idx: 390 |  Loss: (0.0370) | Acc: (98.75%) (49377/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3555) | Acc: (91.48%) (9148/10000)\n",
            "Epoch: 115 | Batch_idx: 0 |  Loss: (0.0229) | Acc: (99.22%) (127/128)\n",
            "Epoch: 115 | Batch_idx: 10 |  Loss: (0.0225) | Acc: (99.22%) (1397/1408)\n",
            "Epoch: 115 | Batch_idx: 20 |  Loss: (0.0313) | Acc: (99.00%) (2661/2688)\n",
            "Epoch: 115 | Batch_idx: 30 |  Loss: (0.0293) | Acc: (99.02%) (3929/3968)\n",
            "Epoch: 115 | Batch_idx: 40 |  Loss: (0.0289) | Acc: (99.07%) (5199/5248)\n",
            "Epoch: 115 | Batch_idx: 50 |  Loss: (0.0300) | Acc: (99.02%) (6464/6528)\n",
            "Epoch: 115 | Batch_idx: 60 |  Loss: (0.0285) | Acc: (99.05%) (7734/7808)\n",
            "Epoch: 115 | Batch_idx: 70 |  Loss: (0.0276) | Acc: (99.10%) (9006/9088)\n",
            "Epoch: 115 | Batch_idx: 80 |  Loss: (0.0281) | Acc: (99.10%) (10275/10368)\n",
            "Epoch: 115 | Batch_idx: 90 |  Loss: (0.0282) | Acc: (99.08%) (11541/11648)\n",
            "Epoch: 115 | Batch_idx: 100 |  Loss: (0.0277) | Acc: (99.09%) (12810/12928)\n",
            "Epoch: 115 | Batch_idx: 110 |  Loss: (0.0270) | Acc: (99.11%) (14081/14208)\n",
            "Epoch: 115 | Batch_idx: 120 |  Loss: (0.0263) | Acc: (99.13%) (15354/15488)\n",
            "Epoch: 115 | Batch_idx: 130 |  Loss: (0.0267) | Acc: (99.11%) (16618/16768)\n",
            "Epoch: 115 | Batch_idx: 140 |  Loss: (0.0280) | Acc: (99.07%) (17881/18048)\n",
            "Epoch: 115 | Batch_idx: 150 |  Loss: (0.0275) | Acc: (99.10%) (19154/19328)\n",
            "Epoch: 115 | Batch_idx: 160 |  Loss: (0.0275) | Acc: (99.11%) (20425/20608)\n",
            "Epoch: 115 | Batch_idx: 170 |  Loss: (0.0274) | Acc: (99.11%) (21693/21888)\n",
            "Epoch: 115 | Batch_idx: 180 |  Loss: (0.0286) | Acc: (99.07%) (22952/23168)\n",
            "Epoch: 115 | Batch_idx: 190 |  Loss: (0.0285) | Acc: (99.07%) (24221/24448)\n",
            "Epoch: 115 | Batch_idx: 200 |  Loss: (0.0288) | Acc: (99.04%) (25481/25728)\n",
            "Epoch: 115 | Batch_idx: 210 |  Loss: (0.0290) | Acc: (99.03%) (26746/27008)\n",
            "Epoch: 115 | Batch_idx: 220 |  Loss: (0.0297) | Acc: (99.00%) (28006/28288)\n",
            "Epoch: 115 | Batch_idx: 230 |  Loss: (0.0301) | Acc: (98.98%) (29267/29568)\n",
            "Epoch: 115 | Batch_idx: 240 |  Loss: (0.0301) | Acc: (98.98%) (30534/30848)\n",
            "Epoch: 115 | Batch_idx: 250 |  Loss: (0.0305) | Acc: (98.98%) (31800/32128)\n",
            "Epoch: 115 | Batch_idx: 260 |  Loss: (0.0303) | Acc: (98.99%) (33070/33408)\n",
            "Epoch: 115 | Batch_idx: 270 |  Loss: (0.0301) | Acc: (99.00%) (34340/34688)\n",
            "Epoch: 115 | Batch_idx: 280 |  Loss: (0.0305) | Acc: (98.97%) (35597/35968)\n",
            "Epoch: 115 | Batch_idx: 290 |  Loss: (0.0304) | Acc: (98.96%) (36859/37248)\n",
            "Epoch: 115 | Batch_idx: 300 |  Loss: (0.0305) | Acc: (98.94%) (38121/38528)\n",
            "Epoch: 115 | Batch_idx: 310 |  Loss: (0.0312) | Acc: (98.93%) (39381/39808)\n",
            "Epoch: 115 | Batch_idx: 320 |  Loss: (0.0314) | Acc: (98.92%) (40646/41088)\n",
            "Epoch: 115 | Batch_idx: 330 |  Loss: (0.0316) | Acc: (98.91%) (41908/42368)\n",
            "Epoch: 115 | Batch_idx: 340 |  Loss: (0.0316) | Acc: (98.91%) (43174/43648)\n",
            "Epoch: 115 | Batch_idx: 350 |  Loss: (0.0319) | Acc: (98.90%) (44436/44928)\n",
            "Epoch: 115 | Batch_idx: 360 |  Loss: (0.0320) | Acc: (98.90%) (45699/46208)\n",
            "Epoch: 115 | Batch_idx: 370 |  Loss: (0.0319) | Acc: (98.90%) (46967/47488)\n",
            "Epoch: 115 | Batch_idx: 380 |  Loss: (0.0319) | Acc: (98.90%) (48233/48768)\n",
            "Epoch: 115 | Batch_idx: 390 |  Loss: (0.0321) | Acc: (98.89%) (49443/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3565) | Acc: (91.70%) (9170/10000)\n",
            "Epoch: 116 | Batch_idx: 0 |  Loss: (0.0349) | Acc: (99.22%) (127/128)\n",
            "Epoch: 116 | Batch_idx: 10 |  Loss: (0.0356) | Acc: (98.58%) (1388/1408)\n",
            "Epoch: 116 | Batch_idx: 20 |  Loss: (0.0339) | Acc: (98.81%) (2656/2688)\n",
            "Epoch: 116 | Batch_idx: 30 |  Loss: (0.0310) | Acc: (98.92%) (3925/3968)\n",
            "Epoch: 116 | Batch_idx: 40 |  Loss: (0.0343) | Acc: (98.82%) (5186/5248)\n",
            "Epoch: 116 | Batch_idx: 50 |  Loss: (0.0357) | Acc: (98.73%) (6445/6528)\n",
            "Epoch: 116 | Batch_idx: 60 |  Loss: (0.0344) | Acc: (98.81%) (7715/7808)\n",
            "Epoch: 116 | Batch_idx: 70 |  Loss: (0.0335) | Acc: (98.84%) (8983/9088)\n",
            "Epoch: 116 | Batch_idx: 80 |  Loss: (0.0330) | Acc: (98.84%) (10248/10368)\n",
            "Epoch: 116 | Batch_idx: 90 |  Loss: (0.0326) | Acc: (98.87%) (11516/11648)\n",
            "Epoch: 116 | Batch_idx: 100 |  Loss: (0.0318) | Acc: (98.88%) (12783/12928)\n",
            "Epoch: 116 | Batch_idx: 110 |  Loss: (0.0320) | Acc: (98.87%) (14047/14208)\n",
            "Epoch: 116 | Batch_idx: 120 |  Loss: (0.0330) | Acc: (98.83%) (15307/15488)\n",
            "Epoch: 116 | Batch_idx: 130 |  Loss: (0.0334) | Acc: (98.84%) (16573/16768)\n",
            "Epoch: 116 | Batch_idx: 140 |  Loss: (0.0327) | Acc: (98.87%) (17844/18048)\n",
            "Epoch: 116 | Batch_idx: 150 |  Loss: (0.0328) | Acc: (98.85%) (19106/19328)\n",
            "Epoch: 116 | Batch_idx: 160 |  Loss: (0.0323) | Acc: (98.86%) (20374/20608)\n",
            "Epoch: 116 | Batch_idx: 170 |  Loss: (0.0327) | Acc: (98.84%) (21635/21888)\n",
            "Epoch: 116 | Batch_idx: 180 |  Loss: (0.0335) | Acc: (98.81%) (22892/23168)\n",
            "Epoch: 116 | Batch_idx: 190 |  Loss: (0.0336) | Acc: (98.81%) (24157/24448)\n",
            "Epoch: 116 | Batch_idx: 200 |  Loss: (0.0335) | Acc: (98.82%) (25425/25728)\n",
            "Epoch: 116 | Batch_idx: 210 |  Loss: (0.0329) | Acc: (98.83%) (26693/27008)\n",
            "Epoch: 116 | Batch_idx: 220 |  Loss: (0.0334) | Acc: (98.82%) (27954/28288)\n",
            "Epoch: 116 | Batch_idx: 230 |  Loss: (0.0331) | Acc: (98.83%) (29221/29568)\n",
            "Epoch: 116 | Batch_idx: 240 |  Loss: (0.0328) | Acc: (98.84%) (30491/30848)\n",
            "Epoch: 116 | Batch_idx: 250 |  Loss: (0.0327) | Acc: (98.84%) (31756/32128)\n",
            "Epoch: 116 | Batch_idx: 260 |  Loss: (0.0330) | Acc: (98.83%) (33016/33408)\n",
            "Epoch: 116 | Batch_idx: 270 |  Loss: (0.0331) | Acc: (98.83%) (34281/34688)\n",
            "Epoch: 116 | Batch_idx: 280 |  Loss: (0.0335) | Acc: (98.80%) (35536/35968)\n",
            "Epoch: 116 | Batch_idx: 290 |  Loss: (0.0337) | Acc: (98.78%) (36794/37248)\n",
            "Epoch: 116 | Batch_idx: 300 |  Loss: (0.0339) | Acc: (98.78%) (38058/38528)\n",
            "Epoch: 116 | Batch_idx: 310 |  Loss: (0.0335) | Acc: (98.78%) (39324/39808)\n",
            "Epoch: 116 | Batch_idx: 320 |  Loss: (0.0336) | Acc: (98.78%) (40585/41088)\n",
            "Epoch: 116 | Batch_idx: 330 |  Loss: (0.0340) | Acc: (98.77%) (41847/42368)\n",
            "Epoch: 116 | Batch_idx: 340 |  Loss: (0.0340) | Acc: (98.77%) (43112/43648)\n",
            "Epoch: 116 | Batch_idx: 350 |  Loss: (0.0339) | Acc: (98.78%) (44379/44928)\n",
            "Epoch: 116 | Batch_idx: 360 |  Loss: (0.0337) | Acc: (98.79%) (45647/46208)\n",
            "Epoch: 116 | Batch_idx: 370 |  Loss: (0.0338) | Acc: (98.78%) (46911/47488)\n",
            "Epoch: 116 | Batch_idx: 380 |  Loss: (0.0337) | Acc: (98.79%) (48178/48768)\n",
            "Epoch: 116 | Batch_idx: 390 |  Loss: (0.0334) | Acc: (98.80%) (49399/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3549) | Acc: (91.47%) (9147/10000)\n",
            "Epoch: 117 | Batch_idx: 0 |  Loss: (0.0487) | Acc: (98.44%) (126/128)\n",
            "Epoch: 117 | Batch_idx: 10 |  Loss: (0.0529) | Acc: (98.44%) (1386/1408)\n",
            "Epoch: 117 | Batch_idx: 20 |  Loss: (0.0422) | Acc: (98.66%) (2652/2688)\n",
            "Epoch: 117 | Batch_idx: 30 |  Loss: (0.0379) | Acc: (98.79%) (3920/3968)\n",
            "Epoch: 117 | Batch_idx: 40 |  Loss: (0.0386) | Acc: (98.78%) (5184/5248)\n",
            "Epoch: 117 | Batch_idx: 50 |  Loss: (0.0378) | Acc: (98.85%) (6453/6528)\n",
            "Epoch: 117 | Batch_idx: 60 |  Loss: (0.0360) | Acc: (98.86%) (7719/7808)\n",
            "Epoch: 117 | Batch_idx: 70 |  Loss: (0.0347) | Acc: (98.88%) (8986/9088)\n",
            "Epoch: 117 | Batch_idx: 80 |  Loss: (0.0335) | Acc: (98.95%) (10259/10368)\n",
            "Epoch: 117 | Batch_idx: 90 |  Loss: (0.0334) | Acc: (98.97%) (11528/11648)\n",
            "Epoch: 117 | Batch_idx: 100 |  Loss: (0.0341) | Acc: (98.92%) (12788/12928)\n",
            "Epoch: 117 | Batch_idx: 110 |  Loss: (0.0336) | Acc: (98.92%) (14055/14208)\n",
            "Epoch: 117 | Batch_idx: 120 |  Loss: (0.0336) | Acc: (98.91%) (15319/15488)\n",
            "Epoch: 117 | Batch_idx: 130 |  Loss: (0.0350) | Acc: (98.87%) (16579/16768)\n",
            "Epoch: 117 | Batch_idx: 140 |  Loss: (0.0349) | Acc: (98.88%) (17846/18048)\n",
            "Epoch: 117 | Batch_idx: 150 |  Loss: (0.0350) | Acc: (98.88%) (19111/19328)\n",
            "Epoch: 117 | Batch_idx: 160 |  Loss: (0.0349) | Acc: (98.88%) (20377/20608)\n",
            "Epoch: 117 | Batch_idx: 170 |  Loss: (0.0357) | Acc: (98.84%) (21634/21888)\n",
            "Epoch: 117 | Batch_idx: 180 |  Loss: (0.0349) | Acc: (98.87%) (22907/23168)\n",
            "Epoch: 117 | Batch_idx: 190 |  Loss: (0.0345) | Acc: (98.89%) (24176/24448)\n",
            "Epoch: 117 | Batch_idx: 200 |  Loss: (0.0348) | Acc: (98.88%) (25439/25728)\n",
            "Epoch: 117 | Batch_idx: 210 |  Loss: (0.0344) | Acc: (98.90%) (26710/27008)\n",
            "Epoch: 117 | Batch_idx: 220 |  Loss: (0.0342) | Acc: (98.90%) (27976/28288)\n",
            "Epoch: 117 | Batch_idx: 230 |  Loss: (0.0339) | Acc: (98.91%) (29245/29568)\n",
            "Epoch: 117 | Batch_idx: 240 |  Loss: (0.0333) | Acc: (98.92%) (30514/30848)\n",
            "Epoch: 117 | Batch_idx: 250 |  Loss: (0.0328) | Acc: (98.92%) (31782/32128)\n",
            "Epoch: 117 | Batch_idx: 260 |  Loss: (0.0327) | Acc: (98.93%) (33049/33408)\n",
            "Epoch: 117 | Batch_idx: 270 |  Loss: (0.0325) | Acc: (98.92%) (34313/34688)\n",
            "Epoch: 117 | Batch_idx: 280 |  Loss: (0.0325) | Acc: (98.92%) (35581/35968)\n",
            "Epoch: 117 | Batch_idx: 290 |  Loss: (0.0325) | Acc: (98.92%) (36846/37248)\n",
            "Epoch: 117 | Batch_idx: 300 |  Loss: (0.0325) | Acc: (98.92%) (38112/38528)\n",
            "Epoch: 117 | Batch_idx: 310 |  Loss: (0.0328) | Acc: (98.90%) (39371/39808)\n",
            "Epoch: 117 | Batch_idx: 320 |  Loss: (0.0331) | Acc: (98.89%) (40631/41088)\n",
            "Epoch: 117 | Batch_idx: 330 |  Loss: (0.0333) | Acc: (98.88%) (41892/42368)\n",
            "Epoch: 117 | Batch_idx: 340 |  Loss: (0.0336) | Acc: (98.87%) (43154/43648)\n",
            "Epoch: 117 | Batch_idx: 350 |  Loss: (0.0341) | Acc: (98.85%) (44410/44928)\n",
            "Epoch: 117 | Batch_idx: 360 |  Loss: (0.0339) | Acc: (98.85%) (45676/46208)\n",
            "Epoch: 117 | Batch_idx: 370 |  Loss: (0.0341) | Acc: (98.85%) (46940/47488)\n",
            "Epoch: 117 | Batch_idx: 380 |  Loss: (0.0338) | Acc: (98.85%) (48208/48768)\n",
            "Epoch: 117 | Batch_idx: 390 |  Loss: (0.0342) | Acc: (98.84%) (49418/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3552) | Acc: (91.65%) (9165/10000)\n",
            "Epoch: 118 | Batch_idx: 0 |  Loss: (0.0530) | Acc: (98.44%) (126/128)\n",
            "Epoch: 118 | Batch_idx: 10 |  Loss: (0.0350) | Acc: (98.79%) (1391/1408)\n",
            "Epoch: 118 | Batch_idx: 20 |  Loss: (0.0320) | Acc: (98.92%) (2659/2688)\n",
            "Epoch: 118 | Batch_idx: 30 |  Loss: (0.0297) | Acc: (98.97%) (3927/3968)\n",
            "Epoch: 118 | Batch_idx: 40 |  Loss: (0.0318) | Acc: (99.03%) (5197/5248)\n",
            "Epoch: 118 | Batch_idx: 50 |  Loss: (0.0317) | Acc: (99.05%) (6466/6528)\n",
            "Epoch: 118 | Batch_idx: 60 |  Loss: (0.0297) | Acc: (99.10%) (7738/7808)\n",
            "Epoch: 118 | Batch_idx: 70 |  Loss: (0.0301) | Acc: (99.08%) (9004/9088)\n",
            "Epoch: 118 | Batch_idx: 80 |  Loss: (0.0300) | Acc: (99.08%) (10273/10368)\n",
            "Epoch: 118 | Batch_idx: 90 |  Loss: (0.0315) | Acc: (99.03%) (11535/11648)\n",
            "Epoch: 118 | Batch_idx: 100 |  Loss: (0.0311) | Acc: (99.02%) (12801/12928)\n",
            "Epoch: 118 | Batch_idx: 110 |  Loss: (0.0308) | Acc: (99.00%) (14066/14208)\n",
            "Epoch: 118 | Batch_idx: 120 |  Loss: (0.0298) | Acc: (99.03%) (15338/15488)\n",
            "Epoch: 118 | Batch_idx: 130 |  Loss: (0.0296) | Acc: (99.06%) (16610/16768)\n",
            "Epoch: 118 | Batch_idx: 140 |  Loss: (0.0304) | Acc: (99.02%) (17871/18048)\n",
            "Epoch: 118 | Batch_idx: 150 |  Loss: (0.0298) | Acc: (99.03%) (19141/19328)\n",
            "Epoch: 118 | Batch_idx: 160 |  Loss: (0.0294) | Acc: (99.04%) (20410/20608)\n",
            "Epoch: 118 | Batch_idx: 170 |  Loss: (0.0291) | Acc: (99.05%) (21681/21888)\n",
            "Epoch: 118 | Batch_idx: 180 |  Loss: (0.0293) | Acc: (99.04%) (22945/23168)\n",
            "Epoch: 118 | Batch_idx: 190 |  Loss: (0.0289) | Acc: (99.05%) (24216/24448)\n",
            "Epoch: 118 | Batch_idx: 200 |  Loss: (0.0289) | Acc: (99.04%) (25481/25728)\n",
            "Epoch: 118 | Batch_idx: 210 |  Loss: (0.0290) | Acc: (99.03%) (26746/27008)\n",
            "Epoch: 118 | Batch_idx: 220 |  Loss: (0.0293) | Acc: (99.01%) (28009/28288)\n",
            "Epoch: 118 | Batch_idx: 230 |  Loss: (0.0296) | Acc: (99.00%) (29272/29568)\n",
            "Epoch: 118 | Batch_idx: 240 |  Loss: (0.0296) | Acc: (99.01%) (30543/30848)\n",
            "Epoch: 118 | Batch_idx: 250 |  Loss: (0.0297) | Acc: (99.01%) (31811/32128)\n",
            "Epoch: 118 | Batch_idx: 260 |  Loss: (0.0299) | Acc: (99.01%) (33078/33408)\n",
            "Epoch: 118 | Batch_idx: 270 |  Loss: (0.0300) | Acc: (99.00%) (34341/34688)\n",
            "Epoch: 118 | Batch_idx: 280 |  Loss: (0.0304) | Acc: (98.99%) (35605/35968)\n",
            "Epoch: 118 | Batch_idx: 290 |  Loss: (0.0300) | Acc: (99.00%) (36877/37248)\n",
            "Epoch: 118 | Batch_idx: 300 |  Loss: (0.0299) | Acc: (99.01%) (38145/38528)\n",
            "Epoch: 118 | Batch_idx: 310 |  Loss: (0.0301) | Acc: (99.01%) (39412/39808)\n",
            "Epoch: 118 | Batch_idx: 320 |  Loss: (0.0300) | Acc: (99.00%) (40679/41088)\n",
            "Epoch: 118 | Batch_idx: 330 |  Loss: (0.0302) | Acc: (99.00%) (41943/42368)\n",
            "Epoch: 118 | Batch_idx: 340 |  Loss: (0.0305) | Acc: (98.99%) (43209/43648)\n",
            "Epoch: 118 | Batch_idx: 350 |  Loss: (0.0304) | Acc: (98.99%) (44473/44928)\n",
            "Epoch: 118 | Batch_idx: 360 |  Loss: (0.0304) | Acc: (98.99%) (45741/46208)\n",
            "Epoch: 118 | Batch_idx: 370 |  Loss: (0.0302) | Acc: (99.00%) (47012/47488)\n",
            "Epoch: 118 | Batch_idx: 380 |  Loss: (0.0300) | Acc: (99.00%) (48278/48768)\n",
            "Epoch: 118 | Batch_idx: 390 |  Loss: (0.0305) | Acc: (98.98%) (49492/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3582) | Acc: (91.48%) (9148/10000)\n",
            "Epoch: 119 | Batch_idx: 0 |  Loss: (0.0299) | Acc: (99.22%) (127/128)\n",
            "Epoch: 119 | Batch_idx: 10 |  Loss: (0.0287) | Acc: (99.01%) (1394/1408)\n",
            "Epoch: 119 | Batch_idx: 20 |  Loss: (0.0371) | Acc: (98.59%) (2650/2688)\n",
            "Epoch: 119 | Batch_idx: 30 |  Loss: (0.0334) | Acc: (98.74%) (3918/3968)\n",
            "Epoch: 119 | Batch_idx: 40 |  Loss: (0.0355) | Acc: (98.67%) (5178/5248)\n",
            "Epoch: 119 | Batch_idx: 50 |  Loss: (0.0366) | Acc: (98.64%) (6439/6528)\n",
            "Epoch: 119 | Batch_idx: 60 |  Loss: (0.0354) | Acc: (98.67%) (7704/7808)\n",
            "Epoch: 119 | Batch_idx: 70 |  Loss: (0.0333) | Acc: (98.76%) (8975/9088)\n",
            "Epoch: 119 | Batch_idx: 80 |  Loss: (0.0323) | Acc: (98.81%) (10245/10368)\n",
            "Epoch: 119 | Batch_idx: 90 |  Loss: (0.0315) | Acc: (98.83%) (11512/11648)\n",
            "Epoch: 119 | Batch_idx: 100 |  Loss: (0.0314) | Acc: (98.82%) (12776/12928)\n",
            "Epoch: 119 | Batch_idx: 110 |  Loss: (0.0307) | Acc: (98.87%) (14047/14208)\n",
            "Epoch: 119 | Batch_idx: 120 |  Loss: (0.0308) | Acc: (98.88%) (15314/15488)\n",
            "Epoch: 119 | Batch_idx: 130 |  Loss: (0.0308) | Acc: (98.88%) (16581/16768)\n",
            "Epoch: 119 | Batch_idx: 140 |  Loss: (0.0299) | Acc: (98.93%) (17854/18048)\n",
            "Epoch: 119 | Batch_idx: 150 |  Loss: (0.0298) | Acc: (98.93%) (19121/19328)\n",
            "Epoch: 119 | Batch_idx: 160 |  Loss: (0.0305) | Acc: (98.92%) (20386/20608)\n",
            "Epoch: 119 | Batch_idx: 170 |  Loss: (0.0308) | Acc: (98.91%) (21649/21888)\n",
            "Epoch: 119 | Batch_idx: 180 |  Loss: (0.0310) | Acc: (98.92%) (22917/23168)\n",
            "Epoch: 119 | Batch_idx: 190 |  Loss: (0.0312) | Acc: (98.90%) (24180/24448)\n",
            "Epoch: 119 | Batch_idx: 200 |  Loss: (0.0313) | Acc: (98.90%) (25445/25728)\n",
            "Epoch: 119 | Batch_idx: 210 |  Loss: (0.0316) | Acc: (98.89%) (26709/27008)\n",
            "Epoch: 119 | Batch_idx: 220 |  Loss: (0.0313) | Acc: (98.90%) (27977/28288)\n",
            "Epoch: 119 | Batch_idx: 230 |  Loss: (0.0313) | Acc: (98.91%) (29245/29568)\n",
            "Epoch: 119 | Batch_idx: 240 |  Loss: (0.0313) | Acc: (98.91%) (30511/30848)\n",
            "Epoch: 119 | Batch_idx: 250 |  Loss: (0.0313) | Acc: (98.91%) (31777/32128)\n",
            "Epoch: 119 | Batch_idx: 260 |  Loss: (0.0313) | Acc: (98.90%) (33041/33408)\n",
            "Epoch: 119 | Batch_idx: 270 |  Loss: (0.0314) | Acc: (98.90%) (34308/34688)\n",
            "Epoch: 119 | Batch_idx: 280 |  Loss: (0.0313) | Acc: (98.91%) (35576/35968)\n",
            "Epoch: 119 | Batch_idx: 290 |  Loss: (0.0314) | Acc: (98.91%) (36842/37248)\n",
            "Epoch: 119 | Batch_idx: 300 |  Loss: (0.0315) | Acc: (98.89%) (38101/38528)\n",
            "Epoch: 119 | Batch_idx: 310 |  Loss: (0.0315) | Acc: (98.88%) (39363/39808)\n",
            "Epoch: 119 | Batch_idx: 320 |  Loss: (0.0316) | Acc: (98.87%) (40623/41088)\n",
            "Epoch: 119 | Batch_idx: 330 |  Loss: (0.0318) | Acc: (98.86%) (41886/42368)\n",
            "Epoch: 119 | Batch_idx: 340 |  Loss: (0.0316) | Acc: (98.88%) (43157/43648)\n",
            "Epoch: 119 | Batch_idx: 350 |  Loss: (0.0313) | Acc: (98.89%) (44429/44928)\n",
            "Epoch: 119 | Batch_idx: 360 |  Loss: (0.0315) | Acc: (98.88%) (45690/46208)\n",
            "Epoch: 119 | Batch_idx: 370 |  Loss: (0.0314) | Acc: (98.89%) (46960/47488)\n",
            "Epoch: 119 | Batch_idx: 380 |  Loss: (0.0313) | Acc: (98.89%) (48229/48768)\n",
            "Epoch: 119 | Batch_idx: 390 |  Loss: (0.0313) | Acc: (98.89%) (49447/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3588) | Acc: (91.54%) (9154/10000)\n",
            "Epoch: 120 | Batch_idx: 0 |  Loss: (0.0561) | Acc: (97.66%) (125/128)\n",
            "Epoch: 120 | Batch_idx: 10 |  Loss: (0.0390) | Acc: (98.65%) (1389/1408)\n",
            "Epoch: 120 | Batch_idx: 20 |  Loss: (0.0281) | Acc: (99.03%) (2662/2688)\n",
            "Epoch: 120 | Batch_idx: 30 |  Loss: (0.0275) | Acc: (99.07%) (3931/3968)\n",
            "Epoch: 120 | Batch_idx: 40 |  Loss: (0.0270) | Acc: (99.05%) (5198/5248)\n",
            "Epoch: 120 | Batch_idx: 50 |  Loss: (0.0312) | Acc: (99.00%) (6463/6528)\n",
            "Epoch: 120 | Batch_idx: 60 |  Loss: (0.0308) | Acc: (98.96%) (7727/7808)\n",
            "Epoch: 120 | Batch_idx: 70 |  Loss: (0.0305) | Acc: (98.97%) (8994/9088)\n",
            "Epoch: 120 | Batch_idx: 80 |  Loss: (0.0295) | Acc: (98.97%) (10261/10368)\n",
            "Epoch: 120 | Batch_idx: 90 |  Loss: (0.0304) | Acc: (98.92%) (11522/11648)\n",
            "Epoch: 120 | Batch_idx: 100 |  Loss: (0.0292) | Acc: (98.96%) (12793/12928)\n",
            "Epoch: 120 | Batch_idx: 110 |  Loss: (0.0287) | Acc: (98.98%) (14063/14208)\n",
            "Epoch: 120 | Batch_idx: 120 |  Loss: (0.0284) | Acc: (99.02%) (15336/15488)\n",
            "Epoch: 120 | Batch_idx: 130 |  Loss: (0.0282) | Acc: (99.03%) (16605/16768)\n",
            "Epoch: 120 | Batch_idx: 140 |  Loss: (0.0275) | Acc: (99.05%) (17877/18048)\n",
            "Epoch: 120 | Batch_idx: 150 |  Loss: (0.0274) | Acc: (99.06%) (19146/19328)\n",
            "Epoch: 120 | Batch_idx: 160 |  Loss: (0.0278) | Acc: (99.06%) (20414/20608)\n",
            "Epoch: 120 | Batch_idx: 170 |  Loss: (0.0273) | Acc: (99.07%) (21685/21888)\n",
            "Epoch: 120 | Batch_idx: 180 |  Loss: (0.0276) | Acc: (99.08%) (22954/23168)\n",
            "Epoch: 120 | Batch_idx: 190 |  Loss: (0.0277) | Acc: (99.07%) (24220/24448)\n",
            "Epoch: 120 | Batch_idx: 200 |  Loss: (0.0279) | Acc: (99.06%) (25487/25728)\n",
            "Epoch: 120 | Batch_idx: 210 |  Loss: (0.0280) | Acc: (99.07%) (26756/27008)\n",
            "Epoch: 120 | Batch_idx: 220 |  Loss: (0.0277) | Acc: (99.08%) (28029/28288)\n",
            "Epoch: 120 | Batch_idx: 230 |  Loss: (0.0274) | Acc: (99.10%) (29301/29568)\n",
            "Epoch: 120 | Batch_idx: 240 |  Loss: (0.0268) | Acc: (99.12%) (30577/30848)\n",
            "Epoch: 120 | Batch_idx: 250 |  Loss: (0.0273) | Acc: (99.11%) (31843/32128)\n",
            "Epoch: 120 | Batch_idx: 260 |  Loss: (0.0271) | Acc: (99.13%) (33116/33408)\n",
            "Epoch: 120 | Batch_idx: 270 |  Loss: (0.0266) | Acc: (99.14%) (34391/34688)\n",
            "Epoch: 120 | Batch_idx: 280 |  Loss: (0.0264) | Acc: (99.14%) (35659/35968)\n",
            "Epoch: 120 | Batch_idx: 290 |  Loss: (0.0259) | Acc: (99.15%) (36933/37248)\n",
            "Epoch: 120 | Batch_idx: 300 |  Loss: (0.0259) | Acc: (99.16%) (38204/38528)\n",
            "Epoch: 120 | Batch_idx: 310 |  Loss: (0.0264) | Acc: (99.15%) (39469/39808)\n",
            "Epoch: 120 | Batch_idx: 320 |  Loss: (0.0261) | Acc: (99.17%) (40745/41088)\n",
            "Epoch: 120 | Batch_idx: 330 |  Loss: (0.0262) | Acc: (99.16%) (42010/42368)\n",
            "Epoch: 120 | Batch_idx: 340 |  Loss: (0.0261) | Acc: (99.16%) (43281/43648)\n",
            "Epoch: 120 | Batch_idx: 350 |  Loss: (0.0258) | Acc: (99.17%) (44555/44928)\n",
            "Epoch: 120 | Batch_idx: 360 |  Loss: (0.0261) | Acc: (99.15%) (45817/46208)\n",
            "Epoch: 120 | Batch_idx: 370 |  Loss: (0.0262) | Acc: (99.15%) (47084/47488)\n",
            "Epoch: 120 | Batch_idx: 380 |  Loss: (0.0261) | Acc: (99.15%) (48352/48768)\n",
            "Epoch: 120 | Batch_idx: 390 |  Loss: (0.0261) | Acc: (99.15%) (49573/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3535) | Acc: (91.66%) (9166/10000)\n",
            "Epoch: 121 | Batch_idx: 0 |  Loss: (0.0397) | Acc: (97.66%) (125/128)\n",
            "Epoch: 121 | Batch_idx: 10 |  Loss: (0.0241) | Acc: (98.86%) (1392/1408)\n",
            "Epoch: 121 | Batch_idx: 20 |  Loss: (0.0260) | Acc: (98.77%) (2655/2688)\n",
            "Epoch: 121 | Batch_idx: 30 |  Loss: (0.0251) | Acc: (98.87%) (3923/3968)\n",
            "Epoch: 121 | Batch_idx: 40 |  Loss: (0.0248) | Acc: (98.97%) (5194/5248)\n",
            "Epoch: 121 | Batch_idx: 50 |  Loss: (0.0259) | Acc: (98.94%) (6459/6528)\n",
            "Epoch: 121 | Batch_idx: 60 |  Loss: (0.0257) | Acc: (98.96%) (7727/7808)\n",
            "Epoch: 121 | Batch_idx: 70 |  Loss: (0.0242) | Acc: (99.04%) (9001/9088)\n",
            "Epoch: 121 | Batch_idx: 80 |  Loss: (0.0237) | Acc: (99.07%) (10272/10368)\n",
            "Epoch: 121 | Batch_idx: 90 |  Loss: (0.0235) | Acc: (99.09%) (11542/11648)\n",
            "Epoch: 121 | Batch_idx: 100 |  Loss: (0.0239) | Acc: (99.06%) (12807/12928)\n",
            "Epoch: 121 | Batch_idx: 110 |  Loss: (0.0248) | Acc: (99.02%) (14069/14208)\n",
            "Epoch: 121 | Batch_idx: 120 |  Loss: (0.0246) | Acc: (99.04%) (15340/15488)\n",
            "Epoch: 121 | Batch_idx: 130 |  Loss: (0.0260) | Acc: (99.00%) (16601/16768)\n",
            "Epoch: 121 | Batch_idx: 140 |  Loss: (0.0254) | Acc: (99.03%) (17873/18048)\n",
            "Epoch: 121 | Batch_idx: 150 |  Loss: (0.0253) | Acc: (99.03%) (19141/19328)\n",
            "Epoch: 121 | Batch_idx: 160 |  Loss: (0.0254) | Acc: (99.04%) (20411/20608)\n",
            "Epoch: 121 | Batch_idx: 170 |  Loss: (0.0252) | Acc: (99.05%) (21679/21888)\n",
            "Epoch: 121 | Batch_idx: 180 |  Loss: (0.0256) | Acc: (99.04%) (22946/23168)\n",
            "Epoch: 121 | Batch_idx: 190 |  Loss: (0.0250) | Acc: (99.05%) (24216/24448)\n",
            "Epoch: 121 | Batch_idx: 200 |  Loss: (0.0252) | Acc: (99.05%) (25484/25728)\n",
            "Epoch: 121 | Batch_idx: 210 |  Loss: (0.0251) | Acc: (99.06%) (26755/27008)\n",
            "Epoch: 121 | Batch_idx: 220 |  Loss: (0.0255) | Acc: (99.06%) (28023/28288)\n",
            "Epoch: 121 | Batch_idx: 230 |  Loss: (0.0256) | Acc: (99.06%) (29291/29568)\n",
            "Epoch: 121 | Batch_idx: 240 |  Loss: (0.0258) | Acc: (99.04%) (30552/30848)\n",
            "Epoch: 121 | Batch_idx: 250 |  Loss: (0.0255) | Acc: (99.05%) (31824/32128)\n",
            "Epoch: 121 | Batch_idx: 260 |  Loss: (0.0254) | Acc: (99.06%) (33093/33408)\n",
            "Epoch: 121 | Batch_idx: 270 |  Loss: (0.0253) | Acc: (99.07%) (34364/34688)\n",
            "Epoch: 121 | Batch_idx: 280 |  Loss: (0.0250) | Acc: (99.07%) (35635/35968)\n",
            "Epoch: 121 | Batch_idx: 290 |  Loss: (0.0246) | Acc: (99.09%) (36909/37248)\n",
            "Epoch: 121 | Batch_idx: 300 |  Loss: (0.0246) | Acc: (99.10%) (38180/38528)\n",
            "Epoch: 121 | Batch_idx: 310 |  Loss: (0.0245) | Acc: (99.10%) (39450/39808)\n",
            "Epoch: 121 | Batch_idx: 320 |  Loss: (0.0247) | Acc: (99.09%) (40715/41088)\n",
            "Epoch: 121 | Batch_idx: 330 |  Loss: (0.0248) | Acc: (99.08%) (41980/42368)\n",
            "Epoch: 121 | Batch_idx: 340 |  Loss: (0.0247) | Acc: (99.08%) (43247/43648)\n",
            "Epoch: 121 | Batch_idx: 350 |  Loss: (0.0248) | Acc: (99.07%) (44511/44928)\n",
            "Epoch: 121 | Batch_idx: 360 |  Loss: (0.0247) | Acc: (99.08%) (45783/46208)\n",
            "Epoch: 121 | Batch_idx: 370 |  Loss: (0.0245) | Acc: (99.08%) (47053/47488)\n",
            "Epoch: 121 | Batch_idx: 380 |  Loss: (0.0246) | Acc: (99.08%) (48320/48768)\n",
            "Epoch: 121 | Batch_idx: 390 |  Loss: (0.0248) | Acc: (99.07%) (49537/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3556) | Acc: (91.81%) (9181/10000)\n",
            "Epoch: 122 | Batch_idx: 0 |  Loss: (0.0265) | Acc: (99.22%) (127/128)\n",
            "Epoch: 122 | Batch_idx: 10 |  Loss: (0.0213) | Acc: (99.01%) (1394/1408)\n",
            "Epoch: 122 | Batch_idx: 20 |  Loss: (0.0244) | Acc: (98.96%) (2660/2688)\n",
            "Epoch: 122 | Batch_idx: 30 |  Loss: (0.0226) | Acc: (99.12%) (3933/3968)\n",
            "Epoch: 122 | Batch_idx: 40 |  Loss: (0.0230) | Acc: (99.18%) (5205/5248)\n",
            "Epoch: 122 | Batch_idx: 50 |  Loss: (0.0234) | Acc: (99.19%) (6475/6528)\n",
            "Epoch: 122 | Batch_idx: 60 |  Loss: (0.0267) | Acc: (99.10%) (7738/7808)\n",
            "Epoch: 122 | Batch_idx: 70 |  Loss: (0.0264) | Acc: (99.13%) (9009/9088)\n",
            "Epoch: 122 | Batch_idx: 80 |  Loss: (0.0260) | Acc: (99.11%) (10276/10368)\n",
            "Epoch: 122 | Batch_idx: 90 |  Loss: (0.0255) | Acc: (99.12%) (11545/11648)\n",
            "Epoch: 122 | Batch_idx: 100 |  Loss: (0.0255) | Acc: (99.11%) (12813/12928)\n",
            "Epoch: 122 | Batch_idx: 110 |  Loss: (0.0251) | Acc: (99.13%) (14085/14208)\n",
            "Epoch: 122 | Batch_idx: 120 |  Loss: (0.0242) | Acc: (99.17%) (15359/15488)\n",
            "Epoch: 122 | Batch_idx: 130 |  Loss: (0.0239) | Acc: (99.17%) (16628/16768)\n",
            "Epoch: 122 | Batch_idx: 140 |  Loss: (0.0243) | Acc: (99.15%) (17894/18048)\n",
            "Epoch: 122 | Batch_idx: 150 |  Loss: (0.0240) | Acc: (99.17%) (19168/19328)\n",
            "Epoch: 122 | Batch_idx: 160 |  Loss: (0.0246) | Acc: (99.16%) (20435/20608)\n",
            "Epoch: 122 | Batch_idx: 170 |  Loss: (0.0248) | Acc: (99.15%) (21703/21888)\n",
            "Epoch: 122 | Batch_idx: 180 |  Loss: (0.0252) | Acc: (99.14%) (22969/23168)\n",
            "Epoch: 122 | Batch_idx: 190 |  Loss: (0.0249) | Acc: (99.15%) (24241/24448)\n",
            "Epoch: 122 | Batch_idx: 200 |  Loss: (0.0249) | Acc: (99.16%) (25512/25728)\n",
            "Epoch: 122 | Batch_idx: 210 |  Loss: (0.0246) | Acc: (99.17%) (26784/27008)\n",
            "Epoch: 122 | Batch_idx: 220 |  Loss: (0.0244) | Acc: (99.18%) (28055/28288)\n",
            "Epoch: 122 | Batch_idx: 230 |  Loss: (0.0248) | Acc: (99.17%) (29323/29568)\n",
            "Epoch: 122 | Batch_idx: 240 |  Loss: (0.0249) | Acc: (99.18%) (30594/30848)\n",
            "Epoch: 122 | Batch_idx: 250 |  Loss: (0.0248) | Acc: (99.17%) (31862/32128)\n",
            "Epoch: 122 | Batch_idx: 260 |  Loss: (0.0249) | Acc: (99.16%) (33129/33408)\n",
            "Epoch: 122 | Batch_idx: 270 |  Loss: (0.0247) | Acc: (99.16%) (34398/34688)\n",
            "Epoch: 122 | Batch_idx: 280 |  Loss: (0.0249) | Acc: (99.15%) (35664/35968)\n",
            "Epoch: 122 | Batch_idx: 290 |  Loss: (0.0247) | Acc: (99.15%) (36933/37248)\n",
            "Epoch: 122 | Batch_idx: 300 |  Loss: (0.0246) | Acc: (99.16%) (38205/38528)\n",
            "Epoch: 122 | Batch_idx: 310 |  Loss: (0.0247) | Acc: (99.15%) (39469/39808)\n",
            "Epoch: 122 | Batch_idx: 320 |  Loss: (0.0247) | Acc: (99.15%) (40737/41088)\n",
            "Epoch: 122 | Batch_idx: 330 |  Loss: (0.0249) | Acc: (99.13%) (42001/42368)\n",
            "Epoch: 122 | Batch_idx: 340 |  Loss: (0.0250) | Acc: (99.14%) (43272/43648)\n",
            "Epoch: 122 | Batch_idx: 350 |  Loss: (0.0248) | Acc: (99.14%) (44543/44928)\n",
            "Epoch: 122 | Batch_idx: 360 |  Loss: (0.0246) | Acc: (99.15%) (45815/46208)\n",
            "Epoch: 122 | Batch_idx: 370 |  Loss: (0.0246) | Acc: (99.16%) (47087/47488)\n",
            "Epoch: 122 | Batch_idx: 380 |  Loss: (0.0246) | Acc: (99.16%) (48356/48768)\n",
            "Epoch: 122 | Batch_idx: 390 |  Loss: (0.0245) | Acc: (99.16%) (49580/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3566) | Acc: (91.82%) (9182/10000)\n",
            "Epoch: 123 | Batch_idx: 0 |  Loss: (0.0493) | Acc: (96.09%) (123/128)\n",
            "Epoch: 123 | Batch_idx: 10 |  Loss: (0.0223) | Acc: (98.93%) (1393/1408)\n",
            "Epoch: 123 | Batch_idx: 20 |  Loss: (0.0193) | Acc: (99.14%) (2665/2688)\n",
            "Epoch: 123 | Batch_idx: 30 |  Loss: (0.0181) | Acc: (99.22%) (3937/3968)\n",
            "Epoch: 123 | Batch_idx: 40 |  Loss: (0.0180) | Acc: (99.26%) (5209/5248)\n",
            "Epoch: 123 | Batch_idx: 50 |  Loss: (0.0177) | Acc: (99.30%) (6482/6528)\n",
            "Epoch: 123 | Batch_idx: 60 |  Loss: (0.0176) | Acc: (99.33%) (7756/7808)\n",
            "Epoch: 123 | Batch_idx: 70 |  Loss: (0.0187) | Acc: (99.28%) (9023/9088)\n",
            "Epoch: 123 | Batch_idx: 80 |  Loss: (0.0186) | Acc: (99.31%) (10296/10368)\n",
            "Epoch: 123 | Batch_idx: 90 |  Loss: (0.0197) | Acc: (99.30%) (11566/11648)\n",
            "Epoch: 123 | Batch_idx: 100 |  Loss: (0.0205) | Acc: (99.31%) (12839/12928)\n",
            "Epoch: 123 | Batch_idx: 110 |  Loss: (0.0213) | Acc: (99.27%) (14104/14208)\n",
            "Epoch: 123 | Batch_idx: 120 |  Loss: (0.0219) | Acc: (99.26%) (15373/15488)\n",
            "Epoch: 123 | Batch_idx: 130 |  Loss: (0.0212) | Acc: (99.27%) (16646/16768)\n",
            "Epoch: 123 | Batch_idx: 140 |  Loss: (0.0219) | Acc: (99.25%) (17912/18048)\n",
            "Epoch: 123 | Batch_idx: 150 |  Loss: (0.0219) | Acc: (99.23%) (19180/19328)\n",
            "Epoch: 123 | Batch_idx: 160 |  Loss: (0.0221) | Acc: (99.24%) (20451/20608)\n",
            "Epoch: 123 | Batch_idx: 170 |  Loss: (0.0220) | Acc: (99.24%) (21721/21888)\n",
            "Epoch: 123 | Batch_idx: 180 |  Loss: (0.0223) | Acc: (99.24%) (22991/23168)\n",
            "Epoch: 123 | Batch_idx: 190 |  Loss: (0.0229) | Acc: (99.23%) (24260/24448)\n",
            "Epoch: 123 | Batch_idx: 200 |  Loss: (0.0229) | Acc: (99.23%) (25531/25728)\n",
            "Epoch: 123 | Batch_idx: 210 |  Loss: (0.0229) | Acc: (99.24%) (26803/27008)\n",
            "Epoch: 123 | Batch_idx: 220 |  Loss: (0.0226) | Acc: (99.25%) (28075/28288)\n",
            "Epoch: 123 | Batch_idx: 230 |  Loss: (0.0227) | Acc: (99.24%) (29342/29568)\n",
            "Epoch: 123 | Batch_idx: 240 |  Loss: (0.0225) | Acc: (99.24%) (30615/30848)\n",
            "Epoch: 123 | Batch_idx: 250 |  Loss: (0.0230) | Acc: (99.23%) (31880/32128)\n",
            "Epoch: 123 | Batch_idx: 260 |  Loss: (0.0227) | Acc: (99.23%) (33152/33408)\n",
            "Epoch: 123 | Batch_idx: 270 |  Loss: (0.0230) | Acc: (99.23%) (34420/34688)\n",
            "Epoch: 123 | Batch_idx: 280 |  Loss: (0.0238) | Acc: (99.20%) (35682/35968)\n",
            "Epoch: 123 | Batch_idx: 290 |  Loss: (0.0242) | Acc: (99.18%) (36944/37248)\n",
            "Epoch: 123 | Batch_idx: 300 |  Loss: (0.0244) | Acc: (99.18%) (38212/38528)\n",
            "Epoch: 123 | Batch_idx: 310 |  Loss: (0.0243) | Acc: (99.19%) (39485/39808)\n",
            "Epoch: 123 | Batch_idx: 320 |  Loss: (0.0241) | Acc: (99.20%) (40760/41088)\n",
            "Epoch: 123 | Batch_idx: 330 |  Loss: (0.0240) | Acc: (99.20%) (42031/42368)\n",
            "Epoch: 123 | Batch_idx: 340 |  Loss: (0.0238) | Acc: (99.21%) (43303/43648)\n",
            "Epoch: 123 | Batch_idx: 350 |  Loss: (0.0238) | Acc: (99.20%) (44567/44928)\n",
            "Epoch: 123 | Batch_idx: 360 |  Loss: (0.0238) | Acc: (99.19%) (45836/46208)\n",
            "Epoch: 123 | Batch_idx: 370 |  Loss: (0.0238) | Acc: (99.20%) (47108/47488)\n",
            "Epoch: 123 | Batch_idx: 380 |  Loss: (0.0240) | Acc: (99.19%) (48373/48768)\n",
            "Epoch: 123 | Batch_idx: 390 |  Loss: (0.0244) | Acc: (99.17%) (49587/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3544) | Acc: (91.75%) (9175/10000)\n",
            "Epoch: 124 | Batch_idx: 0 |  Loss: (0.0218) | Acc: (99.22%) (127/128)\n",
            "Epoch: 124 | Batch_idx: 10 |  Loss: (0.0299) | Acc: (99.01%) (1394/1408)\n",
            "Epoch: 124 | Batch_idx: 20 |  Loss: (0.0293) | Acc: (98.88%) (2658/2688)\n",
            "Epoch: 124 | Batch_idx: 30 |  Loss: (0.0267) | Acc: (98.99%) (3928/3968)\n",
            "Epoch: 124 | Batch_idx: 40 |  Loss: (0.0261) | Acc: (98.99%) (5195/5248)\n",
            "Epoch: 124 | Batch_idx: 50 |  Loss: (0.0264) | Acc: (99.02%) (6464/6528)\n",
            "Epoch: 124 | Batch_idx: 60 |  Loss: (0.0257) | Acc: (99.04%) (7733/7808)\n",
            "Epoch: 124 | Batch_idx: 70 |  Loss: (0.0238) | Acc: (99.12%) (9008/9088)\n",
            "Epoch: 124 | Batch_idx: 80 |  Loss: (0.0246) | Acc: (99.12%) (10277/10368)\n",
            "Epoch: 124 | Batch_idx: 90 |  Loss: (0.0249) | Acc: (99.12%) (11546/11648)\n",
            "Epoch: 124 | Batch_idx: 100 |  Loss: (0.0244) | Acc: (99.13%) (12815/12928)\n",
            "Epoch: 124 | Batch_idx: 110 |  Loss: (0.0240) | Acc: (99.15%) (14087/14208)\n",
            "Epoch: 124 | Batch_idx: 120 |  Loss: (0.0241) | Acc: (99.16%) (15358/15488)\n",
            "Epoch: 124 | Batch_idx: 130 |  Loss: (0.0235) | Acc: (99.19%) (16633/16768)\n",
            "Epoch: 124 | Batch_idx: 140 |  Loss: (0.0235) | Acc: (99.19%) (17901/18048)\n",
            "Epoch: 124 | Batch_idx: 150 |  Loss: (0.0237) | Acc: (99.17%) (19167/19328)\n",
            "Epoch: 124 | Batch_idx: 160 |  Loss: (0.0237) | Acc: (99.17%) (20436/20608)\n",
            "Epoch: 124 | Batch_idx: 170 |  Loss: (0.0243) | Acc: (99.14%) (21700/21888)\n",
            "Epoch: 124 | Batch_idx: 180 |  Loss: (0.0242) | Acc: (99.15%) (22971/23168)\n",
            "Epoch: 124 | Batch_idx: 190 |  Loss: (0.0244) | Acc: (99.13%) (24236/24448)\n",
            "Epoch: 124 | Batch_idx: 200 |  Loss: (0.0246) | Acc: (99.12%) (25502/25728)\n",
            "Epoch: 124 | Batch_idx: 210 |  Loss: (0.0243) | Acc: (99.13%) (26774/27008)\n",
            "Epoch: 124 | Batch_idx: 220 |  Loss: (0.0243) | Acc: (99.13%) (28041/28288)\n",
            "Epoch: 124 | Batch_idx: 230 |  Loss: (0.0242) | Acc: (99.13%) (29312/29568)\n",
            "Epoch: 124 | Batch_idx: 240 |  Loss: (0.0246) | Acc: (99.11%) (30574/30848)\n",
            "Epoch: 124 | Batch_idx: 250 |  Loss: (0.0251) | Acc: (99.11%) (31841/32128)\n",
            "Epoch: 124 | Batch_idx: 260 |  Loss: (0.0247) | Acc: (99.13%) (33117/33408)\n",
            "Epoch: 124 | Batch_idx: 270 |  Loss: (0.0246) | Acc: (99.14%) (34388/34688)\n",
            "Epoch: 124 | Batch_idx: 280 |  Loss: (0.0247) | Acc: (99.13%) (35655/35968)\n",
            "Epoch: 124 | Batch_idx: 290 |  Loss: (0.0245) | Acc: (99.14%) (36929/37248)\n",
            "Epoch: 124 | Batch_idx: 300 |  Loss: (0.0244) | Acc: (99.15%) (38199/38528)\n",
            "Epoch: 124 | Batch_idx: 310 |  Loss: (0.0243) | Acc: (99.15%) (39469/39808)\n",
            "Epoch: 124 | Batch_idx: 320 |  Loss: (0.0246) | Acc: (99.14%) (40735/41088)\n",
            "Epoch: 124 | Batch_idx: 330 |  Loss: (0.0249) | Acc: (99.15%) (42006/42368)\n",
            "Epoch: 124 | Batch_idx: 340 |  Loss: (0.0250) | Acc: (99.15%) (43275/43648)\n",
            "Epoch: 124 | Batch_idx: 350 |  Loss: (0.0250) | Acc: (99.14%) (44542/44928)\n",
            "Epoch: 124 | Batch_idx: 360 |  Loss: (0.0248) | Acc: (99.15%) (45813/46208)\n",
            "Epoch: 124 | Batch_idx: 370 |  Loss: (0.0248) | Acc: (99.14%) (47080/47488)\n",
            "Epoch: 124 | Batch_idx: 380 |  Loss: (0.0245) | Acc: (99.15%) (48353/48768)\n",
            "Epoch: 124 | Batch_idx: 390 |  Loss: (0.0244) | Acc: (99.15%) (49577/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3563) | Acc: (91.85%) (9185/10000)\n",
            "Epoch: 125 | Batch_idx: 0 |  Loss: (0.0132) | Acc: (100.00%) (128/128)\n",
            "Epoch: 125 | Batch_idx: 10 |  Loss: (0.0251) | Acc: (99.22%) (1397/1408)\n",
            "Epoch: 125 | Batch_idx: 20 |  Loss: (0.0209) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 125 | Batch_idx: 30 |  Loss: (0.0195) | Acc: (99.40%) (3944/3968)\n",
            "Epoch: 125 | Batch_idx: 40 |  Loss: (0.0215) | Acc: (99.29%) (5211/5248)\n",
            "Epoch: 125 | Batch_idx: 50 |  Loss: (0.0219) | Acc: (99.31%) (6483/6528)\n",
            "Epoch: 125 | Batch_idx: 60 |  Loss: (0.0229) | Acc: (99.24%) (7749/7808)\n",
            "Epoch: 125 | Batch_idx: 70 |  Loss: (0.0239) | Acc: (99.20%) (9015/9088)\n",
            "Epoch: 125 | Batch_idx: 80 |  Loss: (0.0228) | Acc: (99.23%) (10288/10368)\n",
            "Epoch: 125 | Batch_idx: 90 |  Loss: (0.0238) | Acc: (99.20%) (11555/11648)\n",
            "Epoch: 125 | Batch_idx: 100 |  Loss: (0.0243) | Acc: (99.17%) (12821/12928)\n",
            "Epoch: 125 | Batch_idx: 110 |  Loss: (0.0231) | Acc: (99.22%) (14097/14208)\n",
            "Epoch: 125 | Batch_idx: 120 |  Loss: (0.0231) | Acc: (99.21%) (15366/15488)\n",
            "Epoch: 125 | Batch_idx: 130 |  Loss: (0.0229) | Acc: (99.22%) (16638/16768)\n",
            "Epoch: 125 | Batch_idx: 140 |  Loss: (0.0236) | Acc: (99.21%) (17905/18048)\n",
            "Epoch: 125 | Batch_idx: 150 |  Loss: (0.0236) | Acc: (99.21%) (19175/19328)\n",
            "Epoch: 125 | Batch_idx: 160 |  Loss: (0.0235) | Acc: (99.21%) (20446/20608)\n",
            "Epoch: 125 | Batch_idx: 170 |  Loss: (0.0235) | Acc: (99.21%) (21715/21888)\n",
            "Epoch: 125 | Batch_idx: 180 |  Loss: (0.0233) | Acc: (99.23%) (22989/23168)\n",
            "Epoch: 125 | Batch_idx: 190 |  Loss: (0.0232) | Acc: (99.23%) (24260/24448)\n",
            "Epoch: 125 | Batch_idx: 200 |  Loss: (0.0229) | Acc: (99.24%) (25532/25728)\n",
            "Epoch: 125 | Batch_idx: 210 |  Loss: (0.0226) | Acc: (99.24%) (26803/27008)\n",
            "Epoch: 125 | Batch_idx: 220 |  Loss: (0.0226) | Acc: (99.25%) (28075/28288)\n",
            "Epoch: 125 | Batch_idx: 230 |  Loss: (0.0220) | Acc: (99.27%) (29351/29568)\n",
            "Epoch: 125 | Batch_idx: 240 |  Loss: (0.0220) | Acc: (99.26%) (30621/30848)\n",
            "Epoch: 125 | Batch_idx: 250 |  Loss: (0.0219) | Acc: (99.27%) (31893/32128)\n",
            "Epoch: 125 | Batch_idx: 260 |  Loss: (0.0225) | Acc: (99.25%) (33157/33408)\n",
            "Epoch: 125 | Batch_idx: 270 |  Loss: (0.0223) | Acc: (99.25%) (34429/34688)\n",
            "Epoch: 125 | Batch_idx: 280 |  Loss: (0.0222) | Acc: (99.25%) (35699/35968)\n",
            "Epoch: 125 | Batch_idx: 290 |  Loss: (0.0217) | Acc: (99.27%) (36976/37248)\n",
            "Epoch: 125 | Batch_idx: 300 |  Loss: (0.0218) | Acc: (99.27%) (38247/38528)\n",
            "Epoch: 125 | Batch_idx: 310 |  Loss: (0.0217) | Acc: (99.28%) (39522/39808)\n",
            "Epoch: 125 | Batch_idx: 320 |  Loss: (0.0217) | Acc: (99.29%) (40795/41088)\n",
            "Epoch: 125 | Batch_idx: 330 |  Loss: (0.0218) | Acc: (99.28%) (42064/42368)\n",
            "Epoch: 125 | Batch_idx: 340 |  Loss: (0.0219) | Acc: (99.28%) (43333/43648)\n",
            "Epoch: 125 | Batch_idx: 350 |  Loss: (0.0218) | Acc: (99.28%) (44604/44928)\n",
            "Epoch: 125 | Batch_idx: 360 |  Loss: (0.0219) | Acc: (99.28%) (45874/46208)\n",
            "Epoch: 125 | Batch_idx: 370 |  Loss: (0.0220) | Acc: (99.27%) (47141/47488)\n",
            "Epoch: 125 | Batch_idx: 380 |  Loss: (0.0219) | Acc: (99.27%) (48414/48768)\n",
            "Epoch: 125 | Batch_idx: 390 |  Loss: (0.0217) | Acc: (99.28%) (49642/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3529) | Acc: (91.80%) (9180/10000)\n",
            "Epoch: 126 | Batch_idx: 0 |  Loss: (0.0526) | Acc: (97.66%) (125/128)\n",
            "Epoch: 126 | Batch_idx: 10 |  Loss: (0.0269) | Acc: (99.01%) (1394/1408)\n",
            "Epoch: 126 | Batch_idx: 20 |  Loss: (0.0242) | Acc: (99.18%) (2666/2688)\n",
            "Epoch: 126 | Batch_idx: 30 |  Loss: (0.0250) | Acc: (99.12%) (3933/3968)\n",
            "Epoch: 126 | Batch_idx: 40 |  Loss: (0.0251) | Acc: (99.10%) (5201/5248)\n",
            "Epoch: 126 | Batch_idx: 50 |  Loss: (0.0254) | Acc: (99.16%) (6473/6528)\n",
            "Epoch: 126 | Batch_idx: 60 |  Loss: (0.0252) | Acc: (99.15%) (7742/7808)\n",
            "Epoch: 126 | Batch_idx: 70 |  Loss: (0.0240) | Acc: (99.19%) (9014/9088)\n",
            "Epoch: 126 | Batch_idx: 80 |  Loss: (0.0234) | Acc: (99.21%) (10286/10368)\n",
            "Epoch: 126 | Batch_idx: 90 |  Loss: (0.0224) | Acc: (99.24%) (11560/11648)\n",
            "Epoch: 126 | Batch_idx: 100 |  Loss: (0.0229) | Acc: (99.22%) (12827/12928)\n",
            "Epoch: 126 | Batch_idx: 110 |  Loss: (0.0229) | Acc: (99.19%) (14093/14208)\n",
            "Epoch: 126 | Batch_idx: 120 |  Loss: (0.0233) | Acc: (99.18%) (15361/15488)\n",
            "Epoch: 126 | Batch_idx: 130 |  Loss: (0.0229) | Acc: (99.19%) (16633/16768)\n",
            "Epoch: 126 | Batch_idx: 140 |  Loss: (0.0233) | Acc: (99.18%) (17900/18048)\n",
            "Epoch: 126 | Batch_idx: 150 |  Loss: (0.0232) | Acc: (99.19%) (19172/19328)\n",
            "Epoch: 126 | Batch_idx: 160 |  Loss: (0.0231) | Acc: (99.18%) (20440/20608)\n",
            "Epoch: 126 | Batch_idx: 170 |  Loss: (0.0231) | Acc: (99.20%) (21713/21888)\n",
            "Epoch: 126 | Batch_idx: 180 |  Loss: (0.0231) | Acc: (99.21%) (22985/23168)\n",
            "Epoch: 126 | Batch_idx: 190 |  Loss: (0.0230) | Acc: (99.21%) (24255/24448)\n",
            "Epoch: 126 | Batch_idx: 200 |  Loss: (0.0232) | Acc: (99.20%) (25523/25728)\n",
            "Epoch: 126 | Batch_idx: 210 |  Loss: (0.0233) | Acc: (99.21%) (26795/27008)\n",
            "Epoch: 126 | Batch_idx: 220 |  Loss: (0.0230) | Acc: (99.23%) (28070/28288)\n",
            "Epoch: 126 | Batch_idx: 230 |  Loss: (0.0231) | Acc: (99.23%) (29339/29568)\n",
            "Epoch: 126 | Batch_idx: 240 |  Loss: (0.0233) | Acc: (99.22%) (30607/30848)\n",
            "Epoch: 126 | Batch_idx: 250 |  Loss: (0.0230) | Acc: (99.22%) (31879/32128)\n",
            "Epoch: 126 | Batch_idx: 260 |  Loss: (0.0228) | Acc: (99.25%) (33156/33408)\n",
            "Epoch: 126 | Batch_idx: 270 |  Loss: (0.0227) | Acc: (99.25%) (34428/34688)\n",
            "Epoch: 126 | Batch_idx: 280 |  Loss: (0.0231) | Acc: (99.23%) (35691/35968)\n",
            "Epoch: 126 | Batch_idx: 290 |  Loss: (0.0230) | Acc: (99.24%) (36964/37248)\n",
            "Epoch: 126 | Batch_idx: 300 |  Loss: (0.0230) | Acc: (99.23%) (38231/38528)\n",
            "Epoch: 126 | Batch_idx: 310 |  Loss: (0.0233) | Acc: (99.23%) (39501/39808)\n",
            "Epoch: 126 | Batch_idx: 320 |  Loss: (0.0234) | Acc: (99.22%) (40767/41088)\n",
            "Epoch: 126 | Batch_idx: 330 |  Loss: (0.0233) | Acc: (99.22%) (42037/42368)\n",
            "Epoch: 126 | Batch_idx: 340 |  Loss: (0.0230) | Acc: (99.23%) (43313/43648)\n",
            "Epoch: 126 | Batch_idx: 350 |  Loss: (0.0228) | Acc: (99.24%) (44585/44928)\n",
            "Epoch: 126 | Batch_idx: 360 |  Loss: (0.0229) | Acc: (99.24%) (45858/46208)\n",
            "Epoch: 126 | Batch_idx: 370 |  Loss: (0.0227) | Acc: (99.24%) (47129/47488)\n",
            "Epoch: 126 | Batch_idx: 380 |  Loss: (0.0229) | Acc: (99.23%) (48394/48768)\n",
            "Epoch: 126 | Batch_idx: 390 |  Loss: (0.0228) | Acc: (99.24%) (49618/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3541) | Acc: (91.86%) (9186/10000)\n",
            "Epoch: 127 | Batch_idx: 0 |  Loss: (0.0045) | Acc: (100.00%) (128/128)\n",
            "Epoch: 127 | Batch_idx: 10 |  Loss: (0.0187) | Acc: (99.15%) (1396/1408)\n",
            "Epoch: 127 | Batch_idx: 20 |  Loss: (0.0274) | Acc: (98.96%) (2660/2688)\n",
            "Epoch: 127 | Batch_idx: 30 |  Loss: (0.0303) | Acc: (98.94%) (3926/3968)\n",
            "Epoch: 127 | Batch_idx: 40 |  Loss: (0.0287) | Acc: (99.03%) (5197/5248)\n",
            "Epoch: 127 | Batch_idx: 50 |  Loss: (0.0288) | Acc: (98.97%) (6461/6528)\n",
            "Epoch: 127 | Batch_idx: 60 |  Loss: (0.0261) | Acc: (99.05%) (7734/7808)\n",
            "Epoch: 127 | Batch_idx: 70 |  Loss: (0.0253) | Acc: (99.09%) (9005/9088)\n",
            "Epoch: 127 | Batch_idx: 80 |  Loss: (0.0258) | Acc: (99.07%) (10272/10368)\n",
            "Epoch: 127 | Batch_idx: 90 |  Loss: (0.0256) | Acc: (99.12%) (11545/11648)\n",
            "Epoch: 127 | Batch_idx: 100 |  Loss: (0.0246) | Acc: (99.15%) (12818/12928)\n",
            "Epoch: 127 | Batch_idx: 110 |  Loss: (0.0247) | Acc: (99.16%) (14088/14208)\n",
            "Epoch: 127 | Batch_idx: 120 |  Loss: (0.0239) | Acc: (99.18%) (15361/15488)\n",
            "Epoch: 127 | Batch_idx: 130 |  Loss: (0.0239) | Acc: (99.20%) (16634/16768)\n",
            "Epoch: 127 | Batch_idx: 140 |  Loss: (0.0237) | Acc: (99.20%) (17903/18048)\n",
            "Epoch: 127 | Batch_idx: 150 |  Loss: (0.0241) | Acc: (99.19%) (19171/19328)\n",
            "Epoch: 127 | Batch_idx: 160 |  Loss: (0.0233) | Acc: (99.22%) (20447/20608)\n",
            "Epoch: 127 | Batch_idx: 170 |  Loss: (0.0227) | Acc: (99.24%) (21722/21888)\n",
            "Epoch: 127 | Batch_idx: 180 |  Loss: (0.0227) | Acc: (99.24%) (22993/23168)\n",
            "Epoch: 127 | Batch_idx: 190 |  Loss: (0.0228) | Acc: (99.24%) (24263/24448)\n",
            "Epoch: 127 | Batch_idx: 200 |  Loss: (0.0222) | Acc: (99.26%) (25537/25728)\n",
            "Epoch: 127 | Batch_idx: 210 |  Loss: (0.0220) | Acc: (99.27%) (26810/27008)\n",
            "Epoch: 127 | Batch_idx: 220 |  Loss: (0.0223) | Acc: (99.26%) (28078/28288)\n",
            "Epoch: 127 | Batch_idx: 230 |  Loss: (0.0219) | Acc: (99.27%) (29352/29568)\n",
            "Epoch: 127 | Batch_idx: 240 |  Loss: (0.0221) | Acc: (99.26%) (30621/30848)\n",
            "Epoch: 127 | Batch_idx: 250 |  Loss: (0.0221) | Acc: (99.26%) (31890/32128)\n",
            "Epoch: 127 | Batch_idx: 260 |  Loss: (0.0224) | Acc: (99.25%) (33158/33408)\n",
            "Epoch: 127 | Batch_idx: 270 |  Loss: (0.0224) | Acc: (99.26%) (34431/34688)\n",
            "Epoch: 127 | Batch_idx: 280 |  Loss: (0.0220) | Acc: (99.27%) (35705/35968)\n",
            "Epoch: 127 | Batch_idx: 290 |  Loss: (0.0220) | Acc: (99.26%) (36974/37248)\n",
            "Epoch: 127 | Batch_idx: 300 |  Loss: (0.0223) | Acc: (99.25%) (38240/38528)\n",
            "Epoch: 127 | Batch_idx: 310 |  Loss: (0.0218) | Acc: (99.27%) (39519/39808)\n",
            "Epoch: 127 | Batch_idx: 320 |  Loss: (0.0215) | Acc: (99.28%) (40793/41088)\n",
            "Epoch: 127 | Batch_idx: 330 |  Loss: (0.0215) | Acc: (99.29%) (42066/42368)\n",
            "Epoch: 127 | Batch_idx: 340 |  Loss: (0.0214) | Acc: (99.29%) (43339/43648)\n",
            "Epoch: 127 | Batch_idx: 350 |  Loss: (0.0213) | Acc: (99.30%) (44612/44928)\n",
            "Epoch: 127 | Batch_idx: 360 |  Loss: (0.0212) | Acc: (99.31%) (45889/46208)\n",
            "Epoch: 127 | Batch_idx: 370 |  Loss: (0.0214) | Acc: (99.30%) (47157/47488)\n",
            "Epoch: 127 | Batch_idx: 380 |  Loss: (0.0214) | Acc: (99.30%) (48427/48768)\n",
            "Epoch: 127 | Batch_idx: 390 |  Loss: (0.0214) | Acc: (99.30%) (49649/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3551) | Acc: (91.84%) (9184/10000)\n",
            "Epoch: 128 | Batch_idx: 0 |  Loss: (0.0092) | Acc: (99.22%) (127/128)\n",
            "Epoch: 128 | Batch_idx: 10 |  Loss: (0.0164) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 128 | Batch_idx: 20 |  Loss: (0.0182) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 128 | Batch_idx: 30 |  Loss: (0.0197) | Acc: (99.29%) (3940/3968)\n",
            "Epoch: 128 | Batch_idx: 40 |  Loss: (0.0200) | Acc: (99.26%) (5209/5248)\n",
            "Epoch: 128 | Batch_idx: 50 |  Loss: (0.0205) | Acc: (99.28%) (6481/6528)\n",
            "Epoch: 128 | Batch_idx: 60 |  Loss: (0.0206) | Acc: (99.31%) (7754/7808)\n",
            "Epoch: 128 | Batch_idx: 70 |  Loss: (0.0203) | Acc: (99.32%) (9026/9088)\n",
            "Epoch: 128 | Batch_idx: 80 |  Loss: (0.0213) | Acc: (99.29%) (10294/10368)\n",
            "Epoch: 128 | Batch_idx: 90 |  Loss: (0.0211) | Acc: (99.29%) (11565/11648)\n",
            "Epoch: 128 | Batch_idx: 100 |  Loss: (0.0214) | Acc: (99.26%) (12832/12928)\n",
            "Epoch: 128 | Batch_idx: 110 |  Loss: (0.0212) | Acc: (99.26%) (14103/14208)\n",
            "Epoch: 128 | Batch_idx: 120 |  Loss: (0.0213) | Acc: (99.25%) (15372/15488)\n",
            "Epoch: 128 | Batch_idx: 130 |  Loss: (0.0210) | Acc: (99.28%) (16647/16768)\n",
            "Epoch: 128 | Batch_idx: 140 |  Loss: (0.0210) | Acc: (99.29%) (17920/18048)\n",
            "Epoch: 128 | Batch_idx: 150 |  Loss: (0.0210) | Acc: (99.28%) (19188/19328)\n",
            "Epoch: 128 | Batch_idx: 160 |  Loss: (0.0205) | Acc: (99.30%) (20464/20608)\n",
            "Epoch: 128 | Batch_idx: 170 |  Loss: (0.0215) | Acc: (99.27%) (21728/21888)\n",
            "Epoch: 128 | Batch_idx: 180 |  Loss: (0.0217) | Acc: (99.27%) (22999/23168)\n",
            "Epoch: 128 | Batch_idx: 190 |  Loss: (0.0218) | Acc: (99.27%) (24270/24448)\n",
            "Epoch: 128 | Batch_idx: 200 |  Loss: (0.0218) | Acc: (99.27%) (25541/25728)\n",
            "Epoch: 128 | Batch_idx: 210 |  Loss: (0.0215) | Acc: (99.29%) (26815/27008)\n",
            "Epoch: 128 | Batch_idx: 220 |  Loss: (0.0213) | Acc: (99.29%) (28088/28288)\n",
            "Epoch: 128 | Batch_idx: 230 |  Loss: (0.0216) | Acc: (99.29%) (29357/29568)\n",
            "Epoch: 128 | Batch_idx: 240 |  Loss: (0.0215) | Acc: (99.28%) (30626/30848)\n",
            "Epoch: 128 | Batch_idx: 250 |  Loss: (0.0216) | Acc: (99.28%) (31897/32128)\n",
            "Epoch: 128 | Batch_idx: 260 |  Loss: (0.0212) | Acc: (99.30%) (33173/33408)\n",
            "Epoch: 128 | Batch_idx: 270 |  Loss: (0.0211) | Acc: (99.30%) (34446/34688)\n",
            "Epoch: 128 | Batch_idx: 280 |  Loss: (0.0211) | Acc: (99.30%) (35715/35968)\n",
            "Epoch: 128 | Batch_idx: 290 |  Loss: (0.0209) | Acc: (99.30%) (36987/37248)\n",
            "Epoch: 128 | Batch_idx: 300 |  Loss: (0.0211) | Acc: (99.29%) (38254/38528)\n",
            "Epoch: 128 | Batch_idx: 310 |  Loss: (0.0214) | Acc: (99.29%) (39525/39808)\n",
            "Epoch: 128 | Batch_idx: 320 |  Loss: (0.0217) | Acc: (99.27%) (40790/41088)\n",
            "Epoch: 128 | Batch_idx: 330 |  Loss: (0.0218) | Acc: (99.27%) (42058/42368)\n",
            "Epoch: 128 | Batch_idx: 340 |  Loss: (0.0218) | Acc: (99.27%) (43331/43648)\n",
            "Epoch: 128 | Batch_idx: 350 |  Loss: (0.0215) | Acc: (99.28%) (44605/44928)\n",
            "Epoch: 128 | Batch_idx: 360 |  Loss: (0.0214) | Acc: (99.28%) (45877/46208)\n",
            "Epoch: 128 | Batch_idx: 370 |  Loss: (0.0213) | Acc: (99.29%) (47150/47488)\n",
            "Epoch: 128 | Batch_idx: 380 |  Loss: (0.0214) | Acc: (99.29%) (48420/48768)\n",
            "Epoch: 128 | Batch_idx: 390 |  Loss: (0.0214) | Acc: (99.29%) (49645/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3530) | Acc: (91.84%) (9184/10000)\n",
            "Epoch: 129 | Batch_idx: 0 |  Loss: (0.0272) | Acc: (99.22%) (127/128)\n",
            "Epoch: 129 | Batch_idx: 10 |  Loss: (0.0118) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 129 | Batch_idx: 20 |  Loss: (0.0166) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 129 | Batch_idx: 30 |  Loss: (0.0190) | Acc: (99.42%) (3945/3968)\n",
            "Epoch: 129 | Batch_idx: 40 |  Loss: (0.0231) | Acc: (99.28%) (5210/5248)\n",
            "Epoch: 129 | Batch_idx: 50 |  Loss: (0.0222) | Acc: (99.28%) (6481/6528)\n",
            "Epoch: 129 | Batch_idx: 60 |  Loss: (0.0222) | Acc: (99.28%) (7752/7808)\n",
            "Epoch: 129 | Batch_idx: 70 |  Loss: (0.0216) | Acc: (99.30%) (9024/9088)\n",
            "Epoch: 129 | Batch_idx: 80 |  Loss: (0.0209) | Acc: (99.32%) (10298/10368)\n",
            "Epoch: 129 | Batch_idx: 90 |  Loss: (0.0226) | Acc: (99.26%) (11562/11648)\n",
            "Epoch: 129 | Batch_idx: 100 |  Loss: (0.0216) | Acc: (99.30%) (12837/12928)\n",
            "Epoch: 129 | Batch_idx: 110 |  Loss: (0.0218) | Acc: (99.28%) (14105/14208)\n",
            "Epoch: 129 | Batch_idx: 120 |  Loss: (0.0216) | Acc: (99.30%) (15379/15488)\n",
            "Epoch: 129 | Batch_idx: 130 |  Loss: (0.0212) | Acc: (99.30%) (16651/16768)\n",
            "Epoch: 129 | Batch_idx: 140 |  Loss: (0.0213) | Acc: (99.29%) (17919/18048)\n",
            "Epoch: 129 | Batch_idx: 150 |  Loss: (0.0219) | Acc: (99.27%) (19186/19328)\n",
            "Epoch: 129 | Batch_idx: 160 |  Loss: (0.0218) | Acc: (99.27%) (20457/20608)\n",
            "Epoch: 129 | Batch_idx: 170 |  Loss: (0.0212) | Acc: (99.28%) (21731/21888)\n",
            "Epoch: 129 | Batch_idx: 180 |  Loss: (0.0222) | Acc: (99.25%) (22994/23168)\n",
            "Epoch: 129 | Batch_idx: 190 |  Loss: (0.0218) | Acc: (99.26%) (24268/24448)\n",
            "Epoch: 129 | Batch_idx: 200 |  Loss: (0.0221) | Acc: (99.25%) (25536/25728)\n",
            "Epoch: 129 | Batch_idx: 210 |  Loss: (0.0218) | Acc: (99.27%) (26811/27008)\n",
            "Epoch: 129 | Batch_idx: 220 |  Loss: (0.0216) | Acc: (99.28%) (28085/28288)\n",
            "Epoch: 129 | Batch_idx: 230 |  Loss: (0.0217) | Acc: (99.29%) (29357/29568)\n",
            "Epoch: 129 | Batch_idx: 240 |  Loss: (0.0215) | Acc: (99.29%) (30629/30848)\n",
            "Epoch: 129 | Batch_idx: 250 |  Loss: (0.0213) | Acc: (99.30%) (31903/32128)\n",
            "Epoch: 129 | Batch_idx: 260 |  Loss: (0.0211) | Acc: (99.31%) (33178/33408)\n",
            "Epoch: 129 | Batch_idx: 270 |  Loss: (0.0212) | Acc: (99.31%) (34448/34688)\n",
            "Epoch: 129 | Batch_idx: 280 |  Loss: (0.0213) | Acc: (99.31%) (35720/35968)\n",
            "Epoch: 129 | Batch_idx: 290 |  Loss: (0.0215) | Acc: (99.31%) (36990/37248)\n",
            "Epoch: 129 | Batch_idx: 300 |  Loss: (0.0213) | Acc: (99.32%) (38265/38528)\n",
            "Epoch: 129 | Batch_idx: 310 |  Loss: (0.0212) | Acc: (99.31%) (39535/39808)\n",
            "Epoch: 129 | Batch_idx: 320 |  Loss: (0.0212) | Acc: (99.32%) (40807/41088)\n",
            "Epoch: 129 | Batch_idx: 330 |  Loss: (0.0213) | Acc: (99.32%) (42078/42368)\n",
            "Epoch: 129 | Batch_idx: 340 |  Loss: (0.0213) | Acc: (99.31%) (43346/43648)\n",
            "Epoch: 129 | Batch_idx: 350 |  Loss: (0.0212) | Acc: (99.31%) (44616/44928)\n",
            "Epoch: 129 | Batch_idx: 360 |  Loss: (0.0213) | Acc: (99.31%) (45887/46208)\n",
            "Epoch: 129 | Batch_idx: 370 |  Loss: (0.0215) | Acc: (99.31%) (47158/47488)\n",
            "Epoch: 129 | Batch_idx: 380 |  Loss: (0.0216) | Acc: (99.29%) (48424/48768)\n",
            "Epoch: 129 | Batch_idx: 390 |  Loss: (0.0218) | Acc: (99.29%) (49644/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3580) | Acc: (91.90%) (9190/10000)\n",
            "Epoch: 130 | Batch_idx: 0 |  Loss: (0.0071) | Acc: (100.00%) (128/128)\n",
            "Epoch: 130 | Batch_idx: 10 |  Loss: (0.0151) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 130 | Batch_idx: 20 |  Loss: (0.0140) | Acc: (99.63%) (2678/2688)\n",
            "Epoch: 130 | Batch_idx: 30 |  Loss: (0.0158) | Acc: (99.55%) (3950/3968)\n",
            "Epoch: 130 | Batch_idx: 40 |  Loss: (0.0154) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 130 | Batch_idx: 50 |  Loss: (0.0157) | Acc: (99.49%) (6495/6528)\n",
            "Epoch: 130 | Batch_idx: 60 |  Loss: (0.0169) | Acc: (99.42%) (7763/7808)\n",
            "Epoch: 130 | Batch_idx: 70 |  Loss: (0.0176) | Acc: (99.42%) (9035/9088)\n",
            "Epoch: 130 | Batch_idx: 80 |  Loss: (0.0171) | Acc: (99.45%) (10311/10368)\n",
            "Epoch: 130 | Batch_idx: 90 |  Loss: (0.0176) | Acc: (99.43%) (11582/11648)\n",
            "Epoch: 130 | Batch_idx: 100 |  Loss: (0.0176) | Acc: (99.42%) (12853/12928)\n",
            "Epoch: 130 | Batch_idx: 110 |  Loss: (0.0179) | Acc: (99.37%) (14119/14208)\n",
            "Epoch: 130 | Batch_idx: 120 |  Loss: (0.0173) | Acc: (99.38%) (15392/15488)\n",
            "Epoch: 130 | Batch_idx: 130 |  Loss: (0.0175) | Acc: (99.39%) (16665/16768)\n",
            "Epoch: 130 | Batch_idx: 140 |  Loss: (0.0176) | Acc: (99.38%) (17937/18048)\n",
            "Epoch: 130 | Batch_idx: 150 |  Loss: (0.0174) | Acc: (99.39%) (19210/19328)\n",
            "Epoch: 130 | Batch_idx: 160 |  Loss: (0.0176) | Acc: (99.39%) (20483/20608)\n",
            "Epoch: 130 | Batch_idx: 170 |  Loss: (0.0177) | Acc: (99.41%) (21759/21888)\n",
            "Epoch: 130 | Batch_idx: 180 |  Loss: (0.0181) | Acc: (99.40%) (23028/23168)\n",
            "Epoch: 130 | Batch_idx: 190 |  Loss: (0.0184) | Acc: (99.40%) (24301/24448)\n",
            "Epoch: 130 | Batch_idx: 200 |  Loss: (0.0182) | Acc: (99.41%) (25576/25728)\n",
            "Epoch: 130 | Batch_idx: 210 |  Loss: (0.0182) | Acc: (99.41%) (26848/27008)\n",
            "Epoch: 130 | Batch_idx: 220 |  Loss: (0.0183) | Acc: (99.41%) (28121/28288)\n",
            "Epoch: 130 | Batch_idx: 230 |  Loss: (0.0184) | Acc: (99.39%) (29389/29568)\n",
            "Epoch: 130 | Batch_idx: 240 |  Loss: (0.0184) | Acc: (99.41%) (30665/30848)\n",
            "Epoch: 130 | Batch_idx: 250 |  Loss: (0.0185) | Acc: (99.40%) (31936/32128)\n",
            "Epoch: 130 | Batch_idx: 260 |  Loss: (0.0185) | Acc: (99.40%) (33207/33408)\n",
            "Epoch: 130 | Batch_idx: 270 |  Loss: (0.0185) | Acc: (99.40%) (34479/34688)\n",
            "Epoch: 130 | Batch_idx: 280 |  Loss: (0.0189) | Acc: (99.38%) (35745/35968)\n",
            "Epoch: 130 | Batch_idx: 290 |  Loss: (0.0192) | Acc: (99.37%) (37012/37248)\n",
            "Epoch: 130 | Batch_idx: 300 |  Loss: (0.0192) | Acc: (99.36%) (38281/38528)\n",
            "Epoch: 130 | Batch_idx: 310 |  Loss: (0.0190) | Acc: (99.36%) (39552/39808)\n",
            "Epoch: 130 | Batch_idx: 320 |  Loss: (0.0188) | Acc: (99.36%) (40826/41088)\n",
            "Epoch: 130 | Batch_idx: 330 |  Loss: (0.0190) | Acc: (99.35%) (42093/42368)\n",
            "Epoch: 130 | Batch_idx: 340 |  Loss: (0.0193) | Acc: (99.34%) (43359/43648)\n",
            "Epoch: 130 | Batch_idx: 350 |  Loss: (0.0195) | Acc: (99.33%) (44626/44928)\n",
            "Epoch: 130 | Batch_idx: 360 |  Loss: (0.0197) | Acc: (99.32%) (45894/46208)\n",
            "Epoch: 130 | Batch_idx: 370 |  Loss: (0.0198) | Acc: (99.30%) (47157/47488)\n",
            "Epoch: 130 | Batch_idx: 380 |  Loss: (0.0199) | Acc: (99.30%) (48427/48768)\n",
            "Epoch: 130 | Batch_idx: 390 |  Loss: (0.0198) | Acc: (99.31%) (49654/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3572) | Acc: (91.94%) (9194/10000)\n",
            "Epoch: 131 | Batch_idx: 0 |  Loss: (0.0402) | Acc: (99.22%) (127/128)\n",
            "Epoch: 131 | Batch_idx: 10 |  Loss: (0.0284) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 131 | Batch_idx: 20 |  Loss: (0.0251) | Acc: (99.14%) (2665/2688)\n",
            "Epoch: 131 | Batch_idx: 30 |  Loss: (0.0266) | Acc: (99.12%) (3933/3968)\n",
            "Epoch: 131 | Batch_idx: 40 |  Loss: (0.0234) | Acc: (99.22%) (5207/5248)\n",
            "Epoch: 131 | Batch_idx: 50 |  Loss: (0.0225) | Acc: (99.26%) (6480/6528)\n",
            "Epoch: 131 | Batch_idx: 60 |  Loss: (0.0248) | Acc: (99.27%) (7751/7808)\n",
            "Epoch: 131 | Batch_idx: 70 |  Loss: (0.0244) | Acc: (99.28%) (9023/9088)\n",
            "Epoch: 131 | Batch_idx: 80 |  Loss: (0.0234) | Acc: (99.28%) (10293/10368)\n",
            "Epoch: 131 | Batch_idx: 90 |  Loss: (0.0231) | Acc: (99.32%) (11569/11648)\n",
            "Epoch: 131 | Batch_idx: 100 |  Loss: (0.0227) | Acc: (99.33%) (12842/12928)\n",
            "Epoch: 131 | Batch_idx: 110 |  Loss: (0.0238) | Acc: (99.31%) (14110/14208)\n",
            "Epoch: 131 | Batch_idx: 120 |  Loss: (0.0231) | Acc: (99.32%) (15383/15488)\n",
            "Epoch: 131 | Batch_idx: 130 |  Loss: (0.0234) | Acc: (99.30%) (16650/16768)\n",
            "Epoch: 131 | Batch_idx: 140 |  Loss: (0.0233) | Acc: (99.29%) (17919/18048)\n",
            "Epoch: 131 | Batch_idx: 150 |  Loss: (0.0231) | Acc: (99.29%) (19190/19328)\n",
            "Epoch: 131 | Batch_idx: 160 |  Loss: (0.0230) | Acc: (99.30%) (20464/20608)\n",
            "Epoch: 131 | Batch_idx: 170 |  Loss: (0.0230) | Acc: (99.29%) (21733/21888)\n",
            "Epoch: 131 | Batch_idx: 180 |  Loss: (0.0228) | Acc: (99.29%) (23003/23168)\n",
            "Epoch: 131 | Batch_idx: 190 |  Loss: (0.0227) | Acc: (99.28%) (24273/24448)\n",
            "Epoch: 131 | Batch_idx: 200 |  Loss: (0.0222) | Acc: (99.31%) (25550/25728)\n",
            "Epoch: 131 | Batch_idx: 210 |  Loss: (0.0216) | Acc: (99.32%) (26825/27008)\n",
            "Epoch: 131 | Batch_idx: 220 |  Loss: (0.0214) | Acc: (99.33%) (28098/28288)\n",
            "Epoch: 131 | Batch_idx: 230 |  Loss: (0.0213) | Acc: (99.33%) (29369/29568)\n",
            "Epoch: 131 | Batch_idx: 240 |  Loss: (0.0212) | Acc: (99.32%) (30637/30848)\n",
            "Epoch: 131 | Batch_idx: 250 |  Loss: (0.0214) | Acc: (99.31%) (31907/32128)\n",
            "Epoch: 131 | Batch_idx: 260 |  Loss: (0.0212) | Acc: (99.31%) (33179/33408)\n",
            "Epoch: 131 | Batch_idx: 270 |  Loss: (0.0213) | Acc: (99.31%) (34450/34688)\n",
            "Epoch: 131 | Batch_idx: 280 |  Loss: (0.0211) | Acc: (99.32%) (35725/35968)\n",
            "Epoch: 131 | Batch_idx: 290 |  Loss: (0.0211) | Acc: (99.32%) (36995/37248)\n",
            "Epoch: 131 | Batch_idx: 300 |  Loss: (0.0213) | Acc: (99.32%) (38267/38528)\n",
            "Epoch: 131 | Batch_idx: 310 |  Loss: (0.0212) | Acc: (99.32%) (39539/39808)\n",
            "Epoch: 131 | Batch_idx: 320 |  Loss: (0.0210) | Acc: (99.33%) (40814/41088)\n",
            "Epoch: 131 | Batch_idx: 330 |  Loss: (0.0210) | Acc: (99.33%) (42083/42368)\n",
            "Epoch: 131 | Batch_idx: 340 |  Loss: (0.0209) | Acc: (99.32%) (43352/43648)\n",
            "Epoch: 131 | Batch_idx: 350 |  Loss: (0.0209) | Acc: (99.32%) (44624/44928)\n",
            "Epoch: 131 | Batch_idx: 360 |  Loss: (0.0208) | Acc: (99.32%) (45894/46208)\n",
            "Epoch: 131 | Batch_idx: 370 |  Loss: (0.0206) | Acc: (99.33%) (47168/47488)\n",
            "Epoch: 131 | Batch_idx: 380 |  Loss: (0.0207) | Acc: (99.33%) (48439/48768)\n",
            "Epoch: 131 | Batch_idx: 390 |  Loss: (0.0207) | Acc: (99.33%) (49663/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3618) | Acc: (91.82%) (9182/10000)\n",
            "Epoch: 132 | Batch_idx: 0 |  Loss: (0.0168) | Acc: (99.22%) (127/128)\n",
            "Epoch: 132 | Batch_idx: 10 |  Loss: (0.0217) | Acc: (99.15%) (1396/1408)\n",
            "Epoch: 132 | Batch_idx: 20 |  Loss: (0.0196) | Acc: (99.33%) (2670/2688)\n",
            "Epoch: 132 | Batch_idx: 30 |  Loss: (0.0197) | Acc: (99.37%) (3943/3968)\n",
            "Epoch: 132 | Batch_idx: 40 |  Loss: (0.0195) | Acc: (99.41%) (5217/5248)\n",
            "Epoch: 132 | Batch_idx: 50 |  Loss: (0.0197) | Acc: (99.37%) (6487/6528)\n",
            "Epoch: 132 | Batch_idx: 60 |  Loss: (0.0215) | Acc: (99.33%) (7756/7808)\n",
            "Epoch: 132 | Batch_idx: 70 |  Loss: (0.0205) | Acc: (99.36%) (9030/9088)\n",
            "Epoch: 132 | Batch_idx: 80 |  Loss: (0.0205) | Acc: (99.33%) (10299/10368)\n",
            "Epoch: 132 | Batch_idx: 90 |  Loss: (0.0204) | Acc: (99.31%) (11568/11648)\n",
            "Epoch: 132 | Batch_idx: 100 |  Loss: (0.0203) | Acc: (99.33%) (12841/12928)\n",
            "Epoch: 132 | Batch_idx: 110 |  Loss: (0.0197) | Acc: (99.35%) (14116/14208)\n",
            "Epoch: 132 | Batch_idx: 120 |  Loss: (0.0198) | Acc: (99.33%) (15384/15488)\n",
            "Epoch: 132 | Batch_idx: 130 |  Loss: (0.0197) | Acc: (99.34%) (16657/16768)\n",
            "Epoch: 132 | Batch_idx: 140 |  Loss: (0.0192) | Acc: (99.36%) (17933/18048)\n",
            "Epoch: 132 | Batch_idx: 150 |  Loss: (0.0193) | Acc: (99.36%) (19205/19328)\n",
            "Epoch: 132 | Batch_idx: 160 |  Loss: (0.0187) | Acc: (99.38%) (20481/20608)\n",
            "Epoch: 132 | Batch_idx: 170 |  Loss: (0.0193) | Acc: (99.37%) (21750/21888)\n",
            "Epoch: 132 | Batch_idx: 180 |  Loss: (0.0190) | Acc: (99.37%) (23022/23168)\n",
            "Epoch: 132 | Batch_idx: 190 |  Loss: (0.0188) | Acc: (99.38%) (24296/24448)\n",
            "Epoch: 132 | Batch_idx: 200 |  Loss: (0.0187) | Acc: (99.39%) (25570/25728)\n",
            "Epoch: 132 | Batch_idx: 210 |  Loss: (0.0187) | Acc: (99.37%) (26839/27008)\n",
            "Epoch: 132 | Batch_idx: 220 |  Loss: (0.0184) | Acc: (99.39%) (28115/28288)\n",
            "Epoch: 132 | Batch_idx: 230 |  Loss: (0.0184) | Acc: (99.39%) (29388/29568)\n",
            "Epoch: 132 | Batch_idx: 240 |  Loss: (0.0188) | Acc: (99.38%) (30657/30848)\n",
            "Epoch: 132 | Batch_idx: 250 |  Loss: (0.0189) | Acc: (99.37%) (31925/32128)\n",
            "Epoch: 132 | Batch_idx: 260 |  Loss: (0.0186) | Acc: (99.38%) (33200/33408)\n",
            "Epoch: 132 | Batch_idx: 270 |  Loss: (0.0185) | Acc: (99.38%) (34474/34688)\n",
            "Epoch: 132 | Batch_idx: 280 |  Loss: (0.0185) | Acc: (99.38%) (35746/35968)\n",
            "Epoch: 132 | Batch_idx: 290 |  Loss: (0.0186) | Acc: (99.37%) (37013/37248)\n",
            "Epoch: 132 | Batch_idx: 300 |  Loss: (0.0186) | Acc: (99.37%) (38284/38528)\n",
            "Epoch: 132 | Batch_idx: 310 |  Loss: (0.0190) | Acc: (99.35%) (39548/39808)\n",
            "Epoch: 132 | Batch_idx: 320 |  Loss: (0.0189) | Acc: (99.35%) (40822/41088)\n",
            "Epoch: 132 | Batch_idx: 330 |  Loss: (0.0190) | Acc: (99.35%) (42091/42368)\n",
            "Epoch: 132 | Batch_idx: 340 |  Loss: (0.0188) | Acc: (99.35%) (43366/43648)\n",
            "Epoch: 132 | Batch_idx: 350 |  Loss: (0.0186) | Acc: (99.36%) (44641/44928)\n",
            "Epoch: 132 | Batch_idx: 360 |  Loss: (0.0187) | Acc: (99.36%) (45911/46208)\n",
            "Epoch: 132 | Batch_idx: 370 |  Loss: (0.0187) | Acc: (99.36%) (47182/47488)\n",
            "Epoch: 132 | Batch_idx: 380 |  Loss: (0.0191) | Acc: (99.35%) (48451/48768)\n",
            "Epoch: 132 | Batch_idx: 390 |  Loss: (0.0191) | Acc: (99.35%) (49677/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3594) | Acc: (91.75%) (9175/10000)\n",
            "Epoch: 133 | Batch_idx: 0 |  Loss: (0.0045) | Acc: (100.00%) (128/128)\n",
            "Epoch: 133 | Batch_idx: 10 |  Loss: (0.0198) | Acc: (99.22%) (1397/1408)\n",
            "Epoch: 133 | Batch_idx: 20 |  Loss: (0.0162) | Acc: (99.37%) (2671/2688)\n",
            "Epoch: 133 | Batch_idx: 30 |  Loss: (0.0165) | Acc: (99.34%) (3942/3968)\n",
            "Epoch: 133 | Batch_idx: 40 |  Loss: (0.0190) | Acc: (99.24%) (5208/5248)\n",
            "Epoch: 133 | Batch_idx: 50 |  Loss: (0.0204) | Acc: (99.20%) (6476/6528)\n",
            "Epoch: 133 | Batch_idx: 60 |  Loss: (0.0209) | Acc: (99.21%) (7746/7808)\n",
            "Epoch: 133 | Batch_idx: 70 |  Loss: (0.0208) | Acc: (99.21%) (9016/9088)\n",
            "Epoch: 133 | Batch_idx: 80 |  Loss: (0.0204) | Acc: (99.24%) (10289/10368)\n",
            "Epoch: 133 | Batch_idx: 90 |  Loss: (0.0198) | Acc: (99.28%) (11564/11648)\n",
            "Epoch: 133 | Batch_idx: 100 |  Loss: (0.0211) | Acc: (99.25%) (12831/12928)\n",
            "Epoch: 133 | Batch_idx: 110 |  Loss: (0.0208) | Acc: (99.27%) (14104/14208)\n",
            "Epoch: 133 | Batch_idx: 120 |  Loss: (0.0202) | Acc: (99.29%) (15378/15488)\n",
            "Epoch: 133 | Batch_idx: 130 |  Loss: (0.0215) | Acc: (99.26%) (16644/16768)\n",
            "Epoch: 133 | Batch_idx: 140 |  Loss: (0.0214) | Acc: (99.27%) (17916/18048)\n",
            "Epoch: 133 | Batch_idx: 150 |  Loss: (0.0213) | Acc: (99.27%) (19186/19328)\n",
            "Epoch: 133 | Batch_idx: 160 |  Loss: (0.0210) | Acc: (99.28%) (20459/20608)\n",
            "Epoch: 133 | Batch_idx: 170 |  Loss: (0.0213) | Acc: (99.26%) (21725/21888)\n",
            "Epoch: 133 | Batch_idx: 180 |  Loss: (0.0217) | Acc: (99.26%) (22996/23168)\n",
            "Epoch: 133 | Batch_idx: 190 |  Loss: (0.0220) | Acc: (99.26%) (24266/24448)\n",
            "Epoch: 133 | Batch_idx: 200 |  Loss: (0.0215) | Acc: (99.27%) (25539/25728)\n",
            "Epoch: 133 | Batch_idx: 210 |  Loss: (0.0215) | Acc: (99.27%) (26810/27008)\n",
            "Epoch: 133 | Batch_idx: 220 |  Loss: (0.0215) | Acc: (99.27%) (28082/28288)\n",
            "Epoch: 133 | Batch_idx: 230 |  Loss: (0.0211) | Acc: (99.29%) (29357/29568)\n",
            "Epoch: 133 | Batch_idx: 240 |  Loss: (0.0213) | Acc: (99.27%) (30624/30848)\n",
            "Epoch: 133 | Batch_idx: 250 |  Loss: (0.0215) | Acc: (99.27%) (31895/32128)\n",
            "Epoch: 133 | Batch_idx: 260 |  Loss: (0.0212) | Acc: (99.28%) (33168/33408)\n",
            "Epoch: 133 | Batch_idx: 270 |  Loss: (0.0209) | Acc: (99.29%) (34442/34688)\n",
            "Epoch: 133 | Batch_idx: 280 |  Loss: (0.0211) | Acc: (99.29%) (35711/35968)\n",
            "Epoch: 133 | Batch_idx: 290 |  Loss: (0.0210) | Acc: (99.29%) (36985/37248)\n",
            "Epoch: 133 | Batch_idx: 300 |  Loss: (0.0209) | Acc: (99.30%) (38258/38528)\n",
            "Epoch: 133 | Batch_idx: 310 |  Loss: (0.0210) | Acc: (99.30%) (39529/39808)\n",
            "Epoch: 133 | Batch_idx: 320 |  Loss: (0.0209) | Acc: (99.30%) (40801/41088)\n",
            "Epoch: 133 | Batch_idx: 330 |  Loss: (0.0209) | Acc: (99.30%) (42070/42368)\n",
            "Epoch: 133 | Batch_idx: 340 |  Loss: (0.0211) | Acc: (99.28%) (43334/43648)\n",
            "Epoch: 133 | Batch_idx: 350 |  Loss: (0.0210) | Acc: (99.28%) (44605/44928)\n",
            "Epoch: 133 | Batch_idx: 360 |  Loss: (0.0211) | Acc: (99.27%) (45871/46208)\n",
            "Epoch: 133 | Batch_idx: 370 |  Loss: (0.0212) | Acc: (99.27%) (47141/47488)\n",
            "Epoch: 133 | Batch_idx: 380 |  Loss: (0.0211) | Acc: (99.27%) (48413/48768)\n",
            "Epoch: 133 | Batch_idx: 390 |  Loss: (0.0211) | Acc: (99.27%) (49636/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3616) | Acc: (91.80%) (9180/10000)\n",
            "Epoch: 134 | Batch_idx: 0 |  Loss: (0.0031) | Acc: (100.00%) (128/128)\n",
            "Epoch: 134 | Batch_idx: 10 |  Loss: (0.0195) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 134 | Batch_idx: 20 |  Loss: (0.0228) | Acc: (99.29%) (2669/2688)\n",
            "Epoch: 134 | Batch_idx: 30 |  Loss: (0.0227) | Acc: (99.27%) (3939/3968)\n",
            "Epoch: 134 | Batch_idx: 40 |  Loss: (0.0213) | Acc: (99.33%) (5213/5248)\n",
            "Epoch: 134 | Batch_idx: 50 |  Loss: (0.0211) | Acc: (99.34%) (6485/6528)\n",
            "Epoch: 134 | Batch_idx: 60 |  Loss: (0.0216) | Acc: (99.32%) (7755/7808)\n",
            "Epoch: 134 | Batch_idx: 70 |  Loss: (0.0212) | Acc: (99.34%) (9028/9088)\n",
            "Epoch: 134 | Batch_idx: 80 |  Loss: (0.0212) | Acc: (99.33%) (10299/10368)\n",
            "Epoch: 134 | Batch_idx: 90 |  Loss: (0.0209) | Acc: (99.35%) (11572/11648)\n",
            "Epoch: 134 | Batch_idx: 100 |  Loss: (0.0207) | Acc: (99.32%) (12840/12928)\n",
            "Epoch: 134 | Batch_idx: 110 |  Loss: (0.0198) | Acc: (99.34%) (14114/14208)\n",
            "Epoch: 134 | Batch_idx: 120 |  Loss: (0.0194) | Acc: (99.36%) (15389/15488)\n",
            "Epoch: 134 | Batch_idx: 130 |  Loss: (0.0199) | Acc: (99.34%) (16658/16768)\n",
            "Epoch: 134 | Batch_idx: 140 |  Loss: (0.0203) | Acc: (99.32%) (17925/18048)\n",
            "Epoch: 134 | Batch_idx: 150 |  Loss: (0.0207) | Acc: (99.31%) (19195/19328)\n",
            "Epoch: 134 | Batch_idx: 160 |  Loss: (0.0207) | Acc: (99.31%) (20466/20608)\n",
            "Epoch: 134 | Batch_idx: 170 |  Loss: (0.0207) | Acc: (99.31%) (21737/21888)\n",
            "Epoch: 134 | Batch_idx: 180 |  Loss: (0.0211) | Acc: (99.31%) (23007/23168)\n",
            "Epoch: 134 | Batch_idx: 190 |  Loss: (0.0213) | Acc: (99.30%) (24276/24448)\n",
            "Epoch: 134 | Batch_idx: 200 |  Loss: (0.0213) | Acc: (99.28%) (25543/25728)\n",
            "Epoch: 134 | Batch_idx: 210 |  Loss: (0.0214) | Acc: (99.29%) (26815/27008)\n",
            "Epoch: 134 | Batch_idx: 220 |  Loss: (0.0210) | Acc: (99.31%) (28092/28288)\n",
            "Epoch: 134 | Batch_idx: 230 |  Loss: (0.0209) | Acc: (99.31%) (29363/29568)\n",
            "Epoch: 134 | Batch_idx: 240 |  Loss: (0.0210) | Acc: (99.29%) (30630/30848)\n",
            "Epoch: 134 | Batch_idx: 250 |  Loss: (0.0210) | Acc: (99.30%) (31902/32128)\n",
            "Epoch: 134 | Batch_idx: 260 |  Loss: (0.0209) | Acc: (99.30%) (33174/33408)\n",
            "Epoch: 134 | Batch_idx: 270 |  Loss: (0.0206) | Acc: (99.31%) (34450/34688)\n",
            "Epoch: 134 | Batch_idx: 280 |  Loss: (0.0205) | Acc: (99.32%) (35723/35968)\n",
            "Epoch: 134 | Batch_idx: 290 |  Loss: (0.0205) | Acc: (99.32%) (36994/37248)\n",
            "Epoch: 134 | Batch_idx: 300 |  Loss: (0.0204) | Acc: (99.33%) (38268/38528)\n",
            "Epoch: 134 | Batch_idx: 310 |  Loss: (0.0201) | Acc: (99.33%) (39542/39808)\n",
            "Epoch: 134 | Batch_idx: 320 |  Loss: (0.0199) | Acc: (99.33%) (40814/41088)\n",
            "Epoch: 134 | Batch_idx: 330 |  Loss: (0.0199) | Acc: (99.33%) (42083/42368)\n",
            "Epoch: 134 | Batch_idx: 340 |  Loss: (0.0199) | Acc: (99.32%) (43353/43648)\n",
            "Epoch: 134 | Batch_idx: 350 |  Loss: (0.0203) | Acc: (99.31%) (44619/44928)\n",
            "Epoch: 134 | Batch_idx: 360 |  Loss: (0.0204) | Acc: (99.31%) (45891/46208)\n",
            "Epoch: 134 | Batch_idx: 370 |  Loss: (0.0204) | Acc: (99.31%) (47161/47488)\n",
            "Epoch: 134 | Batch_idx: 380 |  Loss: (0.0203) | Acc: (99.32%) (48434/48768)\n",
            "Epoch: 134 | Batch_idx: 390 |  Loss: (0.0206) | Acc: (99.31%) (49653/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3615) | Acc: (91.96%) (9196/10000)\n",
            "Epoch: 135 | Batch_idx: 0 |  Loss: (0.0332) | Acc: (97.66%) (125/128)\n",
            "Epoch: 135 | Batch_idx: 10 |  Loss: (0.0213) | Acc: (99.15%) (1396/1408)\n",
            "Epoch: 135 | Batch_idx: 20 |  Loss: (0.0246) | Acc: (99.07%) (2663/2688)\n",
            "Epoch: 135 | Batch_idx: 30 |  Loss: (0.0227) | Acc: (99.09%) (3932/3968)\n",
            "Epoch: 135 | Batch_idx: 40 |  Loss: (0.0223) | Acc: (99.14%) (5203/5248)\n",
            "Epoch: 135 | Batch_idx: 50 |  Loss: (0.0218) | Acc: (99.16%) (6473/6528)\n",
            "Epoch: 135 | Batch_idx: 60 |  Loss: (0.0210) | Acc: (99.19%) (7745/7808)\n",
            "Epoch: 135 | Batch_idx: 70 |  Loss: (0.0197) | Acc: (99.25%) (9020/9088)\n",
            "Epoch: 135 | Batch_idx: 80 |  Loss: (0.0202) | Acc: (99.20%) (10285/10368)\n",
            "Epoch: 135 | Batch_idx: 90 |  Loss: (0.0197) | Acc: (99.21%) (11556/11648)\n",
            "Epoch: 135 | Batch_idx: 100 |  Loss: (0.0194) | Acc: (99.23%) (12829/12928)\n",
            "Epoch: 135 | Batch_idx: 110 |  Loss: (0.0196) | Acc: (99.25%) (14101/14208)\n",
            "Epoch: 135 | Batch_idx: 120 |  Loss: (0.0188) | Acc: (99.29%) (15378/15488)\n",
            "Epoch: 135 | Batch_idx: 130 |  Loss: (0.0191) | Acc: (99.30%) (16650/16768)\n",
            "Epoch: 135 | Batch_idx: 140 |  Loss: (0.0189) | Acc: (99.30%) (17922/18048)\n",
            "Epoch: 135 | Batch_idx: 150 |  Loss: (0.0188) | Acc: (99.32%) (19196/19328)\n",
            "Epoch: 135 | Batch_idx: 160 |  Loss: (0.0192) | Acc: (99.32%) (20467/20608)\n",
            "Epoch: 135 | Batch_idx: 170 |  Loss: (0.0195) | Acc: (99.31%) (21737/21888)\n",
            "Epoch: 135 | Batch_idx: 180 |  Loss: (0.0190) | Acc: (99.34%) (23015/23168)\n",
            "Epoch: 135 | Batch_idx: 190 |  Loss: (0.0194) | Acc: (99.32%) (24281/24448)\n",
            "Epoch: 135 | Batch_idx: 200 |  Loss: (0.0191) | Acc: (99.33%) (25556/25728)\n",
            "Epoch: 135 | Batch_idx: 210 |  Loss: (0.0191) | Acc: (99.33%) (26828/27008)\n",
            "Epoch: 135 | Batch_idx: 220 |  Loss: (0.0193) | Acc: (99.33%) (28098/28288)\n",
            "Epoch: 135 | Batch_idx: 230 |  Loss: (0.0190) | Acc: (99.34%) (29373/29568)\n",
            "Epoch: 135 | Batch_idx: 240 |  Loss: (0.0188) | Acc: (99.35%) (30646/30848)\n",
            "Epoch: 135 | Batch_idx: 250 |  Loss: (0.0186) | Acc: (99.35%) (31920/32128)\n",
            "Epoch: 135 | Batch_idx: 260 |  Loss: (0.0188) | Acc: (99.35%) (33191/33408)\n",
            "Epoch: 135 | Batch_idx: 270 |  Loss: (0.0188) | Acc: (99.35%) (34463/34688)\n",
            "Epoch: 135 | Batch_idx: 280 |  Loss: (0.0189) | Acc: (99.35%) (35734/35968)\n",
            "Epoch: 135 | Batch_idx: 290 |  Loss: (0.0186) | Acc: (99.36%) (37008/37248)\n",
            "Epoch: 135 | Batch_idx: 300 |  Loss: (0.0186) | Acc: (99.36%) (38281/38528)\n",
            "Epoch: 135 | Batch_idx: 310 |  Loss: (0.0186) | Acc: (99.35%) (39551/39808)\n",
            "Epoch: 135 | Batch_idx: 320 |  Loss: (0.0191) | Acc: (99.35%) (40822/41088)\n",
            "Epoch: 135 | Batch_idx: 330 |  Loss: (0.0191) | Acc: (99.36%) (42095/42368)\n",
            "Epoch: 135 | Batch_idx: 340 |  Loss: (0.0192) | Acc: (99.36%) (43368/43648)\n",
            "Epoch: 135 | Batch_idx: 350 |  Loss: (0.0189) | Acc: (99.37%) (44645/44928)\n",
            "Epoch: 135 | Batch_idx: 360 |  Loss: (0.0188) | Acc: (99.37%) (45919/46208)\n",
            "Epoch: 135 | Batch_idx: 370 |  Loss: (0.0188) | Acc: (99.37%) (47191/47488)\n",
            "Epoch: 135 | Batch_idx: 380 |  Loss: (0.0190) | Acc: (99.37%) (48459/48768)\n",
            "Epoch: 135 | Batch_idx: 390 |  Loss: (0.0189) | Acc: (99.37%) (49687/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3618) | Acc: (91.72%) (9172/10000)\n",
            "Epoch: 136 | Batch_idx: 0 |  Loss: (0.0142) | Acc: (100.00%) (128/128)\n",
            "Epoch: 136 | Batch_idx: 10 |  Loss: (0.0193) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 136 | Batch_idx: 20 |  Loss: (0.0210) | Acc: (99.37%) (2671/2688)\n",
            "Epoch: 136 | Batch_idx: 30 |  Loss: (0.0203) | Acc: (99.40%) (3944/3968)\n",
            "Epoch: 136 | Batch_idx: 40 |  Loss: (0.0173) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 136 | Batch_idx: 50 |  Loss: (0.0181) | Acc: (99.46%) (6493/6528)\n",
            "Epoch: 136 | Batch_idx: 60 |  Loss: (0.0193) | Acc: (99.41%) (7762/7808)\n",
            "Epoch: 136 | Batch_idx: 70 |  Loss: (0.0201) | Acc: (99.37%) (9031/9088)\n",
            "Epoch: 136 | Batch_idx: 80 |  Loss: (0.0198) | Acc: (99.37%) (10303/10368)\n",
            "Epoch: 136 | Batch_idx: 90 |  Loss: (0.0195) | Acc: (99.38%) (11576/11648)\n",
            "Epoch: 136 | Batch_idx: 100 |  Loss: (0.0191) | Acc: (99.40%) (12850/12928)\n",
            "Epoch: 136 | Batch_idx: 110 |  Loss: (0.0185) | Acc: (99.39%) (14122/14208)\n",
            "Epoch: 136 | Batch_idx: 120 |  Loss: (0.0184) | Acc: (99.38%) (15392/15488)\n",
            "Epoch: 136 | Batch_idx: 130 |  Loss: (0.0193) | Acc: (99.34%) (16658/16768)\n",
            "Epoch: 136 | Batch_idx: 140 |  Loss: (0.0200) | Acc: (99.32%) (17925/18048)\n",
            "Epoch: 136 | Batch_idx: 150 |  Loss: (0.0198) | Acc: (99.33%) (19198/19328)\n",
            "Epoch: 136 | Batch_idx: 160 |  Loss: (0.0201) | Acc: (99.31%) (20466/20608)\n",
            "Epoch: 136 | Batch_idx: 170 |  Loss: (0.0200) | Acc: (99.31%) (21736/21888)\n",
            "Epoch: 136 | Batch_idx: 180 |  Loss: (0.0194) | Acc: (99.33%) (23013/23168)\n",
            "Epoch: 136 | Batch_idx: 190 |  Loss: (0.0197) | Acc: (99.33%) (24284/24448)\n",
            "Epoch: 136 | Batch_idx: 200 |  Loss: (0.0198) | Acc: (99.31%) (25551/25728)\n",
            "Epoch: 136 | Batch_idx: 210 |  Loss: (0.0199) | Acc: (99.31%) (26821/27008)\n",
            "Epoch: 136 | Batch_idx: 220 |  Loss: (0.0195) | Acc: (99.32%) (28096/28288)\n",
            "Epoch: 136 | Batch_idx: 230 |  Loss: (0.0196) | Acc: (99.31%) (29364/29568)\n",
            "Epoch: 136 | Batch_idx: 240 |  Loss: (0.0191) | Acc: (99.33%) (30642/30848)\n",
            "Epoch: 136 | Batch_idx: 250 |  Loss: (0.0193) | Acc: (99.32%) (31911/32128)\n",
            "Epoch: 136 | Batch_idx: 260 |  Loss: (0.0194) | Acc: (99.32%) (33180/33408)\n",
            "Epoch: 136 | Batch_idx: 270 |  Loss: (0.0200) | Acc: (99.29%) (34441/34688)\n",
            "Epoch: 136 | Batch_idx: 280 |  Loss: (0.0200) | Acc: (99.29%) (35714/35968)\n",
            "Epoch: 136 | Batch_idx: 290 |  Loss: (0.0199) | Acc: (99.30%) (36986/37248)\n",
            "Epoch: 136 | Batch_idx: 300 |  Loss: (0.0197) | Acc: (99.30%) (38260/38528)\n",
            "Epoch: 136 | Batch_idx: 310 |  Loss: (0.0196) | Acc: (99.31%) (39532/39808)\n",
            "Epoch: 136 | Batch_idx: 320 |  Loss: (0.0194) | Acc: (99.32%) (40807/41088)\n",
            "Epoch: 136 | Batch_idx: 330 |  Loss: (0.0197) | Acc: (99.30%) (42071/42368)\n",
            "Epoch: 136 | Batch_idx: 340 |  Loss: (0.0198) | Acc: (99.30%) (43342/43648)\n",
            "Epoch: 136 | Batch_idx: 350 |  Loss: (0.0197) | Acc: (99.30%) (44612/44928)\n",
            "Epoch: 136 | Batch_idx: 360 |  Loss: (0.0201) | Acc: (99.28%) (45873/46208)\n",
            "Epoch: 136 | Batch_idx: 370 |  Loss: (0.0201) | Acc: (99.27%) (47141/47488)\n",
            "Epoch: 136 | Batch_idx: 380 |  Loss: (0.0199) | Acc: (99.28%) (48415/48768)\n",
            "Epoch: 136 | Batch_idx: 390 |  Loss: (0.0200) | Acc: (99.28%) (49638/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3624) | Acc: (91.78%) (9178/10000)\n",
            "Epoch: 137 | Batch_idx: 0 |  Loss: (0.0068) | Acc: (100.00%) (128/128)\n",
            "Epoch: 137 | Batch_idx: 10 |  Loss: (0.0156) | Acc: (99.15%) (1396/1408)\n",
            "Epoch: 137 | Batch_idx: 20 |  Loss: (0.0191) | Acc: (99.18%) (2666/2688)\n",
            "Epoch: 137 | Batch_idx: 30 |  Loss: (0.0153) | Acc: (99.34%) (3942/3968)\n",
            "Epoch: 137 | Batch_idx: 40 |  Loss: (0.0207) | Acc: (99.26%) (5209/5248)\n",
            "Epoch: 137 | Batch_idx: 50 |  Loss: (0.0194) | Acc: (99.33%) (6484/6528)\n",
            "Epoch: 137 | Batch_idx: 60 |  Loss: (0.0187) | Acc: (99.35%) (7757/7808)\n",
            "Epoch: 137 | Batch_idx: 70 |  Loss: (0.0182) | Acc: (99.36%) (9030/9088)\n",
            "Epoch: 137 | Batch_idx: 80 |  Loss: (0.0171) | Acc: (99.41%) (10307/10368)\n",
            "Epoch: 137 | Batch_idx: 90 |  Loss: (0.0170) | Acc: (99.39%) (11577/11648)\n",
            "Epoch: 137 | Batch_idx: 100 |  Loss: (0.0172) | Acc: (99.40%) (12851/12928)\n",
            "Epoch: 137 | Batch_idx: 110 |  Loss: (0.0175) | Acc: (99.40%) (14123/14208)\n",
            "Epoch: 137 | Batch_idx: 120 |  Loss: (0.0172) | Acc: (99.40%) (15395/15488)\n",
            "Epoch: 137 | Batch_idx: 130 |  Loss: (0.0169) | Acc: (99.41%) (16669/16768)\n",
            "Epoch: 137 | Batch_idx: 140 |  Loss: (0.0168) | Acc: (99.40%) (17940/18048)\n",
            "Epoch: 137 | Batch_idx: 150 |  Loss: (0.0179) | Acc: (99.37%) (19206/19328)\n",
            "Epoch: 137 | Batch_idx: 160 |  Loss: (0.0181) | Acc: (99.35%) (20475/20608)\n",
            "Epoch: 137 | Batch_idx: 170 |  Loss: (0.0181) | Acc: (99.36%) (21749/21888)\n",
            "Epoch: 137 | Batch_idx: 180 |  Loss: (0.0185) | Acc: (99.36%) (23019/23168)\n",
            "Epoch: 137 | Batch_idx: 190 |  Loss: (0.0181) | Acc: (99.37%) (24295/24448)\n",
            "Epoch: 137 | Batch_idx: 200 |  Loss: (0.0179) | Acc: (99.38%) (25569/25728)\n",
            "Epoch: 137 | Batch_idx: 210 |  Loss: (0.0176) | Acc: (99.39%) (26843/27008)\n",
            "Epoch: 137 | Batch_idx: 220 |  Loss: (0.0174) | Acc: (99.39%) (28116/28288)\n",
            "Epoch: 137 | Batch_idx: 230 |  Loss: (0.0175) | Acc: (99.39%) (29387/29568)\n",
            "Epoch: 137 | Batch_idx: 240 |  Loss: (0.0176) | Acc: (99.38%) (30658/30848)\n",
            "Epoch: 137 | Batch_idx: 250 |  Loss: (0.0179) | Acc: (99.37%) (31926/32128)\n",
            "Epoch: 137 | Batch_idx: 260 |  Loss: (0.0178) | Acc: (99.38%) (33200/33408)\n",
            "Epoch: 137 | Batch_idx: 270 |  Loss: (0.0180) | Acc: (99.37%) (34469/34688)\n",
            "Epoch: 137 | Batch_idx: 280 |  Loss: (0.0179) | Acc: (99.37%) (35743/35968)\n",
            "Epoch: 137 | Batch_idx: 290 |  Loss: (0.0180) | Acc: (99.37%) (37013/37248)\n",
            "Epoch: 137 | Batch_idx: 300 |  Loss: (0.0181) | Acc: (99.36%) (38282/38528)\n",
            "Epoch: 137 | Batch_idx: 310 |  Loss: (0.0180) | Acc: (99.36%) (39554/39808)\n",
            "Epoch: 137 | Batch_idx: 320 |  Loss: (0.0180) | Acc: (99.36%) (40825/41088)\n",
            "Epoch: 137 | Batch_idx: 330 |  Loss: (0.0183) | Acc: (99.35%) (42092/42368)\n",
            "Epoch: 137 | Batch_idx: 340 |  Loss: (0.0182) | Acc: (99.36%) (43367/43648)\n",
            "Epoch: 137 | Batch_idx: 350 |  Loss: (0.0180) | Acc: (99.36%) (44641/44928)\n",
            "Epoch: 137 | Batch_idx: 360 |  Loss: (0.0181) | Acc: (99.36%) (45912/46208)\n",
            "Epoch: 137 | Batch_idx: 370 |  Loss: (0.0179) | Acc: (99.37%) (47187/47488)\n",
            "Epoch: 137 | Batch_idx: 380 |  Loss: (0.0179) | Acc: (99.36%) (48458/48768)\n",
            "Epoch: 137 | Batch_idx: 390 |  Loss: (0.0179) | Acc: (99.37%) (49684/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3638) | Acc: (91.82%) (9182/10000)\n",
            "Epoch: 138 | Batch_idx: 0 |  Loss: (0.0213) | Acc: (99.22%) (127/128)\n",
            "Epoch: 138 | Batch_idx: 10 |  Loss: (0.0200) | Acc: (99.22%) (1397/1408)\n",
            "Epoch: 138 | Batch_idx: 20 |  Loss: (0.0172) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 138 | Batch_idx: 30 |  Loss: (0.0185) | Acc: (99.37%) (3943/3968)\n",
            "Epoch: 138 | Batch_idx: 40 |  Loss: (0.0199) | Acc: (99.35%) (5214/5248)\n",
            "Epoch: 138 | Batch_idx: 50 |  Loss: (0.0181) | Acc: (99.42%) (6490/6528)\n",
            "Epoch: 138 | Batch_idx: 60 |  Loss: (0.0181) | Acc: (99.41%) (7762/7808)\n",
            "Epoch: 138 | Batch_idx: 70 |  Loss: (0.0175) | Acc: (99.44%) (9037/9088)\n",
            "Epoch: 138 | Batch_idx: 80 |  Loss: (0.0189) | Acc: (99.40%) (10306/10368)\n",
            "Epoch: 138 | Batch_idx: 90 |  Loss: (0.0192) | Acc: (99.40%) (11578/11648)\n",
            "Epoch: 138 | Batch_idx: 100 |  Loss: (0.0182) | Acc: (99.43%) (12854/12928)\n",
            "Epoch: 138 | Batch_idx: 110 |  Loss: (0.0182) | Acc: (99.43%) (14127/14208)\n",
            "Epoch: 138 | Batch_idx: 120 |  Loss: (0.0182) | Acc: (99.43%) (15399/15488)\n",
            "Epoch: 138 | Batch_idx: 130 |  Loss: (0.0189) | Acc: (99.41%) (16669/16768)\n",
            "Epoch: 138 | Batch_idx: 140 |  Loss: (0.0184) | Acc: (99.43%) (17945/18048)\n",
            "Epoch: 138 | Batch_idx: 150 |  Loss: (0.0185) | Acc: (99.43%) (19217/19328)\n",
            "Epoch: 138 | Batch_idx: 160 |  Loss: (0.0184) | Acc: (99.43%) (20490/20608)\n",
            "Epoch: 138 | Batch_idx: 170 |  Loss: (0.0187) | Acc: (99.42%) (21762/21888)\n",
            "Epoch: 138 | Batch_idx: 180 |  Loss: (0.0192) | Acc: (99.41%) (23032/23168)\n",
            "Epoch: 138 | Batch_idx: 190 |  Loss: (0.0198) | Acc: (99.40%) (24301/24448)\n",
            "Epoch: 138 | Batch_idx: 200 |  Loss: (0.0195) | Acc: (99.41%) (25575/25728)\n",
            "Epoch: 138 | Batch_idx: 210 |  Loss: (0.0193) | Acc: (99.40%) (26847/27008)\n",
            "Epoch: 138 | Batch_idx: 220 |  Loss: (0.0192) | Acc: (99.41%) (28120/28288)\n",
            "Epoch: 138 | Batch_idx: 230 |  Loss: (0.0190) | Acc: (99.40%) (29392/29568)\n",
            "Epoch: 138 | Batch_idx: 240 |  Loss: (0.0190) | Acc: (99.40%) (30663/30848)\n",
            "Epoch: 138 | Batch_idx: 250 |  Loss: (0.0195) | Acc: (99.38%) (31930/32128)\n",
            "Epoch: 138 | Batch_idx: 260 |  Loss: (0.0193) | Acc: (99.39%) (33204/33408)\n",
            "Epoch: 138 | Batch_idx: 270 |  Loss: (0.0196) | Acc: (99.38%) (34474/34688)\n",
            "Epoch: 138 | Batch_idx: 280 |  Loss: (0.0199) | Acc: (99.37%) (35742/35968)\n",
            "Epoch: 138 | Batch_idx: 290 |  Loss: (0.0197) | Acc: (99.38%) (37017/37248)\n",
            "Epoch: 138 | Batch_idx: 300 |  Loss: (0.0197) | Acc: (99.38%) (38288/38528)\n",
            "Epoch: 138 | Batch_idx: 310 |  Loss: (0.0198) | Acc: (99.37%) (39558/39808)\n",
            "Epoch: 138 | Batch_idx: 320 |  Loss: (0.0197) | Acc: (99.37%) (40830/41088)\n",
            "Epoch: 138 | Batch_idx: 330 |  Loss: (0.0196) | Acc: (99.38%) (42104/42368)\n",
            "Epoch: 138 | Batch_idx: 340 |  Loss: (0.0194) | Acc: (99.38%) (43379/43648)\n",
            "Epoch: 138 | Batch_idx: 350 |  Loss: (0.0191) | Acc: (99.39%) (44653/44928)\n",
            "Epoch: 138 | Batch_idx: 360 |  Loss: (0.0190) | Acc: (99.39%) (45927/46208)\n",
            "Epoch: 138 | Batch_idx: 370 |  Loss: (0.0190) | Acc: (99.39%) (47200/47488)\n",
            "Epoch: 138 | Batch_idx: 380 |  Loss: (0.0190) | Acc: (99.39%) (48470/48768)\n",
            "Epoch: 138 | Batch_idx: 390 |  Loss: (0.0190) | Acc: (99.39%) (49697/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3631) | Acc: (91.90%) (9190/10000)\n",
            "Epoch: 139 | Batch_idx: 0 |  Loss: (0.0023) | Acc: (100.00%) (128/128)\n",
            "Epoch: 139 | Batch_idx: 10 |  Loss: (0.0173) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 139 | Batch_idx: 20 |  Loss: (0.0163) | Acc: (99.52%) (2675/2688)\n",
            "Epoch: 139 | Batch_idx: 30 |  Loss: (0.0203) | Acc: (99.34%) (3942/3968)\n",
            "Epoch: 139 | Batch_idx: 40 |  Loss: (0.0215) | Acc: (99.26%) (5209/5248)\n",
            "Epoch: 139 | Batch_idx: 50 |  Loss: (0.0228) | Acc: (99.25%) (6479/6528)\n",
            "Epoch: 139 | Batch_idx: 60 |  Loss: (0.0225) | Acc: (99.23%) (7748/7808)\n",
            "Epoch: 139 | Batch_idx: 70 |  Loss: (0.0236) | Acc: (99.23%) (9018/9088)\n",
            "Epoch: 139 | Batch_idx: 80 |  Loss: (0.0220) | Acc: (99.29%) (10294/10368)\n",
            "Epoch: 139 | Batch_idx: 90 |  Loss: (0.0237) | Acc: (99.25%) (11561/11648)\n",
            "Epoch: 139 | Batch_idx: 100 |  Loss: (0.0232) | Acc: (99.27%) (12834/12928)\n",
            "Epoch: 139 | Batch_idx: 110 |  Loss: (0.0241) | Acc: (99.24%) (14100/14208)\n",
            "Epoch: 139 | Batch_idx: 120 |  Loss: (0.0230) | Acc: (99.28%) (15376/15488)\n",
            "Epoch: 139 | Batch_idx: 130 |  Loss: (0.0226) | Acc: (99.29%) (16649/16768)\n",
            "Epoch: 139 | Batch_idx: 140 |  Loss: (0.0224) | Acc: (99.29%) (17919/18048)\n",
            "Epoch: 139 | Batch_idx: 150 |  Loss: (0.0222) | Acc: (99.29%) (19191/19328)\n",
            "Epoch: 139 | Batch_idx: 160 |  Loss: (0.0219) | Acc: (99.31%) (20465/20608)\n",
            "Epoch: 139 | Batch_idx: 170 |  Loss: (0.0217) | Acc: (99.30%) (21735/21888)\n",
            "Epoch: 139 | Batch_idx: 180 |  Loss: (0.0210) | Acc: (99.33%) (23013/23168)\n",
            "Epoch: 139 | Batch_idx: 190 |  Loss: (0.0211) | Acc: (99.33%) (24283/24448)\n",
            "Epoch: 139 | Batch_idx: 200 |  Loss: (0.0207) | Acc: (99.34%) (25559/25728)\n",
            "Epoch: 139 | Batch_idx: 210 |  Loss: (0.0200) | Acc: (99.37%) (26838/27008)\n",
            "Epoch: 139 | Batch_idx: 220 |  Loss: (0.0200) | Acc: (99.36%) (28108/28288)\n",
            "Epoch: 139 | Batch_idx: 230 |  Loss: (0.0196) | Acc: (99.37%) (29383/29568)\n",
            "Epoch: 139 | Batch_idx: 240 |  Loss: (0.0196) | Acc: (99.37%) (30655/30848)\n",
            "Epoch: 139 | Batch_idx: 250 |  Loss: (0.0194) | Acc: (99.39%) (31931/32128)\n",
            "Epoch: 139 | Batch_idx: 260 |  Loss: (0.0192) | Acc: (99.39%) (33204/33408)\n",
            "Epoch: 139 | Batch_idx: 270 |  Loss: (0.0188) | Acc: (99.40%) (34480/34688)\n",
            "Epoch: 139 | Batch_idx: 280 |  Loss: (0.0191) | Acc: (99.39%) (35747/35968)\n",
            "Epoch: 139 | Batch_idx: 290 |  Loss: (0.0188) | Acc: (99.39%) (37020/37248)\n",
            "Epoch: 139 | Batch_idx: 300 |  Loss: (0.0187) | Acc: (99.39%) (38293/38528)\n",
            "Epoch: 139 | Batch_idx: 310 |  Loss: (0.0189) | Acc: (99.38%) (39560/39808)\n",
            "Epoch: 139 | Batch_idx: 320 |  Loss: (0.0190) | Acc: (99.37%) (40829/41088)\n",
            "Epoch: 139 | Batch_idx: 330 |  Loss: (0.0189) | Acc: (99.37%) (42103/42368)\n",
            "Epoch: 139 | Batch_idx: 340 |  Loss: (0.0192) | Acc: (99.37%) (43371/43648)\n",
            "Epoch: 139 | Batch_idx: 350 |  Loss: (0.0190) | Acc: (99.37%) (44646/44928)\n",
            "Epoch: 139 | Batch_idx: 360 |  Loss: (0.0190) | Acc: (99.37%) (45919/46208)\n",
            "Epoch: 139 | Batch_idx: 370 |  Loss: (0.0189) | Acc: (99.38%) (47194/47488)\n",
            "Epoch: 139 | Batch_idx: 380 |  Loss: (0.0191) | Acc: (99.37%) (48462/48768)\n",
            "Epoch: 139 | Batch_idx: 390 |  Loss: (0.0193) | Acc: (99.36%) (49682/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3651) | Acc: (91.90%) (9190/10000)\n",
            "Epoch: 140 | Batch_idx: 0 |  Loss: (0.0075) | Acc: (100.00%) (128/128)\n",
            "Epoch: 140 | Batch_idx: 10 |  Loss: (0.0287) | Acc: (99.22%) (1397/1408)\n",
            "Epoch: 140 | Batch_idx: 20 |  Loss: (0.0251) | Acc: (99.07%) (2663/2688)\n",
            "Epoch: 140 | Batch_idx: 30 |  Loss: (0.0222) | Acc: (99.17%) (3935/3968)\n",
            "Epoch: 140 | Batch_idx: 40 |  Loss: (0.0196) | Acc: (99.26%) (5209/5248)\n",
            "Epoch: 140 | Batch_idx: 50 |  Loss: (0.0191) | Acc: (99.26%) (6480/6528)\n",
            "Epoch: 140 | Batch_idx: 60 |  Loss: (0.0193) | Acc: (99.28%) (7752/7808)\n",
            "Epoch: 140 | Batch_idx: 70 |  Loss: (0.0177) | Acc: (99.34%) (9028/9088)\n",
            "Epoch: 140 | Batch_idx: 80 |  Loss: (0.0170) | Acc: (99.37%) (10303/10368)\n",
            "Epoch: 140 | Batch_idx: 90 |  Loss: (0.0173) | Acc: (99.37%) (11575/11648)\n",
            "Epoch: 140 | Batch_idx: 100 |  Loss: (0.0174) | Acc: (99.36%) (12845/12928)\n",
            "Epoch: 140 | Batch_idx: 110 |  Loss: (0.0172) | Acc: (99.38%) (14120/14208)\n",
            "Epoch: 140 | Batch_idx: 120 |  Loss: (0.0172) | Acc: (99.37%) (15391/15488)\n",
            "Epoch: 140 | Batch_idx: 130 |  Loss: (0.0171) | Acc: (99.37%) (16663/16768)\n",
            "Epoch: 140 | Batch_idx: 140 |  Loss: (0.0170) | Acc: (99.38%) (17937/18048)\n",
            "Epoch: 140 | Batch_idx: 150 |  Loss: (0.0171) | Acc: (99.39%) (19210/19328)\n",
            "Epoch: 140 | Batch_idx: 160 |  Loss: (0.0174) | Acc: (99.37%) (20478/20608)\n",
            "Epoch: 140 | Batch_idx: 170 |  Loss: (0.0176) | Acc: (99.37%) (21750/21888)\n",
            "Epoch: 140 | Batch_idx: 180 |  Loss: (0.0180) | Acc: (99.36%) (23020/23168)\n",
            "Epoch: 140 | Batch_idx: 190 |  Loss: (0.0176) | Acc: (99.38%) (24296/24448)\n",
            "Epoch: 140 | Batch_idx: 200 |  Loss: (0.0180) | Acc: (99.37%) (25567/25728)\n",
            "Epoch: 140 | Batch_idx: 210 |  Loss: (0.0179) | Acc: (99.38%) (26840/27008)\n",
            "Epoch: 140 | Batch_idx: 220 |  Loss: (0.0177) | Acc: (99.38%) (28113/28288)\n",
            "Epoch: 140 | Batch_idx: 230 |  Loss: (0.0178) | Acc: (99.37%) (29383/29568)\n",
            "Epoch: 140 | Batch_idx: 240 |  Loss: (0.0178) | Acc: (99.37%) (30655/30848)\n",
            "Epoch: 140 | Batch_idx: 250 |  Loss: (0.0181) | Acc: (99.37%) (31927/32128)\n",
            "Epoch: 140 | Batch_idx: 260 |  Loss: (0.0182) | Acc: (99.36%) (33195/33408)\n",
            "Epoch: 140 | Batch_idx: 270 |  Loss: (0.0179) | Acc: (99.37%) (34471/34688)\n",
            "Epoch: 140 | Batch_idx: 280 |  Loss: (0.0177) | Acc: (99.39%) (35747/35968)\n",
            "Epoch: 140 | Batch_idx: 290 |  Loss: (0.0178) | Acc: (99.37%) (37014/37248)\n",
            "Epoch: 140 | Batch_idx: 300 |  Loss: (0.0179) | Acc: (99.37%) (38284/38528)\n",
            "Epoch: 140 | Batch_idx: 310 |  Loss: (0.0180) | Acc: (99.37%) (39559/39808)\n",
            "Epoch: 140 | Batch_idx: 320 |  Loss: (0.0181) | Acc: (99.37%) (40828/41088)\n",
            "Epoch: 140 | Batch_idx: 330 |  Loss: (0.0183) | Acc: (99.36%) (42098/42368)\n",
            "Epoch: 140 | Batch_idx: 340 |  Loss: (0.0184) | Acc: (99.36%) (43367/43648)\n",
            "Epoch: 140 | Batch_idx: 350 |  Loss: (0.0186) | Acc: (99.35%) (44635/44928)\n",
            "Epoch: 140 | Batch_idx: 360 |  Loss: (0.0187) | Acc: (99.34%) (45902/46208)\n",
            "Epoch: 140 | Batch_idx: 370 |  Loss: (0.0187) | Acc: (99.34%) (47175/47488)\n",
            "Epoch: 140 | Batch_idx: 380 |  Loss: (0.0186) | Acc: (99.34%) (48448/48768)\n",
            "Epoch: 140 | Batch_idx: 390 |  Loss: (0.0189) | Acc: (99.34%) (49669/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3644) | Acc: (91.91%) (9191/10000)\n",
            "Epoch: 141 | Batch_idx: 0 |  Loss: (0.0159) | Acc: (99.22%) (127/128)\n",
            "Epoch: 141 | Batch_idx: 10 |  Loss: (0.0178) | Acc: (99.22%) (1397/1408)\n",
            "Epoch: 141 | Batch_idx: 20 |  Loss: (0.0165) | Acc: (99.37%) (2671/2688)\n",
            "Epoch: 141 | Batch_idx: 30 |  Loss: (0.0187) | Acc: (99.34%) (3942/3968)\n",
            "Epoch: 141 | Batch_idx: 40 |  Loss: (0.0208) | Acc: (99.22%) (5207/5248)\n",
            "Epoch: 141 | Batch_idx: 50 |  Loss: (0.0197) | Acc: (99.28%) (6481/6528)\n",
            "Epoch: 141 | Batch_idx: 60 |  Loss: (0.0197) | Acc: (99.28%) (7752/7808)\n",
            "Epoch: 141 | Batch_idx: 70 |  Loss: (0.0203) | Acc: (99.27%) (9022/9088)\n",
            "Epoch: 141 | Batch_idx: 80 |  Loss: (0.0190) | Acc: (99.32%) (10298/10368)\n",
            "Epoch: 141 | Batch_idx: 90 |  Loss: (0.0182) | Acc: (99.36%) (11574/11648)\n",
            "Epoch: 141 | Batch_idx: 100 |  Loss: (0.0176) | Acc: (99.37%) (12847/12928)\n",
            "Epoch: 141 | Batch_idx: 110 |  Loss: (0.0174) | Acc: (99.37%) (14118/14208)\n",
            "Epoch: 141 | Batch_idx: 120 |  Loss: (0.0171) | Acc: (99.39%) (15393/15488)\n",
            "Epoch: 141 | Batch_idx: 130 |  Loss: (0.0171) | Acc: (99.39%) (16666/16768)\n",
            "Epoch: 141 | Batch_idx: 140 |  Loss: (0.0180) | Acc: (99.37%) (17934/18048)\n",
            "Epoch: 141 | Batch_idx: 150 |  Loss: (0.0178) | Acc: (99.38%) (19209/19328)\n",
            "Epoch: 141 | Batch_idx: 160 |  Loss: (0.0178) | Acc: (99.39%) (20482/20608)\n",
            "Epoch: 141 | Batch_idx: 170 |  Loss: (0.0179) | Acc: (99.39%) (21755/21888)\n",
            "Epoch: 141 | Batch_idx: 180 |  Loss: (0.0181) | Acc: (99.39%) (23027/23168)\n",
            "Epoch: 141 | Batch_idx: 190 |  Loss: (0.0180) | Acc: (99.39%) (24300/24448)\n",
            "Epoch: 141 | Batch_idx: 200 |  Loss: (0.0181) | Acc: (99.39%) (25570/25728)\n",
            "Epoch: 141 | Batch_idx: 210 |  Loss: (0.0178) | Acc: (99.39%) (26844/27008)\n",
            "Epoch: 141 | Batch_idx: 220 |  Loss: (0.0181) | Acc: (99.38%) (28113/28288)\n",
            "Epoch: 141 | Batch_idx: 230 |  Loss: (0.0184) | Acc: (99.37%) (29381/29568)\n",
            "Epoch: 141 | Batch_idx: 240 |  Loss: (0.0187) | Acc: (99.35%) (30649/30848)\n",
            "Epoch: 141 | Batch_idx: 250 |  Loss: (0.0189) | Acc: (99.35%) (31920/32128)\n",
            "Epoch: 141 | Batch_idx: 260 |  Loss: (0.0186) | Acc: (99.37%) (33196/33408)\n",
            "Epoch: 141 | Batch_idx: 270 |  Loss: (0.0187) | Acc: (99.36%) (34466/34688)\n",
            "Epoch: 141 | Batch_idx: 280 |  Loss: (0.0185) | Acc: (99.37%) (35742/35968)\n",
            "Epoch: 141 | Batch_idx: 290 |  Loss: (0.0183) | Acc: (99.38%) (37017/37248)\n",
            "Epoch: 141 | Batch_idx: 300 |  Loss: (0.0182) | Acc: (99.38%) (38291/38528)\n",
            "Epoch: 141 | Batch_idx: 310 |  Loss: (0.0184) | Acc: (99.38%) (39561/39808)\n",
            "Epoch: 141 | Batch_idx: 320 |  Loss: (0.0182) | Acc: (99.39%) (40838/41088)\n",
            "Epoch: 141 | Batch_idx: 330 |  Loss: (0.0181) | Acc: (99.39%) (42110/42368)\n",
            "Epoch: 141 | Batch_idx: 340 |  Loss: (0.0180) | Acc: (99.40%) (43384/43648)\n",
            "Epoch: 141 | Batch_idx: 350 |  Loss: (0.0179) | Acc: (99.41%) (44661/44928)\n",
            "Epoch: 141 | Batch_idx: 360 |  Loss: (0.0179) | Acc: (99.40%) (45933/46208)\n",
            "Epoch: 141 | Batch_idx: 370 |  Loss: (0.0180) | Acc: (99.40%) (47204/47488)\n",
            "Epoch: 141 | Batch_idx: 380 |  Loss: (0.0180) | Acc: (99.40%) (48476/48768)\n",
            "Epoch: 141 | Batch_idx: 390 |  Loss: (0.0183) | Acc: (99.40%) (49698/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3632) | Acc: (91.78%) (9178/10000)\n",
            "Epoch: 142 | Batch_idx: 0 |  Loss: (0.0385) | Acc: (99.22%) (127/128)\n",
            "Epoch: 142 | Batch_idx: 10 |  Loss: (0.0168) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 142 | Batch_idx: 20 |  Loss: (0.0160) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 142 | Batch_idx: 30 |  Loss: (0.0190) | Acc: (99.37%) (3943/3968)\n",
            "Epoch: 142 | Batch_idx: 40 |  Loss: (0.0181) | Acc: (99.43%) (5218/5248)\n",
            "Epoch: 142 | Batch_idx: 50 |  Loss: (0.0175) | Acc: (99.42%) (6490/6528)\n",
            "Epoch: 142 | Batch_idx: 60 |  Loss: (0.0174) | Acc: (99.41%) (7762/7808)\n",
            "Epoch: 142 | Batch_idx: 70 |  Loss: (0.0162) | Acc: (99.47%) (9040/9088)\n",
            "Epoch: 142 | Batch_idx: 80 |  Loss: (0.0171) | Acc: (99.44%) (10310/10368)\n",
            "Epoch: 142 | Batch_idx: 90 |  Loss: (0.0174) | Acc: (99.42%) (11581/11648)\n",
            "Epoch: 142 | Batch_idx: 100 |  Loss: (0.0185) | Acc: (99.40%) (12851/12928)\n",
            "Epoch: 142 | Batch_idx: 110 |  Loss: (0.0186) | Acc: (99.40%) (14123/14208)\n",
            "Epoch: 142 | Batch_idx: 120 |  Loss: (0.0188) | Acc: (99.41%) (15396/15488)\n",
            "Epoch: 142 | Batch_idx: 130 |  Loss: (0.0180) | Acc: (99.43%) (16673/16768)\n",
            "Epoch: 142 | Batch_idx: 140 |  Loss: (0.0178) | Acc: (99.42%) (17944/18048)\n",
            "Epoch: 142 | Batch_idx: 150 |  Loss: (0.0178) | Acc: (99.42%) (19216/19328)\n",
            "Epoch: 142 | Batch_idx: 160 |  Loss: (0.0175) | Acc: (99.42%) (20488/20608)\n",
            "Epoch: 142 | Batch_idx: 170 |  Loss: (0.0173) | Acc: (99.43%) (21763/21888)\n",
            "Epoch: 142 | Batch_idx: 180 |  Loss: (0.0168) | Acc: (99.45%) (23041/23168)\n",
            "Epoch: 142 | Batch_idx: 190 |  Loss: (0.0173) | Acc: (99.41%) (24304/24448)\n",
            "Epoch: 142 | Batch_idx: 200 |  Loss: (0.0173) | Acc: (99.41%) (25575/25728)\n",
            "Epoch: 142 | Batch_idx: 210 |  Loss: (0.0171) | Acc: (99.42%) (26851/27008)\n",
            "Epoch: 142 | Batch_idx: 220 |  Loss: (0.0170) | Acc: (99.43%) (28127/28288)\n",
            "Epoch: 142 | Batch_idx: 230 |  Loss: (0.0166) | Acc: (99.44%) (29403/29568)\n",
            "Epoch: 142 | Batch_idx: 240 |  Loss: (0.0166) | Acc: (99.45%) (30679/30848)\n",
            "Epoch: 142 | Batch_idx: 250 |  Loss: (0.0172) | Acc: (99.43%) (31946/32128)\n",
            "Epoch: 142 | Batch_idx: 260 |  Loss: (0.0173) | Acc: (99.42%) (33215/33408)\n",
            "Epoch: 142 | Batch_idx: 270 |  Loss: (0.0172) | Acc: (99.43%) (34490/34688)\n",
            "Epoch: 142 | Batch_idx: 280 |  Loss: (0.0173) | Acc: (99.43%) (35762/35968)\n",
            "Epoch: 142 | Batch_idx: 290 |  Loss: (0.0169) | Acc: (99.44%) (37041/37248)\n",
            "Epoch: 142 | Batch_idx: 300 |  Loss: (0.0172) | Acc: (99.42%) (38306/38528)\n",
            "Epoch: 142 | Batch_idx: 310 |  Loss: (0.0170) | Acc: (99.43%) (39581/39808)\n",
            "Epoch: 142 | Batch_idx: 320 |  Loss: (0.0169) | Acc: (99.43%) (40852/41088)\n",
            "Epoch: 142 | Batch_idx: 330 |  Loss: (0.0171) | Acc: (99.42%) (42124/42368)\n",
            "Epoch: 142 | Batch_idx: 340 |  Loss: (0.0172) | Acc: (99.42%) (43396/43648)\n",
            "Epoch: 142 | Batch_idx: 350 |  Loss: (0.0175) | Acc: (99.41%) (44665/44928)\n",
            "Epoch: 142 | Batch_idx: 360 |  Loss: (0.0174) | Acc: (99.42%) (45940/46208)\n",
            "Epoch: 142 | Batch_idx: 370 |  Loss: (0.0174) | Acc: (99.42%) (47212/47488)\n",
            "Epoch: 142 | Batch_idx: 380 |  Loss: (0.0177) | Acc: (99.41%) (48478/48768)\n",
            "Epoch: 142 | Batch_idx: 390 |  Loss: (0.0175) | Acc: (99.41%) (49705/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3666) | Acc: (91.83%) (9183/10000)\n",
            "Epoch: 143 | Batch_idx: 0 |  Loss: (0.0127) | Acc: (99.22%) (127/128)\n",
            "Epoch: 143 | Batch_idx: 10 |  Loss: (0.0134) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 143 | Batch_idx: 20 |  Loss: (0.0178) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 143 | Batch_idx: 30 |  Loss: (0.0189) | Acc: (99.29%) (3940/3968)\n",
            "Epoch: 143 | Batch_idx: 40 |  Loss: (0.0200) | Acc: (99.29%) (5211/5248)\n",
            "Epoch: 143 | Batch_idx: 50 |  Loss: (0.0198) | Acc: (99.34%) (6485/6528)\n",
            "Epoch: 143 | Batch_idx: 60 |  Loss: (0.0198) | Acc: (99.36%) (7758/7808)\n",
            "Epoch: 143 | Batch_idx: 70 |  Loss: (0.0198) | Acc: (99.35%) (9029/9088)\n",
            "Epoch: 143 | Batch_idx: 80 |  Loss: (0.0195) | Acc: (99.35%) (10301/10368)\n",
            "Epoch: 143 | Batch_idx: 90 |  Loss: (0.0199) | Acc: (99.30%) (11567/11648)\n",
            "Epoch: 143 | Batch_idx: 100 |  Loss: (0.0203) | Acc: (99.31%) (12839/12928)\n",
            "Epoch: 143 | Batch_idx: 110 |  Loss: (0.0200) | Acc: (99.32%) (14111/14208)\n",
            "Epoch: 143 | Batch_idx: 120 |  Loss: (0.0193) | Acc: (99.34%) (15386/15488)\n",
            "Epoch: 143 | Batch_idx: 130 |  Loss: (0.0187) | Acc: (99.34%) (16658/16768)\n",
            "Epoch: 143 | Batch_idx: 140 |  Loss: (0.0189) | Acc: (99.34%) (17928/18048)\n",
            "Epoch: 143 | Batch_idx: 150 |  Loss: (0.0195) | Acc: (99.34%) (19200/19328)\n",
            "Epoch: 143 | Batch_idx: 160 |  Loss: (0.0203) | Acc: (99.33%) (20469/20608)\n",
            "Epoch: 143 | Batch_idx: 170 |  Loss: (0.0201) | Acc: (99.33%) (21741/21888)\n",
            "Epoch: 143 | Batch_idx: 180 |  Loss: (0.0203) | Acc: (99.32%) (23011/23168)\n",
            "Epoch: 143 | Batch_idx: 190 |  Loss: (0.0199) | Acc: (99.33%) (24285/24448)\n",
            "Epoch: 143 | Batch_idx: 200 |  Loss: (0.0195) | Acc: (99.35%) (25560/25728)\n",
            "Epoch: 143 | Batch_idx: 210 |  Loss: (0.0195) | Acc: (99.35%) (26832/27008)\n",
            "Epoch: 143 | Batch_idx: 220 |  Loss: (0.0196) | Acc: (99.36%) (28106/28288)\n",
            "Epoch: 143 | Batch_idx: 230 |  Loss: (0.0195) | Acc: (99.36%) (29378/29568)\n",
            "Epoch: 143 | Batch_idx: 240 |  Loss: (0.0190) | Acc: (99.38%) (30658/30848)\n",
            "Epoch: 143 | Batch_idx: 250 |  Loss: (0.0192) | Acc: (99.37%) (31926/32128)\n",
            "Epoch: 143 | Batch_idx: 260 |  Loss: (0.0189) | Acc: (99.38%) (33200/33408)\n",
            "Epoch: 143 | Batch_idx: 270 |  Loss: (0.0188) | Acc: (99.37%) (34470/34688)\n",
            "Epoch: 143 | Batch_idx: 280 |  Loss: (0.0188) | Acc: (99.37%) (35743/35968)\n",
            "Epoch: 143 | Batch_idx: 290 |  Loss: (0.0186) | Acc: (99.38%) (37018/37248)\n",
            "Epoch: 143 | Batch_idx: 300 |  Loss: (0.0185) | Acc: (99.38%) (38290/38528)\n",
            "Epoch: 143 | Batch_idx: 310 |  Loss: (0.0186) | Acc: (99.38%) (39562/39808)\n",
            "Epoch: 143 | Batch_idx: 320 |  Loss: (0.0185) | Acc: (99.38%) (40834/41088)\n",
            "Epoch: 143 | Batch_idx: 330 |  Loss: (0.0186) | Acc: (99.37%) (42103/42368)\n",
            "Epoch: 143 | Batch_idx: 340 |  Loss: (0.0184) | Acc: (99.38%) (43379/43648)\n",
            "Epoch: 143 | Batch_idx: 350 |  Loss: (0.0182) | Acc: (99.39%) (44654/44928)\n",
            "Epoch: 143 | Batch_idx: 360 |  Loss: (0.0182) | Acc: (99.39%) (45925/46208)\n",
            "Epoch: 143 | Batch_idx: 370 |  Loss: (0.0181) | Acc: (99.39%) (47200/47488)\n",
            "Epoch: 143 | Batch_idx: 380 |  Loss: (0.0181) | Acc: (99.40%) (48474/48768)\n",
            "Epoch: 143 | Batch_idx: 390 |  Loss: (0.0179) | Acc: (99.40%) (49701/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3693) | Acc: (91.80%) (9180/10000)\n",
            "Epoch: 144 | Batch_idx: 0 |  Loss: (0.0089) | Acc: (100.00%) (128/128)\n",
            "Epoch: 144 | Batch_idx: 10 |  Loss: (0.0216) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 144 | Batch_idx: 20 |  Loss: (0.0214) | Acc: (99.33%) (2670/2688)\n",
            "Epoch: 144 | Batch_idx: 30 |  Loss: (0.0186) | Acc: (99.42%) (3945/3968)\n",
            "Epoch: 144 | Batch_idx: 40 |  Loss: (0.0168) | Acc: (99.47%) (5220/5248)\n",
            "Epoch: 144 | Batch_idx: 50 |  Loss: (0.0173) | Acc: (99.42%) (6490/6528)\n",
            "Epoch: 144 | Batch_idx: 60 |  Loss: (0.0168) | Acc: (99.39%) (7760/7808)\n",
            "Epoch: 144 | Batch_idx: 70 |  Loss: (0.0184) | Acc: (99.34%) (9028/9088)\n",
            "Epoch: 144 | Batch_idx: 80 |  Loss: (0.0188) | Acc: (99.37%) (10303/10368)\n",
            "Epoch: 144 | Batch_idx: 90 |  Loss: (0.0198) | Acc: (99.33%) (11570/11648)\n",
            "Epoch: 144 | Batch_idx: 100 |  Loss: (0.0199) | Acc: (99.32%) (12840/12928)\n",
            "Epoch: 144 | Batch_idx: 110 |  Loss: (0.0191) | Acc: (99.35%) (14115/14208)\n",
            "Epoch: 144 | Batch_idx: 120 |  Loss: (0.0187) | Acc: (99.35%) (15388/15488)\n",
            "Epoch: 144 | Batch_idx: 130 |  Loss: (0.0188) | Acc: (99.35%) (16659/16768)\n",
            "Epoch: 144 | Batch_idx: 140 |  Loss: (0.0184) | Acc: (99.37%) (17935/18048)\n",
            "Epoch: 144 | Batch_idx: 150 |  Loss: (0.0185) | Acc: (99.35%) (19203/19328)\n",
            "Epoch: 144 | Batch_idx: 160 |  Loss: (0.0188) | Acc: (99.33%) (20470/20608)\n",
            "Epoch: 144 | Batch_idx: 170 |  Loss: (0.0193) | Acc: (99.31%) (21738/21888)\n",
            "Epoch: 144 | Batch_idx: 180 |  Loss: (0.0191) | Acc: (99.34%) (23014/23168)\n",
            "Epoch: 144 | Batch_idx: 190 |  Loss: (0.0188) | Acc: (99.35%) (24288/24448)\n",
            "Epoch: 144 | Batch_idx: 200 |  Loss: (0.0189) | Acc: (99.35%) (25560/25728)\n",
            "Epoch: 144 | Batch_idx: 210 |  Loss: (0.0188) | Acc: (99.34%) (26831/27008)\n",
            "Epoch: 144 | Batch_idx: 220 |  Loss: (0.0189) | Acc: (99.35%) (28103/28288)\n",
            "Epoch: 144 | Batch_idx: 230 |  Loss: (0.0187) | Acc: (99.36%) (29378/29568)\n",
            "Epoch: 144 | Batch_idx: 240 |  Loss: (0.0190) | Acc: (99.35%) (30648/30848)\n",
            "Epoch: 144 | Batch_idx: 250 |  Loss: (0.0193) | Acc: (99.33%) (31914/32128)\n",
            "Epoch: 144 | Batch_idx: 260 |  Loss: (0.0191) | Acc: (99.34%) (33186/33408)\n",
            "Epoch: 144 | Batch_idx: 270 |  Loss: (0.0193) | Acc: (99.33%) (34457/34688)\n",
            "Epoch: 144 | Batch_idx: 280 |  Loss: (0.0192) | Acc: (99.33%) (35728/35968)\n",
            "Epoch: 144 | Batch_idx: 290 |  Loss: (0.0189) | Acc: (99.34%) (37002/37248)\n",
            "Epoch: 144 | Batch_idx: 300 |  Loss: (0.0190) | Acc: (99.34%) (38275/38528)\n",
            "Epoch: 144 | Batch_idx: 310 |  Loss: (0.0189) | Acc: (99.35%) (39551/39808)\n",
            "Epoch: 144 | Batch_idx: 320 |  Loss: (0.0188) | Acc: (99.36%) (40825/41088)\n",
            "Epoch: 144 | Batch_idx: 330 |  Loss: (0.0185) | Acc: (99.37%) (42101/42368)\n",
            "Epoch: 144 | Batch_idx: 340 |  Loss: (0.0186) | Acc: (99.37%) (43371/43648)\n",
            "Epoch: 144 | Batch_idx: 350 |  Loss: (0.0185) | Acc: (99.37%) (44645/44928)\n",
            "Epoch: 144 | Batch_idx: 360 |  Loss: (0.0186) | Acc: (99.37%) (45915/46208)\n",
            "Epoch: 144 | Batch_idx: 370 |  Loss: (0.0185) | Acc: (99.37%) (47188/47488)\n",
            "Epoch: 144 | Batch_idx: 380 |  Loss: (0.0185) | Acc: (99.36%) (48458/48768)\n",
            "Epoch: 144 | Batch_idx: 390 |  Loss: (0.0186) | Acc: (99.36%) (49680/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3688) | Acc: (91.90%) (9190/10000)\n",
            "Epoch: 145 | Batch_idx: 0 |  Loss: (0.0109) | Acc: (99.22%) (127/128)\n",
            "Epoch: 145 | Batch_idx: 10 |  Loss: (0.0185) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 145 | Batch_idx: 20 |  Loss: (0.0207) | Acc: (99.29%) (2669/2688)\n",
            "Epoch: 145 | Batch_idx: 30 |  Loss: (0.0224) | Acc: (99.19%) (3936/3968)\n",
            "Epoch: 145 | Batch_idx: 40 |  Loss: (0.0208) | Acc: (99.24%) (5208/5248)\n",
            "Epoch: 145 | Batch_idx: 50 |  Loss: (0.0208) | Acc: (99.22%) (6477/6528)\n",
            "Epoch: 145 | Batch_idx: 60 |  Loss: (0.0198) | Acc: (99.27%) (7751/7808)\n",
            "Epoch: 145 | Batch_idx: 70 |  Loss: (0.0189) | Acc: (99.31%) (9025/9088)\n",
            "Epoch: 145 | Batch_idx: 80 |  Loss: (0.0191) | Acc: (99.31%) (10296/10368)\n",
            "Epoch: 145 | Batch_idx: 90 |  Loss: (0.0191) | Acc: (99.29%) (11565/11648)\n",
            "Epoch: 145 | Batch_idx: 100 |  Loss: (0.0192) | Acc: (99.30%) (12837/12928)\n",
            "Epoch: 145 | Batch_idx: 110 |  Loss: (0.0190) | Acc: (99.32%) (14111/14208)\n",
            "Epoch: 145 | Batch_idx: 120 |  Loss: (0.0185) | Acc: (99.33%) (15385/15488)\n",
            "Epoch: 145 | Batch_idx: 130 |  Loss: (0.0187) | Acc: (99.33%) (16656/16768)\n",
            "Epoch: 145 | Batch_idx: 140 |  Loss: (0.0193) | Acc: (99.30%) (17922/18048)\n",
            "Epoch: 145 | Batch_idx: 150 |  Loss: (0.0194) | Acc: (99.31%) (19194/19328)\n",
            "Epoch: 145 | Batch_idx: 160 |  Loss: (0.0194) | Acc: (99.30%) (20464/20608)\n",
            "Epoch: 145 | Batch_idx: 170 |  Loss: (0.0191) | Acc: (99.32%) (21739/21888)\n",
            "Epoch: 145 | Batch_idx: 180 |  Loss: (0.0190) | Acc: (99.33%) (23012/23168)\n",
            "Epoch: 145 | Batch_idx: 190 |  Loss: (0.0189) | Acc: (99.33%) (24285/24448)\n",
            "Epoch: 145 | Batch_idx: 200 |  Loss: (0.0187) | Acc: (99.35%) (25560/25728)\n",
            "Epoch: 145 | Batch_idx: 210 |  Loss: (0.0187) | Acc: (99.34%) (26830/27008)\n",
            "Epoch: 145 | Batch_idx: 220 |  Loss: (0.0184) | Acc: (99.36%) (28106/28288)\n",
            "Epoch: 145 | Batch_idx: 230 |  Loss: (0.0179) | Acc: (99.37%) (29383/29568)\n",
            "Epoch: 145 | Batch_idx: 240 |  Loss: (0.0178) | Acc: (99.38%) (30656/30848)\n",
            "Epoch: 145 | Batch_idx: 250 |  Loss: (0.0182) | Acc: (99.37%) (31924/32128)\n",
            "Epoch: 145 | Batch_idx: 260 |  Loss: (0.0182) | Acc: (99.36%) (33195/33408)\n",
            "Epoch: 145 | Batch_idx: 270 |  Loss: (0.0181) | Acc: (99.37%) (34469/34688)\n",
            "Epoch: 145 | Batch_idx: 280 |  Loss: (0.0183) | Acc: (99.37%) (35741/35968)\n",
            "Epoch: 145 | Batch_idx: 290 |  Loss: (0.0182) | Acc: (99.37%) (37015/37248)\n",
            "Epoch: 145 | Batch_idx: 300 |  Loss: (0.0183) | Acc: (99.36%) (38282/38528)\n",
            "Epoch: 145 | Batch_idx: 310 |  Loss: (0.0184) | Acc: (99.35%) (39551/39808)\n",
            "Epoch: 145 | Batch_idx: 320 |  Loss: (0.0183) | Acc: (99.36%) (40823/41088)\n",
            "Epoch: 145 | Batch_idx: 330 |  Loss: (0.0182) | Acc: (99.36%) (42096/42368)\n",
            "Epoch: 145 | Batch_idx: 340 |  Loss: (0.0182) | Acc: (99.36%) (43370/43648)\n",
            "Epoch: 145 | Batch_idx: 350 |  Loss: (0.0180) | Acc: (99.37%) (44643/44928)\n",
            "Epoch: 145 | Batch_idx: 360 |  Loss: (0.0182) | Acc: (99.37%) (45915/46208)\n",
            "Epoch: 145 | Batch_idx: 370 |  Loss: (0.0181) | Acc: (99.37%) (47189/47488)\n",
            "Epoch: 145 | Batch_idx: 380 |  Loss: (0.0179) | Acc: (99.37%) (48463/48768)\n",
            "Epoch: 145 | Batch_idx: 390 |  Loss: (0.0180) | Acc: (99.37%) (49686/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3674) | Acc: (91.87%) (9187/10000)\n",
            "Epoch: 146 | Batch_idx: 0 |  Loss: (0.0236) | Acc: (99.22%) (127/128)\n",
            "Epoch: 146 | Batch_idx: 10 |  Loss: (0.0127) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 146 | Batch_idx: 20 |  Loss: (0.0200) | Acc: (99.03%) (2662/2688)\n",
            "Epoch: 146 | Batch_idx: 30 |  Loss: (0.0189) | Acc: (99.14%) (3934/3968)\n",
            "Epoch: 146 | Batch_idx: 40 |  Loss: (0.0188) | Acc: (99.20%) (5206/5248)\n",
            "Epoch: 146 | Batch_idx: 50 |  Loss: (0.0189) | Acc: (99.23%) (6478/6528)\n",
            "Epoch: 146 | Batch_idx: 60 |  Loss: (0.0189) | Acc: (99.24%) (7749/7808)\n",
            "Epoch: 146 | Batch_idx: 70 |  Loss: (0.0185) | Acc: (99.27%) (9022/9088)\n",
            "Epoch: 146 | Batch_idx: 80 |  Loss: (0.0184) | Acc: (99.32%) (10297/10368)\n",
            "Epoch: 146 | Batch_idx: 90 |  Loss: (0.0175) | Acc: (99.36%) (11573/11648)\n",
            "Epoch: 146 | Batch_idx: 100 |  Loss: (0.0180) | Acc: (99.37%) (12846/12928)\n",
            "Epoch: 146 | Batch_idx: 110 |  Loss: (0.0175) | Acc: (99.38%) (14120/14208)\n",
            "Epoch: 146 | Batch_idx: 120 |  Loss: (0.0174) | Acc: (99.37%) (15390/15488)\n",
            "Epoch: 146 | Batch_idx: 130 |  Loss: (0.0177) | Acc: (99.37%) (16662/16768)\n",
            "Epoch: 146 | Batch_idx: 140 |  Loss: (0.0177) | Acc: (99.37%) (17934/18048)\n",
            "Epoch: 146 | Batch_idx: 150 |  Loss: (0.0182) | Acc: (99.36%) (19205/19328)\n",
            "Epoch: 146 | Batch_idx: 160 |  Loss: (0.0190) | Acc: (99.34%) (20471/20608)\n",
            "Epoch: 146 | Batch_idx: 170 |  Loss: (0.0198) | Acc: (99.31%) (21736/21888)\n",
            "Epoch: 146 | Batch_idx: 180 |  Loss: (0.0195) | Acc: (99.32%) (23011/23168)\n",
            "Epoch: 146 | Batch_idx: 190 |  Loss: (0.0190) | Acc: (99.34%) (24286/24448)\n",
            "Epoch: 146 | Batch_idx: 200 |  Loss: (0.0189) | Acc: (99.34%) (25559/25728)\n",
            "Epoch: 146 | Batch_idx: 210 |  Loss: (0.0189) | Acc: (99.34%) (26830/27008)\n",
            "Epoch: 146 | Batch_idx: 220 |  Loss: (0.0190) | Acc: (99.34%) (28101/28288)\n",
            "Epoch: 146 | Batch_idx: 230 |  Loss: (0.0196) | Acc: (99.31%) (29365/29568)\n",
            "Epoch: 146 | Batch_idx: 240 |  Loss: (0.0194) | Acc: (99.32%) (30639/30848)\n",
            "Epoch: 146 | Batch_idx: 250 |  Loss: (0.0200) | Acc: (99.31%) (31907/32128)\n",
            "Epoch: 146 | Batch_idx: 260 |  Loss: (0.0201) | Acc: (99.30%) (33173/33408)\n",
            "Epoch: 146 | Batch_idx: 270 |  Loss: (0.0200) | Acc: (99.29%) (34442/34688)\n",
            "Epoch: 146 | Batch_idx: 280 |  Loss: (0.0196) | Acc: (99.31%) (35720/35968)\n",
            "Epoch: 146 | Batch_idx: 290 |  Loss: (0.0196) | Acc: (99.31%) (36990/37248)\n",
            "Epoch: 146 | Batch_idx: 300 |  Loss: (0.0193) | Acc: (99.32%) (38266/38528)\n",
            "Epoch: 146 | Batch_idx: 310 |  Loss: (0.0191) | Acc: (99.33%) (39542/39808)\n",
            "Epoch: 146 | Batch_idx: 320 |  Loss: (0.0193) | Acc: (99.33%) (40814/41088)\n",
            "Epoch: 146 | Batch_idx: 330 |  Loss: (0.0194) | Acc: (99.32%) (42081/42368)\n",
            "Epoch: 146 | Batch_idx: 340 |  Loss: (0.0192) | Acc: (99.32%) (43352/43648)\n",
            "Epoch: 146 | Batch_idx: 350 |  Loss: (0.0194) | Acc: (99.32%) (44622/44928)\n",
            "Epoch: 146 | Batch_idx: 360 |  Loss: (0.0194) | Acc: (99.32%) (45892/46208)\n",
            "Epoch: 146 | Batch_idx: 370 |  Loss: (0.0196) | Acc: (99.32%) (47164/47488)\n",
            "Epoch: 146 | Batch_idx: 380 |  Loss: (0.0196) | Acc: (99.32%) (48435/48768)\n",
            "Epoch: 146 | Batch_idx: 390 |  Loss: (0.0197) | Acc: (99.32%) (49659/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3655) | Acc: (91.82%) (9182/10000)\n",
            "Epoch: 147 | Batch_idx: 0 |  Loss: (0.0191) | Acc: (99.22%) (127/128)\n",
            "Epoch: 147 | Batch_idx: 10 |  Loss: (0.0128) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 147 | Batch_idx: 20 |  Loss: (0.0112) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 147 | Batch_idx: 30 |  Loss: (0.0132) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 147 | Batch_idx: 40 |  Loss: (0.0151) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 147 | Batch_idx: 50 |  Loss: (0.0159) | Acc: (99.43%) (6491/6528)\n",
            "Epoch: 147 | Batch_idx: 60 |  Loss: (0.0156) | Acc: (99.44%) (7764/7808)\n",
            "Epoch: 147 | Batch_idx: 70 |  Loss: (0.0165) | Acc: (99.37%) (9031/9088)\n",
            "Epoch: 147 | Batch_idx: 80 |  Loss: (0.0171) | Acc: (99.39%) (10305/10368)\n",
            "Epoch: 147 | Batch_idx: 90 |  Loss: (0.0165) | Acc: (99.42%) (11581/11648)\n",
            "Epoch: 147 | Batch_idx: 100 |  Loss: (0.0166) | Acc: (99.44%) (12856/12928)\n",
            "Epoch: 147 | Batch_idx: 110 |  Loss: (0.0171) | Acc: (99.43%) (14127/14208)\n",
            "Epoch: 147 | Batch_idx: 120 |  Loss: (0.0170) | Acc: (99.43%) (15400/15488)\n",
            "Epoch: 147 | Batch_idx: 130 |  Loss: (0.0163) | Acc: (99.46%) (16678/16768)\n",
            "Epoch: 147 | Batch_idx: 140 |  Loss: (0.0169) | Acc: (99.43%) (17946/18048)\n",
            "Epoch: 147 | Batch_idx: 150 |  Loss: (0.0174) | Acc: (99.42%) (19215/19328)\n",
            "Epoch: 147 | Batch_idx: 160 |  Loss: (0.0175) | Acc: (99.41%) (20487/20608)\n",
            "Epoch: 147 | Batch_idx: 170 |  Loss: (0.0173) | Acc: (99.41%) (21759/21888)\n",
            "Epoch: 147 | Batch_idx: 180 |  Loss: (0.0177) | Acc: (99.39%) (23027/23168)\n",
            "Epoch: 147 | Batch_idx: 190 |  Loss: (0.0175) | Acc: (99.39%) (24300/24448)\n",
            "Epoch: 147 | Batch_idx: 200 |  Loss: (0.0172) | Acc: (99.41%) (25576/25728)\n",
            "Epoch: 147 | Batch_idx: 210 |  Loss: (0.0169) | Acc: (99.43%) (26853/27008)\n",
            "Epoch: 147 | Batch_idx: 220 |  Loss: (0.0167) | Acc: (99.43%) (28127/28288)\n",
            "Epoch: 147 | Batch_idx: 230 |  Loss: (0.0166) | Acc: (99.44%) (29402/29568)\n",
            "Epoch: 147 | Batch_idx: 240 |  Loss: (0.0174) | Acc: (99.41%) (30667/30848)\n",
            "Epoch: 147 | Batch_idx: 250 |  Loss: (0.0173) | Acc: (99.41%) (31939/32128)\n",
            "Epoch: 147 | Batch_idx: 260 |  Loss: (0.0172) | Acc: (99.41%) (33211/33408)\n",
            "Epoch: 147 | Batch_idx: 270 |  Loss: (0.0170) | Acc: (99.42%) (34486/34688)\n",
            "Epoch: 147 | Batch_idx: 280 |  Loss: (0.0168) | Acc: (99.42%) (35760/35968)\n",
            "Epoch: 147 | Batch_idx: 290 |  Loss: (0.0165) | Acc: (99.43%) (37034/37248)\n",
            "Epoch: 147 | Batch_idx: 300 |  Loss: (0.0164) | Acc: (99.43%) (38309/38528)\n",
            "Epoch: 147 | Batch_idx: 310 |  Loss: (0.0166) | Acc: (99.43%) (39582/39808)\n",
            "Epoch: 147 | Batch_idx: 320 |  Loss: (0.0165) | Acc: (99.44%) (40856/41088)\n",
            "Epoch: 147 | Batch_idx: 330 |  Loss: (0.0168) | Acc: (99.43%) (42126/42368)\n",
            "Epoch: 147 | Batch_idx: 340 |  Loss: (0.0167) | Acc: (99.42%) (43397/43648)\n",
            "Epoch: 147 | Batch_idx: 350 |  Loss: (0.0167) | Acc: (99.43%) (44672/44928)\n",
            "Epoch: 147 | Batch_idx: 360 |  Loss: (0.0165) | Acc: (99.44%) (45949/46208)\n",
            "Epoch: 147 | Batch_idx: 370 |  Loss: (0.0165) | Acc: (99.44%) (47223/47488)\n",
            "Epoch: 147 | Batch_idx: 380 |  Loss: (0.0167) | Acc: (99.44%) (48496/48768)\n",
            "Epoch: 147 | Batch_idx: 390 |  Loss: (0.0165) | Acc: (99.44%) (49721/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3669) | Acc: (91.89%) (9189/10000)\n",
            "Epoch: 148 | Batch_idx: 0 |  Loss: (0.0024) | Acc: (100.00%) (128/128)\n",
            "Epoch: 148 | Batch_idx: 10 |  Loss: (0.0145) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 148 | Batch_idx: 20 |  Loss: (0.0174) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 148 | Batch_idx: 30 |  Loss: (0.0189) | Acc: (99.42%) (3945/3968)\n",
            "Epoch: 148 | Batch_idx: 40 |  Loss: (0.0179) | Acc: (99.41%) (5217/5248)\n",
            "Epoch: 148 | Batch_idx: 50 |  Loss: (0.0181) | Acc: (99.37%) (6487/6528)\n",
            "Epoch: 148 | Batch_idx: 60 |  Loss: (0.0188) | Acc: (99.36%) (7758/7808)\n",
            "Epoch: 148 | Batch_idx: 70 |  Loss: (0.0174) | Acc: (99.39%) (9033/9088)\n",
            "Epoch: 148 | Batch_idx: 80 |  Loss: (0.0180) | Acc: (99.38%) (10304/10368)\n",
            "Epoch: 148 | Batch_idx: 90 |  Loss: (0.0174) | Acc: (99.40%) (11578/11648)\n",
            "Epoch: 148 | Batch_idx: 100 |  Loss: (0.0172) | Acc: (99.41%) (12852/12928)\n",
            "Epoch: 148 | Batch_idx: 110 |  Loss: (0.0173) | Acc: (99.41%) (14124/14208)\n",
            "Epoch: 148 | Batch_idx: 120 |  Loss: (0.0182) | Acc: (99.38%) (15392/15488)\n",
            "Epoch: 148 | Batch_idx: 130 |  Loss: (0.0184) | Acc: (99.38%) (16664/16768)\n",
            "Epoch: 148 | Batch_idx: 140 |  Loss: (0.0183) | Acc: (99.38%) (17937/18048)\n",
            "Epoch: 148 | Batch_idx: 150 |  Loss: (0.0179) | Acc: (99.38%) (19208/19328)\n",
            "Epoch: 148 | Batch_idx: 160 |  Loss: (0.0182) | Acc: (99.38%) (20480/20608)\n",
            "Epoch: 148 | Batch_idx: 170 |  Loss: (0.0182) | Acc: (99.38%) (21753/21888)\n",
            "Epoch: 148 | Batch_idx: 180 |  Loss: (0.0182) | Acc: (99.38%) (23025/23168)\n",
            "Epoch: 148 | Batch_idx: 190 |  Loss: (0.0183) | Acc: (99.38%) (24296/24448)\n",
            "Epoch: 148 | Batch_idx: 200 |  Loss: (0.0181) | Acc: (99.39%) (25572/25728)\n",
            "Epoch: 148 | Batch_idx: 210 |  Loss: (0.0179) | Acc: (99.40%) (26847/27008)\n",
            "Epoch: 148 | Batch_idx: 220 |  Loss: (0.0179) | Acc: (99.41%) (28121/28288)\n",
            "Epoch: 148 | Batch_idx: 230 |  Loss: (0.0179) | Acc: (99.41%) (29393/29568)\n",
            "Epoch: 148 | Batch_idx: 240 |  Loss: (0.0178) | Acc: (99.41%) (30665/30848)\n",
            "Epoch: 148 | Batch_idx: 250 |  Loss: (0.0177) | Acc: (99.41%) (31939/32128)\n",
            "Epoch: 148 | Batch_idx: 260 |  Loss: (0.0180) | Acc: (99.39%) (33205/33408)\n",
            "Epoch: 148 | Batch_idx: 270 |  Loss: (0.0180) | Acc: (99.40%) (34479/34688)\n",
            "Epoch: 148 | Batch_idx: 280 |  Loss: (0.0181) | Acc: (99.40%) (35751/35968)\n",
            "Epoch: 148 | Batch_idx: 290 |  Loss: (0.0180) | Acc: (99.40%) (37024/37248)\n",
            "Epoch: 148 | Batch_idx: 300 |  Loss: (0.0183) | Acc: (99.38%) (38289/38528)\n",
            "Epoch: 148 | Batch_idx: 310 |  Loss: (0.0181) | Acc: (99.39%) (39564/39808)\n",
            "Epoch: 148 | Batch_idx: 320 |  Loss: (0.0186) | Acc: (99.37%) (40829/41088)\n",
            "Epoch: 148 | Batch_idx: 330 |  Loss: (0.0184) | Acc: (99.38%) (42105/42368)\n",
            "Epoch: 148 | Batch_idx: 340 |  Loss: (0.0184) | Acc: (99.38%) (43378/43648)\n",
            "Epoch: 148 | Batch_idx: 350 |  Loss: (0.0183) | Acc: (99.39%) (44652/44928)\n",
            "Epoch: 148 | Batch_idx: 360 |  Loss: (0.0183) | Acc: (99.39%) (45924/46208)\n",
            "Epoch: 148 | Batch_idx: 370 |  Loss: (0.0182) | Acc: (99.39%) (47197/47488)\n",
            "Epoch: 148 | Batch_idx: 380 |  Loss: (0.0183) | Acc: (99.39%) (48469/48768)\n",
            "Epoch: 148 | Batch_idx: 390 |  Loss: (0.0182) | Acc: (99.39%) (49695/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3681) | Acc: (91.81%) (9181/10000)\n",
            "Epoch: 149 | Batch_idx: 0 |  Loss: (0.0076) | Acc: (100.00%) (128/128)\n",
            "Epoch: 149 | Batch_idx: 10 |  Loss: (0.0145) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 149 | Batch_idx: 20 |  Loss: (0.0154) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 149 | Batch_idx: 30 |  Loss: (0.0211) | Acc: (99.32%) (3941/3968)\n",
            "Epoch: 149 | Batch_idx: 40 |  Loss: (0.0182) | Acc: (99.43%) (5218/5248)\n",
            "Epoch: 149 | Batch_idx: 50 |  Loss: (0.0181) | Acc: (99.39%) (6488/6528)\n",
            "Epoch: 149 | Batch_idx: 60 |  Loss: (0.0184) | Acc: (99.39%) (7760/7808)\n",
            "Epoch: 149 | Batch_idx: 70 |  Loss: (0.0175) | Acc: (99.39%) (9033/9088)\n",
            "Epoch: 149 | Batch_idx: 80 |  Loss: (0.0181) | Acc: (99.39%) (10305/10368)\n",
            "Epoch: 149 | Batch_idx: 90 |  Loss: (0.0189) | Acc: (99.37%) (11575/11648)\n",
            "Epoch: 149 | Batch_idx: 100 |  Loss: (0.0181) | Acc: (99.41%) (12852/12928)\n",
            "Epoch: 149 | Batch_idx: 110 |  Loss: (0.0183) | Acc: (99.41%) (14124/14208)\n",
            "Epoch: 149 | Batch_idx: 120 |  Loss: (0.0183) | Acc: (99.42%) (15398/15488)\n",
            "Epoch: 149 | Batch_idx: 130 |  Loss: (0.0183) | Acc: (99.42%) (16670/16768)\n",
            "Epoch: 149 | Batch_idx: 140 |  Loss: (0.0179) | Acc: (99.42%) (17944/18048)\n",
            "Epoch: 149 | Batch_idx: 150 |  Loss: (0.0174) | Acc: (99.44%) (19220/19328)\n",
            "Epoch: 149 | Batch_idx: 160 |  Loss: (0.0173) | Acc: (99.45%) (20495/20608)\n",
            "Epoch: 149 | Batch_idx: 170 |  Loss: (0.0172) | Acc: (99.47%) (21771/21888)\n",
            "Epoch: 149 | Batch_idx: 180 |  Loss: (0.0168) | Acc: (99.47%) (23045/23168)\n",
            "Epoch: 149 | Batch_idx: 190 |  Loss: (0.0165) | Acc: (99.48%) (24321/24448)\n",
            "Epoch: 149 | Batch_idx: 200 |  Loss: (0.0160) | Acc: (99.49%) (25598/25728)\n",
            "Epoch: 149 | Batch_idx: 210 |  Loss: (0.0159) | Acc: (99.49%) (26871/27008)\n",
            "Epoch: 149 | Batch_idx: 220 |  Loss: (0.0160) | Acc: (99.48%) (28140/28288)\n",
            "Epoch: 149 | Batch_idx: 230 |  Loss: (0.0163) | Acc: (99.48%) (29414/29568)\n",
            "Epoch: 149 | Batch_idx: 240 |  Loss: (0.0161) | Acc: (99.48%) (30688/30848)\n",
            "Epoch: 149 | Batch_idx: 250 |  Loss: (0.0161) | Acc: (99.48%) (31962/32128)\n",
            "Epoch: 149 | Batch_idx: 260 |  Loss: (0.0160) | Acc: (99.49%) (33237/33408)\n",
            "Epoch: 149 | Batch_idx: 270 |  Loss: (0.0157) | Acc: (99.50%) (34513/34688)\n",
            "Epoch: 149 | Batch_idx: 280 |  Loss: (0.0158) | Acc: (99.50%) (35787/35968)\n",
            "Epoch: 149 | Batch_idx: 290 |  Loss: (0.0161) | Acc: (99.50%) (37060/37248)\n",
            "Epoch: 149 | Batch_idx: 300 |  Loss: (0.0161) | Acc: (99.50%) (38334/38528)\n",
            "Epoch: 149 | Batch_idx: 310 |  Loss: (0.0159) | Acc: (99.50%) (39609/39808)\n",
            "Epoch: 149 | Batch_idx: 320 |  Loss: (0.0157) | Acc: (99.51%) (40886/41088)\n",
            "Epoch: 149 | Batch_idx: 330 |  Loss: (0.0156) | Acc: (99.51%) (42162/42368)\n",
            "Epoch: 149 | Batch_idx: 340 |  Loss: (0.0156) | Acc: (99.52%) (43438/43648)\n",
            "Epoch: 149 | Batch_idx: 350 |  Loss: (0.0155) | Acc: (99.52%) (44713/44928)\n",
            "Epoch: 149 | Batch_idx: 360 |  Loss: (0.0156) | Acc: (99.52%) (45987/46208)\n",
            "Epoch: 149 | Batch_idx: 370 |  Loss: (0.0157) | Acc: (99.52%) (47258/47488)\n",
            "Epoch: 149 | Batch_idx: 380 |  Loss: (0.0159) | Acc: (99.50%) (48524/48768)\n",
            "Epoch: 149 | Batch_idx: 390 |  Loss: (0.0158) | Acc: (99.51%) (49753/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3661) | Acc: (91.95%) (9195/10000)\n",
            "Epoch: 150 | Batch_idx: 0 |  Loss: (0.0378) | Acc: (98.44%) (126/128)\n",
            "Epoch: 150 | Batch_idx: 10 |  Loss: (0.0146) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 150 | Batch_idx: 20 |  Loss: (0.0165) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 150 | Batch_idx: 30 |  Loss: (0.0173) | Acc: (99.37%) (3943/3968)\n",
            "Epoch: 150 | Batch_idx: 40 |  Loss: (0.0174) | Acc: (99.39%) (5216/5248)\n",
            "Epoch: 150 | Batch_idx: 50 |  Loss: (0.0169) | Acc: (99.43%) (6491/6528)\n",
            "Epoch: 150 | Batch_idx: 60 |  Loss: (0.0167) | Acc: (99.46%) (7766/7808)\n",
            "Epoch: 150 | Batch_idx: 70 |  Loss: (0.0176) | Acc: (99.47%) (9040/9088)\n",
            "Epoch: 150 | Batch_idx: 80 |  Loss: (0.0178) | Acc: (99.46%) (10312/10368)\n",
            "Epoch: 150 | Batch_idx: 90 |  Loss: (0.0184) | Acc: (99.42%) (11581/11648)\n",
            "Epoch: 150 | Batch_idx: 100 |  Loss: (0.0181) | Acc: (99.44%) (12855/12928)\n",
            "Epoch: 150 | Batch_idx: 110 |  Loss: (0.0181) | Acc: (99.43%) (14127/14208)\n",
            "Epoch: 150 | Batch_idx: 120 |  Loss: (0.0182) | Acc: (99.44%) (15401/15488)\n",
            "Epoch: 150 | Batch_idx: 130 |  Loss: (0.0188) | Acc: (99.42%) (16670/16768)\n",
            "Epoch: 150 | Batch_idx: 140 |  Loss: (0.0191) | Acc: (99.42%) (17943/18048)\n",
            "Epoch: 150 | Batch_idx: 150 |  Loss: (0.0197) | Acc: (99.39%) (19210/19328)\n",
            "Epoch: 150 | Batch_idx: 160 |  Loss: (0.0196) | Acc: (99.39%) (20482/20608)\n",
            "Epoch: 150 | Batch_idx: 170 |  Loss: (0.0192) | Acc: (99.40%) (21757/21888)\n",
            "Epoch: 150 | Batch_idx: 180 |  Loss: (0.0189) | Acc: (99.41%) (23031/23168)\n",
            "Epoch: 150 | Batch_idx: 190 |  Loss: (0.0190) | Acc: (99.41%) (24304/24448)\n",
            "Epoch: 150 | Batch_idx: 200 |  Loss: (0.0191) | Acc: (99.39%) (25571/25728)\n",
            "Epoch: 150 | Batch_idx: 210 |  Loss: (0.0193) | Acc: (99.39%) (26843/27008)\n",
            "Epoch: 150 | Batch_idx: 220 |  Loss: (0.0191) | Acc: (99.38%) (28113/28288)\n",
            "Epoch: 150 | Batch_idx: 230 |  Loss: (0.0187) | Acc: (99.39%) (29388/29568)\n",
            "Epoch: 150 | Batch_idx: 240 |  Loss: (0.0187) | Acc: (99.39%) (30661/30848)\n",
            "Epoch: 150 | Batch_idx: 250 |  Loss: (0.0184) | Acc: (99.40%) (31935/32128)\n",
            "Epoch: 150 | Batch_idx: 260 |  Loss: (0.0186) | Acc: (99.38%) (33202/33408)\n",
            "Epoch: 150 | Batch_idx: 270 |  Loss: (0.0184) | Acc: (99.39%) (34477/34688)\n",
            "Epoch: 150 | Batch_idx: 280 |  Loss: (0.0182) | Acc: (99.40%) (35752/35968)\n",
            "Epoch: 150 | Batch_idx: 290 |  Loss: (0.0182) | Acc: (99.40%) (37025/37248)\n",
            "Epoch: 150 | Batch_idx: 300 |  Loss: (0.0182) | Acc: (99.40%) (38298/38528)\n",
            "Epoch: 150 | Batch_idx: 310 |  Loss: (0.0182) | Acc: (99.40%) (39568/39808)\n",
            "Epoch: 150 | Batch_idx: 320 |  Loss: (0.0183) | Acc: (99.39%) (40836/41088)\n",
            "Epoch: 150 | Batch_idx: 330 |  Loss: (0.0184) | Acc: (99.38%) (42107/42368)\n",
            "Epoch: 150 | Batch_idx: 340 |  Loss: (0.0187) | Acc: (99.38%) (43378/43648)\n",
            "Epoch: 150 | Batch_idx: 350 |  Loss: (0.0185) | Acc: (99.39%) (44652/44928)\n",
            "Epoch: 150 | Batch_idx: 360 |  Loss: (0.0185) | Acc: (99.38%) (45922/46208)\n",
            "Epoch: 150 | Batch_idx: 370 |  Loss: (0.0184) | Acc: (99.39%) (47196/47488)\n",
            "Epoch: 150 | Batch_idx: 380 |  Loss: (0.0182) | Acc: (99.39%) (48472/48768)\n",
            "Epoch: 150 | Batch_idx: 390 |  Loss: (0.0182) | Acc: (99.39%) (49695/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3630) | Acc: (92.01%) (9201/10000)\n",
            "Epoch: 151 | Batch_idx: 0 |  Loss: (0.0402) | Acc: (98.44%) (126/128)\n",
            "Epoch: 151 | Batch_idx: 10 |  Loss: (0.0128) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 151 | Batch_idx: 20 |  Loss: (0.0111) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 151 | Batch_idx: 30 |  Loss: (0.0121) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 151 | Batch_idx: 40 |  Loss: (0.0124) | Acc: (99.54%) (5224/5248)\n",
            "Epoch: 151 | Batch_idx: 50 |  Loss: (0.0129) | Acc: (99.57%) (6500/6528)\n",
            "Epoch: 151 | Batch_idx: 60 |  Loss: (0.0150) | Acc: (99.51%) (7770/7808)\n",
            "Epoch: 151 | Batch_idx: 70 |  Loss: (0.0170) | Acc: (99.46%) (9039/9088)\n",
            "Epoch: 151 | Batch_idx: 80 |  Loss: (0.0169) | Acc: (99.47%) (10313/10368)\n",
            "Epoch: 151 | Batch_idx: 90 |  Loss: (0.0165) | Acc: (99.47%) (11586/11648)\n",
            "Epoch: 151 | Batch_idx: 100 |  Loss: (0.0164) | Acc: (99.45%) (12857/12928)\n",
            "Epoch: 151 | Batch_idx: 110 |  Loss: (0.0166) | Acc: (99.43%) (14127/14208)\n",
            "Epoch: 151 | Batch_idx: 120 |  Loss: (0.0164) | Acc: (99.42%) (15398/15488)\n",
            "Epoch: 151 | Batch_idx: 130 |  Loss: (0.0158) | Acc: (99.43%) (16673/16768)\n",
            "Epoch: 151 | Batch_idx: 140 |  Loss: (0.0158) | Acc: (99.44%) (17947/18048)\n",
            "Epoch: 151 | Batch_idx: 150 |  Loss: (0.0157) | Acc: (99.45%) (19221/19328)\n",
            "Epoch: 151 | Batch_idx: 160 |  Loss: (0.0169) | Acc: (99.40%) (20485/20608)\n",
            "Epoch: 151 | Batch_idx: 170 |  Loss: (0.0168) | Acc: (99.42%) (21760/21888)\n",
            "Epoch: 151 | Batch_idx: 180 |  Loss: (0.0164) | Acc: (99.43%) (23035/23168)\n",
            "Epoch: 151 | Batch_idx: 190 |  Loss: (0.0172) | Acc: (99.40%) (24301/24448)\n",
            "Epoch: 151 | Batch_idx: 200 |  Loss: (0.0171) | Acc: (99.41%) (25577/25728)\n",
            "Epoch: 151 | Batch_idx: 210 |  Loss: (0.0170) | Acc: (99.41%) (26849/27008)\n",
            "Epoch: 151 | Batch_idx: 220 |  Loss: (0.0171) | Acc: (99.40%) (28118/28288)\n",
            "Epoch: 151 | Batch_idx: 230 |  Loss: (0.0171) | Acc: (99.39%) (29389/29568)\n",
            "Epoch: 151 | Batch_idx: 240 |  Loss: (0.0170) | Acc: (99.41%) (30665/30848)\n",
            "Epoch: 151 | Batch_idx: 250 |  Loss: (0.0170) | Acc: (99.41%) (31939/32128)\n",
            "Epoch: 151 | Batch_idx: 260 |  Loss: (0.0168) | Acc: (99.43%) (33217/33408)\n",
            "Epoch: 151 | Batch_idx: 270 |  Loss: (0.0170) | Acc: (99.41%) (34482/34688)\n",
            "Epoch: 151 | Batch_idx: 280 |  Loss: (0.0170) | Acc: (99.41%) (35754/35968)\n",
            "Epoch: 151 | Batch_idx: 290 |  Loss: (0.0172) | Acc: (99.41%) (37029/37248)\n",
            "Epoch: 151 | Batch_idx: 300 |  Loss: (0.0173) | Acc: (99.41%) (38299/38528)\n",
            "Epoch: 151 | Batch_idx: 310 |  Loss: (0.0175) | Acc: (99.40%) (39568/39808)\n",
            "Epoch: 151 | Batch_idx: 320 |  Loss: (0.0176) | Acc: (99.39%) (40839/41088)\n",
            "Epoch: 151 | Batch_idx: 330 |  Loss: (0.0174) | Acc: (99.40%) (42113/42368)\n",
            "Epoch: 151 | Batch_idx: 340 |  Loss: (0.0176) | Acc: (99.40%) (43385/43648)\n",
            "Epoch: 151 | Batch_idx: 350 |  Loss: (0.0177) | Acc: (99.40%) (44659/44928)\n",
            "Epoch: 151 | Batch_idx: 360 |  Loss: (0.0178) | Acc: (99.40%) (45930/46208)\n",
            "Epoch: 151 | Batch_idx: 370 |  Loss: (0.0179) | Acc: (99.40%) (47203/47488)\n",
            "Epoch: 151 | Batch_idx: 380 |  Loss: (0.0179) | Acc: (99.40%) (48474/48768)\n",
            "Epoch: 151 | Batch_idx: 390 |  Loss: (0.0179) | Acc: (99.40%) (49699/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3633) | Acc: (92.04%) (9204/10000)\n",
            "Epoch: 152 | Batch_idx: 0 |  Loss: (0.0134) | Acc: (99.22%) (127/128)\n",
            "Epoch: 152 | Batch_idx: 10 |  Loss: (0.0152) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 152 | Batch_idx: 20 |  Loss: (0.0131) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 152 | Batch_idx: 30 |  Loss: (0.0140) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 152 | Batch_idx: 40 |  Loss: (0.0138) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 152 | Batch_idx: 50 |  Loss: (0.0138) | Acc: (99.53%) (6497/6528)\n",
            "Epoch: 152 | Batch_idx: 60 |  Loss: (0.0140) | Acc: (99.50%) (7769/7808)\n",
            "Epoch: 152 | Batch_idx: 70 |  Loss: (0.0142) | Acc: (99.48%) (9041/9088)\n",
            "Epoch: 152 | Batch_idx: 80 |  Loss: (0.0147) | Acc: (99.47%) (10313/10368)\n",
            "Epoch: 152 | Batch_idx: 90 |  Loss: (0.0153) | Acc: (99.43%) (11582/11648)\n",
            "Epoch: 152 | Batch_idx: 100 |  Loss: (0.0155) | Acc: (99.42%) (12853/12928)\n",
            "Epoch: 152 | Batch_idx: 110 |  Loss: (0.0159) | Acc: (99.39%) (14122/14208)\n",
            "Epoch: 152 | Batch_idx: 120 |  Loss: (0.0157) | Acc: (99.41%) (15396/15488)\n",
            "Epoch: 152 | Batch_idx: 130 |  Loss: (0.0152) | Acc: (99.43%) (16672/16768)\n",
            "Epoch: 152 | Batch_idx: 140 |  Loss: (0.0157) | Acc: (99.39%) (17938/18048)\n",
            "Epoch: 152 | Batch_idx: 150 |  Loss: (0.0157) | Acc: (99.40%) (19212/19328)\n",
            "Epoch: 152 | Batch_idx: 160 |  Loss: (0.0156) | Acc: (99.41%) (20486/20608)\n",
            "Epoch: 152 | Batch_idx: 170 |  Loss: (0.0154) | Acc: (99.42%) (21760/21888)\n",
            "Epoch: 152 | Batch_idx: 180 |  Loss: (0.0158) | Acc: (99.41%) (23031/23168)\n",
            "Epoch: 152 | Batch_idx: 190 |  Loss: (0.0156) | Acc: (99.42%) (24307/24448)\n",
            "Epoch: 152 | Batch_idx: 200 |  Loss: (0.0155) | Acc: (99.43%) (25581/25728)\n",
            "Epoch: 152 | Batch_idx: 210 |  Loss: (0.0158) | Acc: (99.41%) (26849/27008)\n",
            "Epoch: 152 | Batch_idx: 220 |  Loss: (0.0155) | Acc: (99.43%) (28127/28288)\n",
            "Epoch: 152 | Batch_idx: 230 |  Loss: (0.0155) | Acc: (99.44%) (29402/29568)\n",
            "Epoch: 152 | Batch_idx: 240 |  Loss: (0.0156) | Acc: (99.44%) (30676/30848)\n",
            "Epoch: 152 | Batch_idx: 250 |  Loss: (0.0156) | Acc: (99.44%) (31949/32128)\n",
            "Epoch: 152 | Batch_idx: 260 |  Loss: (0.0155) | Acc: (99.44%) (33222/33408)\n",
            "Epoch: 152 | Batch_idx: 270 |  Loss: (0.0154) | Acc: (99.45%) (34497/34688)\n",
            "Epoch: 152 | Batch_idx: 280 |  Loss: (0.0153) | Acc: (99.45%) (35771/35968)\n",
            "Epoch: 152 | Batch_idx: 290 |  Loss: (0.0156) | Acc: (99.44%) (37040/37248)\n",
            "Epoch: 152 | Batch_idx: 300 |  Loss: (0.0159) | Acc: (99.44%) (38311/38528)\n",
            "Epoch: 152 | Batch_idx: 310 |  Loss: (0.0158) | Acc: (99.43%) (39583/39808)\n",
            "Epoch: 152 | Batch_idx: 320 |  Loss: (0.0158) | Acc: (99.43%) (40855/41088)\n",
            "Epoch: 152 | Batch_idx: 330 |  Loss: (0.0156) | Acc: (99.44%) (42130/42368)\n",
            "Epoch: 152 | Batch_idx: 340 |  Loss: (0.0157) | Acc: (99.43%) (43399/43648)\n",
            "Epoch: 152 | Batch_idx: 350 |  Loss: (0.0160) | Acc: (99.42%) (44669/44928)\n",
            "Epoch: 152 | Batch_idx: 360 |  Loss: (0.0161) | Acc: (99.43%) (45944/46208)\n",
            "Epoch: 152 | Batch_idx: 370 |  Loss: (0.0161) | Acc: (99.43%) (47215/47488)\n",
            "Epoch: 152 | Batch_idx: 380 |  Loss: (0.0160) | Acc: (99.43%) (48490/48768)\n",
            "Epoch: 152 | Batch_idx: 390 |  Loss: (0.0161) | Acc: (99.43%) (49714/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3667) | Acc: (92.01%) (9201/10000)\n",
            "Epoch: 153 | Batch_idx: 0 |  Loss: (0.0015) | Acc: (100.00%) (128/128)\n",
            "Epoch: 153 | Batch_idx: 10 |  Loss: (0.0147) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 153 | Batch_idx: 20 |  Loss: (0.0172) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 153 | Batch_idx: 30 |  Loss: (0.0164) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 153 | Batch_idx: 40 |  Loss: (0.0166) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 153 | Batch_idx: 50 |  Loss: (0.0182) | Acc: (99.39%) (6488/6528)\n",
            "Epoch: 153 | Batch_idx: 60 |  Loss: (0.0183) | Acc: (99.39%) (7760/7808)\n",
            "Epoch: 153 | Batch_idx: 70 |  Loss: (0.0185) | Acc: (99.38%) (9032/9088)\n",
            "Epoch: 153 | Batch_idx: 80 |  Loss: (0.0186) | Acc: (99.39%) (10305/10368)\n",
            "Epoch: 153 | Batch_idx: 90 |  Loss: (0.0187) | Acc: (99.40%) (11578/11648)\n",
            "Epoch: 153 | Batch_idx: 100 |  Loss: (0.0185) | Acc: (99.39%) (12849/12928)\n",
            "Epoch: 153 | Batch_idx: 110 |  Loss: (0.0185) | Acc: (99.39%) (14122/14208)\n",
            "Epoch: 153 | Batch_idx: 120 |  Loss: (0.0178) | Acc: (99.43%) (15399/15488)\n",
            "Epoch: 153 | Batch_idx: 130 |  Loss: (0.0179) | Acc: (99.43%) (16673/16768)\n",
            "Epoch: 153 | Batch_idx: 140 |  Loss: (0.0176) | Acc: (99.44%) (17947/18048)\n",
            "Epoch: 153 | Batch_idx: 150 |  Loss: (0.0177) | Acc: (99.43%) (19218/19328)\n",
            "Epoch: 153 | Batch_idx: 160 |  Loss: (0.0176) | Acc: (99.44%) (20492/20608)\n",
            "Epoch: 153 | Batch_idx: 170 |  Loss: (0.0176) | Acc: (99.43%) (21763/21888)\n",
            "Epoch: 153 | Batch_idx: 180 |  Loss: (0.0176) | Acc: (99.42%) (23034/23168)\n",
            "Epoch: 153 | Batch_idx: 190 |  Loss: (0.0176) | Acc: (99.42%) (24305/24448)\n",
            "Epoch: 153 | Batch_idx: 200 |  Loss: (0.0177) | Acc: (99.41%) (25577/25728)\n",
            "Epoch: 153 | Batch_idx: 210 |  Loss: (0.0181) | Acc: (99.40%) (26847/27008)\n",
            "Epoch: 153 | Batch_idx: 220 |  Loss: (0.0179) | Acc: (99.41%) (28122/28288)\n",
            "Epoch: 153 | Batch_idx: 230 |  Loss: (0.0175) | Acc: (99.42%) (29397/29568)\n",
            "Epoch: 153 | Batch_idx: 240 |  Loss: (0.0177) | Acc: (99.41%) (30667/30848)\n",
            "Epoch: 153 | Batch_idx: 250 |  Loss: (0.0176) | Acc: (99.42%) (31941/32128)\n",
            "Epoch: 153 | Batch_idx: 260 |  Loss: (0.0175) | Acc: (99.42%) (33215/33408)\n",
            "Epoch: 153 | Batch_idx: 270 |  Loss: (0.0176) | Acc: (99.42%) (34487/34688)\n",
            "Epoch: 153 | Batch_idx: 280 |  Loss: (0.0175) | Acc: (99.42%) (35760/35968)\n",
            "Epoch: 153 | Batch_idx: 290 |  Loss: (0.0176) | Acc: (99.41%) (37030/37248)\n",
            "Epoch: 153 | Batch_idx: 300 |  Loss: (0.0177) | Acc: (99.41%) (38301/38528)\n",
            "Epoch: 153 | Batch_idx: 310 |  Loss: (0.0173) | Acc: (99.43%) (39580/39808)\n",
            "Epoch: 153 | Batch_idx: 320 |  Loss: (0.0170) | Acc: (99.44%) (40857/41088)\n",
            "Epoch: 153 | Batch_idx: 330 |  Loss: (0.0172) | Acc: (99.43%) (42128/42368)\n",
            "Epoch: 153 | Batch_idx: 340 |  Loss: (0.0172) | Acc: (99.44%) (43404/43648)\n",
            "Epoch: 153 | Batch_idx: 350 |  Loss: (0.0173) | Acc: (99.43%) (44671/44928)\n",
            "Epoch: 153 | Batch_idx: 360 |  Loss: (0.0172) | Acc: (99.43%) (45944/46208)\n",
            "Epoch: 153 | Batch_idx: 370 |  Loss: (0.0170) | Acc: (99.44%) (47222/47488)\n",
            "Epoch: 153 | Batch_idx: 380 |  Loss: (0.0171) | Acc: (99.43%) (48492/48768)\n",
            "Epoch: 153 | Batch_idx: 390 |  Loss: (0.0171) | Acc: (99.43%) (49715/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3703) | Acc: (92.03%) (9203/10000)\n",
            "Epoch: 154 | Batch_idx: 0 |  Loss: (0.0075) | Acc: (100.00%) (128/128)\n",
            "Epoch: 154 | Batch_idx: 10 |  Loss: (0.0162) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 154 | Batch_idx: 20 |  Loss: (0.0110) | Acc: (99.70%) (2680/2688)\n",
            "Epoch: 154 | Batch_idx: 30 |  Loss: (0.0170) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 154 | Batch_idx: 40 |  Loss: (0.0165) | Acc: (99.54%) (5224/5248)\n",
            "Epoch: 154 | Batch_idx: 50 |  Loss: (0.0178) | Acc: (99.45%) (6492/6528)\n",
            "Epoch: 154 | Batch_idx: 60 |  Loss: (0.0177) | Acc: (99.44%) (7764/7808)\n",
            "Epoch: 154 | Batch_idx: 70 |  Loss: (0.0165) | Acc: (99.48%) (9041/9088)\n",
            "Epoch: 154 | Batch_idx: 80 |  Loss: (0.0156) | Acc: (99.51%) (10317/10368)\n",
            "Epoch: 154 | Batch_idx: 90 |  Loss: (0.0157) | Acc: (99.49%) (11589/11648)\n",
            "Epoch: 154 | Batch_idx: 100 |  Loss: (0.0161) | Acc: (99.50%) (12863/12928)\n",
            "Epoch: 154 | Batch_idx: 110 |  Loss: (0.0160) | Acc: (99.49%) (14135/14208)\n",
            "Epoch: 154 | Batch_idx: 120 |  Loss: (0.0164) | Acc: (99.48%) (15407/15488)\n",
            "Epoch: 154 | Batch_idx: 130 |  Loss: (0.0172) | Acc: (99.46%) (16677/16768)\n",
            "Epoch: 154 | Batch_idx: 140 |  Loss: (0.0172) | Acc: (99.45%) (17948/18048)\n",
            "Epoch: 154 | Batch_idx: 150 |  Loss: (0.0177) | Acc: (99.44%) (19219/19328)\n",
            "Epoch: 154 | Batch_idx: 160 |  Loss: (0.0171) | Acc: (99.46%) (20496/20608)\n",
            "Epoch: 154 | Batch_idx: 170 |  Loss: (0.0171) | Acc: (99.46%) (21769/21888)\n",
            "Epoch: 154 | Batch_idx: 180 |  Loss: (0.0168) | Acc: (99.46%) (23044/23168)\n",
            "Epoch: 154 | Batch_idx: 190 |  Loss: (0.0168) | Acc: (99.47%) (24318/24448)\n",
            "Epoch: 154 | Batch_idx: 200 |  Loss: (0.0171) | Acc: (99.46%) (25590/25728)\n",
            "Epoch: 154 | Batch_idx: 210 |  Loss: (0.0174) | Acc: (99.45%) (26860/27008)\n",
            "Epoch: 154 | Batch_idx: 220 |  Loss: (0.0172) | Acc: (99.46%) (28136/28288)\n",
            "Epoch: 154 | Batch_idx: 230 |  Loss: (0.0170) | Acc: (99.47%) (29411/29568)\n",
            "Epoch: 154 | Batch_idx: 240 |  Loss: (0.0168) | Acc: (99.47%) (30686/30848)\n",
            "Epoch: 154 | Batch_idx: 250 |  Loss: (0.0167) | Acc: (99.48%) (31960/32128)\n",
            "Epoch: 154 | Batch_idx: 260 |  Loss: (0.0167) | Acc: (99.48%) (33234/33408)\n",
            "Epoch: 154 | Batch_idx: 270 |  Loss: (0.0166) | Acc: (99.48%) (34508/34688)\n",
            "Epoch: 154 | Batch_idx: 280 |  Loss: (0.0165) | Acc: (99.48%) (35782/35968)\n",
            "Epoch: 154 | Batch_idx: 290 |  Loss: (0.0163) | Acc: (99.49%) (37059/37248)\n",
            "Epoch: 154 | Batch_idx: 300 |  Loss: (0.0165) | Acc: (99.48%) (38329/38528)\n",
            "Epoch: 154 | Batch_idx: 310 |  Loss: (0.0164) | Acc: (99.48%) (39602/39808)\n",
            "Epoch: 154 | Batch_idx: 320 |  Loss: (0.0163) | Acc: (99.49%) (40877/41088)\n",
            "Epoch: 154 | Batch_idx: 330 |  Loss: (0.0163) | Acc: (99.48%) (42149/42368)\n",
            "Epoch: 154 | Batch_idx: 340 |  Loss: (0.0162) | Acc: (99.48%) (43419/43648)\n",
            "Epoch: 154 | Batch_idx: 350 |  Loss: (0.0161) | Acc: (99.48%) (44693/44928)\n",
            "Epoch: 154 | Batch_idx: 360 |  Loss: (0.0162) | Acc: (99.47%) (45964/46208)\n",
            "Epoch: 154 | Batch_idx: 370 |  Loss: (0.0162) | Acc: (99.47%) (47237/47488)\n",
            "Epoch: 154 | Batch_idx: 380 |  Loss: (0.0163) | Acc: (99.47%) (48509/48768)\n",
            "Epoch: 154 | Batch_idx: 390 |  Loss: (0.0161) | Acc: (99.47%) (49736/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3659) | Acc: (91.94%) (9194/10000)\n",
            "Epoch: 155 | Batch_idx: 0 |  Loss: (0.0025) | Acc: (100.00%) (128/128)\n",
            "Epoch: 155 | Batch_idx: 10 |  Loss: (0.0194) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 155 | Batch_idx: 20 |  Loss: (0.0239) | Acc: (99.29%) (2669/2688)\n",
            "Epoch: 155 | Batch_idx: 30 |  Loss: (0.0219) | Acc: (99.24%) (3938/3968)\n",
            "Epoch: 155 | Batch_idx: 40 |  Loss: (0.0210) | Acc: (99.24%) (5208/5248)\n",
            "Epoch: 155 | Batch_idx: 50 |  Loss: (0.0203) | Acc: (99.28%) (6481/6528)\n",
            "Epoch: 155 | Batch_idx: 60 |  Loss: (0.0203) | Acc: (99.30%) (7753/7808)\n",
            "Epoch: 155 | Batch_idx: 70 |  Loss: (0.0193) | Acc: (99.32%) (9026/9088)\n",
            "Epoch: 155 | Batch_idx: 80 |  Loss: (0.0182) | Acc: (99.35%) (10301/10368)\n",
            "Epoch: 155 | Batch_idx: 90 |  Loss: (0.0174) | Acc: (99.36%) (11574/11648)\n",
            "Epoch: 155 | Batch_idx: 100 |  Loss: (0.0176) | Acc: (99.34%) (12843/12928)\n",
            "Epoch: 155 | Batch_idx: 110 |  Loss: (0.0173) | Acc: (99.36%) (14117/14208)\n",
            "Epoch: 155 | Batch_idx: 120 |  Loss: (0.0181) | Acc: (99.33%) (15385/15488)\n",
            "Epoch: 155 | Batch_idx: 130 |  Loss: (0.0177) | Acc: (99.36%) (16660/16768)\n",
            "Epoch: 155 | Batch_idx: 140 |  Loss: (0.0171) | Acc: (99.37%) (17935/18048)\n",
            "Epoch: 155 | Batch_idx: 150 |  Loss: (0.0171) | Acc: (99.38%) (19208/19328)\n",
            "Epoch: 155 | Batch_idx: 160 |  Loss: (0.0175) | Acc: (99.35%) (20475/20608)\n",
            "Epoch: 155 | Batch_idx: 170 |  Loss: (0.0173) | Acc: (99.36%) (21747/21888)\n",
            "Epoch: 155 | Batch_idx: 180 |  Loss: (0.0178) | Acc: (99.34%) (23016/23168)\n",
            "Epoch: 155 | Batch_idx: 190 |  Loss: (0.0179) | Acc: (99.33%) (24284/24448)\n",
            "Epoch: 155 | Batch_idx: 200 |  Loss: (0.0183) | Acc: (99.33%) (25556/25728)\n",
            "Epoch: 155 | Batch_idx: 210 |  Loss: (0.0183) | Acc: (99.34%) (26829/27008)\n",
            "Epoch: 155 | Batch_idx: 220 |  Loss: (0.0180) | Acc: (99.35%) (28105/28288)\n",
            "Epoch: 155 | Batch_idx: 230 |  Loss: (0.0177) | Acc: (99.36%) (29380/29568)\n",
            "Epoch: 155 | Batch_idx: 240 |  Loss: (0.0176) | Acc: (99.38%) (30657/30848)\n",
            "Epoch: 155 | Batch_idx: 250 |  Loss: (0.0174) | Acc: (99.39%) (31932/32128)\n",
            "Epoch: 155 | Batch_idx: 260 |  Loss: (0.0173) | Acc: (99.40%) (33206/33408)\n",
            "Epoch: 155 | Batch_idx: 270 |  Loss: (0.0172) | Acc: (99.40%) (34481/34688)\n",
            "Epoch: 155 | Batch_idx: 280 |  Loss: (0.0171) | Acc: (99.40%) (35751/35968)\n",
            "Epoch: 155 | Batch_idx: 290 |  Loss: (0.0172) | Acc: (99.39%) (37022/37248)\n",
            "Epoch: 155 | Batch_idx: 300 |  Loss: (0.0176) | Acc: (99.38%) (38290/38528)\n",
            "Epoch: 155 | Batch_idx: 310 |  Loss: (0.0174) | Acc: (99.39%) (39566/39808)\n",
            "Epoch: 155 | Batch_idx: 320 |  Loss: (0.0175) | Acc: (99.39%) (40838/41088)\n",
            "Epoch: 155 | Batch_idx: 330 |  Loss: (0.0175) | Acc: (99.39%) (42110/42368)\n",
            "Epoch: 155 | Batch_idx: 340 |  Loss: (0.0178) | Acc: (99.38%) (43378/43648)\n",
            "Epoch: 155 | Batch_idx: 350 |  Loss: (0.0178) | Acc: (99.38%) (44651/44928)\n",
            "Epoch: 155 | Batch_idx: 360 |  Loss: (0.0178) | Acc: (99.39%) (45924/46208)\n",
            "Epoch: 155 | Batch_idx: 370 |  Loss: (0.0178) | Acc: (99.39%) (47196/47488)\n",
            "Epoch: 155 | Batch_idx: 380 |  Loss: (0.0177) | Acc: (99.39%) (48471/48768)\n",
            "Epoch: 155 | Batch_idx: 390 |  Loss: (0.0177) | Acc: (99.39%) (49696/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3662) | Acc: (92.02%) (9202/10000)\n",
            "Epoch: 156 | Batch_idx: 0 |  Loss: (0.0175) | Acc: (99.22%) (127/128)\n",
            "Epoch: 156 | Batch_idx: 10 |  Loss: (0.0222) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 156 | Batch_idx: 20 |  Loss: (0.0165) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 156 | Batch_idx: 30 |  Loss: (0.0163) | Acc: (99.34%) (3942/3968)\n",
            "Epoch: 156 | Batch_idx: 40 |  Loss: (0.0169) | Acc: (99.33%) (5213/5248)\n",
            "Epoch: 156 | Batch_idx: 50 |  Loss: (0.0162) | Acc: (99.36%) (6486/6528)\n",
            "Epoch: 156 | Batch_idx: 60 |  Loss: (0.0187) | Acc: (99.30%) (7753/7808)\n",
            "Epoch: 156 | Batch_idx: 70 |  Loss: (0.0180) | Acc: (99.33%) (9027/9088)\n",
            "Epoch: 156 | Batch_idx: 80 |  Loss: (0.0193) | Acc: (99.31%) (10296/10368)\n",
            "Epoch: 156 | Batch_idx: 90 |  Loss: (0.0195) | Acc: (99.30%) (11566/11648)\n",
            "Epoch: 156 | Batch_idx: 100 |  Loss: (0.0196) | Acc: (99.32%) (12840/12928)\n",
            "Epoch: 156 | Batch_idx: 110 |  Loss: (0.0192) | Acc: (99.32%) (14112/14208)\n",
            "Epoch: 156 | Batch_idx: 120 |  Loss: (0.0193) | Acc: (99.32%) (15383/15488)\n",
            "Epoch: 156 | Batch_idx: 130 |  Loss: (0.0192) | Acc: (99.31%) (16653/16768)\n",
            "Epoch: 156 | Batch_idx: 140 |  Loss: (0.0190) | Acc: (99.34%) (17928/18048)\n",
            "Epoch: 156 | Batch_idx: 150 |  Loss: (0.0191) | Acc: (99.34%) (19200/19328)\n",
            "Epoch: 156 | Batch_idx: 160 |  Loss: (0.0188) | Acc: (99.35%) (20474/20608)\n",
            "Epoch: 156 | Batch_idx: 170 |  Loss: (0.0187) | Acc: (99.37%) (21750/21888)\n",
            "Epoch: 156 | Batch_idx: 180 |  Loss: (0.0189) | Acc: (99.36%) (23020/23168)\n",
            "Epoch: 156 | Batch_idx: 190 |  Loss: (0.0200) | Acc: (99.33%) (24285/24448)\n",
            "Epoch: 156 | Batch_idx: 200 |  Loss: (0.0198) | Acc: (99.34%) (25558/25728)\n",
            "Epoch: 156 | Batch_idx: 210 |  Loss: (0.0194) | Acc: (99.36%) (26834/27008)\n",
            "Epoch: 156 | Batch_idx: 220 |  Loss: (0.0189) | Acc: (99.37%) (28110/28288)\n",
            "Epoch: 156 | Batch_idx: 230 |  Loss: (0.0186) | Acc: (99.38%) (29385/29568)\n",
            "Epoch: 156 | Batch_idx: 240 |  Loss: (0.0185) | Acc: (99.38%) (30657/30848)\n",
            "Epoch: 156 | Batch_idx: 250 |  Loss: (0.0183) | Acc: (99.38%) (31929/32128)\n",
            "Epoch: 156 | Batch_idx: 260 |  Loss: (0.0181) | Acc: (99.39%) (33205/33408)\n",
            "Epoch: 156 | Batch_idx: 270 |  Loss: (0.0184) | Acc: (99.38%) (34472/34688)\n",
            "Epoch: 156 | Batch_idx: 280 |  Loss: (0.0184) | Acc: (99.37%) (35742/35968)\n",
            "Epoch: 156 | Batch_idx: 290 |  Loss: (0.0182) | Acc: (99.37%) (37015/37248)\n",
            "Epoch: 156 | Batch_idx: 300 |  Loss: (0.0182) | Acc: (99.38%) (38289/38528)\n",
            "Epoch: 156 | Batch_idx: 310 |  Loss: (0.0184) | Acc: (99.37%) (39558/39808)\n",
            "Epoch: 156 | Batch_idx: 320 |  Loss: (0.0184) | Acc: (99.37%) (40829/41088)\n",
            "Epoch: 156 | Batch_idx: 330 |  Loss: (0.0186) | Acc: (99.37%) (42099/42368)\n",
            "Epoch: 156 | Batch_idx: 340 |  Loss: (0.0185) | Acc: (99.37%) (43371/43648)\n",
            "Epoch: 156 | Batch_idx: 350 |  Loss: (0.0183) | Acc: (99.37%) (44644/44928)\n",
            "Epoch: 156 | Batch_idx: 360 |  Loss: (0.0183) | Acc: (99.37%) (45916/46208)\n",
            "Epoch: 156 | Batch_idx: 370 |  Loss: (0.0180) | Acc: (99.37%) (47191/47488)\n",
            "Epoch: 156 | Batch_idx: 380 |  Loss: (0.0180) | Acc: (99.37%) (48463/48768)\n",
            "Epoch: 156 | Batch_idx: 390 |  Loss: (0.0181) | Acc: (99.37%) (49686/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3689) | Acc: (91.88%) (9188/10000)\n",
            "Epoch: 157 | Batch_idx: 0 |  Loss: (0.0291) | Acc: (99.22%) (127/128)\n",
            "Epoch: 157 | Batch_idx: 10 |  Loss: (0.0193) | Acc: (99.15%) (1396/1408)\n",
            "Epoch: 157 | Batch_idx: 20 |  Loss: (0.0174) | Acc: (99.26%) (2668/2688)\n",
            "Epoch: 157 | Batch_idx: 30 |  Loss: (0.0152) | Acc: (99.37%) (3943/3968)\n",
            "Epoch: 157 | Batch_idx: 40 |  Loss: (0.0164) | Acc: (99.35%) (5214/5248)\n",
            "Epoch: 157 | Batch_idx: 50 |  Loss: (0.0152) | Acc: (99.42%) (6490/6528)\n",
            "Epoch: 157 | Batch_idx: 60 |  Loss: (0.0169) | Acc: (99.39%) (7760/7808)\n",
            "Epoch: 157 | Batch_idx: 70 |  Loss: (0.0175) | Acc: (99.38%) (9032/9088)\n",
            "Epoch: 157 | Batch_idx: 80 |  Loss: (0.0167) | Acc: (99.44%) (10310/10368)\n",
            "Epoch: 157 | Batch_idx: 90 |  Loss: (0.0171) | Acc: (99.42%) (11581/11648)\n",
            "Epoch: 157 | Batch_idx: 100 |  Loss: (0.0172) | Acc: (99.42%) (12853/12928)\n",
            "Epoch: 157 | Batch_idx: 110 |  Loss: (0.0167) | Acc: (99.44%) (14129/14208)\n",
            "Epoch: 157 | Batch_idx: 120 |  Loss: (0.0168) | Acc: (99.43%) (15399/15488)\n",
            "Epoch: 157 | Batch_idx: 130 |  Loss: (0.0171) | Acc: (99.40%) (16668/16768)\n",
            "Epoch: 157 | Batch_idx: 140 |  Loss: (0.0169) | Acc: (99.40%) (17940/18048)\n",
            "Epoch: 157 | Batch_idx: 150 |  Loss: (0.0169) | Acc: (99.40%) (19212/19328)\n",
            "Epoch: 157 | Batch_idx: 160 |  Loss: (0.0166) | Acc: (99.42%) (20488/20608)\n",
            "Epoch: 157 | Batch_idx: 170 |  Loss: (0.0164) | Acc: (99.42%) (21762/21888)\n",
            "Epoch: 157 | Batch_idx: 180 |  Loss: (0.0165) | Acc: (99.43%) (23036/23168)\n",
            "Epoch: 157 | Batch_idx: 190 |  Loss: (0.0168) | Acc: (99.43%) (24308/24448)\n",
            "Epoch: 157 | Batch_idx: 200 |  Loss: (0.0167) | Acc: (99.43%) (25582/25728)\n",
            "Epoch: 157 | Batch_idx: 210 |  Loss: (0.0166) | Acc: (99.44%) (26858/27008)\n",
            "Epoch: 157 | Batch_idx: 220 |  Loss: (0.0166) | Acc: (99.44%) (28131/28288)\n",
            "Epoch: 157 | Batch_idx: 230 |  Loss: (0.0165) | Acc: (99.45%) (29405/29568)\n",
            "Epoch: 157 | Batch_idx: 240 |  Loss: (0.0167) | Acc: (99.44%) (30675/30848)\n",
            "Epoch: 157 | Batch_idx: 250 |  Loss: (0.0166) | Acc: (99.45%) (31950/32128)\n",
            "Epoch: 157 | Batch_idx: 260 |  Loss: (0.0165) | Acc: (99.45%) (33224/33408)\n",
            "Epoch: 157 | Batch_idx: 270 |  Loss: (0.0166) | Acc: (99.45%) (34496/34688)\n",
            "Epoch: 157 | Batch_idx: 280 |  Loss: (0.0167) | Acc: (99.44%) (35767/35968)\n",
            "Epoch: 157 | Batch_idx: 290 |  Loss: (0.0166) | Acc: (99.44%) (37040/37248)\n",
            "Epoch: 157 | Batch_idx: 300 |  Loss: (0.0173) | Acc: (99.42%) (38306/38528)\n",
            "Epoch: 157 | Batch_idx: 310 |  Loss: (0.0175) | Acc: (99.42%) (39577/39808)\n",
            "Epoch: 157 | Batch_idx: 320 |  Loss: (0.0172) | Acc: (99.43%) (40852/41088)\n",
            "Epoch: 157 | Batch_idx: 330 |  Loss: (0.0173) | Acc: (99.43%) (42126/42368)\n",
            "Epoch: 157 | Batch_idx: 340 |  Loss: (0.0174) | Acc: (99.43%) (43399/43648)\n",
            "Epoch: 157 | Batch_idx: 350 |  Loss: (0.0175) | Acc: (99.43%) (44670/44928)\n",
            "Epoch: 157 | Batch_idx: 360 |  Loss: (0.0174) | Acc: (99.43%) (45944/46208)\n",
            "Epoch: 157 | Batch_idx: 370 |  Loss: (0.0174) | Acc: (99.43%) (47219/47488)\n",
            "Epoch: 157 | Batch_idx: 380 |  Loss: (0.0172) | Acc: (99.44%) (48495/48768)\n",
            "Epoch: 157 | Batch_idx: 390 |  Loss: (0.0173) | Acc: (99.44%) (49722/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3641) | Acc: (91.92%) (9192/10000)\n",
            "Epoch: 158 | Batch_idx: 0 |  Loss: (0.0352) | Acc: (98.44%) (126/128)\n",
            "Epoch: 158 | Batch_idx: 10 |  Loss: (0.0140) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 158 | Batch_idx: 20 |  Loss: (0.0160) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 158 | Batch_idx: 30 |  Loss: (0.0156) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 158 | Batch_idx: 40 |  Loss: (0.0159) | Acc: (99.47%) (5220/5248)\n",
            "Epoch: 158 | Batch_idx: 50 |  Loss: (0.0154) | Acc: (99.46%) (6493/6528)\n",
            "Epoch: 158 | Batch_idx: 60 |  Loss: (0.0154) | Acc: (99.47%) (7767/7808)\n",
            "Epoch: 158 | Batch_idx: 70 |  Loss: (0.0152) | Acc: (99.50%) (9043/9088)\n",
            "Epoch: 158 | Batch_idx: 80 |  Loss: (0.0145) | Acc: (99.52%) (10318/10368)\n",
            "Epoch: 158 | Batch_idx: 90 |  Loss: (0.0146) | Acc: (99.50%) (11590/11648)\n",
            "Epoch: 158 | Batch_idx: 100 |  Loss: (0.0157) | Acc: (99.47%) (12859/12928)\n",
            "Epoch: 158 | Batch_idx: 110 |  Loss: (0.0160) | Acc: (99.44%) (14129/14208)\n",
            "Epoch: 158 | Batch_idx: 120 |  Loss: (0.0161) | Acc: (99.44%) (15401/15488)\n",
            "Epoch: 158 | Batch_idx: 130 |  Loss: (0.0160) | Acc: (99.45%) (16675/16768)\n",
            "Epoch: 158 | Batch_idx: 140 |  Loss: (0.0164) | Acc: (99.43%) (17945/18048)\n",
            "Epoch: 158 | Batch_idx: 150 |  Loss: (0.0160) | Acc: (99.45%) (19221/19328)\n",
            "Epoch: 158 | Batch_idx: 160 |  Loss: (0.0157) | Acc: (99.46%) (20496/20608)\n",
            "Epoch: 158 | Batch_idx: 170 |  Loss: (0.0152) | Acc: (99.48%) (21775/21888)\n",
            "Epoch: 158 | Batch_idx: 180 |  Loss: (0.0157) | Acc: (99.46%) (23044/23168)\n",
            "Epoch: 158 | Batch_idx: 190 |  Loss: (0.0154) | Acc: (99.48%) (24320/24448)\n",
            "Epoch: 158 | Batch_idx: 200 |  Loss: (0.0163) | Acc: (99.45%) (25586/25728)\n",
            "Epoch: 158 | Batch_idx: 210 |  Loss: (0.0161) | Acc: (99.45%) (26859/27008)\n",
            "Epoch: 158 | Batch_idx: 220 |  Loss: (0.0162) | Acc: (99.44%) (28131/28288)\n",
            "Epoch: 158 | Batch_idx: 230 |  Loss: (0.0164) | Acc: (99.44%) (29403/29568)\n",
            "Epoch: 158 | Batch_idx: 240 |  Loss: (0.0168) | Acc: (99.42%) (30670/30848)\n",
            "Epoch: 158 | Batch_idx: 250 |  Loss: (0.0166) | Acc: (99.43%) (31946/32128)\n",
            "Epoch: 158 | Batch_idx: 260 |  Loss: (0.0168) | Acc: (99.42%) (33214/33408)\n",
            "Epoch: 158 | Batch_idx: 270 |  Loss: (0.0167) | Acc: (99.42%) (34486/34688)\n",
            "Epoch: 158 | Batch_idx: 280 |  Loss: (0.0166) | Acc: (99.42%) (35760/35968)\n",
            "Epoch: 158 | Batch_idx: 290 |  Loss: (0.0165) | Acc: (99.43%) (37035/37248)\n",
            "Epoch: 158 | Batch_idx: 300 |  Loss: (0.0166) | Acc: (99.43%) (38307/38528)\n",
            "Epoch: 158 | Batch_idx: 310 |  Loss: (0.0166) | Acc: (99.43%) (39580/39808)\n",
            "Epoch: 158 | Batch_idx: 320 |  Loss: (0.0167) | Acc: (99.43%) (40852/41088)\n",
            "Epoch: 158 | Batch_idx: 330 |  Loss: (0.0166) | Acc: (99.43%) (42127/42368)\n",
            "Epoch: 158 | Batch_idx: 340 |  Loss: (0.0165) | Acc: (99.43%) (43401/43648)\n",
            "Epoch: 158 | Batch_idx: 350 |  Loss: (0.0164) | Acc: (99.44%) (44676/44928)\n",
            "Epoch: 158 | Batch_idx: 360 |  Loss: (0.0165) | Acc: (99.44%) (45949/46208)\n",
            "Epoch: 158 | Batch_idx: 370 |  Loss: (0.0166) | Acc: (99.43%) (47219/47488)\n",
            "Epoch: 158 | Batch_idx: 380 |  Loss: (0.0167) | Acc: (99.43%) (48490/48768)\n",
            "Epoch: 158 | Batch_idx: 390 |  Loss: (0.0168) | Acc: (99.43%) (49715/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3648) | Acc: (91.87%) (9187/10000)\n",
            "Epoch: 159 | Batch_idx: 0 |  Loss: (0.0101) | Acc: (100.00%) (128/128)\n",
            "Epoch: 159 | Batch_idx: 10 |  Loss: (0.0213) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 159 | Batch_idx: 20 |  Loss: (0.0178) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 159 | Batch_idx: 30 |  Loss: (0.0167) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 159 | Batch_idx: 40 |  Loss: (0.0154) | Acc: (99.54%) (5224/5248)\n",
            "Epoch: 159 | Batch_idx: 50 |  Loss: (0.0147) | Acc: (99.57%) (6500/6528)\n",
            "Epoch: 159 | Batch_idx: 60 |  Loss: (0.0163) | Acc: (99.54%) (7772/7808)\n",
            "Epoch: 159 | Batch_idx: 70 |  Loss: (0.0159) | Acc: (99.54%) (9046/9088)\n",
            "Epoch: 159 | Batch_idx: 80 |  Loss: (0.0148) | Acc: (99.57%) (10323/10368)\n",
            "Epoch: 159 | Batch_idx: 90 |  Loss: (0.0160) | Acc: (99.53%) (11593/11648)\n",
            "Epoch: 159 | Batch_idx: 100 |  Loss: (0.0161) | Acc: (99.51%) (12865/12928)\n",
            "Epoch: 159 | Batch_idx: 110 |  Loss: (0.0155) | Acc: (99.52%) (14140/14208)\n",
            "Epoch: 159 | Batch_idx: 120 |  Loss: (0.0155) | Acc: (99.50%) (15410/15488)\n",
            "Epoch: 159 | Batch_idx: 130 |  Loss: (0.0155) | Acc: (99.49%) (16683/16768)\n",
            "Epoch: 159 | Batch_idx: 140 |  Loss: (0.0150) | Acc: (99.51%) (17959/18048)\n",
            "Epoch: 159 | Batch_idx: 150 |  Loss: (0.0152) | Acc: (99.49%) (19229/19328)\n",
            "Epoch: 159 | Batch_idx: 160 |  Loss: (0.0154) | Acc: (99.48%) (20500/20608)\n",
            "Epoch: 159 | Batch_idx: 170 |  Loss: (0.0161) | Acc: (99.45%) (21768/21888)\n",
            "Epoch: 159 | Batch_idx: 180 |  Loss: (0.0160) | Acc: (99.46%) (23042/23168)\n",
            "Epoch: 159 | Batch_idx: 190 |  Loss: (0.0158) | Acc: (99.46%) (24315/24448)\n",
            "Epoch: 159 | Batch_idx: 200 |  Loss: (0.0158) | Acc: (99.45%) (25587/25728)\n",
            "Epoch: 159 | Batch_idx: 210 |  Loss: (0.0161) | Acc: (99.45%) (26859/27008)\n",
            "Epoch: 159 | Batch_idx: 220 |  Loss: (0.0160) | Acc: (99.45%) (28133/28288)\n",
            "Epoch: 159 | Batch_idx: 230 |  Loss: (0.0158) | Acc: (99.46%) (29409/29568)\n",
            "Epoch: 159 | Batch_idx: 240 |  Loss: (0.0158) | Acc: (99.47%) (30684/30848)\n",
            "Epoch: 159 | Batch_idx: 250 |  Loss: (0.0161) | Acc: (99.46%) (31956/32128)\n",
            "Epoch: 159 | Batch_idx: 260 |  Loss: (0.0163) | Acc: (99.46%) (33226/33408)\n",
            "Epoch: 159 | Batch_idx: 270 |  Loss: (0.0165) | Acc: (99.44%) (34495/34688)\n",
            "Epoch: 159 | Batch_idx: 280 |  Loss: (0.0164) | Acc: (99.45%) (35770/35968)\n",
            "Epoch: 159 | Batch_idx: 290 |  Loss: (0.0162) | Acc: (99.46%) (37045/37248)\n",
            "Epoch: 159 | Batch_idx: 300 |  Loss: (0.0160) | Acc: (99.46%) (38321/38528)\n",
            "Epoch: 159 | Batch_idx: 310 |  Loss: (0.0164) | Acc: (99.45%) (39589/39808)\n",
            "Epoch: 159 | Batch_idx: 320 |  Loss: (0.0165) | Acc: (99.45%) (40860/41088)\n",
            "Epoch: 159 | Batch_idx: 330 |  Loss: (0.0164) | Acc: (99.45%) (42135/42368)\n",
            "Epoch: 159 | Batch_idx: 340 |  Loss: (0.0165) | Acc: (99.45%) (43406/43648)\n",
            "Epoch: 159 | Batch_idx: 350 |  Loss: (0.0164) | Acc: (99.45%) (44681/44928)\n",
            "Epoch: 159 | Batch_idx: 360 |  Loss: (0.0163) | Acc: (99.45%) (45952/46208)\n",
            "Epoch: 159 | Batch_idx: 370 |  Loss: (0.0164) | Acc: (99.45%) (47225/47488)\n",
            "Epoch: 159 | Batch_idx: 380 |  Loss: (0.0164) | Acc: (99.45%) (48499/48768)\n",
            "Epoch: 159 | Batch_idx: 390 |  Loss: (0.0163) | Acc: (99.46%) (49728/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3649) | Acc: (91.95%) (9195/10000)\n",
            "Epoch: 160 | Batch_idx: 0 |  Loss: (0.0041) | Acc: (100.00%) (128/128)\n",
            "Epoch: 160 | Batch_idx: 10 |  Loss: (0.0205) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 160 | Batch_idx: 20 |  Loss: (0.0200) | Acc: (99.29%) (2669/2688)\n",
            "Epoch: 160 | Batch_idx: 30 |  Loss: (0.0191) | Acc: (99.34%) (3942/3968)\n",
            "Epoch: 160 | Batch_idx: 40 |  Loss: (0.0189) | Acc: (99.37%) (5215/5248)\n",
            "Epoch: 160 | Batch_idx: 50 |  Loss: (0.0180) | Acc: (99.42%) (6490/6528)\n",
            "Epoch: 160 | Batch_idx: 60 |  Loss: (0.0172) | Acc: (99.42%) (7763/7808)\n",
            "Epoch: 160 | Batch_idx: 70 |  Loss: (0.0165) | Acc: (99.46%) (9039/9088)\n",
            "Epoch: 160 | Batch_idx: 80 |  Loss: (0.0168) | Acc: (99.44%) (10310/10368)\n",
            "Epoch: 160 | Batch_idx: 90 |  Loss: (0.0172) | Acc: (99.43%) (11582/11648)\n",
            "Epoch: 160 | Batch_idx: 100 |  Loss: (0.0164) | Acc: (99.46%) (12858/12928)\n",
            "Epoch: 160 | Batch_idx: 110 |  Loss: (0.0167) | Acc: (99.42%) (14126/14208)\n",
            "Epoch: 160 | Batch_idx: 120 |  Loss: (0.0162) | Acc: (99.44%) (15402/15488)\n",
            "Epoch: 160 | Batch_idx: 130 |  Loss: (0.0168) | Acc: (99.43%) (16673/16768)\n",
            "Epoch: 160 | Batch_idx: 140 |  Loss: (0.0170) | Acc: (99.43%) (17945/18048)\n",
            "Epoch: 160 | Batch_idx: 150 |  Loss: (0.0166) | Acc: (99.44%) (19220/19328)\n",
            "Epoch: 160 | Batch_idx: 160 |  Loss: (0.0170) | Acc: (99.43%) (20490/20608)\n",
            "Epoch: 160 | Batch_idx: 170 |  Loss: (0.0175) | Acc: (99.42%) (21761/21888)\n",
            "Epoch: 160 | Batch_idx: 180 |  Loss: (0.0174) | Acc: (99.43%) (23035/23168)\n",
            "Epoch: 160 | Batch_idx: 190 |  Loss: (0.0174) | Acc: (99.44%) (24310/24448)\n",
            "Epoch: 160 | Batch_idx: 200 |  Loss: (0.0176) | Acc: (99.43%) (25582/25728)\n",
            "Epoch: 160 | Batch_idx: 210 |  Loss: (0.0179) | Acc: (99.43%) (26853/27008)\n",
            "Epoch: 160 | Batch_idx: 220 |  Loss: (0.0177) | Acc: (99.42%) (28125/28288)\n",
            "Epoch: 160 | Batch_idx: 230 |  Loss: (0.0175) | Acc: (99.43%) (29399/29568)\n",
            "Epoch: 160 | Batch_idx: 240 |  Loss: (0.0172) | Acc: (99.44%) (30675/30848)\n",
            "Epoch: 160 | Batch_idx: 250 |  Loss: (0.0173) | Acc: (99.43%) (31944/32128)\n",
            "Epoch: 160 | Batch_idx: 260 |  Loss: (0.0172) | Acc: (99.43%) (33218/33408)\n",
            "Epoch: 160 | Batch_idx: 270 |  Loss: (0.0172) | Acc: (99.43%) (34492/34688)\n",
            "Epoch: 160 | Batch_idx: 280 |  Loss: (0.0172) | Acc: (99.44%) (35767/35968)\n",
            "Epoch: 160 | Batch_idx: 290 |  Loss: (0.0168) | Acc: (99.46%) (37045/37248)\n",
            "Epoch: 160 | Batch_idx: 300 |  Loss: (0.0168) | Acc: (99.46%) (38319/38528)\n",
            "Epoch: 160 | Batch_idx: 310 |  Loss: (0.0166) | Acc: (99.46%) (39593/39808)\n",
            "Epoch: 160 | Batch_idx: 320 |  Loss: (0.0166) | Acc: (99.45%) (40864/41088)\n",
            "Epoch: 160 | Batch_idx: 330 |  Loss: (0.0167) | Acc: (99.45%) (42134/42368)\n",
            "Epoch: 160 | Batch_idx: 340 |  Loss: (0.0166) | Acc: (99.45%) (43409/43648)\n",
            "Epoch: 160 | Batch_idx: 350 |  Loss: (0.0165) | Acc: (99.45%) (44683/44928)\n",
            "Epoch: 160 | Batch_idx: 360 |  Loss: (0.0165) | Acc: (99.45%) (45955/46208)\n",
            "Epoch: 160 | Batch_idx: 370 |  Loss: (0.0166) | Acc: (99.45%) (47226/47488)\n",
            "Epoch: 160 | Batch_idx: 380 |  Loss: (0.0166) | Acc: (99.45%) (48498/48768)\n",
            "Epoch: 160 | Batch_idx: 390 |  Loss: (0.0167) | Acc: (99.44%) (49721/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3671) | Acc: (91.95%) (9195/10000)\n",
            "Epoch: 161 | Batch_idx: 0 |  Loss: (0.0178) | Acc: (99.22%) (127/128)\n",
            "Epoch: 161 | Batch_idx: 10 |  Loss: (0.0265) | Acc: (99.22%) (1397/1408)\n",
            "Epoch: 161 | Batch_idx: 20 |  Loss: (0.0214) | Acc: (99.33%) (2670/2688)\n",
            "Epoch: 161 | Batch_idx: 30 |  Loss: (0.0190) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 161 | Batch_idx: 40 |  Loss: (0.0178) | Acc: (99.43%) (5218/5248)\n",
            "Epoch: 161 | Batch_idx: 50 |  Loss: (0.0186) | Acc: (99.40%) (6489/6528)\n",
            "Epoch: 161 | Batch_idx: 60 |  Loss: (0.0185) | Acc: (99.37%) (7759/7808)\n",
            "Epoch: 161 | Batch_idx: 70 |  Loss: (0.0172) | Acc: (99.41%) (9034/9088)\n",
            "Epoch: 161 | Batch_idx: 80 |  Loss: (0.0168) | Acc: (99.41%) (10307/10368)\n",
            "Epoch: 161 | Batch_idx: 90 |  Loss: (0.0166) | Acc: (99.42%) (11581/11648)\n",
            "Epoch: 161 | Batch_idx: 100 |  Loss: (0.0169) | Acc: (99.42%) (12853/12928)\n",
            "Epoch: 161 | Batch_idx: 110 |  Loss: (0.0174) | Acc: (99.43%) (14127/14208)\n",
            "Epoch: 161 | Batch_idx: 120 |  Loss: (0.0177) | Acc: (99.43%) (15400/15488)\n",
            "Epoch: 161 | Batch_idx: 130 |  Loss: (0.0178) | Acc: (99.44%) (16674/16768)\n",
            "Epoch: 161 | Batch_idx: 140 |  Loss: (0.0178) | Acc: (99.42%) (17944/18048)\n",
            "Epoch: 161 | Batch_idx: 150 |  Loss: (0.0182) | Acc: (99.41%) (19213/19328)\n",
            "Epoch: 161 | Batch_idx: 160 |  Loss: (0.0180) | Acc: (99.41%) (20486/20608)\n",
            "Epoch: 161 | Batch_idx: 170 |  Loss: (0.0181) | Acc: (99.40%) (21756/21888)\n",
            "Epoch: 161 | Batch_idx: 180 |  Loss: (0.0180) | Acc: (99.39%) (23027/23168)\n",
            "Epoch: 161 | Batch_idx: 190 |  Loss: (0.0178) | Acc: (99.39%) (24298/24448)\n",
            "Epoch: 161 | Batch_idx: 200 |  Loss: (0.0178) | Acc: (99.38%) (25568/25728)\n",
            "Epoch: 161 | Batch_idx: 210 |  Loss: (0.0178) | Acc: (99.37%) (26838/27008)\n",
            "Epoch: 161 | Batch_idx: 220 |  Loss: (0.0180) | Acc: (99.36%) (28107/28288)\n",
            "Epoch: 161 | Batch_idx: 230 |  Loss: (0.0178) | Acc: (99.37%) (29381/29568)\n",
            "Epoch: 161 | Batch_idx: 240 |  Loss: (0.0175) | Acc: (99.37%) (30654/30848)\n",
            "Epoch: 161 | Batch_idx: 250 |  Loss: (0.0172) | Acc: (99.38%) (31930/32128)\n",
            "Epoch: 161 | Batch_idx: 260 |  Loss: (0.0170) | Acc: (99.40%) (33206/33408)\n",
            "Epoch: 161 | Batch_idx: 270 |  Loss: (0.0171) | Acc: (99.40%) (34479/34688)\n",
            "Epoch: 161 | Batch_idx: 280 |  Loss: (0.0173) | Acc: (99.39%) (35748/35968)\n",
            "Epoch: 161 | Batch_idx: 290 |  Loss: (0.0173) | Acc: (99.39%) (37019/37248)\n",
            "Epoch: 161 | Batch_idx: 300 |  Loss: (0.0172) | Acc: (99.40%) (38296/38528)\n",
            "Epoch: 161 | Batch_idx: 310 |  Loss: (0.0174) | Acc: (99.40%) (39569/39808)\n",
            "Epoch: 161 | Batch_idx: 320 |  Loss: (0.0174) | Acc: (99.40%) (40843/41088)\n",
            "Epoch: 161 | Batch_idx: 330 |  Loss: (0.0173) | Acc: (99.41%) (42117/42368)\n",
            "Epoch: 161 | Batch_idx: 340 |  Loss: (0.0175) | Acc: (99.39%) (43383/43648)\n",
            "Epoch: 161 | Batch_idx: 350 |  Loss: (0.0174) | Acc: (99.39%) (44656/44928)\n",
            "Epoch: 161 | Batch_idx: 360 |  Loss: (0.0172) | Acc: (99.40%) (45931/46208)\n",
            "Epoch: 161 | Batch_idx: 370 |  Loss: (0.0171) | Acc: (99.40%) (47205/47488)\n",
            "Epoch: 161 | Batch_idx: 380 |  Loss: (0.0169) | Acc: (99.41%) (48480/48768)\n",
            "Epoch: 161 | Batch_idx: 390 |  Loss: (0.0168) | Acc: (99.41%) (49705/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3631) | Acc: (91.97%) (9197/10000)\n",
            "Epoch: 162 | Batch_idx: 0 |  Loss: (0.0155) | Acc: (99.22%) (127/128)\n",
            "Epoch: 162 | Batch_idx: 10 |  Loss: (0.0178) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 162 | Batch_idx: 20 |  Loss: (0.0168) | Acc: (99.37%) (2671/2688)\n",
            "Epoch: 162 | Batch_idx: 30 |  Loss: (0.0194) | Acc: (99.34%) (3942/3968)\n",
            "Epoch: 162 | Batch_idx: 40 |  Loss: (0.0202) | Acc: (99.28%) (5210/5248)\n",
            "Epoch: 162 | Batch_idx: 50 |  Loss: (0.0199) | Acc: (99.31%) (6483/6528)\n",
            "Epoch: 162 | Batch_idx: 60 |  Loss: (0.0178) | Acc: (99.40%) (7761/7808)\n",
            "Epoch: 162 | Batch_idx: 70 |  Loss: (0.0163) | Acc: (99.46%) (9039/9088)\n",
            "Epoch: 162 | Batch_idx: 80 |  Loss: (0.0156) | Acc: (99.47%) (10313/10368)\n",
            "Epoch: 162 | Batch_idx: 90 |  Loss: (0.0157) | Acc: (99.47%) (11586/11648)\n",
            "Epoch: 162 | Batch_idx: 100 |  Loss: (0.0158) | Acc: (99.47%) (12860/12928)\n",
            "Epoch: 162 | Batch_idx: 110 |  Loss: (0.0158) | Acc: (99.49%) (14135/14208)\n",
            "Epoch: 162 | Batch_idx: 120 |  Loss: (0.0159) | Acc: (99.47%) (15406/15488)\n",
            "Epoch: 162 | Batch_idx: 130 |  Loss: (0.0154) | Acc: (99.49%) (16682/16768)\n",
            "Epoch: 162 | Batch_idx: 140 |  Loss: (0.0154) | Acc: (99.48%) (17955/18048)\n",
            "Epoch: 162 | Batch_idx: 150 |  Loss: (0.0154) | Acc: (99.49%) (19230/19328)\n",
            "Epoch: 162 | Batch_idx: 160 |  Loss: (0.0151) | Acc: (99.50%) (20504/20608)\n",
            "Epoch: 162 | Batch_idx: 170 |  Loss: (0.0155) | Acc: (99.49%) (21776/21888)\n",
            "Epoch: 162 | Batch_idx: 180 |  Loss: (0.0157) | Acc: (99.50%) (23052/23168)\n",
            "Epoch: 162 | Batch_idx: 190 |  Loss: (0.0155) | Acc: (99.50%) (24326/24448)\n",
            "Epoch: 162 | Batch_idx: 200 |  Loss: (0.0154) | Acc: (99.50%) (25599/25728)\n",
            "Epoch: 162 | Batch_idx: 210 |  Loss: (0.0153) | Acc: (99.50%) (26873/27008)\n",
            "Epoch: 162 | Batch_idx: 220 |  Loss: (0.0151) | Acc: (99.50%) (28146/28288)\n",
            "Epoch: 162 | Batch_idx: 230 |  Loss: (0.0150) | Acc: (99.50%) (29421/29568)\n",
            "Epoch: 162 | Batch_idx: 240 |  Loss: (0.0148) | Acc: (99.50%) (30695/30848)\n",
            "Epoch: 162 | Batch_idx: 250 |  Loss: (0.0147) | Acc: (99.51%) (31972/32128)\n",
            "Epoch: 162 | Batch_idx: 260 |  Loss: (0.0145) | Acc: (99.52%) (33248/33408)\n",
            "Epoch: 162 | Batch_idx: 270 |  Loss: (0.0145) | Acc: (99.53%) (34525/34688)\n",
            "Epoch: 162 | Batch_idx: 280 |  Loss: (0.0147) | Acc: (99.52%) (35797/35968)\n",
            "Epoch: 162 | Batch_idx: 290 |  Loss: (0.0145) | Acc: (99.53%) (37072/37248)\n",
            "Epoch: 162 | Batch_idx: 300 |  Loss: (0.0146) | Acc: (99.53%) (38346/38528)\n",
            "Epoch: 162 | Batch_idx: 310 |  Loss: (0.0146) | Acc: (99.52%) (39615/39808)\n",
            "Epoch: 162 | Batch_idx: 320 |  Loss: (0.0145) | Acc: (99.52%) (40890/41088)\n",
            "Epoch: 162 | Batch_idx: 330 |  Loss: (0.0148) | Acc: (99.51%) (42160/42368)\n",
            "Epoch: 162 | Batch_idx: 340 |  Loss: (0.0146) | Acc: (99.51%) (43436/43648)\n",
            "Epoch: 162 | Batch_idx: 350 |  Loss: (0.0146) | Acc: (99.52%) (44712/44928)\n",
            "Epoch: 162 | Batch_idx: 360 |  Loss: (0.0146) | Acc: (99.52%) (45988/46208)\n",
            "Epoch: 162 | Batch_idx: 370 |  Loss: (0.0147) | Acc: (99.52%) (47258/47488)\n",
            "Epoch: 162 | Batch_idx: 380 |  Loss: (0.0146) | Acc: (99.52%) (48534/48768)\n",
            "Epoch: 162 | Batch_idx: 390 |  Loss: (0.0144) | Acc: (99.53%) (49763/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3698) | Acc: (91.87%) (9187/10000)\n",
            "Epoch: 163 | Batch_idx: 0 |  Loss: (0.0112) | Acc: (99.22%) (127/128)\n",
            "Epoch: 163 | Batch_idx: 10 |  Loss: (0.0110) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 163 | Batch_idx: 20 |  Loss: (0.0127) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 163 | Batch_idx: 30 |  Loss: (0.0153) | Acc: (99.47%) (3947/3968)\n",
            "Epoch: 163 | Batch_idx: 40 |  Loss: (0.0169) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 163 | Batch_idx: 50 |  Loss: (0.0163) | Acc: (99.48%) (6494/6528)\n",
            "Epoch: 163 | Batch_idx: 60 |  Loss: (0.0163) | Acc: (99.44%) (7764/7808)\n",
            "Epoch: 163 | Batch_idx: 70 |  Loss: (0.0165) | Acc: (99.43%) (9036/9088)\n",
            "Epoch: 163 | Batch_idx: 80 |  Loss: (0.0157) | Acc: (99.46%) (10312/10368)\n",
            "Epoch: 163 | Batch_idx: 90 |  Loss: (0.0155) | Acc: (99.47%) (11586/11648)\n",
            "Epoch: 163 | Batch_idx: 100 |  Loss: (0.0161) | Acc: (99.46%) (12858/12928)\n",
            "Epoch: 163 | Batch_idx: 110 |  Loss: (0.0166) | Acc: (99.44%) (14128/14208)\n",
            "Epoch: 163 | Batch_idx: 120 |  Loss: (0.0167) | Acc: (99.42%) (15398/15488)\n",
            "Epoch: 163 | Batch_idx: 130 |  Loss: (0.0161) | Acc: (99.45%) (16676/16768)\n",
            "Epoch: 163 | Batch_idx: 140 |  Loss: (0.0157) | Acc: (99.47%) (17953/18048)\n",
            "Epoch: 163 | Batch_idx: 150 |  Loss: (0.0154) | Acc: (99.49%) (19229/19328)\n",
            "Epoch: 163 | Batch_idx: 160 |  Loss: (0.0158) | Acc: (99.49%) (20502/20608)\n",
            "Epoch: 163 | Batch_idx: 170 |  Loss: (0.0161) | Acc: (99.47%) (21772/21888)\n",
            "Epoch: 163 | Batch_idx: 180 |  Loss: (0.0165) | Acc: (99.46%) (23042/23168)\n",
            "Epoch: 163 | Batch_idx: 190 |  Loss: (0.0169) | Acc: (99.44%) (24312/24448)\n",
            "Epoch: 163 | Batch_idx: 200 |  Loss: (0.0168) | Acc: (99.45%) (25587/25728)\n",
            "Epoch: 163 | Batch_idx: 210 |  Loss: (0.0164) | Acc: (99.47%) (26865/27008)\n",
            "Epoch: 163 | Batch_idx: 220 |  Loss: (0.0162) | Acc: (99.47%) (28139/28288)\n",
            "Epoch: 163 | Batch_idx: 230 |  Loss: (0.0161) | Acc: (99.49%) (29416/29568)\n",
            "Epoch: 163 | Batch_idx: 240 |  Loss: (0.0161) | Acc: (99.48%) (30687/30848)\n",
            "Epoch: 163 | Batch_idx: 250 |  Loss: (0.0162) | Acc: (99.48%) (31960/32128)\n",
            "Epoch: 163 | Batch_idx: 260 |  Loss: (0.0160) | Acc: (99.49%) (33236/33408)\n",
            "Epoch: 163 | Batch_idx: 270 |  Loss: (0.0162) | Acc: (99.48%) (34508/34688)\n",
            "Epoch: 163 | Batch_idx: 280 |  Loss: (0.0160) | Acc: (99.49%) (35784/35968)\n",
            "Epoch: 163 | Batch_idx: 290 |  Loss: (0.0159) | Acc: (99.50%) (37060/37248)\n",
            "Epoch: 163 | Batch_idx: 300 |  Loss: (0.0158) | Acc: (99.50%) (38334/38528)\n",
            "Epoch: 163 | Batch_idx: 310 |  Loss: (0.0157) | Acc: (99.50%) (39608/39808)\n",
            "Epoch: 163 | Batch_idx: 320 |  Loss: (0.0155) | Acc: (99.50%) (40884/41088)\n",
            "Epoch: 163 | Batch_idx: 330 |  Loss: (0.0155) | Acc: (99.50%) (42157/42368)\n",
            "Epoch: 163 | Batch_idx: 340 |  Loss: (0.0157) | Acc: (99.49%) (43427/43648)\n",
            "Epoch: 163 | Batch_idx: 350 |  Loss: (0.0155) | Acc: (99.50%) (44703/44928)\n",
            "Epoch: 163 | Batch_idx: 360 |  Loss: (0.0153) | Acc: (99.50%) (45978/46208)\n",
            "Epoch: 163 | Batch_idx: 370 |  Loss: (0.0153) | Acc: (99.51%) (47253/47488)\n",
            "Epoch: 163 | Batch_idx: 380 |  Loss: (0.0152) | Acc: (99.51%) (48527/48768)\n",
            "Epoch: 163 | Batch_idx: 390 |  Loss: (0.0153) | Acc: (99.51%) (49754/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3663) | Acc: (91.96%) (9196/10000)\n",
            "Epoch: 164 | Batch_idx: 0 |  Loss: (0.0491) | Acc: (98.44%) (126/128)\n",
            "Epoch: 164 | Batch_idx: 10 |  Loss: (0.0280) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 164 | Batch_idx: 20 |  Loss: (0.0234) | Acc: (99.18%) (2666/2688)\n",
            "Epoch: 164 | Batch_idx: 30 |  Loss: (0.0204) | Acc: (99.24%) (3938/3968)\n",
            "Epoch: 164 | Batch_idx: 40 |  Loss: (0.0192) | Acc: (99.31%) (5212/5248)\n",
            "Epoch: 164 | Batch_idx: 50 |  Loss: (0.0191) | Acc: (99.33%) (6484/6528)\n",
            "Epoch: 164 | Batch_idx: 60 |  Loss: (0.0185) | Acc: (99.36%) (7758/7808)\n",
            "Epoch: 164 | Batch_idx: 70 |  Loss: (0.0182) | Acc: (99.37%) (9031/9088)\n",
            "Epoch: 164 | Batch_idx: 80 |  Loss: (0.0186) | Acc: (99.34%) (10300/10368)\n",
            "Epoch: 164 | Batch_idx: 90 |  Loss: (0.0179) | Acc: (99.37%) (11575/11648)\n",
            "Epoch: 164 | Batch_idx: 100 |  Loss: (0.0176) | Acc: (99.38%) (12848/12928)\n",
            "Epoch: 164 | Batch_idx: 110 |  Loss: (0.0173) | Acc: (99.39%) (14122/14208)\n",
            "Epoch: 164 | Batch_idx: 120 |  Loss: (0.0171) | Acc: (99.41%) (15396/15488)\n",
            "Epoch: 164 | Batch_idx: 130 |  Loss: (0.0165) | Acc: (99.42%) (16671/16768)\n",
            "Epoch: 164 | Batch_idx: 140 |  Loss: (0.0160) | Acc: (99.45%) (17948/18048)\n",
            "Epoch: 164 | Batch_idx: 150 |  Loss: (0.0159) | Acc: (99.46%) (19223/19328)\n",
            "Epoch: 164 | Batch_idx: 160 |  Loss: (0.0158) | Acc: (99.46%) (20496/20608)\n",
            "Epoch: 164 | Batch_idx: 170 |  Loss: (0.0162) | Acc: (99.44%) (21766/21888)\n",
            "Epoch: 164 | Batch_idx: 180 |  Loss: (0.0161) | Acc: (99.46%) (23042/23168)\n",
            "Epoch: 164 | Batch_idx: 190 |  Loss: (0.0165) | Acc: (99.45%) (24313/24448)\n",
            "Epoch: 164 | Batch_idx: 200 |  Loss: (0.0167) | Acc: (99.43%) (25581/25728)\n",
            "Epoch: 164 | Batch_idx: 210 |  Loss: (0.0166) | Acc: (99.44%) (26856/27008)\n",
            "Epoch: 164 | Batch_idx: 220 |  Loss: (0.0167) | Acc: (99.42%) (28125/28288)\n",
            "Epoch: 164 | Batch_idx: 230 |  Loss: (0.0167) | Acc: (99.43%) (29400/29568)\n",
            "Epoch: 164 | Batch_idx: 240 |  Loss: (0.0171) | Acc: (99.42%) (30670/30848)\n",
            "Epoch: 164 | Batch_idx: 250 |  Loss: (0.0171) | Acc: (99.42%) (31943/32128)\n",
            "Epoch: 164 | Batch_idx: 260 |  Loss: (0.0170) | Acc: (99.43%) (33219/33408)\n",
            "Epoch: 164 | Batch_idx: 270 |  Loss: (0.0170) | Acc: (99.43%) (34491/34688)\n",
            "Epoch: 164 | Batch_idx: 280 |  Loss: (0.0172) | Acc: (99.42%) (35761/35968)\n",
            "Epoch: 164 | Batch_idx: 290 |  Loss: (0.0171) | Acc: (99.43%) (37035/37248)\n",
            "Epoch: 164 | Batch_idx: 300 |  Loss: (0.0169) | Acc: (99.44%) (38311/38528)\n",
            "Epoch: 164 | Batch_idx: 310 |  Loss: (0.0168) | Acc: (99.43%) (39583/39808)\n",
            "Epoch: 164 | Batch_idx: 320 |  Loss: (0.0171) | Acc: (99.43%) (40853/41088)\n",
            "Epoch: 164 | Batch_idx: 330 |  Loss: (0.0172) | Acc: (99.42%) (42123/42368)\n",
            "Epoch: 164 | Batch_idx: 340 |  Loss: (0.0172) | Acc: (99.42%) (43394/43648)\n",
            "Epoch: 164 | Batch_idx: 350 |  Loss: (0.0172) | Acc: (99.42%) (44667/44928)\n",
            "Epoch: 164 | Batch_idx: 360 |  Loss: (0.0173) | Acc: (99.42%) (45940/46208)\n",
            "Epoch: 164 | Batch_idx: 370 |  Loss: (0.0175) | Acc: (99.42%) (47211/47488)\n",
            "Epoch: 164 | Batch_idx: 380 |  Loss: (0.0174) | Acc: (99.42%) (48486/48768)\n",
            "Epoch: 164 | Batch_idx: 390 |  Loss: (0.0175) | Acc: (99.42%) (49710/50000)\n",
            "=> saving checkpoint\n",
            "# TEST : Loss: (0.3685) | Acc: (91.93%) (9193/10000)\n",
            "0 hours 56 mins 37 secs for training\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import os\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'                # GPU Number \n",
        "start_time = time.time()\n",
        "batch_size = 128\n",
        "learning_rate = 0.1 #Changed the initial Learning rate\n",
        "root_dir = 'drive/app/cifar10/'\n",
        "default_directory = 'drive/app/torch/save_models'\n",
        "\n",
        "# Data Augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),               # Random Position Crop\n",
        "    transforms.RandomHorizontalFlip(),                  # right and left flip\n",
        "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
        "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
        "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
        "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
        "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
        "])\n",
        "\n",
        "# automatically download\n",
        "train_dataset = datasets.CIFAR10(root=root_dir,\n",
        "                                 train=True,\n",
        "                                 transform=transform_train,\n",
        "                                 download=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root=root_dir,\n",
        "                                train=False,\n",
        "                                transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,            # at Training Procedure, Data Shuffle = True\n",
        "                                           num_workers=4)           # CPU loader number\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,            # at Test Procedure, Data Shuffle = False\n",
        "                                          num_workers=4)            # CPU loader number\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.3),                                       ################### Added\n",
        "\t    \n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.3),                                       ################### Added\n",
        "\t    \n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.3), #################### Dropout value set to 0.3\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.3), #################### Dropout value set to 0.3\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "model = VGG()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), learning_rate,\n",
        "                                momentum=0.9,\n",
        "                                weight_decay=1e-4,\n",
        "                                nesterov=True)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "if torch.cuda.device_count() > 0:\n",
        "    print(\"USE\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model).cuda()\n",
        "    cudnn.benchmark = True\n",
        "else:\n",
        "    print(\"USE ONLY CPU!\")\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0 \n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
        "        else:\n",
        "            data, target = Variable(data), Variable(target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.data).cpu().sum()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Epoch: {} | Batch_idx: {} |  Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
        "                  .format(epoch, batch_idx, train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
        "        else:\n",
        "            data, target = Variable(data), Variable(target)\n",
        "\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, target)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.data).cpu().sum()\n",
        "    print('# TEST : Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
        "          .format(test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "\n",
        "\n",
        "def save_checkpoint(directory, state, filename='latest.tar.gz'):\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    model_filename = os.path.join(directory, filename)\n",
        "    torch.save(state, model_filename)\n",
        "    print(\"=> saving checkpoint\")\n",
        "\n",
        "def load_checkpoint(directory, filename='latest.tar.gz'):\n",
        "\n",
        "    model_filename = os.path.join(directory, filename)\n",
        "    if os.path.exists(model_filename):\n",
        "        print(\"=> loading checkpoint\")\n",
        "        state = torch.load(model_filename)\n",
        "        return state\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "start_epoch = 0\n",
        "\n",
        "for epoch in range(start_epoch, 165):#################### Changing epoch\n",
        "\n",
        "    if epoch < 80:\n",
        "        lr = learning_rate\n",
        "    elif epoch < 120:\n",
        "        lr = learning_rate * 0.1\n",
        "    else:\n",
        "        lr = learning_rate * 0.01\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    train(epoch)\n",
        "    save_checkpoint(default_directory, {\n",
        "        'epoch': epoch,\n",
        "        'model': model,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "    })\n",
        "    test()  \n",
        "\n",
        "now = time.gmtime(time.time() - start_time)\n",
        "print('{} hours {} mins {} secs for training'.format(now.tm_hour, now.tm_min, now.tm_sec))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "z3679FisFAmj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}